_getAnonBuiltins_getBuiltinExceptionNames&PyCode_TypeInstanceType Built-ins module. Information about built-ins of the running Python.

SystemExitClassTypebuiltin_all_names&Nuitka_Function_Type&PyMethod_Typecompiled_generatorany_fileisExceptionName&PyClass_Typebuiltin_warningsnew_kwcompiled_function<module Builtins>_getBuiltinNamescalledWithBuiltinArgumentNamesDecorator.<locals>.wrapperbuiltin_exception_namePy_TYPE( Py_None )&PyEllipsis_TypeNotImplementedTypePy_TYPE( Py_NotImplemented )&PyFunction_Type&PyCFunction_Type&Nuitka_Generator_Type&PyFile_TypeC:\msys64\mingw64\bin\python3.exegetBuiltinTypeNamesKeyboardInterruptGeneratorExit_getBuiltinExceptionNames.<locals>.isExceptionName Allow a function to be called with an "_arg" if a built-in name.

        This avoids using built-in names in Nuitka source, while enforcing
        a policy how to make them pretty.
    C:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\Builtins.py&PyInstance_Typeanon_namesanon_codesea1ea2eb1eb2C:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\Constants.pyconstant_builtin_types Determine if a value will be usable at compile time.

     Is a constant hashable

        That means a user of a reference to it, can use it for dicts and set
        keys. This is distinct from mutable, there is one types that is not
        mutable, and still not hashable: slices.
    <module Constants> Is a constant mutable

        That means a user of a reference to it, can modify it. Strings are
        a prime example of mutable, dictionaries are mutable.
     Module for constants in Nuitka.

This contains tools to compare, classify and test constants.
The above information should be included in a bug report.NuitkaErrorBaseNuitkaNodeError.__str__<module Errors> For enhanced bug reporting, these exceptions should be used.

They ideally should point out what it ought to take for reproducing the
issue when output.

nuitka.codegen.IndentationC:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\Errors.pyFinalizationhandleSyntaxError__constants.cgetobjectslto_modeseen_filenames Get the full list of modules imported, create code for all of them.

    mingw_modeadd_pathhelper_impl_code.binmakeSourceDirectory.manifestgdbpython_sysflag_no_site.cppfrozen_codemsvc_versiongdb_pathError, no previous build directory exists.Error, failed to locate module %r.nuitka_srcgetSourceDirectoryPathpython_sysflag_verboseTotal memory usage before running scons: {memory}:unstripped_modemodule_filenamesprepared_modulesc_filenametarget_filenametarget_dirhelper_decl_codeTreeDisplayorigin_prefix_filenamepython_sysflag_unicodeIncluded compiled module '%s'..objxml_root@%dexecuteMainpickSourceFilenamespython_sysflag_bytes_warningError, failed to locate package %r.import %s<module MainControl>dumpTreeXMLclean_pathpython_commandcollision_countsmodule_countoutput_filecollision_filenamesgetFilenameshash_suffixC:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\MainControl.py-ex=runold_python_pathpickSourceFilenames.<locals>.<lambda>suggested_python_version_strgetResultFullpathExpstatic_pythongetResultBasepathasBoolStrpython_sysflag_py3k_warningbinary_dataDidn't recurse to '%s', apparently not used.python_sysflag_division_warningtrace_modecreateNodeTreemodule_modenuitka_cache.osresult_namedisplayTreeSconsInterfacecallExecPythonrunScons.<locals>.asBoolStr# This file was generated by Nuitka and describes the types of the
# created shared library.

# At this time it lists only the imports made and can be used by the
# tools that bundle libraries, including Nuitka itself. For instance
# standalone mode usage of the created library will need it.

# In the future, this will also contain type information for values
# in the module, so IDEs will use this. Therfore please include it
# when you make software releases of the extension module that it
# describes.

%(imports)s

# This is not Python source even if it looks so. Make it clear for
# now. This was decided by PEP 484 designers.
__name__ = ...

target_arch.SError, no 'gdb' binary found in path.CodeGeneration.build__frozen.c Main program flow of Nuitka

        At this point, options will be parsed already, Nuitka will be executing
        in the desired version of Python with desired flags, and we just get
        to execute the task assigned.

        We might be asked to only re-compile generated C, dump only an XML
        representation of the internal node tree after optimization, etc.
    profile_mode.res.rc.distuninstalled_python__helpers.cpython_prefix--args-xclang_modepickSourceFilenames.<locals>.getFilenames__constants.binstandalone_dirdebug_modecompileTreemain.<locals>.<genexpr>data_files-ex=where This is the main actions of Nuitka.

This can do all the steps to translate one module to a target language using
the Python C/API, to compile it to either an executable or an extension
module, potentially with bytecode included and used library copied into
a distribution folder.

getStandaloneDirectoryPathgetTreeFilenameWithSuffix__import__('%s')

Nuitka is very syntax compatible with standard Python. It is currently running
with Python version '%s', you might want to specify more clearly with the use
of the precise Python interpreter binary and '-m nuitka', e.g. use this
'python%s -m nuitka' option, if that's not the one the program expects.
cache_modeexecuteModulewriteBinaryDatastandalone_mode__helpers.hcleanSourceDirectory Create a node tree.

    Turn that source code into a node tree structure. If recursion into
    imported modules is available, more trees will be available during
    optimization, or immediately through recursed directory paths.

    writeSourceCodeno_python_warningsutf8_modefull_compatpython_sysflag_utf8C:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\ModuleRegistry.py<module ModuleRegistry>_function_code_nameactive_module_normalizeModuleFilenameactive_modulesgetDoneModules.<locals>.<lambda>getDoneUserModules.<locals>.<lambda>getUncompiledNonTechnicalModules.<locals>.<lambda>new_root_modulesgetUncompiledTechnicalModules.<locals>.<lambda>getUncompiledModules.<locals>.<lambda>.cpython-%d.pyc This to keep track of used modules.

    There is a set of root modules, which are user specified, and must be
    processed. As they go, they add more modules to active modules list
    and move done modules out of it.

    That process can be restarted and modules will be fetched back from
    the existing set of modules.
uncompiled_modulesdone_modulesEnable vmprof based profiling of time spent. Defaults to off.--plugin-list--mingwFor an update of the dependency walker cache. Will result in much longer times
to create the distribution folder, but might be used in case the cache is suspect
to cause errors or known to need an update.
Tracing featuresrecurse_not_modulesMODULE/PACKAGEDo not recurse to that module, or if a package, to the whole package in any
case, overrides all other options. Can be given multiple times. Default
empty.--unstripped--no-strip--unstriped--include-moduleupdate_dependency_cachescons_pythonc_compiler_groupwarn_unusual_codeDisplay the final result of optimization in a GUI, then exit.Executing all self checks possible to find errors in Nuitka, do not use for
production. Defaults to off.ICON_PATH--keep-pythonpathfile_reference_mode--enhanced--standalone--portable--generate-c-onlyusage: %prog [--module] [--run] [options] main_module.pyrecurse_stdlibAlso descend into imported modules from standard library. This will increase
the compilation time by a lot. Defaults to off.list_plugins--show-progressEnable warnings for implicit exceptions detected at compile time.--msvcplugins_enabledinclude_packagesInclude a whole package. Give as a Python namespace, e.g. ``some_package.sub_package``
and Nuitka will then find it and include it and all the modules found below that
disk location in the binary or extension module it creates, and make it available
for import by the code. Default empty.--windows-iconWhen compiling for Windows, disable the console window. Defaults to off.--dump-xml--xmlEnable standalone mode in build. This allows you to transfer the created binary
to other machines without it relying on an existing Python installation. It
implies these option: "--recurse-all". You may also want to use
"--python-flag=no_site" to avoid the "site.py" module, which can save a lot
of code dependencies. Defaults to off.--force-dll-dependency-cache-update--code-gen-no-statement-linesexecute_groupoutput_dirDIRECTORYSpecify where intermediate and final output files should be put. The DIRECTORY
will be populated with C files, object files, etc.
Defaults to current directory.
Immediate execution after compilation--plugin-disablerecurse_extraRecurse into that directory, no matter if it's used by the given main program
in a visible form. Overrides all other recursion options. Can be given multiple
times. Default empty.bad--clang--assume-yes-for-downloads--windows-disable-console--iconProvide memory information and statistics.
Defaults to off. Return the names of plugin that were enabled.

    norandomizationPython flags to use. Default uses what you are using to run Nuitka, this
enforces a specific mode. These are options that also exist to standard
Python executable. Currently supported: "-S" (alias "nosite"),
"static_hashes" (not use hash randomization), "no_warnings" (do not give
Python runtime warnings), "-O" (alias "noasserts"). Default empty.Create an extension module executable instead of a program. Defaults to off.jobs--disable-pluginplugin_enabledProvide progress information and statistics.
Defaults to off.--show-memory--recurse-noneUse features declared as 'experimental'. May have no effect if no experimental
features are present in the code. Uses secret tags (check source) per
experimented feature.plugins_disabledIf using Python3.3 or Python3.4, provide the path of a Python binary to use
for Scons. Otherwise Nuitka can use what you run Nuitka with or a "scons"
binary that is found in PATH, or a Python installation from Windows registry.--debugdisplay_treeno_randomizationtrace_importrecurse_extra_filesPATTERNRecurse into files matching the PATTERN. Overrides all recursion other options.
Can be given multiple times. Default empty.--remove-outputrecurse_modulesRecurse to that module, or if a package, to the whole package. Can be given
multiple times. Default empty.--executeShow list of all available plugins and exit. Defaults to off.--python-dbg--python-arch--ltoinclude_groupWhen --recurse-none is used, do not descend into any imported modules at all,
overrides all other recursion options. Defaults to off.Removes the build directory after producing the module or exe file.
Defaults to off.Enabled plugins. Must be plug-in names. Use --plugin-list to query the
full list and exit. Default empty.--profile--python-for-scons--warn-unusual-codeInclude a single module. Give as a Python namespace, e.g. ``some_package.some_module``
and Nuitka will then find it and include it in the binary or extension module
it creates, and make it available for import by the code. Default empty.trace_executionTraced execution output, output the line of code before executing it.
Defaults to off.Error, conflicting options, cannot make standalone module, only executable.--gdb--recurse-pattern--recurse-filesWindows specific output controlshallOptimizeStringExecno_case_modulepython_sconsindicationrecompile_c_onlyTake existing files and compile them again. Allows compiling edited C files
with the C compiler for quick debugging changes to the generated source.
Defaults to off. Depends on compiling Python source to determine which files it
should look at.codegen_groupallow_reexecuteExecute inside "gdb" to automatically get a stack trace.
Defaults to off.Provide a final summary on included modules.
Defaults to off.Control the inclusion of modules and packages.C:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\Options.pyusage: %prog [options] main_module.pyKeep debug info in the resulting object file for better debugger interaction.
Defaults to off.--show-modulesPlugins can detect if they might be used, and the you can disable the warning
via --plugin-disable=plugin-that-warned, or you can use this option to disable
the mechanism entirely, which also speeds up compilation slightly of course as
this detection code is run in vain once you are certain of which plug-ins to
use. Defaults to off.show_inclusionobsolete_executable--show-scons--output-dir--python2-for-sconsdump_xmlDump the final result of optimization as XML, then exit.recurse_all--warn-implicit-exceptions--no-pyi-file--plugin-no-detectionDebug featuresis_standalone--execute-with-pythonpathCode generation choicesEnforce the use of clang (needs clang 3.2 or higher).
Defaults to off.--recurse-directory
    Error, need only one positional argument unless "--run" is specified to
    pass them to the compiled program execution.improved--graphUse link time optimizations if available and usable (g++ 4.6 and higher).
Defaults to off.recurse_groupEnforce the use of specific MSVC version on Windows. Allowed values
are e.g. 9.0, 9.0exp, specify an illegal value for a list of installed
compilers. Defaults to the most recent version.debug_group--improved--recurse-not-toStandalone mode on NetBSD is not functional, due to $ORIGIN linkage not being supported.assume_yes_for_downloadsdetect_missing_pluginsUse debug version or not. Default uses what you are using to run Nuitka, most
likely a non-debug version._splitShellPattern--python-debugremove_build--full-compat--recurse-to
    Error, need positional argument with python module or main program.generate_c_onlyGenerate only C source code, and do not compile it to binary or module. This
is for debugging and code coverage analysis that doesn't waste CPU. Defaults to
off.nowarningsAdd executable icon (Windows only). Options module windows_groupExecute immediately the created binary (or import the compiled module).
Defaults to %s.Enable warnings for unusual code detected at compile time.recurse_noneOutput details of actions taken, esp. in optimizations. Can become a lot.
Defaults to off.Enforce absolute compatibility with CPython. Do not even allow minor
deviations from CPython behavior, e.g. better tracebacks, which are
not really incompatible, but different. This is intended for tests
only and should not be necessary for normal use.--recurse-stdlibEnforce the use of MinGW on Windows.
Defaults to off.python_flags Return the options provided for a specific plugin.

    --plugin-enableplugin_groupno_dependency_cacheDisable the dependency walker cache. Will result in much longer times to create
the distribution folder, but might be used in case the cache is suspect to cause
errors.
--include-packagepython_arch--enable-plugin--explain-importsUnsupported flag '%s'.--experimental--display-tree--trace-executionkeep_pythonpathWhen immediately executing the created binary (--execute), don't reset
PYTHONPATH. When all modules are successfully included, you ought to not need
PYTHONPATH anymore.Error, no such Python2 binary '%s'.--python-versionControl the recursion into imported modulesBackend C compiler choiceoutputdir_group--recurse-onwarn_implicit_exceptions/\:explain_importsdump_groupstatement_lines--recurse-plugins--debugger Are experimental features to be enabled.Disabled plugins. Must be plug-in names. Use --plugin-list to query the
full list and exit. Default empty.Operate Scons in non-quiet mode, showing the executed commands.
Defaults to off.include_modulesSelect what value "__file__" is going to be. With "runtime" (default for
standalone binary mode and module mode), the created binaries and modules,
use the location of themselves to deduct the value of "__file__". Included
packages pretend to be in directories below that location. This allows you
to include data files in deployments. If you merely seek acceleration, it's
better for you to use the "original" value, where the source files location
will be used. With "frozen" a notation "<frozen module_name>" is used. For
compatibility reasons, the "__file__" value will always have ".py" suffix
independent of what it really is.Output choicesshow_memory--recompile-c-only--recompile-c++-onlyError, '--recurse-not-to' takes only module names, not directory path '%s'.--file-reference-choiceSpecify the allowed number of parallel C compiler jobs. Defaults to the
system CPU count.Error, '--recurse-to' takes only module names, not directory path '%s'.<module Options>shallListPluginsAllow Nuitka to download code if necessary, e.g. dependency walker on Windows.--must-not-re-executeWhen --recurse-all is used, attempt to descend into all imported modules.
Defaults to off.Do not create a ".pyi" file for extension modules created by Nuitka.
Defaults to off. Return the names of plugin that were disabled.

    Dump options for internal treeshow_progressimmediate_execution--disable-dll-dependency-cachePlugin controlCreate graph of optimization process. Defaults to off.tracing_group_python_flagsArchitecture of Python to use. One of "x86" or "x86_64".
Defaults to what you run Nuitka with (currently "%s").IFloorDivIBitOrITrueDivIRShiftBitXorIMod<module PythonOperators>idivmatchExceptionother_comparison_functionsBitAndvalue2value1IBitAndC:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\PythonOperators.pycatching classes that do not inherit from BaseException is not allowedIBitXorLShift Python operator tables

These are mostly used to resolve the operator in the module operator and to know the list
of operations allowed.

rich_comparison_functionsIDivILShiftISubpython_version_full_strGetModuleFileName Error message of the concrete Python in case an exec occurs in a
        function that takes a closure variable.
    WinPythonPy_ENABLE_SHARED\1, or\2Error, cannot switch to non-debug Python, not installed._getPythonVersionError, cannot switch to debug Python, not installed.getSupportedPythonVersionStr_d.dllsupported_python_versionssupported_python_versions_str'f'getRunningPythonDLLPath Python version specifics.

This abstracts the Python version decisions. This makes decisions based on
the numbers, and attempts to give them meaningful names. Where possible it
should attempt to make run time detections.

(.*),(.*)$
def f():
   exec ""
   def nested():
      return closureneedsDuplicateArgumentColOffsetGetModuleFileNameWisAtLeastSubVersionError, cannot detect expected error message.dll_pathsystem_pathNoneType objectGetSystemDirectoryGetSystemDirectoryW<module PythonVersions>C:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\PythonVersions.py{1,1.0}.pop()Anaconda<module SourceCodeReferences>SourceCodeReference.getLineNumberC:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\SourceCodeReferences.pySourceCodeReference.__lt__SourceCodeReferenceInternal_cloneSourceCodeReference._cloneSourceCodeReference.atColumnNumber<%s to %s:%s>SourceCodeReference.getFilenameSourceCodeReference.getAsStringSourceCodeReferenceInternal.__init__SourceCodeReferenceInternal.isInternalSourceCodeReference.isInternalSourceCodeReference.__eq__ Make a copy it itself.

        SourceCodeReference.fromFilenameAndLine Make a copy it itself but mark as internal code.

            Avoids useless copies, by returning an internal object again if
            it is already internal.
        SourceCodeReference.__init__ Make a reference to the same file, but different line.

            Avoids useless copies, by returning same object if the line is
            the same.
        SourceCodeReference.getColumnNumberSourceCodeReference.atInternalSourceCodeReference.__repr__ Source code reference record.

All the information to lookup line and file of a code location, together with
the future flags in use there.
SourceCodeReference.atLineNumberC:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\Tracing.py**********my_print Make sure we flush after every print.

    Not even the "-u" option does more than that and this is easy enough.
    <module Tracing> Outputs to the user.

Printing with intends or plain, mostly a compensation for the print strangeness.

We want to avoid "from __future__ import print_function" in every file out
there, which makes adding another debug print rather tedious. This should
cover all calls/uses of "print" we have to do, and the make it easy to simply
to "print for_debug" without much hassle (braces).

xml_tostringlxml.xmlfileC:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\TreeXML.pymore_sibsxml_writerpretty_print XML node tree handling

Means to create XML elements from Nuitka tree nodes and to convert the
XML tree to ASCII or output it.
xml_module<module TreeXML>num_kidsVariable.hasDefiniteWritesvariable '%s'Variable.getOwnerParameterVariable.__init__LocalsDictVariable.__repr__<TempVariable '%s' of '%s'>LocalVariable.isLocalVariableVariable.allocateTargetNumberVariable.getCodeNameparameter variable '%s'<ModuleVariable '%s' of '%s'>writersVariable.isModuleVariableVariable.removeTraceuserstemp variable '%s'C:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\Variables.pyhasWritesOutsideOfModuleVariable.__init__LocalVariable.__repr__shared_usersVariable.addVariableUserModuleVariable.getDescriptionTempVariable.__init__touched_variablesVariable.updateUsageStateVariable.isSharedTechnicallyVariable.getNameVariable.isTempVariable<LocalsDictVariable '%s' of '%s'>LocalVariable.__init__Variable.hasWritesOutsideOfVariable.getEntryPointParameterVariable.isParameterVariableVariable.isSharedAmongScopesLocalsDictVariable.isLocalsDictVariableshared_scopesVariable.addTraceModuleVariable.isModuleVariableVariable.getTypeShapes<%s '%s' of '%s'>ModuleVariable.__repr__TempVariable.getDescriptionParameterVariable.getDescription<module Variables>TempVariable.__repr__global variable '%s' Variables link the storage and use of a Python variable together.

Different kinds of variables represent different scopes and owners types,
and their links between each other, i.e. references as in closure or
module variable references.

TempVariable.isTempVariableModuleVariable.getModuleLocalsDictVariable.__init__Variable.getMatchingAssignTraceVariable.hasAccessesOutsideOf Nuitka version related stuff.

C:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\Version.pyNuitka V0.5.31
Copyright (C) 2018 Kay Hayen.Return first release in which this feature was recognized.

        This is a 5-tuple, of the same form as sys.version_info.
        _FeaturegetOptionalReleasemandatoryRelease<module __future__>optionalReleaseCO_FUTURE_WITH_STATEMENTRecord of phased-in incompatible language changes.

Each line is of the form:

    FeatureName = "_Feature(" OptionalRelease "," MandatoryRelease ","
                              CompilerFlag ")"

where, normally, OptionalRelease < MandatoryRelease, and both are 5-tuples
of the same form as sys.version_info:

    (PY_MAJOR_VERSION, # the 2 in 2.1.0a3; an int
     PY_MINOR_VERSION, # the 1; an int
     PY_MICRO_VERSION, # the 0; an int
     PY_RELEASE_LEVEL, # "alpha", "beta", "candidate" or "final"; string
     PY_RELEASE_SERIAL # the 3; an int
    )

OptionalRelease records the first release in which

    from __future__ import FeatureName

was accepted.

In the case of MandatoryReleases that have not yet occurred,
MandatoryRelease predicts the release in which the feature will become part
of the language.

Else MandatoryRelease records when the feature became part of the language;
in releases at or after that, modules no longer need

    from __future__ import FeatureName

to use the feature in question, but may continue to use such imports.

MandatoryRelease may also be None, meaning that a planned feature got
dropped.

Instances of class _Feature have two corresponding methods,
.getOptionalRelease() and .getMandatoryRelease().

CompilerFlag is the (bitfield) flag that should be passed in the fourth
argument to the builtin function compile() to enable the feature in
dynamically compiled code.  This flag is stored in the .compiler_flag
attribute on _Future instances.  These values must match the appropriate
#defines of CO_xxx flags in Include/compile.h.

No feature line is ever to be deleted from this file.
_Feature.__init___Feature.getMandatoryReleaseReturn release in which this feature will become mandatory.

        This is a 5-tuple, of the same form as sys.version_info, or, if
        the feature was dropped, is None.
        _Feature.__repr___Feature.getOptionalReleaseCO_NESTEDC:\msys64\mingw64\lib\python3.6\__future__.pyCO_GENERATOR_ALLOWEDNuitka:%(levelname)s:%(message)sNUITKA_NAMESPACESneeds_reexecpython_binaryNUITKA_PYTHONPATHC:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\__main__.pycurrent_versionintended_versionour_filenamepyc_filenameError, not allowed to re-execute, but that would be needed.<module __main__>-1The version '%s' is not currently supported. Expect problems.nuitka.utilsNUITKA_PTH_IMPORTEDError, cannot find Python %s binary in PATH (%s).
This is the main program of Nuitka, it checks the options and then translates
one or more modules to a C-ish source code using Python C/API in a "*.build"
directory and then compiles that to either an executable or an extension module
or package, that can contain all used modules too.
NUITKA_BINARY_NAME<module __past__>
Module like __future__ for things that are changed between Python2 and Python3.

These are here to provide compatible fall-backs. This is required to run the
same code easily with both CPython2 and CPython3. Sometimes, we do not care
about the actual types, or API, but would rather just check for something to
be a "in (str, unicode)" rather than making useless version checks.

total_ordering.<locals>.<lambda>C:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\__past__.pyC:\msys64\mingw64\lib\python3.6\_bootlocale.py<module _bootlocale>nl_langinfoA minimal subset of the locale module used at interpreter startup
(imported by the _io module), in order to reduce startup time.

Don't import directly from third-party code; use the `locale` module instead!
MAXMASKhxA set is a finite, iterable container.

    This class provides concrete generic implementations of all
    methods except for __contains__, __iter__ and __len__.

    To override the comparisons (presumably for speed, as the
    semantics are fixed), redefine __le__ and __ge__,
    then the other operations will automatically follow suit.
    Return the next item from the asynchronous generator.
        When exhausted, raise StopAsyncIteration.
        Remove an element. If not a member, raise a KeyError.AsyncGenerator.__anext__S.pop([index]) -> item -- remove and return item at index (default last).
           Raise IndexError if list is empty or index is out of range.
        Generator.__subclasshook__Set.__eq__Coroutine.sendS.extend(iterable) -- extend sequence by appending elements from the iterable_from_iterableD.popitem() -> (k, v), remove and return some (key, value) pair
           as a 2-tuple; but raise KeyError if D is empty.
        MutableSequence.reverseSet.isdisjointMutableMapping.__setitem__Hashable.__subclasshook__Send a value into the asynchronous generator.
        Return next yielded value or raise StopAsyncIteration.
        D.pop(k[,d]) -> v, remove specified key and return the corresponding value.
          If key is not found, d is returned if given, otherwise KeyError is raised.
        AsyncIteratorMutableSequence.popByteStringlist_reverseiterator D.update([E, ]**F) -> None.  Update D from mapping/iterable E and F.
            If E present and has a .keys() method, does:     for k in E: D[k] = E[k]
            If E present and lacks .keys() method, does:     for (k, v) in E: D[k] = v
            In either case, this is followed by: for k, v in F.items(): D[k] = v
        Add an element.Abstract Base Classes (ABCs) for collections, according to PEP 3119.

Unit tests are in test_collections.
MutableSet.__ior__Set.__and__A mutable set is a finite, iterable container.

    This class provides concrete generic implementations of all
    methods except for __contains__, __iter__, __len__,
    add(), and discard().

    To override the comparisons (presumably for speed, as the
    semantics are fixed), all you have to do is redefine __le__ and
    then the other operations will automatically follow suit.
    generator ignored GeneratorExitKeysView.__iter__MutableMapping.__delitem__Set._from_iterableItemsView.__iter__Generator.__next__Sized.__subclasshook__Set.__ge__dict_itemiteratorSet.__or__.<locals>.<genexpr>dict_itemsReturn the next item from the generator.
        When exhausted, raise StopIteration.
        Container.__subclasshook__Return the popped value.  Raise KeyError if empty.This is slow (creates N new iterators!) but effective.D.setdefault(k[,d]) -> D.get(k,d), also set D[k]=d if k not in DMappingView.__repr____aiter__ValuesView.__contains___coroIterable.__iter__S.clear() -> None -- remove all items from SValuesView.__iter__longrange_iteratorMutableSet.cleardescriptor 'update' of 'MutableMapping' object needs an argumentAsyncIterator.__aiter__C:\msys64\mingw64\lib\python3.6\_collections_abc.pyMapping.__eq__Set.__gt__Set.__xor__AsyncIterator.__anext__ItemsView._from_iterableMutableMapping.popCallableasynchronous generator ignored GeneratorExitMutableSequence.__setitem__athrowGenerator.closeMappingView.__len__Raise GeneratorExit inside coroutine.
        AsyncIterator.__subclasshook__Sequence.count.<locals>.<genexpr>update expected at most 1 arguments, got %dAsyncGenerator.acloseKeysView.__contains__MutableSequence.extendRaise an exception in the asynchronous generator.
        Return next yielded value or raise StopAsyncIteration.
        Raise an exception in the generator.
        Return next yielded value or raise StopIteration.
        All the operations on a read-only sequence.

    Concrete subclasses must override __new__ or __init__,
    __getitem__, and __len__.
    Mapping.valuesmappingproxyMutableSet.__isub__Raise GeneratorExit inside generator.
        S.reverse() -- reverse *IN PLACE*D.get(k[,d]) -> D[k] if k in D, else d.  d defaults to None.Callable.__subclasshook__Raise an exception in the coroutine.
        Return next yielded value or raise StopIteration.
        Mapping.__contains__Sequence.__reversed__Reversible.__reversed__dict_keyiteratorzip_iteratorMapping.keysMutableSet.__iand__Callable.__call__Mapping.__getitem__ìC                                                                                                                                        Sequence.__getitem__Awaitable.__subclasshook__MutableSequence.insertS.count(value) -> integer -- return number of occurrences of valueMutableSequence.__iadd__Û   z	Awaitablez	CoroutinezAsyncIterablezAsyncIteratorzAsyncGeneratorzHashablezIterablezIteratorz	Generatorz
ReversiblezSizedz	ContainerzCallablez
CollectionzSetz
MutableSetzMappingzMutableMappingzMappingViewzKeysViewz	ItemsViewz
ValuesViewzSequencezMutableSequencez
ByteStringSet._hashSend a value into the coroutine.
        Return next yielded value or raise StopIteration.
        MutableSequence.clearThis unifies bytes and bytearray.

    XXX Should add all their methods.
    Coroutine.throwSet.__rsub__Iterator.__next__MutableMapping.updateCoroutine.__subclasshook__MutableSequence.removeAsyncGenerator.asendSequence.indexConstruct an instance of the class from any iterable input.

        Must override this method if the class constructor signature
        does not accept an iterable for an input.
        D.clear() -> None.  Remove all items from D.Return True if two sets have a null intersection.Container.__contains__Compute the hash value of a set.

        Note that we don't define __hash__: not all sets are hashable.
        But if you define a hashable set type, its __hash__ should
        call this function.

        This must be compatible __eq__.

        All sets ought to compare equal if they contain the same
        elements, regardless of how they are implemented, and
        regardless of the order of the elements; so there's not much
        freedom for __eq__ or __hash__.  We match the algorithm used
        by the built-in frozenset type.
        Generator.sendIterable.__subclasshook__{0.__class__.__name__}({0._mapping!r})Set.__rsub__.<locals>.<genexpr><module _collections_abc>S.remove(value) -- remove first occurrence of value.
           Raise ValueError if the value is not present.
        Remove an element.  Do not raise an exception if absent.MutableSequence.__delitem__AsyncGenerator.athrowSequence.__iter__S.append(value) -- append value to the end of the sequenceSet.__and__.<locals>.<genexpr>S.index(value, [start, [stop]]) -> integer -- return first index of value.
           Raises ValueError if the value is not present.

           Supporting start and stop arguments is optional, but
           recommended.
        MutableMapping.popitemSequence.__contains__dict_valuesSet.__sub__.<locals>.<genexpr>Sized.__len__Generator.throwHashable.__hash__Send a value into the generator.
        Return next yielded value or raise StopIteration.
        MutableSet.addMutableSet.popdict_keysCollection.__subclasshook__Set.__lt__async_generatorSet.__le__MutableSet.removedict_valueiteratorMapping.itemsAsyncGenerator.__subclasshook__MappingView.__init__MutableMapping.setdefault_MutableMapping__markerMutableSequence.appendReversible.__subclasshook__Iterator.__iter__KeysView._from_iterableReturn the next item or raise StopAsyncIteration when exhausted.coroutine ignored GeneratorExitAsyncIterable.__subclasshook__Coroutine.closeMapping.getReturn the next item from the iterator. When exhausted, raise StopIterationAwaitable.__await__ItemsView.__contains__AsyncIterable.__aiter__S.insert(index, value) -- insert value before indexMutableSet.discardMutableMapping.clearMutableSet.__ixor__StandardError_socketobjectSocketTypeConnectionResetErrorConnectionAbortedErrorû)z
_functoolszreduce)z__builtin__zreduce)ztkinter.filedialogz
FileDialog)z
FileDialogz
FileDialog)ztkinter.filedialogzLoadFileDialog)z
FileDialogzLoadFileDialog)ztkinter.filedialogzSaveFileDialog)z
FileDialogzSaveFileDialog)ztkinter.simpledialogzSimpleDialog)zSimpleDialogzSimpleDialog)zxmlrpc.serverzServerHTMLDoc)zDocXMLRPCServerzServerHTMLDoc)zxmlrpc.serverzXMLRPCDocGenerator)zDocXMLRPCServerzXMLRPCDocGenerator)zxmlrpc.serverzDocXMLRPCRequestHandler)zDocXMLRPCServerzDocXMLRPCRequestHandler)zxmlrpc.serverzDocXMLRPCServer)zDocXMLRPCServerzDocXMLRPCServer)zxmlrpc.serverzDocCGIXMLRPCRequestHandler)zDocXMLRPCServerzDocCGIXMLRPCRequestHandler)zhttp.serverzSimpleHTTPRequestHandler)zSimpleHTTPServerzSimpleHTTPRequestHandler)zhttp.serverzCGIHTTPRequestHandler)zCGIHTTPServerzCGIHTTPRequestHandler)z_socketzsocket)zsocketz_socketobject0ûz__builtin__zbuiltinszcopy_regzcopyregzQueuezqueuezSocketServerzsocketserverzConfigParserzconfigparserzreprzreprlibztkFileDialogztkinter.filedialogztkSimpleDialogztkinter.simpledialogztkColorChooserztkinter.colorchooserztkCommonDialogztkinter.commondialogzDialogztkinter.dialogzTkdndztkinter.dndztkFontztkinter.fontztkMessageBoxztkinter.messageboxzScrolledTextztkinter.scrolledtextzTkconstantsztkinter.constantszTixztkinter.tixzttkztkinter.ttkzTkinterztkinterz
markupbasez_markupbasez_winregzwinregzthreadz_threadzdummy_threadz_dummy_threadzdbhashzdbm.bsdzdumbdbmzdbm.dumbzdbmzdbm.ndbmzgdbmzdbm.gnuz	xmlrpclibzxmlrpc.clientzSimpleXMLRPCServerzxmlrpc.serverzhttplibzhttp.clientzhtmlentitydefszhtml.entitiesz
HTMLParserzhtml.parserzCookiezhttp.cookiesz	cookielibzhttp.cookiejarzBaseHTTPServerzhttp.serverztest.test_supportztest.supportzcommandsz
subprocesszurlparsezurllib.parsezrobotparserzurllib.robotparserzurllib2zurllib.requestzanydbmzdbmz_abcollzcollections.abc0C:\msys64\mingw64\lib\python3.6\_compat_pickle.py_dbm_gdbmPermissionErrorWindowsError©/zArithmeticErrorzAssertionErrorzAttributeErrorzBaseExceptionzBufferErrorzBytesWarningzDeprecationWarningzEOFErrorzEnvironmentErrorz	ExceptionzFloatingPointErrorzFutureWarningzGeneratorExitzIOErrorzImportErrorzImportWarningzIndentationErrorz
IndexErrorzKeyErrorzKeyboardInterruptzLookupErrorzMemoryErrorz	NameErrorzNotImplementedErrorzOSErrorzOverflowErrorzPendingDeprecationWarningzReferenceErrorzRuntimeErrorzRuntimeWarningzStopIterationzSyntaxErrorzSyntaxWarningzSystemErrorz
SystemExitzTabErrorz	TypeErrorzUnboundLocalErrorzUnicodeDecodeErrorzUnicodeEncodeErrorzUnicodeErrorzUnicodeTranslateErrorzUnicodeWarningzUserWarningz
ValueErrorzWarningzZeroDivisionErrorNotADirectoryErrorexcnameModuleNotFoundErrorPYTHON3_IMPORTERROR_EXCEPTIONSBrokenPipeErrorChildProcessErrorConnectionErrorConnectionRefusedErrorFileExistsErrorFileNotFoundErrorInterruptedErrorIsADirectoryErrorProcessLookupErrorûzcPicklezpicklez_elementtreezxml.etree.ElementTreez
FileDialogztkinter.filedialogzSimpleDialogztkinter.simpledialogzDocXMLRPCServerzxmlrpc.serverzSimpleHTTPServerzhttp.serverzCGIHTTPServerzhttp.serverzUserDictzcollectionszUserListzcollectionsz
UserStringzcollectionszwhichdbzdbmzStringIOzioz	cStringIOzio0PYTHON2_EXCEPTIONSû)z__builtin__zxrange)zbuiltinszrange)z__builtin__zreduce)z	functoolszreduce)z__builtin__zintern)zsyszintern)z__builtin__zunichr)zbuiltinszchr)z__builtin__zunicode)zbuiltinszstr)z__builtin__zlong)zbuiltinszint)z	itertoolszizip)zbuiltinszzip)z	itertoolszimap)zbuiltinszmap)z	itertoolszifilter)zbuiltinszfilter)z	itertoolszifilterfalse)z	itertoolszfilterfalse)z	itertoolszizip_longest)z	itertoolszzip_longest)zUserDictzIterableUserDict)zcollectionszUserDict)zUserListzUserList)zcollectionszUserList)z
UserStringz
UserString)zcollectionsz
UserString)zwhichdbzwhichdb)zdbmzwhichdb)z_socketzfromfd)zsocketzfromfd)z_multiprocessingz
Connection)zmultiprocessing.connectionz
Connection)zmultiprocessing.processzProcess)zmultiprocessing.contextzProcess)zmultiprocessing.forkingzPopen)zmultiprocessing.popen_forkzPopen)zurllibzContentTooShortError)zurllib.errorzContentTooShortError)zurllibz
getproxies)zurllib.requestz
getproxies)zurllibzpathname2url)zurllib.requestzpathname2url)zurllibz
quote_plus)zurllib.parsez
quote_plus)zurllibzquote)zurllib.parsezquote)zurllibzunquote_plus)zurllib.parsezunquote_plus)zurllibzunquote)zurllib.parsezunquote)zurllibzurl2pathname)zurllib.requestzurl2pathname)zurllibz
urlcleanup)zurllib.requestz
urlcleanup)zurllibz	urlencode)zurllib.parsez	urlencode)zurllibzurlopen)zurllib.requestzurlopen)zurllibzurlretrieve)zurllib.requestzurlretrieve)zurllib2z	HTTPError)zurllib.errorz	HTTPError)zurllib2zURLError)zurllib.errorzURLError0<module _compat_pickle>PYTHON3_OSERROR_EXCEPTIONSMULTIPROCESSING_EXCEPTIONSSeeking is only supported on files open for readingC:\msys64\mingw64\lib\python3.6\_compression.pyBUFFER_SIZEInvalid value for whence: {}DecompressReader.tellBaseStream._check_can_readMode-checking helper functions.File not open for readingThe underlying file object does not support seekingrawblock_trailing_errorFile not open for writingDecompressReader.readintoBaseStream._check_can_writedecomp_factoryBaseStream._check_not_closeddecomp_argsInternal classes used by the gzip, lzma and bz2 modulesDecompressReader._rewindDecompressReader.closeDecompressReader.seekableDecompressReader.__init__DecompressReader.readableAdapts the decompressor API to a RawIOBase reader APIneeds_inputBaseStream._check_can_seek<module _compression>Release the dummy lock.LockType.__init___interruptDummy implementation of acquire().

        For blocking calls, self.locked_status is automatically set to
        True and returned appropriately based on value of
        ``waitflag``.  If it is non-blocking, then the value is
        actually checked and not set if it is already acquired.  This
        is all done so that threading.Condition's assert statements
        aren't triggered and throw a little fit.

        LockType.acquireDummy implementation of _thread.get_ident().

    Since this module should only be used when _threadmodule is not
    available, it is safe to assume that the current process is the
    only thread.  Thus a constant can be safely returned.
    Set _interrupt flag to True to have start_new_thread raise
    KeyboardInterrupt upon exiting.Class implementing dummy implementation of _thread.LockType.

    Compatibility is maintained by maintaining self.locked_status
    which is a boolean that stores the state of the lock.  Pickling of
    the lock, though, should not be done since if the _thread module is
    then used with an unpickled ``lock()`` from here problems could
    occur from this class not having atomic methods.

    interrupt_main3rd arg must be a dictsetting thread stack size not supportedDummy implementation of _thread.allocate_lock().LockType.__exit__Dummy implementation of _thread._set_sentinel().2nd arg must be a tupleLockType.releaseC:\msys64\mingw64\lib\python3.6\_dummy_thread.pyDrop-in replacement for the thread module.

Meant to be used as a brain-dead substitute so that threaded code does
not need to be rewritten for when the thread module is not present.

Suggested usage is::

    try:
        import _thread
    except ImportError:
        import _dummy_thread as _thread

Dummy implementation of _thread.exit().LockType.__repr__Dummy implementation of _thread.start_new_thread().

    Compatibility is maintained by making sure that ``args`` is a
    tuple and ``kwargs`` is a dictionary.  If an exception is raised
    and it is SystemExit (which can be done by _thread.exit()) it is
    caught and nothing is done; all other exceptions are printed out
    by using traceback.print_exc().

    If the executed function calls interrupt_main the KeyboardInterrupt will be
    raised when the function returns.

    LockType.lockedDummy implementation of _thread.stack_size().<%s %s.%s object at %s><module _dummy_thread>Shared OS X support functions.sdkCustomize compiler path and configuration variables.

    This customization is performed when the first
    extension module build is requested
    in distutils.sysconfig.customize_compiler).
    MACOSX_DEPLOYMENT_TARGETi386Remove original unmodified values for testingPY_CORE_CFLAGSPY_CPPFLAGS_config_varsDon't know machine value for archs=%r%s 2>/dev/null >'%s'compiler_sollvm-gcc_SYSTEM_VERSIONC:\msys64\mingw64\lib\python3.6\_osx_support.py_UNIVERSAL_CONFIG_VARSPower_MacintoshtoolnamePlease check your Xcode installationoldcccv_split_supports_universal_builds.<locals>.<genexpr>CXXintel_save_modified_valueCannot locate working compilerfat64/usr/bin/xcrun -find %sstripArchcc_argsstripSysrootsysrootCompiling with an SDK that doesn't seem to exist: %sReturns True if universal builds are supported on this systemBASECFLAGSecho 'int main{};' | '%s' -c -arch ppc -x c -o /dev/null /dev/null 2>/dev/null-isysroot\s+\S+(?:\s|$)macrelease_read_output<module _osx_support>Remove any unsupported archs from config vars/tmp/_osx_support.%sRemove all universal build arguments from config varscommandstring_remove_universal_flagscompiler_fixupFind appropriate C compiler for extension module buildsPY_CFLAGSPY_LDFLAGSAllow override of all archs with ARCHFLAGS env var_get_system_versionSave modified and original unmodified value of configuration var<key>ProductUserVisibleVersion</key>\s*<string>(.*?)</string>_INITPREmacosxRemove references to any SDKs not availablecflags_override_all_archsOutput from successful command execution or None_find_appropriate_compilermacver_COMPILER_CONFIG_VARS-arch\s+(\S+)ppc64-arch\s+ppc_OSX_SUPPORT_INITIAL_Find a build tool on current path or using xcrun-isysroot\s+(\S+)-arch\s+\w+\s_remove_unsupported_archs-isysroot [^ 	]*fat3Customize Python build configuration variables.

    Called internally from sysconfig with a mutable mapping
    containing name/value pairs parsed from the configured
    makefile used to build this interpreter.  Returns
    the mapping updated as needed to reflect the environment
    in which the interpreter is running; in the case of
    a Python from a binary installer, the installed
    environment may be very different from the build
    environment, i.e. different OS levels, different
    built tools, different available CPU architectures.

    This customization is performed whenever
    distutils.sysconfig.get_config_vars() is first
    called.  It may be used in environments where no
    compilers are present, i.e. when installing pure
    Python dists.  Customization of compiler paths
    and detection of unavailable archs is deferred
    until the first extension module build is
    requested (in distutils.sysconfig.customize_compiler).

    Currently called from distutils.sysconfig
    '%s' --versionFilter values for get_platform()_find_executable_check_for_unavailable_sdk_remove_original_values
    This function will strip '-isysroot PATH' and '-arch ARCH' from the
    compile flags if the user has specified one them in extra_compile_flags.

    This is needed because '-arch ARCH' adds another architecture to the
    build, without a way to remove an architecture. Furthermore GCC will
    barf if multiple '-isysroot' arguments are present.
    Return the OS X system version as a stringTries to find 'executable' in the directories listed in 'path'.

    A string listing directories separated by 'os.pathsep'; defaults to
    os.environ['PATH'].  Returns the complete filename or None if not found.
    _find_build_toolget_platform_osx.<locals>.<genexpr>-arch\s+ppc\w*\ssetcontextContext.logical_invertContext.copy_negateDecimal.__pow__Decimal.copy_negateContext.is_nan_is_specialNumerical underflow with result rounded to 0.

    This occurs and signals underflow if a result is inexact and the
    adjusted exponent of the result would be smaller (more negative) than
    the smallest value that can be handled by the implementation (the value
    Emin).  That is, the result is both inexact and subnormal.

    The result after an underflow will be a subnormal number rounded, if
    necessary, so that its exponent is not less than Etiny.  This may result
    in 0 with the sign of the intermediate result and an exponent of Etiny.

    In all cases, Inexact, Rounded, and Subnormal will also be raised.
    Decimal.adjustedJust returns 10, as this is Decimal, :)

        >>> ExtendedContext.radix()
        Decimal('10')
        ROUND_HALF_EVENDecimal.__bool__Decimal.__ge__Applies an 'and' operation between self and other's digits.remainder_near(0, 0)equality_opReturns the first operand after adding the second value its exp.

        >>> ExtendedContext.scaleb(Decimal('7.50'), Decimal('-2'))
        Decimal('0.0750')
        >>> ExtendedContext.scaleb(Decimal('7.50'), Decimal('0'))
        Decimal('7.50')
        >>> ExtendedContext.scaleb(Decimal('7.50'), Decimal('3'))
        Decimal('7.50E+3')
        >>> ExtendedContext.scaleb(1, 4)
        Decimal('1E+4')
        >>> ExtendedContext.scaleb(Decimal(1), 4)
        Decimal('1E+4')
        >>> ExtendedContext.scaleb(1, Decimal(4))
        Decimal('1E+4')
        to_eng_stringexplanationself_nanother_nanself_keyother_keyCompares self to other using abstract repr., ignoring sign.

        Like compare_total, but with operand's sign ignored and assumed to be 0.
        Returns a shifted copy of self, value-of-other times.Decimal.__floor__2.4.2Return string representation of the number in scientific notation.

        Captures all of the information in the underlying representation.
        yshiftDecimal.__lt__DecimalException.handleCannot convert %r to Decimallxcflags=[is_zeropow() 2nd argument cannot be negative when 3rd argument specifiedContext.__reduce__Decimal.canonical_Log10Memoizeformat_dict_ilogDivision by infinityConversionSyntax-SubnormalContext.to_eng_string_round_down_decimal_lshift_exactis_signedROUND_05UPFloat representation.Return True if self is negative; otherwise return False.quotientDecimal.__eq__Context.min_magReturn (a // b, a % b).

        >>> ExtendedContext.divmod(Decimal(8), Decimal(3))
        (Decimal('2'), Decimal('2'))
        >>> ExtendedContext.divmod(Decimal(8), Decimal(4))
        (Decimal('2'), Decimal('0'))
        >>> ExtendedContext.divmod(8, 4)
        (Decimal('2'), Decimal('0'))
        >>> ExtendedContext.divmod(Decimal(8), 4)
        (Decimal('2'), Decimal('0'))
        >>> ExtendedContext.divmod(8, Decimal(4))
        (Decimal('2'), Decimal('0'))
        Decimal.min_regard_flags-ZeroDecimal._compare_check_nans_log10_digits0 ** 0Return True if self is infinite; otherwise return False.Applies an 'xor' operation between self and other's digits.(+-)INF * 0Context.is_finite_PyHASH_10INV0 * (+-)INFReturns the base 10 logarithm of the operand.

        >>> c = ExtendedContext.copy()
        >>> c.Emin = -999
        >>> c.Emax = 999
        >>> c.log10(Decimal('0'))
        Decimal('-Infinity')
        >>> c.log10(Decimal('0.001'))
        Decimal('-3')
        >>> c.log10(Decimal('1.000'))
        Decimal('0')
        >>> c.log10(Decimal('2'))
        Decimal('0.301029996')
        >>> c.log10(Decimal('10'))
        Decimal('1')
        >>> c.log10(Decimal('70'))
        Decimal('1.84509804')
        >>> c.log10(Decimal('+Infinity'))
        Decimal('Infinity')
        >>> c.log10(0)
        Decimal('-Infinity')
        >>> c.log10(1)
        Decimal('0')
        Mshiftargument should be at least 1 in _roundlog_dlog_10log_tenpowerop1Quantize self so its exponent is the same as that of exp.

        Similar to self._rescale(exp._exp) but with error checking.
        cshiftleftdigits_OneReturns a copy with the sign set to 0. Context.ln%+dRound 5 downGiven an integer x and a nonnegative integer shift, return closest
    integer to x / 2**shift; use round-to-even in case of a tie.

    Converts a number to a string, using scientific notation.

        The operation is not affected by the context.
        Decimal.radix        # A numeric string consists of:
#    \s*
    (?P<sign>[-+])?              # an optional sign, followed by either...
    (
        (?=\d|\.\d)              # ...a number (with at least one digit)
        (?P<int>\d*)             # having a (possibly empty) integer part
        (\.(?P<frac>\d*))?       # followed by an optional fractional part
        (E(?P<exp>[-+]?\d+))?    # followed by an optional exponent, or...
    |
        Inf(inity)?              # ...an infinity, or...
    |
        (?P<signal>s)?           # ...an (optionally signaling)
        NaN                      # NaN
        (?P<diag>\d*)            # with (possibly empty) diagnostic info.
    )
#    \s*
    \Z
MIN_ETINY Returns the exponent of the magnitude of self's MSD.

        The result is the integer which is the exponent of the magnitude
        of the most significant digit of self (as though it were truncated
        to a single digit while maintaining the value of that digit and
        without limiting the resulting exponent).
        max_payload_lenReturns the larger value.

        Like max(self, other) except if one is not a number, returns
        NaN (and signals if one is sNaN).  Also rounds.
        Context.__setattr__Applies the logical operation 'or' between each operand's digits.

        The operands must be both logical numbers.

        >>> ExtendedContext.logical_or(Decimal('0'), Decimal('0'))
        Decimal('0')
        >>> ExtendedContext.logical_or(Decimal('0'), Decimal('1'))
        Decimal('1')
        >>> ExtendedContext.logical_or(Decimal('1'), Decimal('0'))
        Decimal('1')
        >>> ExtendedContext.logical_or(Decimal('1'), Decimal('1'))
        Decimal('1')
        >>> ExtendedContext.logical_or(Decimal('1100'), Decimal('1010'))
        Decimal('1110')
        >>> ExtendedContext.logical_or(Decimal('1110'), Decimal('10'))
        Decimal('1110')
        >>> ExtendedContext.logical_or(110, 1101)
        Decimal('1111')
        >>> ExtendedContext.logical_or(Decimal(110), 1101)
        Decimal('1111')
        >>> ExtendedContext.logical_or(110, Decimal(1101))
        Decimal('1111')
        Had to round, losing information.

    This occurs and signals inexact whenever the result of an operation is
    not exact (that is, it needed to be rounded and any discarded digits
    were non-zero), or if an overflow or underflow condition occurs.  The
    result in all cases is unchanged.

    The inexact signal may be tested (or trapped) to determine if a given
    operation (or sequence of operations) was inexact.
    Decimal.is_canonical_islogicalDecimal.to_eng_stringReturns the same Decimal object.

        As we do not have different encodings for the same number, the
        received object already is in its canonical form.
        Create a decimal instance directly, without any validation,
    normalization (e.g. removal of leading zeros) or argument
    conversion.

    This function is for *internal use only*.
    Return True if the operand is subnormal; otherwise return False.

        >>> c = ExtendedContext.copy()
        >>> c.Emin = -999
        >>> c.Emax = 999
        >>> c.is_subnormal(Decimal('2.50'))
        False
        >>> c.is_subnormal(Decimal('0.1E-999'))
        True
        >>> c.is_subnormal(Decimal('0.00'))
        False
        >>> c.is_subnormal(Decimal('-Inf'))
        False
        >>> c.is_subnormal(Decimal('NaN'))
        False
        >>> c.is_subnormal(1)
        False
        -INF + INF%s is not a valid signal dictrotdigReturns e ** a.

        >>> c = ExtendedContext.copy()
        >>> c.Emin = -999
        >>> c.Emax = 999
        >>> c.exp(Decimal('-Infinity'))
        Decimal('0')
        >>> c.exp(Decimal('-1'))
        Decimal('0.367879441')
        >>> c.exp(Decimal('0'))
        Decimal('1')
        >>> c.exp(Decimal('1'))
        Decimal('2.71828183')
        >>> c.exp(Decimal('0.693147181'))
        Decimal('2.00000000')
        >>> c.exp(Decimal('+Infinity'))
        Decimal('Infinity')
        >>> c.exp(10)
        Decimal('22026.4658')
        fracpart_pick_rounding_functionRepresents the number as an instance of Decimal.quotient too large in //, % or divmodsign digits exponent\A
(?:
   (?P<fill>.)?
   (?P<align>[<>=^])
)?
(?P<sign>[-+ ])?
(?P<alt>\#)?
(?P<zeropad>0)?
(?P<minimumwidth>(?!0)\d+)?
(?P<thousands_sep>,)?
(?:\.(?P<precision>0|(?!0)\d+))?
(?P<type>[eEfFgGn%])?
\Z
Returns the smallest representable number larger than itself.new_contextTrying to convert badly formed string.

    This occurs and signals invalid-operation if a string is being
    converted to a number and it does not conform to the numeric string
    syntax.  The result is [0,qNaN].
    liminfresultexpself_paddedReturn True if self is a qNaN or sNaN; otherwise return False.Decimal.copy_signcoefficientDecimal._fill_logical_Log10Memoize.getdigitsCannot convert infinity to integer%s must be in [%d, %d]. got %starget exponent out of bounds in quantizeDecimal.__mod__Decimal._round_half_downCannot hash a signaling NaN value.Cannot perform the division adequately.

    This occurs and signals invalid-operation if the integer result of a
    divide-integer or remainder operation had too many digits (would be
    longer than precision).  The result is [0,qNaN].
    Undefined result of division.

    This occurs and signals invalid-operation if division by zero was
    attempted (during a divide-integer, divide, or remainder operation), and
    the dividend is also zero.  The result is [0,qNaN].
    opb Returns the exponent of the magnitude of the operand's MSD.

        The result is the integer which is the exponent of the magnitude
        of the most significant digit of the operand (as though the
        operand were truncated to a single digit while maintaining the
        value of that digit and without limiting the resulting exponent).

        >>> ExtendedContext.logb(Decimal('250'))
        Decimal('2')
        >>> ExtendedContext.logb(Decimal('2.50'))
        Decimal('0')
        >>> ExtendedContext.logb(Decimal('0.03'))
        Decimal('-2')
        >>> ExtendedContext.logb(Decimal('0'))
        Decimal('-Infinity')
        >>> ExtendedContext.logb(1)
        Decimal('0')
        >>> ExtendedContext.logb(10)
        Decimal('1')
        >>> ExtendedContext.logb(100)
        Decimal('2')
        _dexp_PyHASH_NANdivmod(INF, INF)Decimal.__gt__multiply multiplies two operands.

        If either operand is a special value then the general rules apply.
        Otherwise, the operands are multiplied together
        ('long multiplication'), resulting in a number which may be as long as
        the sum of the lengths of the two operands.

        >>> ExtendedContext.multiply(Decimal('1.20'), Decimal('3'))
        Decimal('3.60')
        >>> ExtendedContext.multiply(Decimal('7'), Decimal('3'))
        Decimal('21')
        >>> ExtendedContext.multiply(Decimal('0.9'), Decimal('0.8'))
        Decimal('0.72')
        >>> ExtendedContext.multiply(Decimal('0.9'), Decimal('-0'))
        Decimal('-0.0')
        >>> ExtendedContext.multiply(Decimal('654321'), Decimal('654321'))
        Decimal('4.28135971E+11')
        >>> ExtendedContext.multiply(7, 7)
        Decimal('49')
        >>> ExtendedContext.multiply(Decimal(7), 7)
        Decimal('49')
        >>> ExtendedContext.multiply(7, Decimal(7))
        Decimal('49')
        _shallow_copyDecimal.logbCreates a new Decimal instance from a float but rounding using self
        as the context.

        >>> context = Context(prec=5, rounding=ROUND_DOWN)
        >>> context.create_decimal_from_float(3.1415926535897932)
        Decimal('3.1415')
        >>> context = Context(prec=5, traps=[Inexact])
        >>> context.create_decimal_from_float(3.1415926535897932)
        Traceback (most recent call last):
            ...
        decimal.Inexact: None

        Invalid tuple size in creation of Decimal from list or tuple.  The list or tuple should have exactly three elements.rotateDivides two numbers and returns the integer part of the result.

        >>> ExtendedContext.divide_int(Decimal('2'), Decimal('3'))
        Decimal('0')
        >>> ExtendedContext.divide_int(Decimal('10'), Decimal('3'))
        Decimal('3')
        >>> ExtendedContext.divide_int(Decimal('1'), Decimal('0.3'))
        Decimal('3')
        >>> ExtendedContext.divide_int(10, 3)
        Decimal('3')
        >>> ExtendedContext.divide_int(Decimal(10), 3)
        Decimal('3')
        >>> ExtendedContext.divide_int(10, Decimal(3))
        Decimal('3')
        Decimal.__reduce__+ZeroEnable stricter semantics for mixing floats and Decimals.

    If the signal is not trapped (default), mixing floats and Decimals is
    permitted in the Decimal() constructor, context.create_decimal() and
    all comparison operators. Both conversion and comparisons are exact.
    Any occurrence of a mixed operation is silently recorded by setting
    FloatOperation in the context flags.  Explicit conversions with
    Decimal.from_float() or context.create_decimal_from_float() do not
    set the flag.

    Otherwise (the signal is trapped), only equality comparisons and explicit
    conversions are silent. All other mixed operations raise FloatOperation.
    Decimal._fixDecimal.__rdivmod___convert_for_comparisonlimsupDecimal.__pos__Return self * other.

        (+-) INF * 0 (or its reverse) raise InvalidOperation.
        ROUND_HALF_DOWNDecimal.remainder_nearContext.create_decimalDecapitate the payload of a NaN to fit the contextNormalizes op1, op2 to have the same exp and length of coefficient.

    Done during addition.
    Returns the natural (base e) logarithm of the operand.

        >>> c = ExtendedContext.copy()
        >>> c.Emin = -999
        >>> c.Emax = 999
        >>> c.ln(Decimal('0'))
        Decimal('-Infinity')
        >>> c.ln(Decimal('1.000'))
        Decimal('0')
        >>> c.ln(Decimal('2.71828183'))
        Decimal('1.00000000')
        >>> c.ln(Decimal('10'))
        Decimal('2.30258509')
        >>> c.ln(Decimal('+Infinity'))
        Decimal('Infinity')
        >>> c.ln(1)
        Decimal('0')
        getcontextDecimal.copy_absContext.rotateContext._set_signal_dict50*$Numerical overflow.

    This occurs and signals overflow if the adjusted exponent of a result
    (from a conversion or from an operation that is not an attempt to divide
    by zero), after rounding, would be greater than the largest value that
    can be handled by the implementation (the value Emax).

    The result depends on the rounding mode:

    For round-half-up and round-half-even (and for round-half-down and
    round-up, if implemented), the result of the operation is [sign,inf],
    where sign is the sign of the intermediate result.  For round-down, the
    result is the largest finite number that can be represented in the
    current precision, with the sign of the intermediate result.  For
    round-ceiling, the result is the same as for round-down if the sign of
    the intermediate result is 1, or is [0,inf] otherwise.  For round-floor,
    the result is the same as for round-down if the sign of the intermediate
    result is 0, or is [1,inf] otherwise.  In all cases, Inexact and Rounded
    will also be raised.
    Given integers c, e and p with c > 0, compute an integer
    approximation to 10**p * log(c*10**e), with an absolute error of
    at most 1.  Assumes that c*10**e is not exactly 1.Division by 0.

    This occurs and signals division-by-zero if division of a finite number
    by zero was attempted (during a divide-integer or divide operation, or a
    power operation with negative right-hand operand), and the dividend was
    not zero.

    The result of the operation is [sign,inf], where sign is the exclusive
    or of the signs of the operands for divide, or is 1 for an odd power of
    -0, for power.
    log10 of a negative valueDecimal('%s')self // otherReturns the base 10 logarithm of self._applyDecimal.sqrtmin compares two values numerically and returns the minimum.

        If either operand is a NaN then the general rules apply.
        Otherwise, the operands are compared as though by the compare
        operation.  If they are numerically equal then the left-hand operand
        is chosen as the result.  Otherwise the minimum (closer to negative
        infinity) of the two operands is chosen as the result.

        >>> ExtendedContext.min(Decimal('3'), Decimal('2'))
        Decimal('2')
        >>> ExtendedContext.min(Decimal('-10'), Decimal('3'))
        Decimal('-10')
        >>> ExtendedContext.min(Decimal('1.0'), Decimal('1'))
        Decimal('1.0')
        >>> ExtendedContext.min(Decimal('7'), Decimal('NaN'))
        Decimal('7')
        >>> ExtendedContext.min(1, 2)
        Decimal('1')
        >>> ExtendedContext.min(Decimal(1), 2)
        Decimal('1')
        >>> ExtendedContext.min(1, Decimal(29))
        Decimal('1')
        val_n_raise_error_log10_exp_boundDecimal.as_tupleDecimal.is_normalIgnore all flags, if they are raisedInvalid format specifier: Rounds 5 up (away from 0)Context._set_integer_checkRounds down (not towards 0 if negative)Context.copy_signDecimal._round_downRounds to a nearby integer.

        If no rounding mode is specified, take the rounding mode from
        the context.  This method raises the Rounded and Inexact flags
        when appropriate.

        See also: to_integral_value, which does exactly the same as
        this method except that it doesn't raise Inexact or Rounded.
        Converts self to an int, truncating if necessary.d5Context.clear_flags%s must be a signal dictInvalidOperation.handleReturn True if self is a normal number; otherwise return False.Decimal.__complex__Decimal.is_subnormal_WorkRep.__repr__MockThreadingExplicit thousands separator conflicts with 'n' type in format specifier: ROUND_UPBase exception class.

    Used exceptions derive from this.
    If an exception derives from another exception besides this (such as
    Underflow (Inexact, Rounded, Subnormal) that indicates that it is only
    called if the others are present.  This isn't actually used for
    anything, though.

    handle  -- Called when context._raise_error is called and the
               trap_enabler is not set.  First argument is self, second is the
               context.  More arguments can be given, those being after
               the explanation in _raise_error (For example,
               context._raise_error(NewError, '(-x)!', self._sign) would
               call NewError().handle(context, self._sign).)

    To define a new exception, it should be sufficient to have it derive
    from DecimalException.
    Context.logical_xor
This is an implementation of decimal floating point arithmetic based on
the General Decimal Arithmetic Specification:

    http://speleotrove.com/decimal/decarith.html

and IEEE standard 854-1987:

    http://en.wikipedia.org/wiki/IEEE_854-1987

Decimal floating point has finite precision with arbitrarily large bounds.

The purpose of this module is to support arithmetic using familiar
"schoolhouse" rules and to avoid some of the tricky representation
issues associated with binary floating point.  The package is especially
useful for financial applications or for contexts where users have
expectations that are at odds with binary floating point (for instance,
in binary floating point, 1.00 % 0.1 gives 0.09999999999999995 instead
of 0.0; Decimal('1.00') % Decimal('0.1') returns the expected
Decimal('0.00')).

Here are some examples of using the decimal module:

>>> from decimal import *
>>> setcontext(ExtendedContext)
>>> Decimal(0)
Decimal('0')
>>> Decimal('1')
Decimal('1')
>>> Decimal('-.0123')
Decimal('-0.0123')
>>> Decimal(123456)
Decimal('123456')
>>> Decimal('123.45e12345678')
Decimal('1.2345E+12345680')
>>> Decimal('1.33') + Decimal('1.27')
Decimal('2.60')
>>> Decimal('12.34') + Decimal('3.87') - Decimal('18.41')
Decimal('-2.20')
>>> dig = Decimal(1)
>>> print(dig / Decimal(3))
0.333333333
>>> getcontext().prec = 18
>>> print(dig / Decimal(3))
0.333333333333333333
>>> print(dig.sqrt())
1
>>> print(Decimal(3).sqrt())
1.73205080756887729
>>> print(Decimal(3) ** 123)
4.85192780976896427E+58
>>> inf = Decimal(1) / Decimal(0)
>>> print(inf)
Infinity
>>> neginf = Decimal(-1) / Decimal(0)
>>> print(neginf)
-Infinity
>>> print(neginf + inf)
NaN
>>> print(neginf * inf)
-Infinity
>>> print(dig / 0)
Infinity
>>> getcontext().traps[DivisionByZero] = 1
>>> print(dig / 0)
Traceback (most recent call last):
  ...
  ...
  ...
decimal.DivisionByZero: x / 0
>>> c = Context()
>>> c.traps[InvalidOperation] = 0
>>> print(c.flags[InvalidOperation])
0
>>> c.divide(Decimal(0), Decimal(0))
Decimal('NaN')
>>> c.traps[InvalidOperation] = 1
>>> print(c.flags[InvalidOperation])
1
>>> c.flags[InvalidOperation] = 0
>>> print(c.flags[InvalidOperation])
0
>>> print(c.divide(Decimal(0), Decimal(0)))
Traceback (most recent call last):
  ...
  ...
  ...
decimal.InvalidOperation: 0 / 0
>>> print(c.flags[InvalidOperation])
1
>>> c.flags[InvalidOperation] = 0
>>> c.traps[InvalidOperation] = 0
>>> print(c.divide(Decimal(0), Decimal(0)))
NaN
>>> print(c.flags[InvalidOperation])
1
>>>
intpartDecimal._islogicalto_sci_string_insert_thousands_sepReturn True if the operand is negative; otherwise return False.

        >>> ExtendedContext.is_signed(Decimal('2.50'))
        False
        >>> ExtendedContext.is_signed(Decimal('-12'))
        True
        >>> ExtendedContext.is_signed(Decimal('-0'))
        True
        >>> ExtendedContext.is_signed(8)
        False
        >>> ExtendedContext.is_signed(-8)
        True
        Decimal.next_towardmoduloexp_hashnew_expsame_quantumContext._applyquantize result has too many digits for current contextDecimal._cmprotatedRounds away from 0.InvalidContext.handleis_negativeROUND_CEILINGReturns an indication of the class of self.

        The class is one of the following strings:
          sNaN
          NaN
          -Infinity
          -Normal
          -Subnormal
          -Zero
          +Zero
          +Subnormal
          +Normal
          +Infinity
        Round down unless digit prec-1 is 0 or 5.Decimal.compare_signal(+-)INF/(+-)INFother_is_nanDecimal.imagCompares the values numerically with their sign ignored.Cannot convert NaN to integerSecond argument to round should be integralsaved_contextDivisionUndefined.handle_rshift_nearestDecimal._rescaleDecimal.__ceil__Compares self to other using the abstract representations.

        This is not like the standard compare, which use their numerical
        value. Note that a total ordering is defined for all possible abstract
        representations.
        _round_half_upInvert all the digits in the operand.

        The operand must be a logical number.

        >>> ExtendedContext.logical_invert(Decimal('0'))
        Decimal('111111111')
        >>> ExtendedContext.logical_invert(Decimal('1'))
        Decimal('111111110')
        >>> ExtendedContext.logical_invert(Decimal('111111111'))
        Decimal('0')
        >>> ExtendedContext.logical_invert(Decimal('101010101'))
        Decimal('10101010')
        >>> ExtendedContext.logical_invert(1101)
        Decimal('111110010')
        _NegativeOnecannot convert NaN to integer ratiocomparison involving NaN_group_lengths
        Remainder nearest to 0-  abs(remainder-near) <= other/2
        ClampedSwaps self/other and returns __divmod__._NegativeInfinityReturns the absolute value of the operand.

        If the operand is negative, the result is the same as using the minus
        operation on the operand.  Otherwise, the result is the same as using
        the plus operation on the operand.

        >>> ExtendedContext.abs(Decimal('2.1'))
        Decimal('2.1')
        >>> ExtendedContext.abs(Decimal('-100'))
        Decimal('100')
        >>> ExtendedContext.abs(Decimal('101.5'))
        Decimal('101.5')
        >>> ExtendedContext.abs(Decimal('-101.5'))
        Decimal('101.5')
        >>> ExtendedContext.abs(-1)
        Decimal('1')
        Integer approximation to M*log(x/M), with absolute error boundable
    in terms only of x/M.

    Given positive integers x and M, return an integer approximation to
    M * log(x/M).  For L = 8 and 0.1 <= x/M <= 10 the difference
    between the approximation and the exact result is at most 22.  For
    L = 8 and 1.0 <= x/M <= 10.0 the difference is at most 15.  In
    both cases these are upper bounds on the error; it will usually be
    much smaller.Three argument version of __pow__Overflow.handleis_canonical requires a Decimal as an argument.isinf_power_exactReturns a copy of the operand with the sign inverted.

        >>> ExtendedContext.copy_negate(Decimal('101.5'))
        Decimal('-101.5')
        >>> ExtendedContext.copy_negate(Decimal('-101.5'))
        Decimal('101.5')
        >>> ExtendedContext.copy_negate(1)
        Decimal('-1')
        self_infDecimal.quantizeReturn the sum of the two operands.

        >>> ExtendedContext.add(Decimal('12'), Decimal('7.00'))
        Decimal('19.00')
        >>> ExtendedContext.add(Decimal('1E+2'), Decimal('1.01E+4'))
        Decimal('1.02E+4')
        >>> ExtendedContext.add(1, Decimal(2))
        Decimal('3')
        >>> ExtendedContext.add(Decimal(8), 5)
        Decimal('13')
        >>> ExtendedContext.add(5, 5)
        Decimal('10')
        Context.compareReturn True if the operand is a signaling NaN;
        otherwise return False.

        >>> ExtendedContext.is_snan(Decimal('2.50'))
        False
        >>> ExtendedContext.is_snan(Decimal('NaN'))
        False
        >>> ExtendedContext.is_snan(Decimal('sNaN'))
        True
        >>> ExtendedContext.is_snan(1)
        False
        Sets the rounding type.

        Sets the rounding type, and returns the current (previous)
        rounding type.  Often used like:

        context = context.copy()
        # so you don't change the calling context
        # if an error occurs in the middle.
        rounding = context._set_rounding(ROUND_UP)
        val = self.__sub__(other, context=context)
        context._set_rounding(rounding)

        This will make it round up for that operation.
        MAX_PRECCannot convert signaling NaN to float_exact_halfx ** y with x negative and y not an integer_WorkRep.__init__Decimal.is_nan_numbers_isintegerDecimal.next_plus_Log10Memoize.__init__Decimal.__abs__Given an unpadded, non-aligned numeric string 'body' and sign
    string 'sign', add padding and alignment conforming to the given
    format specifier dictionary 'spec' (as produced by
    parse_format_specifier).

    clampReturns self operand after adding the second value to its exp.INF % xThe argument to _log10_lb should be nonnegative.Unrecognised alignment fieldunrecognised format for groupingReturns a copy with the sign switched.

        Rounds, if it has reason.
        Convert a localeconv-style grouping into a (possibly infinite)
    iterable of integers representing group lengths.

    _rounding_modesSwaps self/other and returns __truediv__.Compute an approximation to exp(c*10**e), with p decimal places of
    precision.

    Returns integers d, f such that:

      10**(p-1) <= d <= 10**p, and
      (d-1)*10**f < exp(c*10**e) < (d+1)*10**f

    In other words, d*10**f is an approximation to exp(c*10**e) with p
    digits of precision, and with an error in d of at most 1.  This is
    almost, but not quite, the same as the error being < 1ulp: when d
    = 10**(p-1) the error could be up to 10 ulp.Returns Etiny (= Emin - prec + 1)Decimal._isnan_format_signRound a nonzero, nonspecial Decimal to a fixed number of
        significant figures, using the given rounding mode.

        Infinities, NaNs and zeros are returned unaltered.

        This operation is quiet: it raises no flags, and uses no
        information from the context.

        Decimal.ln_ignore_all_flagsFormat a number, given the following data:

    is_negative: true if the number is negative, else false
    intpart: string of digits that must appear before the decimal point
    fracpart: string of digits that must come after the point
    exp: exponent, as an integer
    spec: dictionary resulting from parsing the format specifier

    This function uses the information in spec to:
      insert separators (decimal separator and thousands separators)
      format the sign
      format the exponent
      add trailing '%' for the '%' type
      zero-pad if necessary
      fill and align if necessary
    dotplaceDecimal.compare_total_magReturns a copy of the operand with the sign set to 0.

        >>> ExtendedContext.copy_abs(Decimal('2.1'))
        Decimal('2.1')
        >>> ExtendedContext.copy_abs(Decimal('-100'))
        Decimal('100')
        >>> ExtendedContext.copy_abs(-1)
        Decimal('1')
        resultsignInvalid context.  Unknown rounding, for example.

    This occurs and signals invalid-operation if an invalid context was
    detected during an operation.  This can occur if contexts are not checked
    on creation and either the precision exceeds the capability of the
    underlying concrete representation or an unknown or unsupported rounding
    was specified.  These aspects of the context need only be checked when
    the values are required to be used.  The result is [0,qNaN].
    Decimal._isinfinityself_is_nanDecimal._round_half_even_ContextManager.__init__Context._ignore_flagsContext.is_normalNormalize- strip trailing 0s, change anything equal to 0 to 0e0Context.next_minusConvert other to Decimal.

    Verifies that it's ok to use in an implicit construction.
    If allow_float is true, allow conversion from float;  this
    is used in the comparison methods (__eq__ and friends).

    Decimal._round_half_uptrailing or leading whitespace and underscores are not permitted.new_selfcopy_decimal_Infinityfma231Rounds up (not away from 0 if negative.)Context.is_subnormalÛ$   zDecimalzContextzDecimalTuplezDefaultContextzBasicContextzExtendedContextzDecimalExceptionzClampedzInvalidOperationzDivisionByZerozInexactzRoundedz	SubnormalzOverflowz	UnderflowzFloatOperationzDivisionImpossiblezInvalidContextzConversionSyntaxzDivisionUndefinedz
ROUND_DOWNzROUND_HALF_UPzROUND_HALF_EVENzROUND_CEILINGzROUND_FLOORzROUND_UPzROUND_HALF_DOWNz
ROUND_05UPz
setcontextz
getcontextzlocalcontextzMAX_PRECzMAX_EMAXzMIN_EMINz	MIN_ETINYzHAVE_THREADS_iseven_condition_mapReturn True if the operand is a normal number;
        otherwise return False.

        >>> c = ExtendedContext.copy()
        >>> c.Emin = -999
        >>> c.Emax = 999
        >>> c.is_normal(Decimal('2.50'))
        True
        >>> c.is_normal(Decimal('0.1E-999'))
        False
        >>> c.is_normal(Decimal('0.00'))
        False
        >>> c.is_normal(Decimal('-Inf'))
        False
        >>> c.is_normal(Decimal('NaN'))
        False
        >>> c.is_normal(1)
        True
        Fill character conflicts with '0' in format specifier: Context.plusDecimal.max_magthis_functiontmp_lenContext.remainderother_paddedApplies an 'or' operation between self and other's digits._convert_otherself_adjustedDecimal.expDecimal.__copy__Context.__init__.<locals>.<genexpr>Context.compare_signalContext.to_sci_stringecharReturn True if self is a logical operand.

        For being logical, it must be a finite number with a sign of 0,
        an exponent of 0, and a coefficient whose digits must all be
        either 0 or 1.
        Floating point class for decimal arithmetic.Swaps self/other and returns __mod__.Decimal._check_nansReturn other - selfDecimal.__truediv__Invert all its digits.Represents the number as a triple tuple.

        To show the internals exactly as they are.
        _NaNDecimal._power_exact23025850929940456840179914546843642076011014886rounding_methodReturn True if the operand is canonical; otherwise return False.

        Currently, the encoding of a Decimal instance is always
        canonical, so this method returns True for any Decimal.

        >>> ExtendedContext.is_canonical(Decimal('2.50'))
        True
        56789Return (self // other, self % other), to context.prec precision.

        Assumes that neither self nor other is a NaN, that self is not
        infinite and that other is nonzero.
        Returns whether the number is not actually one.

        0 if a number
        1 if NaN
        2 if sNaN
        f_log_tenDivisionImpossible.handleCompare self to other.  Return a decimal value:

        a or b is a NaN ==> Decimal('NaN')
        a < b           ==> Decimal('-1')
        a == b          ==> Decimal('0')
        a > b           ==> Decimal('1')
        negativezeroIgnore the flags, if they are raisedContext._regard_flagstorottopadclear_trapsstr_cContext.normalize
        self % other
        Return the difference between the two operands.

        >>> ExtendedContext.subtract(Decimal('1.3'), Decimal('1.07'))
        Decimal('0.23')
        >>> ExtendedContext.subtract(Decimal('1.3'), Decimal('1.30'))
        Decimal('0.00')
        >>> ExtendedContext.subtract(Decimal('1.3'), Decimal('2.07'))
        Decimal('-0.77')
        >>> ExtendedContext.subtract(8, 5)
        Decimal('3')
        >>> ExtendedContext.subtract(Decimal(8), 5)
        Decimal('3')
        >>> ExtendedContext.subtract(8, Decimal(5))
        Decimal('3')
        Decimal.__floordiv__Decimal._round_ceiling_round_05upApplies the logical operation 'xor' between each operand's digits.

        The operands must be both logical numbers.

        >>> ExtendedContext.logical_xor(Decimal('0'), Decimal('0'))
        Decimal('0')
        >>> ExtendedContext.logical_xor(Decimal('0'), Decimal('1'))
        Decimal('1')
        >>> ExtendedContext.logical_xor(Decimal('1'), Decimal('0'))
        Decimal('1')
        >>> ExtendedContext.logical_xor(Decimal('1'), Decimal('1'))
        Decimal('0')
        >>> ExtendedContext.logical_xor(Decimal('1100'), Decimal('1010'))
        Decimal('110')
        >>> ExtendedContext.logical_xor(Decimal('1111'), Decimal('10'))
        Decimal('1101')
        >>> ExtendedContext.logical_xor(110, 1101)
        Decimal('1011')
        >>> ExtendedContext.logical_xor(Decimal(110), 1101)
        Decimal('1011')
        >>> ExtendedContext.logical_xor(110, Decimal(1101))
        Decimal('1011')
        _ignored_flagsDecimal.__format__Decimal.__rsub__ideal_expexpdiff_round_upCompute a lower bound for the adjusted exponent of self.log10().
        In other words, find r such that self.log10() >= 10**r.
        Assumes that self is finite and positive and that self != 1.
        Context.to_integral_valueCompares the values of the two operands numerically.

        It's pretty much like compare(), but all NaNs signal, with signaling
        NaNs taking precedence over quiet NaNs.

        >>> c = ExtendedContext
        >>> c.compare_signal(Decimal('2.1'), Decimal('3'))
        Decimal('-1')
        >>> c.compare_signal(Decimal('2.1'), Decimal('2.1'))
        Decimal('0')
        >>> c.flags[InvalidOperation] = 0
        >>> print(c.flags[InvalidOperation])
        0
        >>> c.compare_signal(Decimal('NaN'), Decimal('2.1'))
        Decimal('NaN')
        >>> print(c.flags[InvalidOperation])
        1
        >>> c.flags[InvalidOperation] = 0
        >>> print(c.flags[InvalidOperation])
        0
        >>> c.compare_signal(Decimal('sNaN'), Decimal('2.1'))
        Decimal('NaN')
        >>> print(c.flags[InvalidOperation])
        1
        >>> c.compare_signal(-1, 2)
        Decimal('-1')
        >>> c.compare_signal(Decimal(-1), 2)
        Decimal('-1')
        >>> c.compare_signal(-1, Decimal(2))
        Decimal('-1')
        fF%Decimal.rotate_format_alignReturns self with the sign of other.Format a Decimal instance according to the given specifier.

        The specifier should be a standard format specifier, with the
        form described in PEP 3101.  Formatting types 'e', 'E', 'f',
        'F', 'g', 'G', 'n' and '%' are supported.  If the formatting
        type is omitted it defaults to 'g' or 'G', depending on the
        value of context.capitals.
        Return True if self is finite; otherwise return False.

        A Decimal instance is considered finite if it is neither
        infinite nor a NaN.
        Decimal.__rmod__ConversionSyntax.handle_signalsDecimal.__neg__Both arguments to _sqrt_nearest should be positive.Express a finite Decimal instance in the form n / d.

        Returns a pair (n, d) of integers.  When called on an infinity
        or NaN, raises OverflowError or ValueError respectively.

        >>> Decimal('3.14').as_integer_ratio()
        (157, 50)
        >>> Decimal('-123e5').as_integer_ratio()
        (-12300000, 1)
        >>> Decimal('0.00').as_integer_ratio()
        (0, 1)

        Returns a copy, unless it is a sNaN.

        Rounds the number (if more than precision digits)
        Return the square root of self.'decimal.Context' object has no attribute '%s'Return the ceiling of self, as an integer.

        For a finite Decimal instance self, return the least integer n
        such that n >= self.  If self is infinite or a NaN then a
        Python exception is raised.

        Decimal.log10ìüÿÿÿÿÇNÎZoReturns True if the two operands have the same exponent.

        The result is never affected by either the sign or the coefficient of
        either operand.

        >>> ExtendedContext.same_quantum(Decimal('2.17'), Decimal('0.001'))
        False
        >>> ExtendedContext.same_quantum(Decimal('2.17'), Decimal('0.01'))
        True
        >>> ExtendedContext.same_quantum(Decimal('2.17'), Decimal('1'))
        False
        >>> ExtendedContext.same_quantum(Decimal('Inf'), Decimal('-Inf'))
        True
        >>> ExtendedContext.same_quantum(10000, -1)
        True
        >>> ExtendedContext.same_quantum(Decimal(10000), -1)
        True
        >>> ExtendedContext.same_quantum(10000, Decimal(-1))
        True
        %s must be an integerRounds to an integer.

        When the operand has a negative exponent, the result is the same
        as using the quantize() operation using the given operand as the
        left-hand-operand, 1E+0 as the right-hand-operand, and the precision
        of the operand as the precision setting; Inexact and Rounded flags
        are allowed in this operation.  The rounding mode is taken from the
        context.

        >>> ExtendedContext.to_integral_exact(Decimal('2.1'))
        Decimal('2')
        >>> ExtendedContext.to_integral_exact(Decimal('100'))
        Decimal('100')
        >>> ExtendedContext.to_integral_exact(Decimal('100.0'))
        Decimal('100')
        >>> ExtendedContext.to_integral_exact(Decimal('101.5'))
        Decimal('102')
        >>> ExtendedContext.to_integral_exact(Decimal('-101.5'))
        Decimal('-102')
        >>> ExtendedContext.to_integral_exact(Decimal('10E+5'))
        Decimal('1.0E+6')
        >>> ExtendedContext.to_integral_exact(Decimal('7.89E+77'))
        Decimal('7.89E+77')
        >>> ExtendedContext.to_integral_exact(Decimal('-Inf'))
        Decimal('-Infinity')
        An invalid operation was performed.

    Various bad things cause this:

    Something creates a signaling NaN
    -INF + INF
    0 * (+-)INF
    (+-)INF / (+-)INF
    x % 0
    (+-)INF % x
    x._rescale( non-integer )
    sqrt(-x) , x > 0
    0 ** 0
    x ** (non-integer)
    x ** (+-)INF
    An operand is invalid

    The result of the operation after these is a quiet positive NaN,
    except when the cause is a signaling NaN, in which case the result is
    also a quiet NaN, but with the original sign, and an optional
    diagnostic information.
    other_lenReturns self + other.

        -INF + INF (or the reverse) cause InvalidOperation errors.
        Round self to the nearest integer, or to a given precision.

        If only one argument is supplied, round a finite Decimal
        instance self to the nearest integer.  If self is infinite or
        a NaN then a Python exception is raised.  If self is finite
        and lies exactly halfway between two integers then it is
        rounded to the integer with even last digit.

        >>> round(Decimal('123.456'))
        123
        >>> round(Decimal('-456.789'))
        -457
        >>> round(Decimal('-3.0'))
        -3
        >>> round(Decimal('2.5'))
        2
        >>> round(Decimal('3.5'))
        4
        >>> round(Decimal('Inf'))
        Traceback (most recent call last):
          ...
        OverflowError: cannot round an infinity
        >>> round(Decimal('NaN'))
        Traceback (most recent call last):
          ...
        ValueError: cannot round a NaN

        If a second argument n is supplied, self is rounded to n
        decimal places using the rounding mode for the current
        context.

        For an integer n, round(self, -n) is exactly equivalent to
        self.quantize(Decimal('1En')).

        >>> round(Decimal('123.456'), 0)
        Decimal('123')
        >>> round(Decimal('123.456'), 2)
        Decimal('123.46')
        >>> round(Decimal('123.456'), -2)
        Decimal('1E+2')
        >>> round(Decimal('-Infinity'), 37)
        Decimal('NaN')
        >>> round(Decimal('sNaN123'), 0)
        Decimal('NaN123')

        modulo_is_nanInvalid literal for Decimal: %rContext._shallow_copyContext.max_mag__xname__Decimal.to_integral_valueDecimal._dividepow() 3rd argument not allowed unless all arguments are integersReturns a copy of the decimal object.

        >>> ExtendedContext.copy_decimal(Decimal('2.1'))
        Decimal('2.1')
        >>> ExtendedContext.copy_decimal(Decimal('-1.00'))
        Decimal('-1.00')
        >>> ExtendedContext.copy_decimal(1)
        Decimal('1')
        exp_maxExponent of a 0 changed to fit bounds.

    This occurs and signals clamped if the exponent of a result has been
    altered in order to fit the constraints of a specific concrete
    representation.  This may occur when the exponent of a zero result would
    be outside the bounds of a representation, or when a large normal
    number would have an encoded exponent that cannot be represented.  In
    this latter case, the exponent is reduced to fit and the corresponding
    number of zero digits are appended to the coefficient ("fold-down").
    ì   ÿÇNÎZoquantize with one INFConvert to a string, using engineering notation if an exponent is needed.

        Engineering notation has an exponent which is a multiple of 3.  This
        can leave up to 3 digits to the left of the decimal place and may
        require the addition of either one or two trailing zeros.

        The operation is not affected by the context.

        >>> ExtendedContext.to_eng_string(Decimal('123E+1'))
        '1.23E+3'
        >>> ExtendedContext.to_eng_string(Decimal('123E+3'))
        '123E+3'
        >>> ExtendedContext.to_eng_string(Decimal('123E-10'))
        '12.3E-9'
        >>> ExtendedContext.to_eng_string(Decimal('-123E-12'))
        '-123E-12'
        >>> ExtendedContext.to_eng_string(Decimal('7E-7'))
        '700E-9'
        >>> ExtendedContext.to_eng_string(Decimal('7E+1'))
        '70'
        >>> ExtendedContext.to_eng_string(Decimal('0E+1'))
        '0.00E+3'

        str_nDecimal._isevenContext.EtinyContext.sqrtstrict semantics for mixing floats and Decimals are enabledpow() 3rd argument cannot be 0Decimal._round_floorContext.canonicalReturns a rotated copy of self, value-of-other times.number_classReturn True if the operand is a qNaN or sNaN;
        otherwise return False.

        >>> ExtendedContext.is_nan(Decimal('2.50'))
        False
        >>> ExtendedContext.is_nan(Decimal('NaN'))
        True
        >>> ExtendedContext.is_nan(Decimal('-sNaN'))
        True
        >>> ExtendedContext.is_nan(1)
        False
        Unable to convert %s to DecimalReturns this thread's context.

        If this thread does not yet have a context, returns
        a new context and sets this thread's context.
        New contexts are copies of DefaultContext.
        Return True if the operand is finite; otherwise return False.

        A Decimal instance is considered finite if it is neither
        infinite nor a NaN.

        >>> ExtendedContext.is_finite(Decimal('2.50'))
        True
        >>> ExtendedContext.is_finite(Decimal('-0.3'))
        True
        >>> ExtendedContext.is_finite(Decimal('0'))
        True
        >>> ExtendedContext.is_finite(Decimal('Inf'))
        False
        >>> ExtendedContext.is_finite(Decimal('NaN'))
        False
        >>> ExtendedContext.is_finite(1)
        True
        %s: invalid rounding modeDecimal.realcannot convert Infinity to integer ratioConvert to a string, using engineering notation if an exponent is needed.

        Engineering notation has an exponent which is a multiple of 3.  This
        can leave up to 3 digits to the left of the decimal place and may
        require the addition of either one or two trailing zeros.
        Square root of a non-negative number to context precision.

        If the result must be inexact, it is rounded using the round-half-even
        algorithm.

        >>> ExtendedContext.sqrt(Decimal('0'))
        Decimal('0')
        >>> ExtendedContext.sqrt(Decimal('-0'))
        Decimal('-0')
        >>> ExtendedContext.sqrt(Decimal('0.39'))
        Decimal('0.624499800')
        >>> ExtendedContext.sqrt(Decimal('100'))
        Decimal('10')
        >>> ExtendedContext.sqrt(Decimal('1'))
        Decimal('1')
        >>> ExtendedContext.sqrt(Decimal('1.0'))
        Decimal('1.0')
        >>> ExtendedContext.sqrt(Decimal('1.00'))
        Decimal('1.0')
        >>> ExtendedContext.sqrt(Decimal('7'))
        Decimal('2.64575131')
        >>> ExtendedContext.sqrt(Decimal('10'))
        Decimal('3.16227766')
        >>> ExtendedContext.sqrt(2)
        Decimal('1.41421356')
        >>> ExtendedContext.prec
        9
        Return True if self is a signaling NaN; otherwise return False.Fused multiply-add.

        Returns self*other+third with no rounding of the intermediate
        product self*other.

        self and other are multiplied together, with no rounding of
        the result.  The third operand is then added to the result,
        and a single final rounding is performed.
        Context.explogb(0)©ÚselfÚotherÚmoduloÚcontextÚansÚresult_signÚ
multiplierÚexpÚself_adjÚexactÚboundÚEtinyÚpÚxÚxcÚxeÚyÚycÚyeÚextraÚcoeffÚexpdiffÚ
newcontextÚ	exceptionReturns a multiplied by b, plus c.

        The first two operands are multiplied together, using multiply,
        the third operand is then added to the result of that
        multiplication, using add, all with only one final rounding.

        >>> ExtendedContext.fma(Decimal('3'), Decimal('5'), Decimal('7'))
        Decimal('22')
        >>> ExtendedContext.fma(Decimal('3'), Decimal('-5'), Decimal('7'))
        Decimal('-8')
        >>> ExtendedContext.fma(Decimal('888565290'), Decimal('1557.96930'), Decimal('-86087.7578'))
        Decimal('1.38435736E+12')
        >>> ExtendedContext.fma(1, 3, 4)
        Decimal('7')
        >>> ExtendedContext.fma(1, Decimal(3), 4)
        Decimal('7')
        >>> ExtendedContext.fma(1, 3, Decimal(4))
        Decimal('7')
        group length should be positive1.70Decimal.__rtruediv__remainder_near(infinity, x)Context.__repr__vmaxReturns the absolute value of self.

        If the keyword argument 'round' is false, do not round.  The
        expression self.__abs__(round=False) is equivalent to
        self.copy_abs().
        Also known as round-towards-0, truncate.Decimal.is_qnanInsert thousands separators into a digit string.

    spec is a dictionary whose keys should include 'thousands_sep' and
    'grouping'; typically it's the result of parsing the format
    specifier using _parse_format_specifier.

    The min_width keyword argument gives the minimum length of the
    result, which will be padded on the left with zeros if necessary.

    If necessary, the zero padding adds an extra '0' on the left to
    avoid a leading thousands separator.  For example, inserting
    commas every three digits in '123456', with min_width=8, gives
    '0,123,456', even though that has length 9.

    Return True if self and other have the same exponent; otherwise
        return False.

        If either operand is a special value, the following rules are used:
           * return True if both operands are infinities
           * return True if both operands are NaNs
           * otherwise, return False.
        _ContextManager.__enter__Given integers x and M, M > 0, such that x/M is small in absolute
    value, compute an integer approximation to M*exp(x/M).  For 0 <=
    x/M <= 2.4, the absolute error in the result is bounded by 60 (and
    is usually much smaller).Returns whether the number is infinite

        0 if finite or not a number
        1 if +INF
        -1 if -INF
        Compares two operands using their abstract representation ignoring sign.

        Like compare_total, but with operand's sign ignored and assumed to be 0.
        Returns maximum exponent (= Emax - prec + 1)Context.powerDecimal.__int__Context.create_decimal_from_floatReturns to be "a - b * n", where n is the integer nearest the exact
        value of "x / b" (if two integers are equally near then the even one
        is chosen).  If the result is equal to 0 then its sign will be the
        sign of a.

        This operation will fail under the same conditions as integer division
        (that is, if integer division on the same two operands would fail, the
        remainder cannot be calculated).

        >>> ExtendedContext.remainder_near(Decimal('2.1'), Decimal('3'))
        Decimal('-0.9')
        >>> ExtendedContext.remainder_near(Decimal('10'), Decimal('6'))
        Decimal('-2')
        >>> ExtendedContext.remainder_near(Decimal('10'), Decimal('3'))
        Decimal('1')
        >>> ExtendedContext.remainder_near(Decimal('-10'), Decimal('3'))
        Decimal('-1')
        >>> ExtendedContext.remainder_near(Decimal('10.2'), Decimal('1'))
        Decimal('0.2')
        >>> ExtendedContext.remainder_near(Decimal('10'), Decimal('0.3'))
        Decimal('0.1')
        >>> ExtendedContext.remainder_near(Decimal('3.6'), Decimal('1.3'))
        Decimal('-0.3')
        >>> ExtendedContext.remainder_near(3, 11)
        Decimal('3')
        >>> ExtendedContext.remainder_near(Decimal(3), 11)
        Decimal('3')
        >>> ExtendedContext.remainder_near(3, Decimal(11))
        Decimal('3')
        Decimal.__rpow__Return the adjusted exponent of selfReturns the smaller value.

        Like min(self, other) except if one is not a number, returns
        NaN (and signals if one is sNaN).  Also rounds.
        Decimal.logical_invert_iexpReturn True if the operand is infinite; otherwise return False.

        >>> ExtendedContext.is_infinite(Decimal('2.50'))
        False
        >>> ExtendedContext.is_infinite(Decimal('-Inf'))
        True
        >>> ExtendedContext.is_infinite(Decimal('NaN'))
        False
        >>> ExtendedContext.is_infinite(1)
        False
        Decimal._ln_exp_bound_fix_nan__decimal_context__shift2Returns a shallow copy from self.Decimal.__divmod__Exponent < Emin before rounding.

    This occurs and signals subnormal whenever the result of a conversion or
    operation is subnormal (that is, its adjusted exponent is less than
    Emin, before any rounding).  The result in all cases is unchanged.

    The subnormal signal may be tested (or trapped) to determine if a given
    or operation (or sequence of operations) yielded a subnormal result.
    Decimal.fmaReturns the largest representable number smaller than itself.Decimal.is_signedReturn self ** other [ % modulo].

        With two arguments, compute self**other.

        With three arguments, compute (self**other) % modulo.  For the
        three argument form, the following restrictions on the
        arguments hold:

         - all three arguments must be integral
         - other must be nonnegative
         - either self or other (or both) must be nonzero
         - modulo must be nonzero and must have at most p digits,
           where p is the context precision.

        If any of these restrictions is violated the InvalidOperation
        flag is raised.

        The result of pow(self, other, modulo) is identical to the
        result that would be obtained by computing (self**other) %
        modulo with unbounded precision, but is computed more
        efficiently.  It is always exact.
        {0}{1:+}Context.is_zeroDecimal.next_minusCreate a decimal point instance.

        >>> Decimal('3.14')              # string input
        Decimal('3.14')
        >>> Decimal((0, (3, 1, 4), -2))  # tuple (sign, digit_tuple, exponent)
        Decimal('3.14')
        >>> Decimal(314)                 # int
        Decimal('314')
        >>> Decimal(Decimal(314))        # another decimal instance
        Decimal('314')
        >>> Decimal('  3.14  \n')        # leading and trailing whitespace okay
        Decimal('3.14')
        Context.is_qnanContext.log10Invalid sign.  The first value in the tuple should be an integer; either 0 for a positive number or 1 for a negative number.Return self / other.
        Return (self // other, self % other)
        remainder_near(x, 0)Swaps self/other and returns __floordiv__.other_infRound if it is necessary to keep self within prec precision.

        Rounds and fixes the exponent.  Does not raise on a sNaN.

        Arguments:
        self - Decimal instance
        context - context used.
        Decimal.__add__Decimal.is_finiteApplies the logical operation 'and' between each operand's digits.

        The operands must be both logical numbers.

        >>> ExtendedContext.logical_and(Decimal('0'), Decimal('0'))
        Decimal('0')
        >>> ExtendedContext.logical_and(Decimal('0'), Decimal('1'))
        Decimal('0')
        >>> ExtendedContext.logical_and(Decimal('1'), Decimal('0'))
        Decimal('0')
        >>> ExtendedContext.logical_and(Decimal('1'), Decimal('1'))
        Decimal('1')
        >>> ExtendedContext.logical_and(Decimal('1100'), Decimal('1010'))
        Decimal('1000')
        >>> ExtendedContext.logical_and(Decimal('1111'), Decimal('10'))
        Decimal('10')
        >>> ExtendedContext.logical_and(110, 1101)
        Decimal('100')
        >>> ExtendedContext.logical_and(Decimal(110), 1101)
        Decimal('100')
        >>> ExtendedContext.logical_and(110, Decimal(1101))
        Decimal('100')
        Returns a shifted copy of a, b times.

        The coefficient of the result is a shifted copy of the digits
        in the coefficient of the first operand.  The number of places
        to shift is taken from the absolute value of the second operand,
        with the shift being to the left if the second operand is
        positive or to the right otherwise.  Digits shifted into the
        coefficient are zeros.

        >>> ExtendedContext.shift(Decimal('34'), Decimal('8'))
        Decimal('400000000')
        >>> ExtendedContext.shift(Decimal('12'), Decimal('9'))
        Decimal('0')
        >>> ExtendedContext.shift(Decimal('123456789'), Decimal('-2'))
        Decimal('1234567')
        >>> ExtendedContext.shift(Decimal('123456789'), Decimal('0'))
        Decimal('123456789')
        >>> ExtendedContext.shift(Decimal('123456789'), Decimal('+2'))
        Decimal('345678900')
        >>> ExtendedContext.shift(88888888, 2)
        Decimal('888888800')
        >>> ExtendedContext.shift(Decimal(88888888), 2)
        Decimal('888888800')
        >>> ExtendedContext.shift(88888888, Decimal(2))
        Decimal('888888800')
        Reset all flags to zeroideal_exponentDecimal._round_upAttempt to compute self**other exactly.

        Given Decimals self and other and an integer p, attempt to
        compute an exact result for the power self**other, with p
        digits of precision.  Return None if self**other is not
        exactly representable in p digits.

        Assumes that elimination of special cases has already been
        performed: self and other must both be nonspecial; self must
        be positive and not numerically equal to 1; other must be
        nonzero.  For efficiency, other._exp should not be too large,
        so that 10**abs(other._exp) is a feasible calculation.(%r, %r, %r)Returns the remainder from integer division.

        The result is the residue of the dividend after the operation of
        calculating integer division as described for divide-integer, rounded
        to precision digits if necessary.  The sign of the result, if
        non-zero, is the same as that of the original dividend.

        This operation will fail under the same conditions as integer division
        (that is, if integer division on the same two operands would fail, the
        remainder cannot be calculated).

        >>> ExtendedContext.remainder(Decimal('2.1'), Decimal('3'))
        Decimal('2.1')
        >>> ExtendedContext.remainder(Decimal('10'), Decimal('3'))
        Decimal('1')
        >>> ExtendedContext.remainder(Decimal('-10'), Decimal('3'))
        Decimal('-1')
        >>> ExtendedContext.remainder(Decimal('10.2'), Decimal('1'))
        Decimal('0.2')
        >>> ExtendedContext.remainder(Decimal('10'), Decimal('0.3'))
        Decimal('0.1')
        >>> ExtendedContext.remainder(Decimal('3.6'), Decimal('1.3'))
        Decimal('1.0')
        >>> ExtendedContext.remainder(22, 6)
        Decimal('4')
        >>> ExtendedContext.remainder(Decimal(22), 6)
        Decimal('4')
        >>> ExtendedContext.remainder(22, Decimal(6))
        Decimal('4')
        C:\msys64\mingw64\lib\python3.6\_pydecimal.pyDecimal.to_integral_exactContext._set_roundingMinus corresponds to unary prefix minus in Python.

        The operation is evaluated using the same rules as subtract; the
        operation minus(a) is calculated as subtract('0', a) where the '0'
        has the same exponent as the operand.

        >>> ExtendedContext.minus(Decimal('1.3'))
        Decimal('-1.3')
        >>> ExtendedContext.minus(Decimal('-1.3'))
        Decimal('1.3')
        >>> ExtendedContext.minus(1)
        Decimal('-1')
        Class to compute, store, and allow retrieval of, digits of the
    constant log(10) = 2.302585....  This constant is needed by
    Decimal.ln, Decimal.log10, Decimal.exp and Decimal.__pow__.Closest integer to a/b, a and b positive integers; rounds to even
    in the case of a tie.

    Decimal.__round___dpowerThe third value in the tuple must be an integer, or one of the strings 'F', 'n', 'N'.Compares values numerically.

        If the signs of the operands differ, a value representing each operand
        ('-1' if the operand is less than zero, '0' if the operand is zero or
        negative zero, or '1' if the operand is greater than zero) is used in
        place of that operand for the comparison instead of the actual
        operand.

        The comparison is then effected by subtracting the second operand from
        the first and then returning a value according to the result of the
        subtraction: '-1' if the result is less than zero, '0' if the result is
        zero or negative zero, or '1' if the result is greater than zero.

        >>> ExtendedContext.compare(Decimal('2.1'), Decimal('3'))
        Decimal('-1')
        >>> ExtendedContext.compare(Decimal('2.1'), Decimal('2.1'))
        Decimal('0')
        >>> ExtendedContext.compare(Decimal('2.1'), Decimal('2.10'))
        Decimal('0')
        >>> ExtendedContext.compare(Decimal('3'), Decimal('2.1'))
        Decimal('1')
        >>> ExtendedContext.compare(Decimal('2.1'), Decimal('-3'))
        Decimal('1')
        >>> ExtendedContext.compare(Decimal('-3'), Decimal('2.1'))
        Decimal('-1')
        >>> ExtendedContext.compare(1, 2)
        Decimal('-1')
        >>> ExtendedContext.compare(Decimal(1), 2)
        Decimal('-1')
        >>> ExtendedContext.compare(1, Decimal(2))
        Decimal('-1')
        %s cannot be deleted<module _pydecimal>Returns the largest representable number smaller than a.

        >>> c = ExtendedContext.copy()
        >>> c.Emin = -999
        >>> c.Emax = 999
        >>> ExtendedContext.next_minus(Decimal('1'))
        Decimal('0.999999999')
        >>> c.next_minus(Decimal('1E-1007'))
        Decimal('0E-1007')
        >>> ExtendedContext.next_minus(Decimal('-1.00000003'))
        Decimal('-1.00000004')
        >>> c.next_minus(Decimal('Infinity'))
        Decimal('9.99999999E+999')
        >>> c.next_minus(1)
        Decimal('0.999999999')
        Decimal.__rfloordiv__max compares two values numerically and returns the maximum.

        If either operand is a NaN then the general rules apply.
        Otherwise, the operands are compared as though by the compare
        operation.  If they are numerically equal then the left-hand operand
        is chosen as the result.  Otherwise the maximum (closer to positive
        infinity) of the two operands is chosen as the result.

        >>> ExtendedContext.max(Decimal('3'), Decimal('2'))
        Decimal('3')
        >>> ExtendedContext.max(Decimal('-10'), Decimal('3'))
        Decimal('3')
        >>> ExtendedContext.max(Decimal('1.0'), Decimal('1'))
        Decimal('1')
        >>> ExtendedContext.max(Decimal('7'), Decimal('NaN'))
        Decimal('7')
        >>> ExtendedContext.max(1, 2)
        Decimal('2')
        >>> ExtendedContext.max(Decimal(1), 2)
        Decimal('2')
        >>> ExtendedContext.max(1, Decimal(2))
        Decimal('2')
        Compute a lower bound for the adjusted exponent of self.ln().
        In other words, compute r such that self.ln() >= 10**r.  Assumes
        that self is finite and positive and that self != 1.
        Context.clear_trapsargument must be int or float.Context.__delattr__sqrt(-x), x > 0Given integers c, e and p with c > 0, p >= 0, compute an integer
    approximation to 10**p * log10(c*10**e), with an absolute error of
    at most 1.  Assumes that c*10**e is not exactly 1.comparison involving sNaNDecimal.__float__raiseitContext.next_plusParse and validate a format specifier.

    Turns a standard numeric format specifier into a dict, with the
    following entries:

      fill: fill character to pad field to minimum width
      align: alignment type, either '<', '>', '=' or '^'
      sign: either '+', '-' or ' '
      minimumwidth: nonnegative integer giving minimum width
      zeropad: boolean, indicating whether to pad with zeros
      thousands_sep: string to use as thousands separator, or ''
      grouping: grouping for thousands separators, in format
        used by localeconv
      decimal_point: string to use for decimal point
      precision: nonnegative integer giving precision, or None
      type: one of the characters 'eEfFgG%', or None

    Given integers xc, xe, yc and ye representing Decimals x = xc*10**xe and
    y = yc*10**ye, compute x**y.  Returns a pair of integers (c, e) such that:

      10**(p-1) <= c <= 10**p, and
      (c-1)*10**e < x**y < (c+1)*10**e

    in other words, c*10**e is an approximation to x**y with p digits
    of precision, and with an error in c of at most 1.  (This is
    almost, but not quite, the same as the error being < 1ulp: when c
    == 10**(p-1) we can only guarantee error < 10ulp.)

    We assume that: x is positive and not equal to 1, and y is nonzero.
    Context.compare_totalContains the context for a Decimal instance.

    Contains:
    prec - precision (for use in rounding, division, square roots..)
    rounding - rounding type (how you round)
    traps - If traps[exception] = 1, then the exception is
                    raised when it is caused.  Otherwise, a value is
                    substituted in.
    flags  - When an exception is caused, flags[exception] is set.
             (Whether or not the trap_enabler is set)
             Should be reset by user of Decimal instance.
    Emin -   Minimum exponent
    Emax -   Maximum exponent
    capitals -      If 1, 1*10^1 is printed as 1E+1.
                    If 0, printed as 1e1
    clamp -  If 1, change exponents if too high (Default 0)
    _ContextManager.__exit___dlog10Decimal.shiftCompare the two non-NaN decimal instances self and other.

        Returns -1 if self < other, 0 if self == other and 1
        if self > other.  This routine is for internal use only.Decimal.is_infiniteCreates a new Decimal instance but using self as context.

        This method implements the to-number operation of the
        IBM Decimal specification._nbitsx // 0Plus corresponds to unary prefix plus in Python.

        The operation is evaluated using the same rules as add; the
        operation plus(a) is calculated as add('0', a) where the '0'
        has the same exponent as the operand.

        >>> ExtendedContext.plus(Decimal('1.3'))
        Decimal('1.3')
        >>> ExtendedContext.plus(Decimal('-1.3'))
        Decimal('-1.3')
        >>> ExtendedContext.plus(-1)
        Decimal('-1')
        INF // INFat least one of pow() 1st argument and 2nd argument must be nonzero ;0**0 is not definedReturn the floor of self, as an integer.

        For a finite Decimal instance self, return the greatest
        integer n such that n <= self.  If self is infinite or a NaN
        then a Python exception is raised.

        Decimal.logical_xorINF * 0 in fmaDecimal.__le__Compute a lower bound for 100*log10(c) for a positive integer c.Returns a value equal to 'a' (rounded), having the exponent of 'b'.

        The coefficient of the result is derived from that of the left-hand
        operand.  It may be rounded using the current rounding setting (if the
        exponent is being increased), multiplied by a positive power of ten (if
        the exponent is being decreased), or is unchanged (if the exponent is
        already equal to that of the right-hand operand).

        Unlike other operations, if the length of the coefficient after the
        quantize operation would be greater than precision then an Invalid
        operation condition is raised.  This guarantees that, unless there is
        an error condition, the exponent of the result of a quantize is always
        equal to that of the right-hand operand.

        Also unlike other operations, quantize will never raise Underflow, even
        if the result is subnormal and inexact.

        >>> ExtendedContext.quantize(Decimal('2.17'), Decimal('0.001'))
        Decimal('2.170')
        >>> ExtendedContext.quantize(Decimal('2.17'), Decimal('0.01'))
        Decimal('2.17')
        >>> ExtendedContext.quantize(Decimal('2.17'), Decimal('0.1'))
        Decimal('2.2')
        >>> ExtendedContext.quantize(Decimal('2.17'), Decimal('1e+0'))
        Decimal('2')
        >>> ExtendedContext.quantize(Decimal('2.17'), Decimal('1e+1'))
        Decimal('0E+1')
        >>> ExtendedContext.quantize(Decimal('-Inf'), Decimal('Infinity'))
        Decimal('-Infinity')
        >>> ExtendedContext.quantize(Decimal('2'), Decimal('Infinity'))
        Decimal('NaN')
        >>> ExtendedContext.quantize(Decimal('-0.1'), Decimal('1'))
        Decimal('-0')
        >>> ExtendedContext.quantize(Decimal('-0'), Decimal('1e+5'))
        Decimal('-0E+5')
        >>> ExtendedContext.quantize(Decimal('+35236450.6'), Decimal('1e-2'))
        Decimal('NaN')
        >>> ExtendedContext.quantize(Decimal('-35236450.6'), Decimal('1e-2'))
        Decimal('NaN')
        >>> ExtendedContext.quantize(Decimal('217'), Decimal('1e-1'))
        Decimal('217.0')
        >>> ExtendedContext.quantize(Decimal('217'), Decimal('1e-0'))
        Decimal('217')
        >>> ExtendedContext.quantize(Decimal('217'), Decimal('1e+1'))
        Decimal('2.2E+2')
        >>> ExtendedContext.quantize(Decimal('217'), Decimal('1e+2'))
        Decimal('2E+2')
        >>> ExtendedContext.quantize(1, 2)
        Decimal('1')
        >>> ExtendedContext.quantize(Decimal(1), 2)
        Decimal('1')
        >>> ExtendedContext.quantize(1, Decimal(2))
        Decimal('1')
        Return True if self is canonical; otherwise return False.

        Currently, the encoding of a Decimal instance is always
        canonical, so this method returns True for any Decimal.
        insufficient precision: pow() 3rd argument must not have more than precision digitsNumber got rounded (not  necessarily changed during rounding).

    This occurs and signals rounded whenever the result of an operation is
    rounded (that is, some zero or non-zero digits were discarded from the
    coefficient), or if an overflow or underflow condition occurs.  The
    result in all cases is unchanged.

    The rounded signal may be tested (or trapped) to determine if a given
    operation (or sequence of operations) caused a loss of precision.
    divmod(0, 0)Decimal.conjugateDecimal._round_05upDecimal._power_moduloSwaps self/other and returns __pow__.Returns the same Decimal object.

        As we do not have different encodings for the same number, the
        received object already is in its canonical form.

        >>> ExtendedContext.canonical(Decimal('2.50'))
        Decimal('2.50')
        _PyHASH_INF©ÚselfÚotherÚpÚxÚxcÚxeÚyÚycÚyeÚexponentÚideal_exponentÚzerosÚ
last_digitÚeÚemaxÚ	remainderÚmÚnÚxc_bitsÚremÚaÚqÚrÚstr_xcDecimal.logical_andGiven a Decimal instance self and a Python object other, return
    a pair (s, o) of Decimal instances such that "s op o" is
    equivalent to "self op other" for any of the 6 comparison
    operators "op".

    Decimal.as_integer_ratioThe second value in the tuple must be composed of integers in the range 0 through 9.Set this thread's context to context._dec_from_tripleDivisionByZero.handleReturns the natural (base e) logarithm of self._parse_format_specifier_regexp should be nonnegativeDetermine sign character.Version of _check_nans used for the signaling comparisons
        compare_signal, __le__, __lt__, __ge__, __gt__.

        Signal InvalidOperation if either self or other is a (quiet
        or signaling) NaN.  Signaling NaNs take precedence over quiet
        NaNs.

        Return 0 if neither operand is a NaN.

         Given integers n and e, return n * 10**e if it's an integer, else None.

    The computation is designed to avoid computing large powers of 10
    unnecessarily.

    >>> _decimal_lshift_exact(3, 4)
    30000
    >>> _decimal_lshift_exact(300, -999999999)  # returns None

    Decimal.__str___format_number_ZeroRaises a to the power of b, to modulo if given.

        With two arguments, compute a**b.  If a is negative then b
        must be integral.  The result will be inexact unless b is
        integral and the result is finite and can be expressed exactly
        in 'precision' digits.

        With three arguments, compute (a**b) % modulo.  For the
        three argument form, the following restrictions on the
        arguments hold:

         - all three arguments must be integral
         - b must be nonnegative
         - at least one of a or b must be nonzero
         - modulo must be nonzero and have at most 'precision' digits

        The result of pow(a, b, modulo) is identical to the result
        that would be obtained by computing (a**b) % modulo with
        unbounded precision, but is computed more efficiently.  It is
        always exact.

        >>> c = ExtendedContext.copy()
        >>> c.Emin = -999
        >>> c.Emax = 999
        >>> c.power(Decimal('2'), Decimal('3'))
        Decimal('8')
        >>> c.power(Decimal('-2'), Decimal('3'))
        Decimal('-8')
        >>> c.power(Decimal('2'), Decimal('-3'))
        Decimal('0.125')
        >>> c.power(Decimal('1.7'), Decimal('8'))
        Decimal('69.7575744')
        >>> c.power(Decimal('10'), Decimal('0.301029996'))
        Decimal('2.00000000')
        >>> c.power(Decimal('Infinity'), Decimal('-1'))
        Decimal('0')
        >>> c.power(Decimal('Infinity'), Decimal('0'))
        Decimal('1')
        >>> c.power(Decimal('Infinity'), Decimal('1'))
        Decimal('Infinity')
        >>> c.power(Decimal('-Infinity'), Decimal('-1'))
        Decimal('-0')
        >>> c.power(Decimal('-Infinity'), Decimal('0'))
        Decimal('1')
        >>> c.power(Decimal('-Infinity'), Decimal('1'))
        Decimal('-Infinity')
        >>> c.power(Decimal('-Infinity'), Decimal('2'))
        Decimal('Infinity')
        >>> c.power(Decimal('0'), Decimal('0'))
        Decimal('NaN')

        >>> c.power(Decimal('3'), Decimal('7'), Decimal('16'))
        Decimal('11')
        >>> c.power(Decimal('-3'), Decimal('7'), Decimal('16'))
        Decimal('-11')
        >>> c.power(Decimal('-3'), Decimal('8'), Decimal('16'))
        Decimal('1')
        >>> c.power(Decimal('3'), Decimal('7'), Decimal('-16'))
        Decimal('11')
        >>> c.power(Decimal('23E12345'), Decimal('67E189'), Decimal('123456789'))
        Decimal('11729830')
        >>> c.power(Decimal('-0'), Decimal('17'), Decimal('1729'))
        Decimal('-0')
        >>> c.power(Decimal('-23'), Decimal('0'), Decimal('65537'))
        Decimal('1')
        >>> ExtendedContext.power(7, 7)
        Decimal('823543')
        >>> ExtendedContext.power(Decimal(7), 7)
        Decimal('823543')
        >>> ExtendedContext.power(7, Decimal(7), 2)
        Decimal('1')
        Decimal.number_classCompares the values numerically with their sign ignored.

        >>> ExtendedContext.max_mag(Decimal('7'), Decimal('NaN'))
        Decimal('7')
        >>> ExtendedContext.max_mag(Decimal('7'), Decimal('-10'))
        Decimal('-10')
        >>> ExtendedContext.max_mag(1, -2)
        Decimal('-2')
        >>> ExtendedContext.max_mag(Decimal(1), -2)
        Decimal('-2')
        >>> ExtendedContext.max_mag(1, Decimal(-2))
        Decimal('-2')
        Returns e ** self.0 * INF in fmaInfinite result from next_towardStop ignoring the flags, if they are raisedReturn True if self is a quiet NaN; otherwise return False.Compares the values numerically with their sign ignored.

        >>> ExtendedContext.min_mag(Decimal('3'), Decimal('-2'))
        Decimal('-2')
        >>> ExtendedContext.min_mag(Decimal('-3'), Decimal('NaN'))
        Decimal('-3')
        >>> ExtendedContext.min_mag(1, -2)
        Decimal('1')
        >>> ExtendedContext.min_mag(Decimal(1), -2)
        Decimal('1')
        >>> ExtendedContext.min_mag(1, Decimal(-2))
        Decimal('1')
        Decimal.__sub__Decimal._log10_exp_boundContext.compare_total_magCompares two operands using their abstract representation.

        This is not like the standard compare, which use their numerical
        value. Note that a total ordering is defined for all possible abstract
        representations.

        >>> ExtendedContext.compare_total(Decimal('12.73'), Decimal('127.9'))
        Decimal('-1')
        >>> ExtendedContext.compare_total(Decimal('-127'),  Decimal('12'))
        Decimal('-1')
        >>> ExtendedContext.compare_total(Decimal('12.30'), Decimal('12.3'))
        Decimal('-1')
        >>> ExtendedContext.compare_total(Decimal('12.30'), Decimal('12.30'))
        Decimal('0')
        >>> ExtendedContext.compare_total(Decimal('12.3'),  Decimal('12.300'))
        Decimal('1')
        >>> ExtendedContext.compare_total(Decimal('12.3'),  Decimal('NaN'))
        Decimal('-1')
        >>> ExtendedContext.compare_total(1, 2)
        Decimal('-1')
        >>> ExtendedContext.compare_total(Decimal(1), 2)
        Decimal('-1')
        >>> ExtendedContext.compare_total(1, Decimal(2))
        Decimal('-1')
        x.__hash__() <==> hash(x)MockThreading.localShow the current context.exponent of quantize result too large for current contextReturns True if self is even.  Assumes self is an integer.Returns a rotated copy of a, b times.

        The coefficient of the result is a rotated copy of the digits in
        the coefficient of the first operand.  The number of places of
        rotation is taken from the absolute value of the second operand,
        with the rotation being to the left if the second operand is
        positive or to the right otherwise.

        >>> ExtendedContext.rotate(Decimal('34'), Decimal('8'))
        Decimal('400000003')
        >>> ExtendedContext.rotate(Decimal('12'), Decimal('9'))
        Decimal('12')
        >>> ExtendedContext.rotate(Decimal('123456789'), Decimal('-2'))
        Decimal('891234567')
        >>> ExtendedContext.rotate(Decimal('123456789'), Decimal('0'))
        Decimal('123456789')
        >>> ExtendedContext.rotate(Decimal('123456789'), Decimal('+2'))
        Decimal('345678912')
        >>> ExtendedContext.rotate(1333333, 1)
        Decimal('13333330')
        >>> ExtendedContext.rotate(Decimal(1333333), 1)
        Decimal('13333330')
        >>> ExtendedContext.rotate(1333333, Decimal(1))
        Decimal('13333330')
        Return self - otherReturn True if self is a zero; otherwise return False.Copies the second operand's sign to the first one.

        In detail, it returns a copy of the first operand with the sign
        equal to the sign of the second operand.

        >>> ExtendedContext.copy_sign(Decimal( '1.50'), Decimal('7.33'))
        Decimal('1.50')
        >>> ExtendedContext.copy_sign(Decimal('-1.50'), Decimal('7.33'))
        Decimal('1.50')
        >>> ExtendedContext.copy_sign(Decimal( '1.50'), Decimal('-7.33'))
        Decimal('-1.50')
        >>> ExtendedContext.copy_sign(Decimal('-1.50'), Decimal('-7.33'))
        Decimal('-1.50')
        >>> ExtendedContext.copy_sign(1, -2)
        Decimal('-1')
        >>> ExtendedContext.copy_sign(Decimal(1), -2)
        Decimal('-1')
        >>> ExtendedContext.copy_sign(1, Decimal(-2))
        Decimal('-1')
        Returns the smallest representable number larger than a.

        >>> c = ExtendedContext.copy()
        >>> c.Emin = -999
        >>> c.Emax = 999
        >>> ExtendedContext.next_plus(Decimal('1'))
        Decimal('1.00000001')
        >>> c.next_plus(Decimal('-1E-1007'))
        Decimal('-0E-1007')
        >>> ExtendedContext.next_plus(Decimal('-1.00000003'))
        Decimal('-1.00000002')
        >>> c.next_plus(Decimal('-Infinity'))
        Decimal('-9.99999999E+999')
        >>> c.next_plus(1)
        Decimal('1.00000001')
        Decimal._isintegerContext.number_class%s must be in [%d, %s]. got: %sdiagnostic info too long in NaNDecimal.__hash___all_zeros%s must be in [%s, %d]. got: %sReset all traps to zero-infContext._ignore_all_flagsDecimal._fix_nanReturns the number closest to a, in direction towards b.

        The result is the closest representable number from the first
        operand (but not the first operand) that is in the direction
        towards the second operand, unless the operands have the same
        value.

        >>> c = ExtendedContext.copy()
        >>> c.Emin = -999
        >>> c.Emax = 999
        >>> c.next_toward(Decimal('1'), Decimal('2'))
        Decimal('1.00000001')
        >>> c.next_toward(Decimal('-1E-1007'), Decimal('1'))
        Decimal('-0E-1007')
        >>> c.next_toward(Decimal('-1.00000003'), Decimal('0'))
        Decimal('-1.00000002')
        >>> c.next_toward(Decimal('1'), Decimal('0'))
        Decimal('0.999999999')
        >>> c.next_toward(Decimal('1E-1007'), Decimal('-100'))
        Decimal('0E-1007')
        >>> c.next_toward(Decimal('-1.00000003'), Decimal('-10'))
        Decimal('-1.00000004')
        >>> c.next_toward(Decimal('0.00'), Decimal('-0.0000'))
        Decimal('-0.00')
        >>> c.next_toward(0, 1)
        Decimal('1E-1007')
        >>> c.next_toward(Decimal(0), 1)
        Decimal('1E-1007')
        >>> c.next_toward(0, Decimal(1))
        Decimal('1E-1007')
        Round 5 to even, rest to nearest.exp_minReturn True if self is nonzero; otherwise return False.

        NaNs and infinities are considered nonzero.
        Context.EtopDecimal.logical_orReturns a deep copy from self.hash_infoDecimal.__mul__Handles an error

        If the flag is in _ignored_flags, returns the default response.
        Otherwise, it sets the flag, then, if the corresponding
        trap_enabler is set, it reraises the exception.  Otherwise, it returns
        the default value after setting the flag.
        Returns a copy with the sign inverted.other_adjusted_PyHASH_MODULUSRescale self so that the exponent is exp, either by padding with zeros
        or by truncating digits, using the given rounding mode.

        Specials are returned without change.  This operation is
        quiet: it raises no flags, and uses no information from the
        context.

        exp = exp to scale to (an integer)
        rounding = rounding mode
        Decimal.is_snanDecimal.__new__Returns whether the number is not actually one.

        if self, other are sNaN, signal
        if self, other are NaN return nan
        return 0

        Done before operations.
        Compares self to the other operand numerically.

        It's pretty much like compare(), but all NaNs signal, with signaling
        NaNs taking precedence over quiet NaNs.
        Given an integer p >= 0, return floor(10**p)*log(10).

        For example, self.getdigits(3) returns 2302.
        Return True if the operand is a quiet NaN; otherwise return False.

        >>> ExtendedContext.is_qnan(Decimal('2.50'))
        False
        >>> ExtendedContext.is_qnan(Decimal('NaN'))
        True
        >>> ExtendedContext.is_qnan(Decimal('sNaN'))
        False
        >>> ExtendedContext.is_qnan(1)
        False
        Returns an indication of the class of the operand.

        The class is one of the following strings:
          -sNaN
          -NaN
          -Infinity
          -Normal
          -Subnormal
          -Zero
          +Zero
          +Subnormal
          +Normal
          +Infinity

        >>> c = ExtendedContext.copy()
        >>> c.Emin = -999
        >>> c.Emax = 999
        >>> c.number_class(Decimal('Infinity'))
        '+Infinity'
        >>> c.number_class(Decimal('1E-10'))
        '+Normal'
        >>> c.number_class(Decimal('2.50'))
        '+Normal'
        >>> c.number_class(Decimal('0.1E-999'))
        '+Subnormal'
        >>> c.number_class(Decimal('0'))
        '+Zero'
        >>> c.number_class(Decimal('-0'))
        '-Zero'
        >>> c.number_class(Decimal('-0.1E-999'))
        '-Subnormal'
        >>> c.number_class(Decimal('-1E-10'))
        '-Normal'
        >>> c.number_class(Decimal('-2.50'))
        '-Normal'
        >>> c.number_class(Decimal('-Infinity'))
        '-Infinity'
        >>> c.number_class(Decimal('NaN'))
        'NaN'
        >>> c.number_class(Decimal('-NaN'))
        'NaN'
        >>> c.number_class(Decimal('sNaN'))
        'sNaN'
        >>> c.number_class(123)
        '+Normal'
        Decimal.scalebContext.next_towardabove EmaxConverts a float to a decimal number, exactly.

        Note that Decimal.from_float(0.1) is not the same as Decimal('0.1').
        Since 0.1 is not exactly representable in binary floating point, the
        value is stored as the nearest representable value which is
        0x1.999999999999ap-4.  The exact equivalent of the value in decimal
        is 0.1000000000000000055511151231257827021181583404541015625.

        >>> Decimal.from_float(0.1)
        Decimal('0.1000000000000000055511151231257827021181583404541015625')
        >>> Decimal.from_float(float('nan'))
        Decimal('NaN')
        >>> Decimal.from_float(float('inf'))
        Decimal('Infinity')
        >>> Decimal.from_float(-float('inf'))
        Decimal('-Infinity')
        >>> Decimal.from_float(-0.0)
        Decimal('-0')

        Decimal.min_magContext manager class to support localcontext().

      Sets a copy of the supplied context in __enter__() and restores
      the previous decimal context in __exit__()
    -nanRounds to an integer.

        When the operand has a negative exponent, the result is the same
        as using the quantize() operation using the given operand as the
        left-hand-operand, 1E+0 as the right-hand-operand, and the precision
        of the operand as the precision setting, except that no flags will
        be set.  The rounding mode is taken from the context.

        >>> ExtendedContext.to_integral_value(Decimal('2.1'))
        Decimal('2')
        >>> ExtendedContext.to_integral_value(Decimal('100'))
        Decimal('100')
        >>> ExtendedContext.to_integral_value(Decimal('100.0'))
        Decimal('100')
        >>> ExtendedContext.to_integral_value(Decimal('101.5'))
        Decimal('102')
        >>> ExtendedContext.to_integral_value(Decimal('-101.5'))
        Decimal('-102')
        >>> ExtendedContext.to_integral_value(Decimal('10E+5'))
        Decimal('1.0E+6')
        >>> ExtendedContext.to_integral_value(Decimal('7.89E+77'))
        Decimal('7.89E+77')
        >>> ExtendedContext.to_integral_value(Decimal('-Inf'))
        Decimal('-Infinity')
        _SignedInfinityContext(prec=%(prec)d, rounding=%(rounding)s, Emin=%(Emin)d, Emax=%(Emax)d, capitals=%(capitals)d, clamp=%(clamp)dDecimal.is_zeroDecimal.__repr__Decimal.same_quantumDecimal division in a specified context.

        >>> ExtendedContext.divide(Decimal('1'), Decimal('3'))
        Decimal('0.333333333')
        >>> ExtendedContext.divide(Decimal('2'), Decimal('3'))
        Decimal('0.666666667')
        >>> ExtendedContext.divide(Decimal('5'), Decimal('2'))
        Decimal('2.5')
        >>> ExtendedContext.divide(Decimal('1'), Decimal('10'))
        Decimal('0.1')
        >>> ExtendedContext.divide(Decimal('12'), Decimal('12'))
        Decimal('1')
        >>> ExtendedContext.divide(Decimal('8.00'), Decimal('2'))
        Decimal('4.00')
        >>> ExtendedContext.divide(Decimal('2.400'), Decimal('2.0'))
        Decimal('1.20')
        >>> ExtendedContext.divide(Decimal('1000'), Decimal('100'))
        Decimal('10')
        >>> ExtendedContext.divide(Decimal('1000'), Decimal('1'))
        Decimal('1000')
        >>> ExtendedContext.divide(Decimal('2.40E+6'), Decimal('2'))
        Decimal('1.20E+6')
        >>> ExtendedContext.divide(5, 5)
        Decimal('1')
        >>> ExtendedContext.divide(Decimal(5), 5)
        Decimal('1')
        >>> ExtendedContext.divide(5, Decimal(5))
        Decimal('1')
        _div_nearestReturn True if the operand is a zero; otherwise return False.

        >>> ExtendedContext.is_zero(Decimal('0'))
        True
        >>> ExtendedContext.is_zero(Decimal('2.50'))
        False
        >>> ExtendedContext.is_zero(Decimal('-0E+2'))
        True
        >>> ExtendedContext.is_zero(1)
        False
        >>> ExtendedContext.is_zero(0)
        True
        024680 // 0Decimal.normalizeself_is_subnormalnormalize reduces an operand to its simplest form.

        Essentially a plus operation with all trailing zeros removed from the
        result.

        >>> ExtendedContext.normalize(Decimal('2.1'))
        Decimal('2.1')
        >>> ExtendedContext.normalize(Decimal('-2.0'))
        Decimal('-2')
        >>> ExtendedContext.normalize(Decimal('1.200'))
        Decimal('1.2')
        >>> ExtendedContext.normalize(Decimal('-120'))
        Decimal('-1.2E+2')
        >>> ExtendedContext.normalize(Decimal('120.00'))
        Decimal('1.2E+2')
        >>> ExtendedContext.normalize(Decimal('0.00'))
        Decimal('0')
        >>> ExtendedContext.normalize(6)
        Decimal('6')
        Return a context manager for a copy of the supplied context

    Uses a copy of the current context if no context is specified
    The returned context manager creates a local decimal context
    in a with statement:
        def sin(x):
             with localcontext() as ctx:
                 ctx.prec += 2
                 # Rest of sin calculation algorithm
                 # uses a precision 2 greater than normal
             return +s  # Convert result to normal precision

         def sin(x):
             with localcontext(ExtendedContext):
                 # Rest of sin calculation algorithm
                 # uses the Extended Context from the
                 # General Decimal Arithmetic Specification
             return +s  # Convert result to normal context

    >>> setcontext(DefaultContext)
    >>> print(getcontext().prec)
    28
    >>> with localcontext():
    ...     ctx = getcontext()
    ...     ctx.prec += 2
    ...     print(ctx.prec)
    ...
    30
    >>> with localcontext(ExtendedContext):
    ...     print(getcontext().prec)
    ...
    9
    >>> print(getcontext().prec)
    28
    Closest integer to the square root of the positive integer n.  a is
    an initial approximation to the square root.  Any positive integer
    will do for a, but the closer a is to the square root of n the
    faster convergence will be.

    ln of a negative valueDecimal.__deepcopy__Alignment conflicts with '0' in format specifier: Context._raise_errorReturns whether self is an integerRounds to the nearest integer, without raising inexact, rounded.Returns the number closest to self, in the direction towards other.

        The result is the closest representable number to self
        (excluding self) that is in the direction towards other,
        unless both have the same value.  If the two operands are
        numerically equal, then the result is a copy of self with the
        sign set to be the same as the sign of other.
        Return True if self is subnormal; otherwise return False._LocaleTime__pad([\\.^$*+?\(\){}\[\]|])whitespace_replacement%w__calc_timezone_LocaleTime__calc_weekdayLocaleTime.__calc_am_pmReturn a class cls instance based on the input string and the
    format string.days_to_weekLC_date_time(?P<I>1[0-2]|0[1-9]|[1-9])C:\msys64\mingw64\lib\python3.6\_strptime.pylocale_time%XTimeRE.__init__.<locals>.<genexpr>iso_weekCalculate the Julian day based on the ISO 8601 year, week, and weekday.
    ISO weeks start on Mondays, with week 01 being the week containing 4 Jan.
    ISO week days range from 1 (Monday) to 7 (Sunday).
    regex_charsweek_of_yearday_of_weekweek_starts_Monfirst_weekdayweek_0_lengthiso_year(?P<U>5[0-3]|[0-4]\d|\d)re_compileISO week directive '%V' is incompatible with the year directive '%Y'. Use the ISO year '%G' instead.LocaleTime.__calc_timezone_LocaleTime__calc_timezone__calc_monthHandle conversion from format directives to regexes.unconverted data remains: %s_TimeRE_cacheConvert a list to a regex string for matching a directive.

        Want possible matching values to be from longest to shortest.  This
        prevents the possibility of a match occurring for a value that also
        a substring of a larger value that should have matched (e.g., 'abc'
        matching when 'abcdef' should have been the match).

        \\s+Set all attributes.

        Order of methods called matters for dependency reasons.

        The locale language is set at the offset and then checked again before
        exiting.  This is to make sure that the attributes were not set with a
        mix of information from more than one locale.  This would most likely
        happen when using threads where one thread calls a locale-dependent
        function while another thread changes the locale while the function in
        the other thread is still running.  Proper coding would call for
        locks to prevent changing the locale while locale-dependent code is
        running.  The check here is done in case someone does not think about
        doing this.

        Only other possible issue is if someone changed the timezone and did
        not call tz.tzset .  That is an issue for the programmer, though,
        since changing the timezone is worthless without that call.

        (?P<z>[+-]\d\d[0-5]\d)to_convertf_weekdayLocaleTime.__calc_month%ITimeRE.compile(?P<G>\d\d\d\d)datetime_datereplacement_pairs%W_regex_cache%cCreate keys/values.

        Order of execution is important for dependency reasons.

        %H_calc_julian_from_U_or_W%Mdata_string%j©'Údata_stringÚformatÚindexÚargÚmsgÚlocale_timeÚformat_regexÚerrÚbad_directiveÚfoundÚiso_yearÚyearÚmonthÚdayÚhourÚminuteÚsecondÚfractionÚtzÚtzoffsetÚiso_weekÚweek_of_yearÚweek_of_year_startÚweekdayÚjulianÚ
found_dictÚ	group_keyÚampmÚsÚzÚ
found_zoneÚvalueÚ	tz_valuesÚleap_year_fixÚweek_starts_MonÚydayÚdatetime_resultÚtznameÚgmtoff(?P<S>6[0-1]|[0-5]\d|\d)1999%Stz_namesprocessed_formatISO week directive '%V' must be used with the ISO year directive '%G' and a weekday directive ('%A', '%a', '%w', or '%u')._strptime_timeLocaleTime.__pad_LocaleTime__calc_montha_monthReturn a time struct based on the input string and the
    format string.Day of the year directive '%j' is not compatible with ISO year directive '%G'. Use '%Y' instead._calc_julian_from_V_TimeRE__seqToREa_weekdayTimeRE.__seqToREhas_savingiso_weekdayre_escape%mdirective_index(?P<H>2[0-3]|[0-1]\d|\d)(?P<w>[0-6])LC_time(?P<f>[0-9]{1,6})'%s' is a bad directive in format '%s'strptime() argument {} must be str, not {}_STRUCT_TM_ITEMS(?P<Y>\d\d\d\d)f_month%a %b %d %H:%M:%S %Yordinaltime_tuplecurrent_formatU_W<module _strptime>TimeRE.__seqToRE.<locals>.<genexpr>(?P<m>1[0-2]|0[1-9]|[1-9])no_savinglocale changed during initializationLocaleTime.__calc_date_time_getlang(?P<d>3[0-1]|[1-2]\d|0[1-9]|[1-9]| [1-9])(?P<y>\d\d)%y(?P<%s>%s%UReturn a compiled re object for the format string.timezone changed during initialization(?P<V>5[0-3]|0[1-9]|[1-4]\d|\d)tzdeltaCalculate the Julian day based on the year, week of the year, and day of
    the week, with week_start_day representing whether the week of the year
    assumes the week starts on Sunday or Monday (6 or 0).Return a 2-tuple consisting of a time struct and an int containing
    the number of microseconds based on the input string and the
    format string.Stores and handles locale-specific information related to time.

    ATTRIBUTES:
        f_weekday -- full weekday names (7-item list)
        a_weekday -- abbreviated weekday names (7-item list)
        f_month -- full month names (13-item list; dummy value in [0], which
                    is added by code)
        a_month -- abbreviated month names (13-item list, dummy value in
                    [0], which is added by code)
        am_pm -- AM/PM representation (2-item list)
        LC_date_time -- format string for date/time representation (string)
        LC_date -- format string for date representation (string)
        LC_time -- format string for time representation (string)
        timezone -- daylight- and non-daylight-savings timezone representation
                    (2-item list of sets)
        lang -- Language used by instance (2-item tuple)
    ISO year directive '%G' must be used with the ISO week directive '%V' and a weekday directive ('%A', '%a', '%w', or '%u').Return regex pattern for the format string.

        Need to make sure that any characters that might be interpreted as
        regex syntax are escaped.

        LocaleTime.__init__datetime_timedelta(?P<j>36[0-6]|3[0-5]\d|[1-2]\d\d|0[1-9]\d|00[1-9]|[1-9]\d|0[1-9]|[1-9])LocaleTime.__calc_weekdayStrptime-related classes and functions.

CLASSES:
    LocaleTime -- Discovers and stores locale-specific time information
    TimeRE -- Creates regexes for pattern matching a string of text containing
                time information

FUNCTIONS:
    _getlang -- Figure out what language is being used for the locale
    strptime -- Calculates the time struct represented by the passed-in string

_CACHE_MAX_SIZEstray %% in format '%s'_LocaleTime__calc_am_pm(?P<u>[1-7])datetime_timezone(?P<M>[0-5]\d|\d)TimeRE.pattern_LocaleTime__calc_date_time_thread_allocate_locktime data %r does not match format %r_cache_locksymmetric_difference_updateC:\msys64\mingw64\lib\python3.6\_weakrefset.pyWeakSet.issubset_IterationGuard.__init__WeakSet.popWeakSet.copyWeakSet.union.<locals>.<genexpr>WeakSet.__iand__WeakSet.clearnewsetWeakSet.isdisjointweakcontainerWeakSet.__iand__.<locals>.<genexpr>WeakSet.__contains__WeakSet.issupersetWeakSet.__lt__.<locals>.<genexpr>WeakSet.intersection.<locals>.<genexpr>intersection_updateWeakSet.__len__WeakSet.__iter__pop from empty WeakSetWeakSet.__gt__.<locals>.<genexpr>WeakSet.discard_IterationGuard.__exit__WeakSet.differenceWeakSet.__ixor__WeakSet.remove<module _weakrefset>WeakSet.__reduce__WeakSet.issubset.<locals>.<genexpr>WeakSet.issuperset.<locals>.<genexpr>WeakSet.__eq__.<locals>.<genexpr>WeakSet._commit_removalsWeakSet.__ior__WeakSet.difference_updateWeakSet.__isub__.<locals>.<genexpr>_IterationGuard.__enter__WeakSet.updateWeakSet.__init__itemrefWeakSet.symmetric_difference_updateWeakSet.__init__.<locals>._removeWeakSet.addWeakSet.intersection_updateWeakSet.__ixor__.<locals>.<genexpr>
<ui>
  <menubar name='MenuBar'>
    <menu action='AbMenu'>
      <separator />
      <menuitem action='AbQuit' />
      <menuitem action='abHome' />
    </menu>
    <menu action='ChoicesMenu'>
      <menuitem action='ChoiceOne'/>
      <menuitem action='ChoiceTwo'/>
      <separator />
      <menuitem action='ChoiceThree'/>
    </menu>
  </menubar>
</ui>
C:\msys64\home\cbper\abMenu.py
    A decorator indicating abstract classmethods.

    Similar to abstractmethod.

    Usage:

        class C(metaclass=ABCMeta):
            @abstractclassmethod
            def my_abstract_classmethod(cls, ...):
                ...

    'abstractclassmethod' is deprecated. Use 'classmethod' with
    'abstractmethod' instead.
    mclsABCMeta._dump_registryInv.counter: %s_abc__abc_registry_abc_negative_cacheabstractstaticmethod.__init__ABCMeta.__instancecheck__Metaclass for defining Abstract Base Classes (ABCs).

    Use this metaclass to create an ABC.  An ABC can be subclassed
    directly, and then acts as a mix-in class.  You can also register
    unrelated concrete classes (even built-in classes) and unrelated
    ABCs as 'virtual subclasses' -- these and their descendants will
    be considered subclasses of the registering ABC by the built-in
    issubclass() function, but the registering ABC won't show up in
    their MRO (Method Resolution Order) nor will method
    implementations defined by the registering ABC be callable (not
    even via super()).

    ABCMeta.__subclasscheck__<module abc>Returns the current ABC cache token.

    The token is an opaque object (supporting equality testing) identifying the
    current version of the ABC cache for virtual subclasses. The token changes
    with every call to ``register()`` on any ABC.
    
    A decorator indicating abstract staticmethods.

    Similar to abstractmethod.

    Usage:

        class C(metaclass=ABCMeta):
            @abstractstaticmethod
            def my_abstract_staticmethod(...):
                ...

    'abstractstaticmethod' is deprecated. Use 'staticmethod' with
    'abstractmethod' instead.
    Refusing to create an inheritance cycleABCMeta.__new__abstractpropertyAbstract Base Classes (ABCs) according to PEP 3119.abstractclassmethod.__init___abc_cacheA decorator indicating abstract methods.

    Requires that the metaclass is ABCMeta or derived from it.  A
    class that has a metaclass derived from ABCMeta cannot be
    instantiated unless all of its abstract methods are overridden.
    The abstract methods can be called using any of the normal
    'super' call mechanisms.

    Usage:

        class C(metaclass=ABCMeta):
            @abstractmethod
            def my_abstract_method(self, ...):
                ...
    Override for issubclass(subclass, cls).rclsDebug helper to print the ABC registry.funcobjOverride for isinstance(instance, cls).Register a virtual subclass of an ABC.

        Returns the subclass, to allow usage as a class decorator.
        Class: %s.%sABCMeta.__instancecheck__.<locals>.<genexpr>C:\msys64\mingw64\lib\python3.6\abc.pyHelper class that provides a standard way to create an ABC using
    inheritance.
    _abc_negative_cache_version
    A decorator indicating abstract properties.

    Requires that the metaclass is ABCMeta or derived from it.  A
    class that has a metaclass derived from ABCMeta cannot be
    instantiated unless all of its abstract properties are overridden.
    The abstract properties can be called using any of the normal
    'super' call mechanisms.

    Usage:

        class C(metaclass=ABCMeta):
            @abstractproperty
            def my_abstract_property(self):
                ...

    This defines a read-only property; you can also define a read-write
    abstract property using the 'long' form of property declaration:

        class C(metaclass=ABCMeta):
            def getx(self): ...
            def setx(self, value): ...
            x = abstractproperty(getx, setx)

    'abstractproperty' is deprecated. Use 'property' with 'abstractmethod'
    instead.
    Can only register classes_abc_invalidation_counterABCMeta.registerunselect_allTrain students to detect abnormalities through an exploratory interfacecase_selector_scroller<span font='16'>You should now understand what a normal abdomen feels like.

For this milestone, familiarize yourself with how these abnormalities feel. In the next step, you will identify them using touch and sound.</span>AbnormalityDetection.reset_pageget_iter_firstAbnormalityDetection.__init__tree_selectioncase_selector_treeiter_root<module abnormalitydetection>select_iterC:\msys64\home\cbper\abnormalitydetection.pyC:\msys64\home\cbper\additiveview.pyAdditiveView.draw_ailmentAdditiveView.draw_palpation_location<module additiveview>AdditiveView.change_ailmentAdditiveView.__init__Admin.reset_active_pagecnc_adjustercommand_to_tensionerCNCAdjustmentInterface.build_buttonSensitivityInterface.__init__Admin.show_disconnection_warningtensioner_adjustmentbutton_hboxstock_idAdmin window. Controls administration of the sim.TensionerAdjustmentInterface.build_buttonright_buttonassignment_interface<span font='12'>Base Abdomen Firmness</span>C:\msys64\home\cbper\admin.pyadjustment_labelAdmin.change_user_typearrow_table_alignmentSTOCK_GO_BACKAdmin.show_do_not_touch_modalAdmin.attach_new_case_observerClick the arrows to calibrate actuator positioning for all ailments at once.Admin.hide_disconnection_warningsensitivity_labelCNCAdjustmentInterface.arrow_handlersensitivity_interfaceminus_buttonPressure
SensitivitySensitivityInterface.reset_pageHSeparatorbutton_alignmentplus_buttonsave_buttonTensionerAdjustmentInterface.__init__STOCK_GO_UPadjustment_label_alignmentassignment_labelarrow_sizedown_buttonsettings_vboxCNCAdjustmentInterface.__init__STOCK_GO_FORWARDsensitivity_settingsBaselineAssessmentPerformanceReview.__init__Admin.__init__STOCK_GO_DOWNup_buttonleft_button<span font='10'>{label_text}</span>Save Tensionset_image<module admin>View/Edit
AssignmentAilment DetectionNo current assignmentCurrent Assignment: {assignment_name}CurrentAssignment.get_from_fileC:\msys64\home\cbper\adminassignment.pyassignment_dictBaseline assessment onlyAdminAssignment.build_interface_partsbaselineailments_buttonset_positiontreeViewrenderer_textconfig_dict_from_file_DETECTION_ONLYset_rules_hintget_assignment_nameexams_BASELINE_AND_DETECTIONUsing assignment found in Baseline assessment and abnormality detectionSet up assessment assignmentassignment_type_labelSHADOW_ETCHED_INcreate_modelon_row_changeovboxAssignmentTypeInterface.connect_baseline_buttonchange_tonext_interfaceTime CompletedAssignmentTypeInterface.__init__exam_view_resources_DEFAULT_ASSIGNMENTCurrentAssignment.get_assignment_nameViewBaselineAssessments.build_logoStudents report the findings they detect in the abdomen.save_new_baseline_assignmentAdminAssignment.change_toassignment.jsonAdminAssignment.reset_pageCurrentAssignment.save_new_baseline_assignmentassign_assessment_buttonView AssessmentsExam IDViewBaselineAssessments.create_columnsassignment_namesMake a new assignmentcurrent_assignment_labelViewBaselineAssessments.on_row_changeset_resizableSimple assessment of depth and coverage of all required ailments.ellipsizeconnect_ailments_buttonAssign what type of assessment?baseline_labelCurrentAssignment.dict_contains_required_valuesViewBaselineAssessments.__init__Abnormality detection onlyWIN_POS_CENTERcurrent_assignment_nameconnect_new_assignment_buttonassignment_type_interfaceset_assignment_textViewBaselineAssessments.create_modelAssignmentTypeInterface.connect_ailments_buttonInitializing assignment to AdminAssignment.__init__ailments_labelViewCurrentAssignmentconfig_handlerAdminAssignment.assemble_interface<module adminassignment>ViewCurrentAssignment.connect_new_assignment_buttonset_sort_column_idNothing is currently assigned.AdminAssignment.new_baseline_assignmentELLIPSIZE_END_BASELINE_ONLYViewCurrentAssignment.set_assignment_textcurrent_assignment_interface_NO_ASSIGNMENTViewCurrentAssignment.__init__baseline_and_detectionAilments.get_active_ailmentnew_ailment_string
Ailments models the selection and depth of an ailment
Ailments.get_pushback_stateAilments.get_stateAilments._calculate_stateaortanew_ailment_list_ailments_array<module ailments>Ailments.set_active_ailmentInvalid ailment: Ailments.__init__Ailments.get_max_stateAilments.state_has_changedAilments.get_depthC:\msys64\home\cbper\ailments.py_expand_help%r is not callablemutually exclusive arguments must be optionalinvocation_length_optionalsinvalid conflict_resolution value: %rarg_strings_patternarg_countsaction_conflicts_ActionsContainer._get_optional_kwargsoption_string(-*A[A-]*)ArgumentParser.add_subparsersHelpFormatter._format_usageHelp message formatter which retains formatting of all help text.

    Only the name of this class is considered a public API. All the methods
    provided by the class are considered an implementation detail.
    _metavar_formatternargs for append actions must be > 0; if arg strings are not supplying the value to append, the append const action may be more appropriatenew_arg_stringsHelpFormatter._metavar_formatterHelpFormatter.add_text^-\d+$|^-\d*\.\d+$invocations_AppendAction.__init__default_metavar[%s [%s ...]]get_subactionsconflict_actioninvalid %(type)s value: %(value)rcan't open '%s': %ssuper_initFileType.__init__add_parserHelpFormatter._split_linesdefaulting_nargsregistry_nameargument %(argument_name)s: %(message)s©ÚselfÚprogÚusageÚdescriptionÚepilogÚparentsÚformatter_classÚprefix_charsÚfromfile_prefix_charsÚargument_defaultÚconflict_handlerÚadd_helpÚallow_abbrevÚ	superinitÚ	add_groupÚidentityÚdefault_prefixÚparentÚdefaultsÚ	__class___ActionsContainer.registerArgumentParser.parse_argspositional argumentsconflicting option strings: %sdest_option_string_get_subactionsnew_count_get_kwargsseen_non_default_actionsnot allowed with argument %s_HelpActionget_invocationaction_lengthMetavarTypeHelpFormatter._get_default_metavar_for_positional%(prog)s_SubParsersAction.__init___AppendConstAction.__call___AttributeHolder.__repr__%(default)ArgumentParser._parse_known_argstuple_size_ActionsContainer._remove_actionitem_helpexpected at most one argumentArgumentParser._match_arguments_partial_ActionsContainer._check_conflictRawTextHelpFormatter._split_linesFormatter for generating usage messages and argument help strings.

    Only the name of this class is considered a public API. All the methods
    provided by the class are considered an implementation detail.
    match_partial_ChoicesPseudoActionHelpFormatter._get_default_metavar_for_optionalArgumentParser.print_usageHelpFormatter._expand_helpget_metavar_AppendConstAction.__init__action_widthnargs must be %r to supply constarg_lineArgumentParser.__init__.<locals>.identityC:\msys64\mingw64\lib\python3.6\argparse.pyHelpFormatter._fill_text_add_actionone of the arguments %s is requiredlong_option_stringsnargs_patternstart_indexsubnamespace_MutuallyExclusiveGroup._remove_actionunrecognized arguments: %s_pop_action_class_CountAction.__call__short_explicit_argArgumentTypeErrorArgumentDefaultsHelpFormatterRawDescriptionHelpFormatterONE_OR_MOREOPTIONALPARSERREMAINDERZERO_OR_MOREconflicting_actionsconflict_string(-*[A-]*)_dedentunexpected option string: %s
        add_argument(dest, ..., name=value, ...)
        add_argument(option_string, option_string, ..., name=value, ...)
        _StoreAction'required' is an invalid argument for positionalsHelpFormatter._format_actions_usagecannot merge actions - two groups are named %r_get_help_string_ArgumentGroupargs_stringArgumentParser._read_args_from_filesconsume_optional©Ústart_indexÚoption_tupleÚactionÚoption_stringÚexplicit_argÚmatch_argumentÚaction_tuplesÚ	arg_countÚcharsÚcharÚnew_explicit_argÚoptionals_mapÚmsgÚstopÚargsÚstartÚselected_patternsÚoption_string_indicesÚselfÚextrasÚarg_stringsÚarg_strings_patternÚtake_action_containerend_sectionconsume_positionalsoption_tuples\(([^|]*)\)part_strings_SubParsersAction.add_parserFileType.__repr__group_map_registries_bufsize_add_item_iter_indented_subactionsexpected one argument_SubParsersAction._get_subactions_StoreTrueActioninvalid option string %(option)r: must start with a character %(prefix_chars)r_get_positional_kwargs==SUPPRESS==ArgumentParser._get_valuehandler_func_name_ActionsContainer.add_mutually_exclusive_group_parse_optionalgroup_actions_root_sectionHelpFormatter._dedentunknown parser %(parser_name)r (choices: %(choices)s)ambiguous option: %(option)s could match %(matches)s_get_optional_actionscannot have multiple subparser argumentsoptional arguments_AppendAction.__call___option_string_actions_handle_conflict_resolve_ActionsContainer._registry_gettype_funcHelpFormatter._Section_add_container_actions_ActionsContainer._get_positional_kwargsHelpFormatter._Section.format_help_action_max_lengthArgumentParser._parse_optionalArgumentParser._check_valueFileType.__call__HelpFormatter._Section.__init__HelpFormatter.format_helpdest= is required for options like %rthe following arguments are required: %s_ActionsContainer._add_actionnargs for store actions must be > 0; if you have nothing to store, actions such as store true or store const may be more appropriate_parser_classtitle_group_mapSimple object for storing attributes.

    Implements equality by attribute names and values, and provides a simple
    string representation.
    _join_partsArgumentParser._get_optional_actionschoice_strs©"ÚselfÚarg_stringsÚ	namespaceÚaction_conflictsÚmutex_groupÚgroup_actionsÚiÚmutex_actionÚ	conflictsÚoption_string_indicesÚarg_string_pattern_partsÚarg_strings_iterÚ
arg_stringÚoption_tupleÚpatternÚarg_strings_patternÚseen_actionsÚseen_non_default_actionsÚtake_actionÚconsume_optionalÚpositionalsÚconsume_positionalsÚextrasÚstart_indexÚmax_option_string_indexÚnext_option_string_indexÚpositionals_end_indexÚstringsÚ
stop_indexÚrequired_actionsÚactionÚgroupÚnamesÚmsgAn error from trying to convert a command line string to a type._indent_increment_SubParsersAction.__call__choice_action%(prog)s: error: %(message)s
_ensure_value(-*A-*)Information about how to convert command line strings to Python objects.

    Action objects are used by an ArgumentParser to represent the information
    needed to parse a single argument from one or more strings from the
    command line. The keyword arguments to the Action constructor are also
    all attributes of Action instances.

    Keyword Arguments:

        - option_strings -- A list of command-line option strings which
            should be associated with this action.

        - dest -- The name of the attribute to hold the created object(s)

        - nargs -- The number of command-line arguments that should be
            consumed. By default, one argument will be consumed and a single
            value will be produced.  Other values include:
                - N (an integer) consumes N arguments (and produces a list)
                - '?' consumes zero or one arguments
                - '*' consumes zero or more arguments (and produces a list)
                - '+' consumes one or more arguments (and produces a list)
            Note that the difference between the default and nargs=1 is that
            with the default, a single value will be produced, while with
            nargs=1, a list containing a single value will be produced.

        - const -- The value to be produced if the option is specified and the
            option uses an action that takes no values.

        - default -- The value to be produced if the option is not specified.

        - type -- A callable that accepts a single string argument, and
            returns the converted value.  The standard Python types str, int,
            float, and complex are useful examples of such callables.  If None,
            str is used.

        - choices -- A container of values that should be allowed. If not None,
            after a command-line argument has been converted to the appropriate
            type, an exception will be raised if it is not a member of this
            collection.

        - required -- True if the action must always be specified at the
            command line. This is only meaningful for optional command-line
            arguments.

        - help -- The help string describing the argument.

        - metavar -- The name to be used for the option's argument with the
            help string. If None, the 'dest' value will be used as the name.
    HelpFormatter.add_arguments_print_messageArgumentParser.error_current_section\(.*?\)+|\[.*?\]+|\S+unknown action "%s"\n\n\n+conflicting option string: %sAn error from creating or using an argument (optional or positional).

    The string value of this exception is the message, augmented with
    information about the argument that caused it.
    Help message formatter which uses the argument 'type' as the default
    metavar value (instead of the argument 'dest')

    Only the name of this class is considered a public API. All the methods
    provided by the class are considered an implementation detail.
    _MutuallyExclusiveGroup.__init__subcommands_get_action_name[\[(]_get_positional_actionsHelpFormatter._format_action_invocation_ActionsContainer.add_argument_ActionsContainer.__init__ArgumentParser._get_kwargs_CountAction.__init__Help message formatter which retains any formatting in descriptions.

    Only the name of this class is considered a public API. All the methods
    provided by the class are considered an implementation detail.
    (-*%s-*)HelpFormatter._join_partsexpected at least one argument_has_negative_number_optionals©ÚselfÚusageÚactionsÚgroupsÚprefixÚprogÚ	optionalsÚpositionalsÚactionÚformatÚaction_usageÚ
text_widthÚpart_regexpÚ	opt_usageÚ	pos_usageÚ	opt_partsÚ	pos_partsÚ	get_linesÚindentÚlinesÚparts_whitespace_matcherargument "-" with mode %r_action_groupsactions_slice_ActionsContainer.get_defaultArgumentError.__init___handle_conflict_%s_choices_actionsaction_headerArgumentParser._get_positional_actionsoption_prefixshort_option_prefixstar_args_get_option_tuples_format_argsArgumentParser._get_option_tupleschoices_strArgumentParser._parse_known_args.<locals>.consume_optionalRawDescriptionHelpFormatter._fill_textadd_usage_negative_number_matcher_AttributeHolder._get_kwargs (default: %(default)s)expected %s arguments_SubParsersAction._ChoicesPseudoAction.__init___MutuallyExclusiveGroup._add_action_prog_prefix_StoreFalseAction_get_valuesNamespace.__eq__<module argparse>_StoreFalseAction.__init__.__call__() not definedHelpFormatter._get_help_string_get_handler_get_nargs_patternRawDescriptionHelpFormatter._fill_text.<locals>.<genexpr>_StoreAction.__init__Namespace.__contains___textwraplength of metavar tuple does not match nargs_StoreConstAction.__call__HelpFormatter._iter_indented_subactionsArgumentParser.format_usageline_len_VersionAction.__init___levelHelpFormatter.end_sectionMetavarTypeHelpFormatter._get_default_metavar_for_optionalinvalid choice: %(value)r (choose from %(choices)s)error(message: string)

        Prints a usage message incorporating the message to stderr and
        exits.

        If you override this in a subclass, it should not return -- it
        should either exit or raise an exception.
        insertsArgumentParser._parse_known_args.<locals>.consume_positionals_unrecognized_argsA..._get_formatter_defaults_ActionsContainer.add_argument_groupObject for parsing command line strings into Python objects.

    Keyword Arguments:
        - prog -- The name of the program (default: sys.argv[0])
        - usage -- A usage message (default: auto-generated from arguments)
        - description -- A description of what the program does
        - epilog -- Text following the argument descriptions
        - parents -- Parsers whose arguments should be copied into this one
        - formatter_class -- HelpFormatter class for printing help messages
        - prefix_chars -- Characters that prefix optional arguments
        - fromfile_prefix_chars -- Characters that prefix files containing
            additional arguments
        - argument_default -- The default value for all arguments
        - conflict_handler -- String indicating how to handle conflicts
        - add_help -- Add a -h/-help option
        - allow_abbrev -- Allow long options to be abbreviated unambiguously
    _HelpAction.__init___ActionsContainer._handle_conflict_error_ArgumentGroup.__init___group_actionsargument_strings_ActionsContainer.set_defaultsArgumentParser.format_helpHelpFormatter._add_itemHelpFormatter.add_usageconfl_optionalsargs_filestart_section_StoreConstAction.__init__HelpFormatter._format_usage.<locals>.get_linesconvert_arg_line_to_argsArgumentParser._get_valuesparsers_class_StoreTrueAction.__init___max_help_positionFactory for creating file object types

    Instances of FileType are typically passed as type= arguments to the
    ArgumentParser add_argument() method.

    Keyword Arguments:
        - mode -- A string indicating how the file is to be opened. Accepts the
            same values as the builtin open() function.
        - bufsize -- The file's desired buffer size. Accepts the same values as
            the builtin open() function.
        - encoding -- The file's encoding. Accepts the same values as the
            builtin open() function.
        - errors -- A string indicating how encoding and decoding errors are to
            be handled. Accepts the same value as the builtin open() function.
    (-*A?-*)_long_break_matcherignored explicit argument %r_AttributeHolder._get_argsnargs_errors[\])]ArgumentDefaultsHelpFormatter._get_help_stringArgumentParser.print_helpHelpFormatter.start_section_UNRECOGNIZED_ARGS_ATTRArgumentParser._get_formatter([-AO]*)%s *%sAbstract base class that provides __repr__.

    The __repr__ method returns a string in the format::
        ClassName(attr=name, attr=name, ...)
    The attributes are determined either by a class-level attribute,
    '_kwarg_names', or by inspecting the instance __dict__.
    Command-line parsing library

This module is an optparse-inspired command-line parsing library that:

    - handles both optional and positional arguments
    - produces highly informative usage messages
    - supports parsers that dispatch to sub-parsers

The following is a simple usage example that sums integers from the
command-line and writes the result to a file::

    parser = argparse.ArgumentParser(
        description='sum the integers at the command line')
    parser.add_argument(
        'integers', metavar='int', nargs='+', type=int,
        help='an integer to be summed')
    parser.add_argument(
        '--log', default=sys.stdout, type=argparse.FileType('w'),
        help='the file where the sum should be written')
    args = parser.parse_args()
    args.log.write('%s' % sum(args.integers))
    args.log.close()

The module contains the following public classes:

    - ArgumentParser -- The main entry point for command-line parsing. As the
        example above shows, the add_argument() method is used to populate
        the parser with actions for optional and positional arguments. Then
        the parse_args() method is invoked to convert the args at the
        command-line into an object with attributes.

    - ArgumentError -- The exception raised by ArgumentParser objects when
        there are errors with the parser's actions. Errors raised while
        parsing the command-line are caught by ArgumentParser and emitted
        as command-line messages.

    - FileType -- A factory for defining types of files to be created. As the
        example above shows, instances of FileType are typically passed as
        the type= argument of add_argument() calls.

    - Action -- The base class for parser actions. Typically actions are
        selected by passing strings like 'store_true' or 'append_const' to
        the action= argument of add_argument(). However, for greater
        customization of ArgumentParser actions, subclasses of Action may
        be defined and passed as the action= argument.

    - HelpFormatter, RawDescriptionHelpFormatter, RawTextHelpFormatter,
        ArgumentDefaultsHelpFormatter -- Formatter classes which
        may be passed as the formatter_class= argument to the
        ArgumentParser constructor. HelpFormatter is the default,
        RawDescriptionHelpFormatter and RawTextHelpFormatter tell the parser
        not to change the formatting for help text, and
        ArgumentDefaultsHelpFormatter adds information about argument defaults
        to the help.

All other classes in this module are considered implementation details.
(Also note that HelpFormatter and RawDescriptionHelpFormatter are only
considered public as object names -- the API of the formatter objects is
still considered an implementation detail.)
ArgumentParser._get_nargs_patternHelp message formatter which adds default values to argument help.

    Only the name of this class is considered a public API. All the methods
    provided by the class are considered an implementation detail.
    ArgumentParser.exit_HelpAction.__call___ArgumentGroup._remove_action_ActionsContainer._get_handlerAction._get_kwargs_ArgumentGroup._add_actionArgumentParser._add_action%s%s

_mutually_exclusive_groups_current_indent_ActionsContainer._handle_conflict_resolveArgumentParser.parse_known_argsdest supplied twice for positional argumentArgumentParser.convert_arg_line_to_args_ActionsContainer._pop_action_class_VersionAction.__call___ActionsContainer._add_container_actions_StoreAction.__call__HelpFormatter._format_argsArgumentParser._print_messageHelpFormatter._indentArgumentError.__str___name_parser_mapHelpFormatter._metavar_formatter.<locals>.formatArgumentParser._parse_known_args.<locals>.take_action(-*A[-AO]*)student_interfaceAbnormalityDetectionAssessment.reset_pageAbnormalityDetectionAssessmentStudentInterface.__init__correct_pretty_name<span font='16'>Waiting for input from instructor...</span>FacultyLedAssessment.reset_active_pagesett_menuitemFacultyBaselineAssessment.init_student_window<span font='20'>Select an ailment.

The student will select detected findings. The student's abdominal exam will be scored for depth and coverage, as well as correctness of detected findings.</span>settings_menumenu_barset_submenuquit_menuitem<span font='22'>The instructor will select findings for you to elicit.

When the sim is ready, perform an abdominal examination. Click what you find.</span>on_student_selected_ddxFacultyLedAssessment.__init__<span font='16'>Perform an abdominal examination using deep palpation.

Your exam's depth and coverage will be scored.</span>FacultyLedAssessment.clear_student_windowfeedback_hboxcorrectness_labelfinding_chosen_callbackgiven_pretty_namegiven_correct_nameFacultyLedAssessment.show_do_not_touch_modalAbnormality Detectionwaiting_labelScore Examination CoverageFacultyLedAssessment.build_windowFacultyBaselineAssessment.reveal_button_pressedAbSim Assessment - Faculty InterfaceReset for New AssessmentAbnormalityDetectionAssessmentStudentInterface.set_correctness_textactivatesaved_pressurepointsstudent_done_buttonFacultyBaselineAssessment.__init__<span font='22'>The student selected {given_pretty_name}.
The correct selection was {given_correct_name} .</span><span font='28'>You selected {given_ddx}.

Waiting for instructor input...</span>AbnormalityDetectionAssessmentStudentInterface.show_feedbackFacultyBaselineAssessment.reset_pagesaved_resources<span font='22'>When the simulator is ready, the student should perform an abdominal exam.

When the student is finished, click Done to view the analysis.</span><module assessment>FacultyLedAssessment.build_menu_barMenuItemFacultyBaselineAssessment.new_learner_button_pressedstudent_vboxcoverage_labelAbSim Assessment - Student InterfaceAbnormalityDetectionAssessmentStudentInterface.on_next_case_buttonanalysis_labelget_childrenFacultyLedAssessment.change_user_typeAbnormalityDetectionAssessment.on_student_selected_ddxC:\msys64\home\cbper\assessment.pyAbnormalityDetectionAssessment.on_new_casestudent_labelAbnormalityDetectionAssessment.__init__Main window used by faculty to control the sim and view the student's performance.FacultyLedAssessment.attach_new_case_observerset_destroy_with_parentStart Over<module assignedassessment>timestrCoverageAssessmentModel.save_to_dbCoverageAssessmentModel.__init__<span font='28'>Welcome!

Please enter your ID and perform an abdominal exam on AbSim.

When you are finished with the examination, click Save Exam.</span>Could not get all assessmentsYou have finished the baseline assessment.BaselineAssessment.show_layoutBaselineAssessment.start_over_button_pressedBaselineAssessment.build_layoutAssignedAssessment.show_disconnection_warningsave_examstart over button: %Y%m%d-%H%M%Ssave_button_pressedCoverageAssessmentModel.get_allstudent_idstudent_id_entrydb updatedprot2fetchallstarting over?add_identifying_data_to_exam_dataAssignedAssessment.change_user_typeCould not save assessment for 
            SELECT exam_id, student_id, time_in
            FROM coverage_assessments
            ORDER BY time_in desc
        pfileAssignedAssessment.reset_active_pageid_stringsensor is connected
            INSERT INTO coverage_assessments
            (student_id, time_in, coverage)
            VALUES (?, ?, ?)
        tuple_listsid_labelpickled_coverageexam_listtext_factoryrollbackBaselineAssessment.make_sure_path_existsAssignedAssessment.__init__BaselineAssessment.save_button_pressedAssignedAssessment.show_do_not_touch_modalCoverageAssessmentModel.get_by_exam_idget_textset_max_lengthBaselineAssessment.save_examBaselineAssessment.add_identifying_data_to_exam_dataAssignedAssessment.attach_new_case_observerlabel_vboxbaseline_assessmentAssignedAssessment.hide_disconnection_warning
            SELECT exam_id, student_id, time_in, coverage
            FROM coverage_assessments
            WHERE exam_id=?
        sid_hboxCoverageAssessmentModel.connectC:\msys64\home\cbper\assignedassessment.py_attributes
    A node visitor base class that walks the abstract syntax tree and calls a
    visitor function for every node found.  This function may return a value
    which is forwarded by the `visit` method.

    This class is meant to be subclassed, with the subclass adding visitor
    methods.

    Per default the visitor functions for the nodes are ``'visit_'`` +
    class name of the node.  So a `TryFinally` node visit function would
    be `visit_TryFinally`.  This behavior can be changed by overriding
    the `visit` method.  If no visitor function exists for a node
    (return value `None`) the `generic_visit` visitor is used instead.

    Don't use the `NodeVisitor` if you want to apply changes to nodes during
    traversing.  For this a special visitor exists (`NodeTransformer`) that
    allows modifications.
    include_attributes
    Recursively yield all descendant nodes in the tree starting at *node*
    (including *node* itself), in no specified order.  This is useful if you
    only want to modify nodes in place and don't care about the context.
    new_valuesannotate_fields_astNodeTransformer.generic_visit<module ast>
    Copy source location (`lineno` and `col_offset` attributes) from
    *old_node* to *new_node* if possible, and return *new_node*.
    _NUM_TYPEStodo
    Yield a tuple of ``(fieldname, value)`` for each field in ``node._fields``
    that is present on *node*.
    %r can't have docstringsget_docstring
    Return a formatted dump of the tree in *node*.  This is mainly useful for
    debugging purposes.  The returned string will show the names and the values
    for fields.  This makes the code impossible to evaluate, so if evaluation is
    wanted *annotate_fields* must be set to False.  Attributes such as line
    numbers and column offsets are not dumped by default.  If this is wanted,
    *include_attributes* can be set to True.
    expected AST, got %rExpressionPyCF_ONLY_AST
    ast
    ~~~

    The `ast` module helps Python applications to process trees of the Python
    abstract syntax grammar.  The abstract syntax itself might change with
    each Python release; this module helps to find out programmatically what
    the current grammar looks like and allows modifications of it.

    An abstract syntax tree can be generated by passing `ast.PyCF_ONLY_AST` as
    a flag to the `compile()` builtin function or by using the `parse()`
    function from this module.  The result will be a tree of objects whose
    classes all inherit from `ast.AST`.

    A modified abstract syntax tree can be compiled into a Python code object
    using the built-in `compile()` function.

    Additionally various helper functions are provided that make working with
    the trees simpler.  The main intention of the helper functions and this
    module in general is to provide an easy to use interface for libraries
    that work tightly with the python syntax (template engines for example).


    :copyright: Copyright 2008 by Armin Ronacher.
    :license: Python License.
literal_eval.<locals>._convert.<locals>.<genexpr>fix_missing_locations.<locals>._fixdump.<locals>._formatCalled if no explicit visitor function exists for a node.node_or_stringcopy_locationNodeVisitor.generic_visit
    A :class:`NodeVisitor` subclass that walks the abstract syntax tree and
    allows modification of nodes.

    The `NodeTransformer` will walk the AST and use the return value of the
    visitor methods to replace or remove the old node.  If the return value of
    the visitor method is ``None``, the node will be removed from its location,
    otherwise it is replaced with the return value.  The return value may be the
    original node in which case no replacement takes place.

    Here is an example transformer that rewrites all occurrences of name lookups
    (``foo``) to ``data['foo']``::

       class RewriteName(NodeTransformer):

           def visit_Name(self, node):
               return copy_location(Subscript(
                   value=Name(id='data', ctx=Load()),
                   slice=Index(value=Str(s=node.id)),
                   ctx=node.ctx
               ), node)

    Keep in mind that if the node you're operating on has child nodes you must
    either transform the child nodes yourself or call the :meth:`generic_visit`
    method for the node first.

    For nodes that were part of a collection of statements (that applies to all
    statement nodes), the visitor may also return a list of nodes rather than
    just a single node.

    Usually you use the transformer like this::

       node = YourTransformer().visit(node)
    
    Safely evaluate an expression node or a string containing a Python
    expression.  The string or node provided may only consist of the following
    Python literal structures: strings, bytes, numbers, tuples, lists, dicts,
    sets, booleans, and None.
    
    Yield all direct child nodes of *node*, that is, all fields that are nodes
    and all items of fields that are lists of nodes.
    malformed node or string: NodeVisitor.visitdump.<locals>._format.<locals>.<genexpr>
    When you compile a node tree with compile(), the compiler expects lineno and
    col_offset attributes for every node that supports them.  This is rather
    tedious to fill in for generated nodes, so this helper adds these attributes
    recursively where not already set, by setting them to the values of the
    parent node.  It works recursively starting at *node*.
    
    Return the docstring for the given node or None if no docstring can
    be found.  If the node provided does not have docstrings a TypeError
    will be raised.
    Visit a node.%s(%s
    Increment the line number of each node in the tree starting at *node* by *n*.
    This is useful to "move code" to a different location in a file.
    C:\msys64\mingw64\lib\python3.6\ast.py
    Parse the source into an AST node.
    Equivalent to compile(source, filename, mode, PyCF_ONLY_AST).
    chars2foldnulsfoldspaces!%dIexpected bytes-like object, not %sBase16, Base32, Base64 (RFC 3548), Base85 and Ascii85 data encodings^[A-Za-z0-9+/]*={0,2}$expected 1-D data, not %d-D data from %sb85decode<~b32encodeEncode a bytestring into a bytes object containing multiple lines
    of base-64 data._85encodey inside Ascii85 5-tupleignorecharsDecode the Base32 encoded bytes-like object or ASCII string s.

    Optional casefold is a flag specifying whether a lowercase alphabet is
    acceptable as input.  For security purposes, the default is False.

    RFC 3548 allows for optional mapping of the digit 0 (zero) to the
    letter O (oh), and for optional mapping of the digit 1 (one) to
    either the letter I (eye) or letter L (el).  The optional argument
    map01 when not None, specifies which letter the digit 1 should be
    mapped to (when map01 is not None, the digit 0 is always mapped to
    the letter O).  For security purposes the default is None, so that
    0 and 1 are not allowed in the input.

    The result is returned as a bytes object.  A binascii.Error is raised if
    the input is incorrectly padded or if there are non-alphabet
    characters present in the input.
    Decode the Ascii85 encoded bytes-like object or ASCII string b.

    foldspaces is a flag that specifies whether the 'y' short sequence should be
    accepted as shorthand for 4 consecutive spaces (ASCII 0x20). This feature is
    not supported by the "standard" Adobe encoding.

    adobe controls whether the input sequence is in Adobe Ascii85 format (i.e.
    is framed with <~ and ~>).

    ignorechars should be a byte string containing characters to ignore from the
    input. This should only contain whitespace characters, and by default
    contains all whitespace characters in ASCII.

    The result is returned as a bytes object.
    curr_append 	
_b85decDecode bytes encoded with the standard Base64 alphabet.

    Argument s is a bytes-like object or ASCII string to decode.  The result
    is returned as a bytes object.  A binascii.Error is raised if the input
    is incorrectly padded.  Characters that are not in the standard alphabet
    are discarded prior to the padding check.
    padcharsb32revquanta-_b16encode_b32alphabetdecoded_appendNon-base32 digit foundAladdin:open sesameb32decodeDecode the base85-encoded bytes-like object or ASCII string b

    The result is returned as a bytes object.
    curr_clear_b32tab2Encode the bytes-like object s using Base64 and return a bytes object.

    Optional altchars should be a byte string of length 2 which specifies an
    alternative alphabet for the '+' and '/' characters.  This allows an
    application to e.g. generate url or filesystem safe Base64 strings.
    base85 overflow in hunk starting at byte %dEncode bytes-like object b in base85 format and return a bytes object.

    If pad is true, the input is padded with b'\0' so its length is a multiple of
    4 bytes before encoding.
    wrapcolb16decode_a85chars!INon-base64 digit foundargument should be a bytes-like object or ASCII string, not %rIncorrect paddingEncode bytes-like object b using Ascii85 and return a bytes object.

    foldspaces is an optional flag that uses the special short sequence 'y'
    instead of 4 consecutive spaces (ASCII 0x20) as supported by 'btoa'. This
    feature is not supported by the "standard" Adobe encoding.

    wrapcol controls whether the output should have newline (b'\n') characters
    added to it. If this is non-zero, each output line will be at most this
    many characters long.

    pad controls whether the input is padded to a multiple of 4 before
    encoding. Note that the btoa implementation always pads.

    adobe controls whether the encoded byte sequence is framed with <~ and ~>,
    which is used by the Adobe implementation.
    a85decodeNon-base16 digit foundABCDEFGHIJKLMNOPQRSTUVWXYZ234567deut_b85chars2_bytes_from_decode_datapackIa85encode_urlsafe_decode_translationC:\msys64\mingw64\lib\python3.6\base64.pyuuuuÛ   NNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNb85encodestandard_b64decodeurlsafe_b64encodeurlsafe_b64decode====MAXBINSIZE_a85chars2hexlify0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz!#$%&()*+-;<=>?@^_`{|}~b'Aladdin:open sesame'string argument should contain only ASCII charactersLegacy alias of decodebytes().======Ascii85 overflowEncode the bytes-like object s using Base32 and return a bytes object.
    Decode bytes using the URL- and filesystem-safe Base64 alphabet.

    Argument s is a bytes-like object or ASCII string to decode.  The result
    is returned as a bytes object.  A binascii.Error is raised if the input
    is incorrectly padded.  Characters that are not in the URL-safe base-64
    alphabet, and are not a plus '+' or slash '/', are discarded prior to the
    padding check.

    The alphabet uses '-' instead of '+' and '_' instead of '/'.
    expected single byte elements, not %r from %sLegacy alias of encodebytes().Decode the Base16 encoded bytes-like object or ASCII string s.

    Optional casefold is a flag specifying whether a lowercase alphabet is
    acceptable as input.  For security purposes, the default is False.

    The result is returned as a bytes object.  A binascii.Error is raised if
    s is incorrectly padded or if there are non-alphabet characters present
    in the input.
    Decode a bytestring of base-64 data into a bytes object.bad base85 character at position %d_input_type_checkAscii85 encoded byte sequences must end with {!r}Non-Ascii85 digit found: %cdecodestring() is a deprecated alias since Python 3.1, use decodebytes()Small main programunhexlifyndimDecode the Base64 encoded bytes-like object or ASCII string s.

    Optional altchars must be a bytes-like object or ASCII string of length 2
    which specifies the alternative alphabet used instead of the '+' and '/'
    characters.

    The result is returned as a bytes object.  A binascii.Error is raised if
    s is incorrectly padded.

    If validate is False (the default), characters that are neither in the
    normal base-64 alphabet nor the alternative alphabet are discarded prior
    to the padding check.  If validate is True, these non-alphabet characters
    in the input result in a binascii.Error.
    Decode a file; input and output are binary files._A85ENDEncode the bytes-like object s using Base16 and return a bytes object.
    encodestring() is a deprecated alias since 3.1, use encodebytes()Encode bytes-like object s using the standard Base64 alphabet.

    The result is returned as a bytes object.
    Encode bytes using the URL- and filesystem-safe Base64 alphabet.

    Argument s is a bytes-like object to encode.  The result is returned as a
    bytes object.  The alphabet uses '-' instead of '+' and '_' instead of
    '/'.
    usage: %s [-d|-e|-u|-t] [file|-]
        -d, -u: decode
        -e: encode (default)
        -t: encode and decode string 'Aladdin:open sesame'Encode a file; input and output are binary files.z inside Ascii85 5-tuple<module base64>_b85alphabet_urlsafe_encode_translation_b32rev_A85START[^0-9A-F]BdbQuitdispatch_lineLine %s:%d does not existBreakpoint.deleteMestopframereturnframestoplinenocaller_frameStop on the next line in or below the given frame.import bdb; bdb.foo(10)Bdb.runctxBdb.stop_here%-4dbreakpoint   %s at %s:%dBdb.user_exceptionBreakpoint class.

    Implements temporary breakpoints, ignore counts, disabling and
    (re)-enabling, and conditionals.

    Breakpoints are indexed by number through bpbynumber and by
    the file,line tuple using bplist.  The former points to a
    single instance of class Breakpoint.  The latter points to a
    list of such instances since there may be more than one
    breakpoint per line.

    bdb.Bdb.dispatch: unknown debugging event:no   dispatch_returnBreakpoint.bpprintpossiblesTdb.user_returnbreakpoint %s at %s:%sc_exceptionfunc_first_executable_linec_returnBreakpoint.__str__Bdb.set_until
	breakpoint already hit %d time%sBdb.do_clearexc_stuff+++ returnC:\msys64\mingw64\lib\python3.6\bdb.pyf_trace<module bdb>Bdb.runevalis_skipped_moduleException to give up completely.Bdb.get_breakBdb.user_callBdb.user_returnblistbreak_anywhereThere are no breakpointsBdb.clear_all_breaksBreakpoint.bpformatThere are no breakpoints in %sBdb._prune_breaksBdb.break_herebar returned
	ignore next %d hitsTdb.user_line+++ callclear_all_file_breaksdispatch_callBdb.clear_breakBdb.trace_dispatchlprefixStop when returning from the given frame.Bdb.clear_bpbynumberquittingBdb.set_returnBdb.set_breakBreakpoint.disablec_callBdb.clear_all_file_breaksBdb.resetyes  Bdb.get_stackBdb.dispatch_exceptionBdb.get_file_breaksThis method is called if an exception occurs,
        but only if we are to stop at or just below this level.Bdb.set_tracesubclass of bdb must implement do_clear()Check whether we should break here because of `b.funcname`.Bdb.__init__Stop when the line with the line no greater than the current one is
        reached or when returning from current framedel  Tdb.user_callStart debugging from `frame`.

        If frame is not specified, debugging starts from caller's frame.
        botframeBdb.runcallBdb.set_stepThere is no breakpoint at %s:%dBdb.set_nextBreakpoint %d already deletedBdb.dispatch_callBdb.user_linebar(Generic Python debugger base class.

    This class takes care of details of the trace facility;
    a derived class should implement user interaction.
    The standard debugger class (pdb.Pdb) is an example.
    Bdb.dispatch_returnBdb.format_stack_entryBreakpoint number %d out of rangeBdb.set_quitframe_returningBreakpoint.enableThis method is called when we stop or break at this line.
	stop only if %sfncache__args__Bdb.get_bpbynumbercheckfuncnameBdb._set_stopinfoGENERATOR_AND_COROUTINE_FLAGSBdb.get_breaks+++ exceptionget_all_breaksThis method is called when a return trap is set here.Bdb.get_all_breaksBdb.dispatch_lineBdb.break_anywhereBdb.canonicNon-numeric breakpoint number %sDebugger basicsBdb.set_continueBdb.is_skipped_moduleDetermine which breakpoint for this file:line is to be acted upon.

    Called only if we know there is a bpt at this
    location.  Returns breakpoint that was triggered and a flag
    that indicates if it is ok to delete a temporary bp.

    Tdb.user_exceptionBreakpoint.__init__Stop after one line of code.insort_rightInsert item x in list a, and keep it sorted assuming a is sorted.

    If x is already in a, insert it to the left of the leftmost x.

    Optional args lo (default 0) and hi (default len(a)) bound the
    slice of a to be searched.
    lo must be non-negativeReturn the index where to insert item x in list a, assuming a is sorted.

    The return value i is such that all e in a[:i] have e < x, and all e in
    a[i:] have e >= x.  So if x already appears in the list, a.insert(x) will
    insert just before the leftmost x already there.

    Optional args lo (default 0) and hi (default len(a)) bound the
    slice of a to be searched.
    bisect_rightReturn the index where to insert item x in list a, assuming a is sorted.

    The return value i is such that all e in a[:i] have e <= x, and all e in
    a[i:] have e > x.  So if x already appears in the list, a.insert(x) will
    insert just after the rightmost x already there.

    Optional args lo (default 0) and hi (default len(a)) bound the
    slice of a to be searched.
    insort_leftBisection algorithms.<module bisect>Insert item x in list a, and keep it sorted assuming a is sorted.

    If x is already in a, insert it to the right of the rightmost x.

    Optional args lo (default 0) and hi (default len(a)) bound the
    slice of a to be searched.
    C:\msys64\mingw64\lib\python3.6\bisect.pyC:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\buildC:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\build\__init__.py_getPythonForSconsExePathscons_pathscons_commandold_pythonpathold_pythonhome Find Python2 on Windows.

    First try a few guesses, the look into registry for user or system wide
    installations of Python2. Both Python 2.6 and 2.7, and 3.5 or higher
    will do.
    python_exescons_supported_getSconsInlinePath Return path to inline copy of scons.  Find a way to call any Python2.

    Scons needs it as it doesn't support Python3.
    _setupSconsEnvironment--debug=explainSCONS_LIB_DIRC:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\build\SconsInterface.py Scons interface.

Interaction with scons. Find the binary, and run it with a set of given
options.

 Build the scons command to run.

    The options are a dictionary to be passed to scons as a command line,
    and other scons stuff is set.
    NUITKA_PYTHON_EXE_PATHc:\Python%s\python.exe_getPythonSconsExePathWindows3.7_buildSconsCommandError, while Nuitka works with Python 3.2 to 3.4, scons does not, and Nuitka
needs to find a Python executable 2.6/2.7 or 3.5 or higher. Simply under the
C:\PythonXY, e.g. C:\Python27 to execute the scons utility which is used
to build the C files to binary.

You may provide it using option "--python-for-scons=path_to_python.exe"
in case it is not visible in registry, e.g. due to using uninstalled
AnaConda Python.
version_candidatebuild.SconsInterfacePYTHONHOME--no-site-dirNUITKA_PYTHON_DLL_PATHscons.py<module build.SconsInterface> Setup the scons execution environment.

    For the scons inline copy on Windows needs to find the library, using
    the "SCONS_LIB_DIR" environment variable "NUITKA_SCONS". And for the
    target Python we provide "NUITKA_PYTHON_DLL_PATH" to see where the
    Python DLL lives, in case it needs to be copied, and then the
    "NUITKA_PYTHON_EXE_PATH" to find the Python binary itself.
    scons-2.3.2 Return path to where data for scons lives, e.g. static C source files.

    Scons command:--warn=no-deprecated_getSconsBinaryCall_buildSconsCommand.<locals>.encode Return a way to execute Scons.

    Using potentially in-line copy if no system Scons is available
    or if we are on Windows, there it is mandatory.
    SingleExe.sconsC:\msys64\mingw64\lib\python3.6\bz2.pyBZ2File.readintoBZ2File.readlinesDecompress a block of data.

    For incremental decompression, use a BZ2Decompressor object instead.
    BZ2File.writebz_modeWrite a byte string to the file.

        Returns the number of uncompressed bytes written, which is
        always len(data). Note that due to buffering, the file on disk
        may not reflect the data written until close() is called.
        BZ2File.__init__Interface to the libbzip2 compression library.

This module provides a file interface, classes for incremental
(de)compression, and functions for one-shot (de)compression.
Nadeem Vawda <nadeem.vawda@gmail.com>BZ2File.filenocompresslevel must be between 1 and 9Read bytes into b.

        Returns the number of bytes read (0 for EOF).
        BZ2File.closeCompress a block of data.

    compresslevel, if given, must be a number between 1 and 9.

    For incremental compression, use a BZ2Compressor object instead.
    BZ2File.seekWrite a sequence of byte strings to the file.

        Returns the number of uncompressed bytes written.
        seq can be any iterable yielding byte strings.

        Line separators are not added between the written byte strings.
        BZ2File.readableBZ2File.closedBZ2File.peekOpen a bzip2-compressed file in binary or text mode.

    The filename argument can be an actual filename (a str, bytes, or
    PathLike object), or an existing file object to read from or write
    to.

    The mode argument can be "r", "rb", "w", "wb", "x", "xb", "a" or
    "ab" for binary mode, or "rt", "wt", "xt" or "at" for text mode.
    The default mode is "rb", and the default compresslevel is 9.

    For binary mode, this function is equivalent to the BZ2File
    constructor: BZ2File(filename, mode, compresslevel). In this case,
    the encoding, errors and newline arguments must not be provided.

    For text mode, a BZ2File object is created, and wrapped in an
    io.TextIOWrapper instance with the specified encoding, error
    handling behavior, and line ending(s).

    BZ2File.seekableBZ2File.writableA file object providing transparent bzip2 (de)compression.

    A BZ2File can act as a wrapper for an existing file object, or refer
    directly to a named file on disk.

    Note that BZ2File provides a *binary* file interface - data read is
    returned as bytes, and data to be written should be given as bytes.
    Change the file position.

        The new position is specified by offset, relative to the
        position indicated by whence. Values for whence are:

            0: start of stream (default); offset must not be negative
            1: current stream position
            2: end of stream; offset must not be positive

        Returns the new file position.

        Note that seeking is emulated, so depending on the parameters,
        this operation may be extremely slow.
        Read a list of lines of uncompressed bytes from the file.

        size can be specified to control the number of lines read: no
        further lines will be read once the total size of the lines read
        so far equals or exceeds size.
        Use of 'buffering' argument is deprecatedBZ2File.tellInteger argument expectedRead up to size uncompressed bytes, while trying to avoid
        making multiple reads from the underlying stream. Reads up to a
        buffer's worth of data if size is negative.

        Returns b'' if the file is at EOF.
        BZ2File.read1<module bz2>Read up to size uncompressed bytes from the file.

        If size is negative or omitted, read until EOF is reached.
        Returns b'' if the file is already at EOF.
        Open a bzip2-compressed file.

        If filename is a str, bytes, or PathLike object, it gives the
        name of the file to be opened. Otherwise, it should be a file
        object, which will be used to read or write the compressed data.

        mode can be 'r' for reading (default), 'w' for (over)writing,
        'x' for creating exclusively, or 'a' for appending. These can
        equivalently be given as 'rb', 'wb', 'xb', and 'ab'.

        buffering is ignored. Its use is deprecated.

        If mode is 'w', 'x' or 'a', compresslevel can be a number between 1
        and 9 specifying the level of compression: 1 produces the least
        compression, and 9 (default) produces the most compression.

        If mode is 'r', the input file may be the concatenation of
        multiple compressed streams.
        BZ2File.writelines
        Return an iterator for one month. The iterator will yield datetime.date
        values and will always iterate through complete weeks, so it will yield
        dates outside the specified month.
        --cssoptdictformatstring<link rel="stylesheet" type="text/css" href="%s" />
LocaleHTMLCalendar.formatweekdaydifferent_locale.__enter__IllegalMonthErrorCalendar.__init__spacing between months (default 6)theyearweekheader_localized_daythemonth<td>_localized_month.__len__calendar.cssbad month number %r; must be 1-12</head>
Return weekday (0-6 ~ Mon-Sun) for year (1970-...), month (1-12),
       day (1-31).
    Subclass of Calendar that outputs a calendar as a simple plain text
    similar to the UNIX program cal.
    setfirstweekdayHTMLCalendar.formatmonth_localized_day.__len__oneday<tr><th colspan="%d" class="year">%s</th></tr>_firstweekdayyeardayscalendarIllegalWeekdayErrory1LocaleHTMLCalendar.formatmonthname--linesyear number (1-9999)
        Return a formatted year as a complete HTML page.
        LocaleTextCalendar.formatweekdayCalendar.monthdayscalendartheweekCalendar.iterweekdaysTextCalendar.formatweekheader
        Return a formatted year as a table of tables.
        different_locale.__init__Calendar.itermonthdaysTUESDAYleapdaysTextCalendar.formatmonthwidth of date column (default 2)<head>
SUNDAYTextCalendar.formatmonthname<td class="%s">%d</td>month number (1-12, text only)itermonthdays2
        Returns a year's calendar as a multi-line string.
        HTMLCalendar.formatdaynumber of lines for each week (default 1)withyear
        Return a complete week as a table row.
        days_beforeReturn number of leap years in range [y1, y2).
       Assume y1 <= y2.FRIDAYTextCalendar.prmonthPrint a year's calendar.</table>formatyearpagebad weekday number %r; must be 0 (Monday) to 6 (Sunday)HTMLCalendar.formatweekheader.<locals>.<genexpr>monthdays2calendarIllegalWeekdayError.__str__encoding to use for output--spacinghtmlgroup_colwidtholdlocaleCSS to use for pageJanuaryCalendar.itermonthdays2
        Like itermonthdates(), but will yield day numbers. For days outside
        the specified month the day number is 0.
        _localized_month.__init__day1TextCalendar.prweekyeardays2calendarCalendar.getfirstweekday_localized_month.__getitem__
        Return a month name as a table row.
        <?xml version="1.0" encoding="%s"?>
Calendar.yeardatescalendar--localeformatstring.<locals>.<genexpr><td class="noday">&nbsp;</td>TextCalendar.formatweek.<locals>.<genexpr><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
text only argumentsif --locale is specified --encoding is required<tr>%s</tr>
    This calendar returns complete HTML pages.
    
        Like itermonthdates(), but will yield (day number, weekday number)
        tuples. For days outside the specified month the day number is 0.
        months per row (default 3)
        Return a matrix representing a month's calendar.
        Each row represents a week; week entries are
        (day number, weekday number) tuples. Day numbers outside this month
        are zero.
        <body>

        Return a matrix representing a month's calendar.
        Each row represents a week; days outside this month are zero.
        Returns a string formatted from n strings, centered within n columns.<meta http-equiv="Content-Type" content="text/html; charset=%s" />
cssclassesmonthdatescalendarmdays
        Return a formatted month name.
        Prints multi-column formatting for year calendars
        Returns a formatted day.
        days_afterCalendar.setfirstweekdayHTMLCalendar.formatyearpageC:\msys64\mingw64\lib\python3.6\calendar.pyIllegalWeekdayError.__init__locale to be used from month and weekday names%2i--type
        Return a month's calendar string (multi-line).
        Return weekday (0-6 ~ Mon-Sun) and number of days (28-31) for
       year, month.pryear<html>

        Return a header for a week as a table row.
        EPOCH
        Return an iterator for one week of weekday numbers starting with the
        configured first one.
        
        Return a formatted month as a table.
        </html>
IllegalMonthError.__init__
        Return the data for the specified year ready for formatting (similar to
        yeardatescalendar()). Entries in the week lists are
        (day number, weekday number) tuples. Day numbers outside this month are
        zero.
        html only arguments
        Print a single week (no newline).
        TextCalendar.formatday
    Base calendar class. This class doesn't do any formatting. It simply
    provides data to subclasses.
    <table border="0" cellpadding="0" cellspacing="0" class="year">LocaleTextCalendar.__init__TextCalendar.formatweekheader.<locals>.<genexpr>MONDAY<table border="0" cellpadding="0" cellspacing="0" class="month">SATURDAY
        Return a matrix (list of lists) representing a month's calendar.
        Each row represents a week; week entries are datetime.date values.
        TextCalendar.formatyearÛ   zIllegalMonthErrorzIllegalWeekdayErrorzsetfirstweekdayzfirstweekdayzisleapzleapdayszweekdayz
monthrangezmonthcalendarzprmonthzmonthzprcalzcalendarztimegmz
month_namez
month_abbrzday_namezday_abbrzCalendarzTextCalendarzHTMLCalendarzLocaleTextCalendarzLocaleHTMLCalendarz
weekheader
        Return a weekday name as a table header.
        --months</body>

        Return a header for a week.
        
        Print a month's calendar.
        --width<module calendar>
        Return the data for the specified year ready for formatting (similar to
        yeardatescalendar()). Entries in the week lists are day numbers.
        Day numbers outside this month are zero.
        Return True for leap years, False for non-leap years.IllegalMonthError.__str__FebruaryCalendar.monthdatescalendar_localized_day.__getitem__Calendar.itermonthdatesdifferent_locale.__exit__Calendar.monthdays2calendargetdefaultencodingLocaleTextCalendar.formatmonthname_localized_day.__init__%s %rtextgroup
        Return a day as a table cell.
        LocaleHTMLCalendar.__init__Calendar printing functions

Note when comparing these calendars to the ones printed by cal(1): By
default, these calendars have Monday as the first day of the week, and
Sunday as the last (the European convention). Use setfirstweekday() to
set the first day of the week (0=Monday, 6=Sunday).<title>Calendar for %d</title>
Unrelated but handy function to calculate Unix timestamp from GMT.
        Returns a formatted week day name.
        TextCalendar.formatyear.<locals>.<genexpr>
    This class can be passed a locale name in the constructor and will return
    month and weekday names in the specified locale. If this locale includes
    an encoding all strings containing month and weekday names will be returned
    as unicode.
    HTMLCalendar.formatweek.<locals>.<genexpr>_months<tr><th colspan="7" class="month">%s</th></tr>
        Return the data for the specified year ready for formatting. The return
        value is a list of month rows. Each month row contains up to width months.
        Each month contains between 4 and 6 weeks and each week contains 1-7
        days. Days are datetime.date objects.
        TextCalendar.pryearoutput type (text or html)
        Returns a single week in a string (no newline).
        _EPOCH_ORD<th class="%s">%s</th>WEDNESDAYCalendar.yeardayscalendarCalendar.yeardays2calendar_localized_month.<lambda>Cases.__init__Cases.enlarged_bladderbladder_commandcommand_listColon, Left Lower Tenderness with GuardingAppendix Tenderness with Rebound Tendernesswith_vignetteGallbladder Tenderness with GuardingCases.ovary_rightOvary, Left Tenderness with GuardingCases.get_random_caseCases.bladderAppendix Tenderness with Guarding and Rebound Tenderness<module cases>current_organOvary, Right Tenderness with GuardingUGICases.get_case_commandsCases.noneCases.pancreasC:\msys64\home\cbper\cases.pyCases.splenomegalyCases.ovary_leftCases.gallbladderCases.get_random_other_organ_caseCases.hepatomegaly
Cases tracks all of the case details
Cases.appendixCases.ugiCases.colonon_case_selectedexpand_allFontDescriptionWith Rebound TendernessC:\msys64\home\cbper\caseselector.pytvcolumnnormal 14Buildableadd_attribute<module caseselector>CaseSelector.__init__CaseSelector.on_case_selectedddx_tree_viewWith GuardingWith Guarding and Rebound TendernessTreeStoreCaseSelector.on_tree_selectedCaseSelector.build_ddx_treefont-descddx_tree_storeHISTORY: A 33 year old male presents for an evaluation of abdominal pain. He describes the pain as acute in onset, mild in nature, colicky and intermittent, not worsening over time, and ongoing for approximately 36 hours prior to presentation. The location is described as epigastric. He describes the following associated findings: nausea and vomiting, diarrhea, blood with bowel movement, feeling feverish, a recent bad tasting meal, exposure to others with vomiting and diarrhea, and heartburn. The patient's past medical history is unremarkable.

PHYSICAL EXAMINATION: General Appearance is grossly unremarkable. VITAL SIGNS are remarkable for the following: temperature 37.8Â°C. THORAX and LUNGS are unremarkable. ABDOMINAL EXAM/INSPECTION is unremarkable. ABDOMINAL AUSCULTATION reveals: increased bowel sounds.HISTORY: A 33 year old female presents for an evaluation of abdominal pain. She describes the pain as acute in onset, moderate to severe, constant, progressive worsening over time, and ongoing for approximately 11 hours prior to presentation. The location is described as epigastric, radiating to the back in mid-line, and occurring after meals. She describes the following associated findings: nausea and vomiting, and bilious emesis. The patient's past medical history is positive for the following: a history of gallbladder stones, and alcohol abuse.

PHYSICAL EXAMINATION: The patient's General Appearance reveals an uncomfortable patient frequently changing positions. VITAL SIGNS are remarkable for the following: temperature 38.1Â°C, and tachycardia at 114. THORAX and LUNGS are unremarkable. ABDOMINAL EXAM/INSPECTION is unremarkable. ABDOMINAL AUSCULTATION reveals: normal bowel sounds.cases.jsonHISTORY: A 32 year old female presents for an evaluation of abdominal pain. She describes the pain as gradual in onset, moderate to severe, constant, progressive worsening over time, and ongoing for approximately 9 hours prior to presentation. The location is described as non-specific. She describes the following associated findings: nausea and vomiting. The patient's past medical history is unremarkable.

PHYSICAL EXAMINATION: General Appearance is grossly unremarkable. VITAL SIGNS are remarkable for the following: temperature 37.7Â°C. THORAX and LUNGS are unremarkable. ABDOMINAL EXAM/INSPECTION is unremarkable. ABDOMINAL AUSCULTATION reveals: decreased bowel sounds.HISTORY: A 66 year old female presents for an evaluation of abdominal pain. She describes the pain as gradual in onset, moderate to severe, colicky and intermittent, progressive worsening over time, and ongoing for less than 3 hours prior to presentation. The location is described as right upper quadrant, and radiating to the scapula. She describes the following associated findings: nausea and vomiting, episodes of abdominal bloating, and prior episodes of similar pain. The patient's past medical history is positive for the following: 3 pregnancies.

PHYSICAL EXAMINATION: The patient's General Appearance reveals an uncomfortable patient frequently changing positions. VITAL SIGNS are remarkable for the following: temperature 36.9Â°C. THORAX and LUNGS are unremarkable. ABDOMINAL EXAM/INSPECTION is unremarkable. ABDOMINAL AUSCULTATION reveals: normal bowel sounds.YdWG4407K10H40B7800G017a8XeGHISTORY: A 51 year old male presents for an evaluation of abdominal pain. He describes the pain as acute in onset, moderate to severe, constant, not worsening over time, and ongoing for approximately 8 hours prior to presentation. The location is described as right upper quadrant, and radiating to the scapula. He describes the following associated findings: dark urine. The patient's past medical history is positive for the following: a history of gallbladder stones.

PHYSICAL EXAMINATION: The patient's General Appearance reveals an uncomfortable patient constantly moving, and icteric conjunctiva. VITAL SIGNS are remarkable for the following: temperature 36.9Â°C, and tachycardia at 122. THORAX and LUNGS are unremarkable. ABDOMINAL EXAM/INSPECTION is unremarkable. ABDOMINAL AUSCULTATION reveals: normal bowel sounds.HISTORY: A 52 year old female presents for an evaluation of abdominal pain. She describes the pain as acute in onset, moderate to severe, colicky and intermittent, not worsening over time, and ongoing for approximately 6 hours prior to presentation. The location is described as right upper quadrant, and occurring after meals. She describes the following associated findings: dark urine, acholic stools, and feeling feverish. The patient's past medical history is positive for the following: a history of gallbladder stones.

PHYSICAL EXAMINATION: The patient's General Appearance reveals an uncomfortable patient constantly moving. VITAL SIGNS are remarkable for the following: temperature 36.7Â°C, and tachycardia at 128. THORAX and LUNGS are unremarkable. ABDOMINAL EXAM/INSPECTION is unremarkable. ABDOMINAL AUSCULTATION reveals: decreased bowel sounds.HISTORY: A 29 year old male presents for an evaluation of abdominal pain. He describes the pain as gradual in onset, moderate to severe, constant, not worsening over time, and ongoing for less than 4 hours prior to presentation. The location is described as epigastric, and radiating to the back in mid-line. He describes the following associated findings: nausea and vomiting, and bilious emesis. The patient's past medical history is positive for the following: alcohol abuse.

PHYSICAL EXAMINATION: The patient's General Appearance reveals an uncomfortable patient continually seeking a position of comfort. VITAL SIGNS are remarkable for the following: temperature 37.4Â°C. THORAX and LUNGS are unremarkable. ABDOMINAL EXAM/INSPECTION is unremarkable. ABDOMINAL AUSCULTATION reveals: normal bowel sounds.D5804S0K2WX1IGHISTORY: A 49 year old male presents for an evaluation of abdominal pain. He describes the pain as gradual in onset, moderate to severe, constant, progressive worsening over time, and ongoing for approximately 16 hours prior to presentation. The location is described as left lower quadrant, and worsening with defecation. He describes the following associated findings: decreased bowel movements, and prior episodes of similar pain. The patient's past medical history is unremarkable.

PHYSICAL EXAMINATION: General Appearance is grossly unremarkable. VITAL SIGNS are remarkable for the following: temperature 36.9Â°C, and tachycardia at 130. THORAX and LUNGS are unremarkable. ABDOMINAL EXAM/INSPECTION is unremarkable. ABDOMINAL AUSCULTATION reveals: decreased bowel sounds. HISTORY: A 72 year old female presents for an evaluation of abdominal pain. She describes the pain as acute in onset, moderate to severe, constant, progressive worsening over time, and ongoing for less than 4 hours prior to presentation. The location is described as peri-umbilical. She describes the following associated findings: decreased bowel movements. The patient's past medical history is positive for the following: cardiac irregularities.

PHYSICAL EXAMINATION: The patient's General Appearance reveals an uncomfortable patient constantly moving, and confusion. VITAL SIGNS are remarkable for the following: temperature 36.5Â°C, tachycardia at 123, tachypnea at 26, and a blood pressure of 80 over 51. THORAX and LUNGS are unremarkable. ABDOMINAL EXAM/INSPECTION is unremarkable. ABDOMINAL AUSCULTATION reveals: decreased bowel sounds, and an abdominal bruit.HISTORY: A 66 year old female presents for an evaluation of abdominal pain. She describes the pain as gradual in onset, moderate to severe, colicky and intermittent, progressive worsening over time, and ongoing for approximately 7 hours prior to presentation. The location is described as non-specific, and radiating to the scapula. She describes the following associated findings: feeling feverish. The patient's past medical history is positive for the following: a history of gallbladder stones.

PHYSICAL EXAMINATION: The patient's General Appearance reveals an uncomfortable patient constantly moving. VITAL SIGNS are remarkable for the following: temperature 36.6Â°C. THORAX and LUNGS are unremarkable. ABDOMINAL EXAM/INSPECTION is unremarkable. ABDOMINAL AUSCULTATION reveals: normal bowel sounds. K8G260I0804H40HISTORY: A 70 year old female presents for an evaluation of abdominal pain. She describes the pain as gradual in onset, moderate to severe, constant, progressive worsening over time, and ongoing for less than 4 hours prior to presentation. The location is described as peri-umbilical. She describes the following associated findings: blood with bowel movement, decreased bowel movements, episodes of abdominal bloating, and bilious emesis. The patient's past medical history is positive for the following: prior abdominal surgery.

PHYSICAL EXAMINATION: The patient's General Appearance reveals an uncomfortable patient constantly moving. VITAL SIGNS are remarkable for the following: temperature 36.1Â°C, tachycardia at 117, and tachypnea at 22. THORAX and LUNGS Decreased breath sounds are noted at the bases. ABDOMINAL EXAM/INSPECTION reveals: sight distention. ABDOMINAL AUSCULTATION reveals: increased bowel sounds, the presence of tympany, and an abdominal bruit.ad8040m0G0WH80last_case_indexHISTORY: A 45 year old male presents for an evaluation of abdominal pain. He describes the pain as gradual in onset, moderate to severe, constant, not worsening over time, and ongoing for approximately 16 hours prior to presentation. The location is described as epigastric, radiating to the back in mid-line, occurring after meals, and worsening with lying down. He describes the following associated findings: feeling feverish, and acid reflux symptoms. The patient's past medical history is positive for the following: ongoing use of aspirin.

PHYSICAL EXAMINATION: The patient's General Appearance reveals a patient who wants to remain very still. VITAL SIGNS are remarkable for the following: temperature 36.7Â°C. THORAX and LUNGS are unremarkable. ABDOMINAL EXAM/INSPECTION is unremarkable. ABDOMINAL AUSCULTATION reveals: normal bowel sounds.      2@HISTORY: A 67 year old male presents for an evaluation of abdominal pain. He describes the pain as gradual in onset, moderate to severe, constant, progressive worsening over time, and ongoing for approximately 16 hours prior to presentation. The location is described as peri-umbilical. He describes the following associated findings: blood with bowel movement, and feeling feverish. The patient's past medical history is positive for the following: ongoing use of aspirin, prior abdominal surgery, cardiac irregularities, a history of gallbladder stones, and alcohol abuse.

PHYSICAL EXAMINATION: The patient's General Appearance reveals a patient who wants to remain very still. VITAL SIGNS are remarkable for the following: temperature 36.7Â°C. THORAX and LUNGS are unremarkable. ABDOMINAL EXAM/INSPECTION is unremarkable. ABDOMINAL AUSCULTATION reveals: normal bowel sounds. case_tagaF10C0n0G0X180HISTORY: A 66 year old female presents for an evaluation of abdominal pain. She describes the pain as gradual in onset, moderate to severe, colicky and intermittent, progressive worsening over time, and ongoing for less than 3 hours prior to presentation. The location is described as non-specific, and radiating to the back in mid-line. She describes the following associated findings: nausea and vomiting, decreased bowel movements, episodes of abdominal fullness, and bilious emesis. The patient's past medical history is positive for the following: prior abdominal surgery.

PHYSICAL EXAMINATION: The patient's General Appearance reveals an uncomfortable patient continually seeking a position of comfort. VITAL SIGNS are remarkable for the following: temperature 36.3Â°C, and tachypnea at 26. THORAX and LUNGS are unremarkable. ABDOMINAL EXAM/INSPECTION reveals: sight distention. ABDOMINAL AUSCULTATION reveals: increased bowel sounds, and the presence of tympany.HISTORY: A 70 year old male presents for an evaluation of abdominal pain. He describes the pain as gradual in onset, moderate to severe, colicky and intermittent, progressive worsening over time, and ongoing for less than 3 hours prior to presentation. The location is described as peri-umbilical. He describes the following associated findings: nausea and vomiting, decreased bowel movements, episodes of abdominal bloating, and bilious emesis. The patient's past medical history is positive for the following: prior abdominal surgery, and a history of gallbladder stones.

PHYSICAL EXAMINATION: The patient's General Appearance reveals confusion. VITAL SIGNS are remarkable for the following: temperature 36.3Â°C, and tachypnea at 23. THORAX and LUNGS are unremarkable. ABDOMINAL EXAM/INSPECTION reveals: mild distention. ABDOMINAL AUSCULTATION reveals: increased bowel sounds.IBW5fG080X0H40HISTORY: A 49 year old female presents for an evaluation of abdominal pain. She describes the pain as gradual in onset, mild in nature, colicky and intermittent, not worsening over time, and ongoing for approximately 48 hours prior to presentation. The location is described as peri-umbilical. She describes the following associated findings: nausea and vomiting, diarrhea, feeling feverish, and recent foreign travel. The patient's past medical history is positive for the following: ongoing use of non-steroidal medications, prior abdominal surgery, cardiac irregularities, a history of gallbladder stones, and alcohol use.

PHYSICAL EXAMINATION: General Appearance is grossly unremarkable. VITAL SIGNS are remarkable for the following: temperature 38.2Â°C. THORAX and LUNGS are unremarkable. ABDOMINAL EXAM/INSPECTION is unremarkable. ABDOMINAL AUSCULTATION reveals: increased bowel sounds.95GG4S0H2WWHIWHISTORY: A 54 year old female presents for an evaluation of abdominal pain. She describes the pain as acute in onset, mild in nature, a burning sensation, constant, progressive worsening over time, and ongoing for approximately 42 hours prior to presentation. The location is described as epigastric, radiating retrosternally, occurring after meals, and worsening with lying down. She describes the following associated findings: bloody emesis, decreased bowel movements, and prior episodes of similar pain. The patient's past medical history is unremarkable.

PHYSICAL EXAMINATION: General Appearance is grossly unremarkable. VITAL SIGNS are remarkable for the following: temperature 36.4Â°C. THORAX and LUNGS are unremarkable. ABDOMINAL EXAM/INSPECTION is unremarkable. ABDOMINAL AUSCULTATION reveals: normal bowel sounds.Ia2103G54Y2180<module casetext>HISTORY: A 27 year old male presents for an evaluation of abdominal pain. He describes the pain as gradual in onset, moderate to severe, constant, progressive worsening over time, and ongoing for approximately 11 hours prior to presentation. The location is described as peri-umbilical. He describes the following associated findings: nausea and vomiting, anorexia, and feeling feverish. The patient's past medical history is unremarkable.

PHYSICAL EXAMINATION: General Appearance is grossly unremarkable. VITAL SIGNS are remarkable for the following: temperature 38.1Â°C. THORAX and LUNGS are unremarkable. ABDOMINAL EXAM/INSPECTION is unremarkable. ABDOMINAL AUSCULTATION reveals: decreased bowel sounds.HISTORY: A 74 year old male presents for an evaluation of abdominal pain. He describes the pain as acute in onset, moderate to severe, constant, progressive worsening over time, and ongoing for less than 5 hours prior to presentation. The location is described as peri-umbilical. He describes the following associated findings: decreased bowel movements. The patient's past medical history is positive for the following: cardiac irregularities.

PHYSICAL EXAMINATION: The patient's General Appearance reveals an uncomfortable patient constantly moving. VITAL SIGNS are remarkable for the following: temperature 38.2Â°C, tachycardia at 128, tachypnea at 24, and a blood pressure of 76 over 54. THORAX and LUNGS are unremarkable. ABDOMINAL EXAM/INSPECTION is unremarkable. ABDOMINAL AUSCULTATION reveals: decreased bowel sounds, and an abdominal bruit.97800y0H6e8HoWC:\msys64\home\cbper\casetext.pyHISTORY: A 51 year old male presents for an evaluation of abdominal pain. He describes the pain as gradual in onset, mild in nature, colicky and intermittent, not worsening over time, and ongoing for approximately 30 hours prior to presentation. The location is described as non-specific. He describes the following associated findings: nausea and vomiting, diarrhea, feeling feverish, and exposure to others with nausea and vomiting. The patient's past medical history is positive for the following: ongoing use of aspirin.

PHYSICAL EXAMINATION: General Appearance is grossly unremarkable. VITAL SIGNS are remarkable for the following: temperature 38.6Â°C. THORAX and LUNGS are unremarkable. ABDOMINAL EXAM/INSPECTION is unremarkable. ABDOMINAL AUSCULTATION reveals: normal bowel sounds.case_idHISTORY: A 75 year old female presents for an evaluation of abdominal pain. She describes the pain as acute in onset, moderate to severe, constant, progressive worsening over time, and ongoing for approximately 14 hours prior to presentation. The location is described as peri-umbilical, and radiating to the back in mid-line. She describes the following associated findings: decreased bowel movements. The patient's past medical history is positive for the following: cardiac irregularities.

PHYSICAL EXAMINATION: The patient's General Appearance reveals an uncomfortable patient constantly moving, and confusion. VITAL SIGNS are remarkable for the following: temperature 36.9Â°C, tachycardia at 128, and tachypnea at 25. THORAX and LUNGS are unremarkable. ABDOMINAL EXAM/INSPECTION is unremarkable. ABDOMINAL AUSCULTATION reveals: decreased bowel sounds.HISTORY: A 54 year old female presents for an evaluation of abdominal pain. She describes the pain as gradual in onset, moderate to severe, colicky and intermittent, progressive worsening over time, and ongoing for less than 2 hours prior to presentation. The location is described as right upper quadrant, and radiating to the scapula. She describes the following associated findings: prior episodes of similar pain. The patient's past medical history is unremarkable.

PHYSICAL EXAMINATION: General Appearance is grossly unremarkable. VITAL SIGNS are remarkable for the following: temperature 38.1Â°C. THORAX and LUNGS are unremarkable. ABDOMINAL EXAM/INSPECTION is unremarkable. ABDOMINAL AUSCULTATION reveals: normal bowel sounds.CaseTextBuffer.__init__HISTORY: A 28 year old male presents for an evaluation of abdominal pain. He describes the pain as gradual in onset, moderate to severe, a burning sensation, constant, progressive worsening over time, and ongoing for approximately 36 hours prior to presentation. The location is described as right lower quadrant. He describes the following associated findings: nausea and vomiting, anorexia, feeling feverish, and heartburn. The patient's past medical history is unremarkable.

PHYSICAL EXAMINATION: General Appearance is grossly unremarkable. VITAL SIGNS are remarkable for the following: temperature 38Â°C. THORAX and LUNGS are unremarkable. ABDOMINAL EXAM/INSPECTION is unremarkable. ABDOMINAL AUSCULTATION reveals: decreased bowel sounds.HISTORY: A 51 year old male presents for an evaluation of abdominal pain. He describes the pain as acute in onset, moderate to severe, a burning sensation, constant, not worsening over time, and ongoing for approximately 6 hours prior to presentation. The location is described as epigastric, radiating retrosternally, occurring after meals, and worsening with lying down. He describes the following associated findings: episodes of abdominal fullness, bilious emesis, heartburn, and prior episodes of similar pain. The patient's past medical history is positive for the following: ongoing use of aspirin, and alcohol abuse.

PHYSICAL EXAMINATION: The patient's General Appearance reveals a patient who wants to remain very still. VITAL SIGNS are remarkable for the following: temperature 36.8Â°C. THORAX and LUNGS are unremarkable. ABDOMINAL EXAM/INSPECTION is unremarkable. ABDOMINAL AUSCULTATION reveals: normal bowel sounds.McW7eC1AWX0H40H5280008G20H40HISTORY: A 67 year old female presents for an evaluation of abdominal pain. She describes the pain as gradual in onset, moderate to severe, constant, progressive worsening over time, and ongoing for approximately 8 hours prior to presentation. The location is described as right lower quadrant. She describes the following associated findings: anorexia, and feeling feverish. The patient's past medical history is unremarkable.

PHYSICAL EXAMINATION: The patient's General Appearance reveals a patient who wants to remain very still. VITAL SIGNS are remarkable for the following: temperature 38.6Â°C. THORAX and LUNGS are unremarkable. ABDOMINAL EXAM/INSPECTION is unremarkable. ABDOMINAL AUSCULTATION reveals: decreased bowel sounds.F7800G01N44He0HISTORY: A 49 year old female presents for an evaluation of abdominal pain. She describes the pain as gradual in onset, moderate to severe, constant, progressive worsening over time, and ongoing for approximately 11 hours prior to presentation. The location is described as peri-umbilical. She describes the following associated findings: anorexia. The patient's past medical history is unremarkable.

PHYSICAL EXAMINATION: General Appearance is grossly unremarkable. VITAL SIGNS are remarkable for the following: temperature 36.7Â°C, and tachycardia at 114. THORAX and LUNGS are unremarkable. ABDOMINAL EXAM/INSPECTION is unremarkable. ABDOMINAL AUSCULTATION reveals: decreased bowel sounds.KN0WGG084W8X80Mc2802054o0H40YdWH4407K10H40Wa29C0Ge0c0H40WdG04000G0X180HISTORY: A 26 year old female presents for an evaluation of abdominal pain. She describes the pain as acute in onset, moderate to severe, constant, progressive worsening over time, and ongoing for approximately 8 hours prior to presentation. The location is described as epigastric, and radiating to the back in mid-line. She describes the following associated findings: nausea and vomiting, and bilious emesis. The patient's past medical history is positive for the following: a history of gallbladder stones, and alcohol use.

PHYSICAL EXAMINATION: The patient's General Appearance reveals an uncomfortable patient frequently changing positions. VITAL SIGNS are remarkable for the following: temperature 38.2Â°C, and tachycardia at 113. THORAX and LUNGS are unremarkable. ABDOMINAL EXAM/INSPECTION is unremarkable. ABDOMINAL AUSCULTATION reveals: normal bowel sounds.8d1000m0e0X1808bG800G50Y0H40CaseText.__init__HISTORY: A 51 year old female presents for an evaluation of abdominal pain. She describes the pain as acute in onset, moderate to severe, colicky and intermittent, progressive worsening over time, and ongoing for approximately 10 hours prior to presentation. The location is described as right upper quadrant. She describes the following associated findings: dark urine. The patient's past medical history is positive for the following: a history of gallbladder stones.

PHYSICAL EXAMINATION: The patient's General Appearance reveals an uncomfortable patient continually seeking a position of comfort, and icteric conjunctiva. VITAL SIGNS are remarkable for the following: temperature 36.6Â°C, and tachycardia at 117. THORAX and LUNGS are unremarkable. ABDOMINAL EXAM/INSPECTION is unremarkable. ABDOMINAL AUSCULTATION reveals: normal bowel sounds.b6WG44030X0H40CaseText.get_case_block9528480f0Y2140KMWJW0H0WX0H40ddx_nameIb2002054o2140HISTORY: A 34 year old female presents for an evaluation of abdominal pain. She describes the pain as gradual in onset, moderate to severe, a burning sensation, colicky and intermittent, not worsening over time, and ongoing for approximately 6 hours prior to presentation. The location is described as right upper quadrant, radiating to the scapula, and occurring after meals. She describes the following associated findings: nausea and vomiting, feeling feverish, and prior episodes of similar pain. The patient's past medical history is positive for the following: cardiac irregularities, and 4 pregnancies.

PHYSICAL EXAMINATION: General Appearance is grossly unremarkable. VITAL SIGNS are remarkable for the following: temperature 36.5Â°C. THORAX and LUNGS are unremarkable. ABDOMINAL EXAM/INSPECTION is unremarkable. ABDOMINAL AUSCULTATION reveals: normal bowel sounds.CaseTextBuffer.new_caseCN820WGMWa8X40AN8G0G016a8X8GG88260OMG44HG0CaseText.get_random_case_by_spacec8W06WN0G04HG0Gd8000W04W8H80set_completerget_endidxoriglineshell List available commands with "help" or detailed help with "help cmd".Cmd.parselineCmd.cmdloop: completeCmd.complete_help.<locals>.<genexpr>old_completer<empty>
maxcolcolwidthsCmd.do_helpnonstringsundoc_headerPROMPTcompfuncrulerCmd.print_topicscmds_undocHook method executed once when the cmdloop() method is called.postloop(Cmd) Undocumented commands:columnizedotextcmdlenCmd.postloopCalled on an input line when the command prefix is not recognized.

        If this method is not overridden, it prints an error message and
        returns.

        Display a list of strings as a compact set of columns.

        Each column is only as wide as necessary.
        Columns are separated by two spaces (one was not legible enough).
        list[i] not a string for i in %sdisplaywidthCmd.defaultMiscellaneous help topics:A simple framework for writing line-oriented command interpreters.

    These are often useful for test harnesses, administrative tools, and
    prototypes that will later be wrapped in a more sophisticated interface.

    A Cmd instance or subclass instance is a line-oriented interpreter
    framework.  There is no good reason to instantiate Cmd itself; rather,
    it's useful as a superclass of an interpreter class you define yourself
    in order to inherit Cmd's methods and encapsulate action methods.

    Called when an empty line is entered in response to the prompt.

        If this method is not overridden, it repeats the last nonempty
        command entered.

        Parse the line into a command name and a string containing
        the arguments.  Returns a tuple containing (command, args, line).
        'command' and 'args' may be None if the line couldn't be parsed.
        Hook method executed once when the cmdloop() method is about to
        return.

        prevnameidentcharsRepeatedly issue a prompt, accept input, parse an initial prefix
        off the received input, and dispatch to action methods, passing them
        the remainder of the line as argument.

        emptylineInstantiate a line-oriented interpreter framework.

        The optional argument 'completekey' is the readline name of a
        completion key; it defaults to the Tab key. If completekey is
        not None and the readline module is available, command completion
        is done automatically. The optional arguments stdin and stdout
        specify alternate input and output file objects; if not specified,
        sys.stdin and sys.stdout are used.

        Cmd.precmdReturn the next possible completion for 'text'.

        If a command has not been entered, then complete against command list.
        Otherwise try to call complete_<command> to get list of completions.
        Cmd.columnize*** No help on %sCmd.completedefaultget_begidxcmds_docCmd.preloopInterpret the argument as though it had been typed in response
        to the prompt.

        This may be overridden, but should not normally need to be;
        see the precmd() and postcmd() methods for useful execution hooks.
        The return value is a flag indicating whether interpretation of
        commands by the interpreter should stop.

        Cmd.postcmdncolstotwidthmisc_headerCmd.emptylineA generic class to build line-oriented command interpreters.

Interpreters constructed with this class obey the following conventions:

1. End of file on input is processed as the command 'EOF'.
2. A command is parsed out of each line by collecting the prefix composed
   of characters in the identchars member.
3. A command `foo' is dispatched to a method 'do_foo()'; the do_ method
   is passed a single argument consisting of the remainder of the line.
4. Typing an empty line repeats the last command.  (Actually, it calls the
   method `emptyline', which may be overridden in a subclass.)
5. There is a predefined `help' method.  Given an argument `topic', it
   calls the command `help_topic'.  With no arguments, it lists all topics
   with defined help_ functions, broken into up to three topics; documented
   commands, miscellaneous help topics, and undocumented commands.
6. The command '?' is a synonym for `help'.  The command '!' is a synonym
   for `shell', if a do_shell method exists.
7. If completion is enabled, completing commands will be done automatically,
   and completing of commands args is done by calling complete_foo() with
   arguments text, line, begidx, endidx.  text is string we are matching
   against, all returned matches must begin with it.  line is the current
   input line (lstripped), begidx and endidx are the beginning and end
   indexes of the text being matched, which could be used to provide
   different completion depending upon which position the argument is in.

The `default' method may be overridden to intercept commands for which there
is no do_ method.

The `completedefault' method may be overridden to intercept completions for
commands that have no complete_ method.

The data member `self.ruler' sets the character used to draw separator lines
in the help messages.  If empty, no ruler line is drawn.  It defaults to "=".

If the value of `self.intro' is nonempty when the cmdloop method is called,
it is printed out on interpreter startup.  This value may be overridden
via an optional argument to the cmdloop() method.

The data members `self.doc_header', `self.misc_header', and
`self.undoc_header' set the headers used for the help function's
listings of documented functions, miscellaneous topics, and undocumented
functions respectively.
get_completernrows<module cmd>C:\msys64\mingw64\lib\python3.6\cmd.pyCmd.__init__completenamesHook method executed just after a command dispatch is finished.doc_leaderCmd.get_namesHook method executed just before the command line is
        interpreted, but after the input prompt is generated and issued.

        Method called to complete an input line when no command-specific
        complete_*() method is available.

        By default, it returns an empty list.

        nohelp*** Unknown syntax: %s
Documented commands (type help <topic>):completion_matchesIDENTCHARSget_line_bufferCmd.completenamesparse_and_bindCmd.onecmd$4=1
$25=1250.000
last_location_senty_adjustment: CNC.searchingadjustments_from_filecnc has portgcodebase_loc_list$110=1250.000
soft_reset$120=25.000
$3=0
$6=0
gcodesget_adjusted_location_gcodeCNC.send_commandMPoscnc_connectionkill_alarm_lockG00Xcnc got first line for status:CNC.stoppedcnc.handler does not recognize command $100=100.000
<module cnc>$26=250
$102=250.000
reset buffercnc called idle$20=0
CNC.__init__CNC.alert_when_idlehome_stop called!got past the alert_when_idle in connectEmergency stop!$2=0
sent home command$X
$121=25.000
CNC.reconnect$131=270.000
$122=10.000
$24=100.000
CNC.get_adjusted_location_gcodemin_coordmax_coordbase_location$1=255
$111=1250.000
check_statusSends commands to the CNC controller, in this case a TinyGCouldn't connect to cnc on put_within_range$0=10

$H
feed_holdcalling cnc busyCNC.check_for_commandenc_command$130=245.000
$10=3
alert when idle: CNC.handler$132=200.000
ûznone{Úxé   Úyr   0zappendix{r   é"   r   éÜ   0zbladder{r   éd   r   éú   0zcolon{r   é²   r   éÖ   0zenlarged_bladder{r   r   r   i  0zgallbladder{r   éA   r   éP   0zhepatomegaly{r   é   r   é<   0zugi{r   ér   r   é   0z
ovary_left{r   é   r   éæ   0zovary_right{r   éZ   r   r   0zpancreas{r   r   r   é2   0zsplenomegaly{r   éÈ   r   éU   00adjustment_commandsCNC.connect$5=0
cnc_configcnc_defaults$23=3
CNC.connection_is_alivelast location sent from cnc: cnc_adjustments.jsonCNC.configure$21=0
CNC.put_within_rangeCNC.emergency_stopwrote to portdisconnecting from portsx_adjustment: C:\msys64\home\cbper\cnc.py$101=100.000
adjusted gcode: failed to reconnect$12=0.002
no port on startupCNC.cnc_home_stop$22=1
$13=0
read linecnc is about to call cnc_is_idle$11=0.020
CNC.handle_commandCNC.disconnectCNC.run$27=1.000
base_locations$112=500.000
<console>InteractiveConsole.resetbufferPython %s on %s
%s
(%s)
InteractiveInterpretercprtBase class for InteractiveConsole.

    This class deals with parsing and interpreter state (the user's
    namespace); it doesn't deal with input buffering or prompting or
    input file naming (the filename is always passed in explicitly).

    InteractiveConsole.__init__dummy_filenamePush a line to the interpreter.

        The line should not have a trailing newline; it may have
        internal newlines.  The line is appended to a buffer and the
        interpreter's runsource() method is called with the
        concatenated contents of the buffer as source.  If this
        indicates that the command was executed or invalid, the buffer
        is reset; otherwise, the command is incomplete, and the buffer
        is left as it was after the line was appended.  The return
        value is 1 if more input is required, 0 if the line was dealt
        with in some way (this is the same as runsource()).

        
KeyboardInterrupt
InteractiveConsole.interactClosely emulate the interactive Python console.

        The optional banner argument specifies the banner to print
        before the first interaction; by default it prints a banner
        similar to the one printed by the real Python interpreter,
        followed by the current class name in parentheses (so as not
        to confuse this with the real interpreter -- since it's so
        close!).

        The optional exitmsg argument specifies the exit message
        printed when exiting. Pass the empty string to suppress
        printing an exit message. If exitmsg is not given or None,
        a default message is printed.

        C:\msys64\mingw64\lib\python3.6\code.pyInteractiveInterpreter.showtracebackreadfuncCompile and run some source in the interpreter.

        Arguments are as for compile_command().

        One several things can happen:

        1) The input is incorrect; compile_command() raised an
        exception (SyntaxError or OverflowError).  A syntax traceback
        will be printed by calling the showsyntaxerror() method.

        2) The input is incomplete, and more input is required;
        compile_command() returned None.  Nothing happens.

        3) The input is complete; compile_command() returned a code
        object.  The code is executed by calling self.runcode() (which
        also handles run-time exceptions, except for SystemExit).

        The return value is True in case 2, False in the other cases (unless
        an exception is raised).  The return value can be used to
        decide whether to use sys.ps1 or sys.ps2 to prompt the next
        line.

        InteractiveInterpreter.runcodeExecute a code object.

        When an exception occurs, self.showtraceback() is called to
        display a traceback.  All exceptions are caught except
        SystemExit, which is reraised.

        A note about KeyboardInterrupt: this exception may occur
        elsewhere in this code, and may not always be caught.  The
        caller should be prepared to deal with it.

        Type "help", "copyright", "credits" or "license" for more information.InteractiveConsole.raw_inputUtilities needed to emulate Python's interactive interpreter.

Display the syntax error that just occurred.

        This doesn't display a stack trace because there isn't one.

        If a filename is given, it is stuffed in the exception instead
        of what was there before (because Python's parser always uses
        "<string>" when reading from a string).

        The output is written by self.write(), below.

        InteractiveConsole.pushReset the input buffer.__console__InteractiveInterpreter.runsourceConstructor.

        The optional locals argument will be passed to the
        InteractiveInterpreter base class.

        The optional filename argument should specify the (file)name
        of the input stream; it will show up in tracebacks.

        InteractiveInterpreter.writeWrite a prompt and read a line.

        The returned line does not include the trailing newline.
        When the user enters the EOF key sequence, EOFError is raised.

        The base implementation uses the built-in function
        input(); a subclass may replace this with a different
        implementation.

        last_tbClosely emulate the behavior of the interactive Python interpreter.

    This class builds on InteractiveInterpreter and adds prompting
    using the familiar sys.ps1 and sys.ps2, and input buffering.

    Display the exception that just occurred.

        We remove the first stack item because it is our own code.

        The output is written by self.write(), below.

        Constructor.

        The optional 'locals' argument specifies the dictionary in
        which code will be executed; it defaults to a newly created
        dictionary with key "__name__" set to "__console__" and key
        "__doc__" set to None.

        InteractiveInterpreter.showsyntaxerrorClosely emulate the interactive Python interpreter.

    This is a backwards compatible interface to the InteractiveConsole
    class.  When readfunc is not specified, it attempts to import the
    readline module to enable GNU readline if it is available.

    Arguments (all optional, all default to None):

    banner -- passed to InteractiveConsole.interact()
    readfunc -- if not None, replaces InteractiveConsole.raw_input()
    local -- passed to InteractiveInterpreter.__init__()
    exitmsg -- passed to InteractiveConsole.interact()

    Write a string.

        The base implementation writes to sys.stderr; a subclass may
        replace this with a different implementation.

        <module code>__excepthook__now exiting %s...
  þÿ Decodes data from the stream self.stream and returns the
            resulting object.

            chars indicates the number of decoded code points or bytes to
            return. read() will never return more data than requested,
            but it might return less, if there is not enough available.

            size indicates the approximate maximum number of decoded
            bytes or code points to read for decoding. The decoder
            can modify this setting as appropriate. The default value
            -1 indicates to read and decode as much as possible.  size
            is intended to prevent having to decode huge files in one
            step.

            If firstline is true, and a UnicodeDecodeError happens
            after the first line terminator in the input only the first line
            will be returned, the rest of the input will be kept until the
            next call to read().

            The method should use a greedy read strategy, meaning that
            it should read as much data as is allowed within the
            definition of the encoding and the given size, e.g.  if
            optional encoding endings or state markers are available
            on the stream, these should be read too.
        StreamReaderWriter.__enter__StreamRecoder.__init__
    This subclass of IncrementalDecoder can be used as the baseclass for an
    incremental decoder if the decoder must be able to handle incomplete
    byte sequences.
    StreamReader.readlineStreamWriter.writelinesreadsizeline0withendline0withoutend Lookup up the codec for the given encoding and return
        its IncrementalDecoder class or factory function.

        Raises a LookupError in case the encoding cannot be found
        or the codecs doesn't provide an incremental decoder.

    charbuffernamereplacereplace_errorsStreamWriter.seekStreamReader.__getattr__StreamReader.resetStreamWriter.__init__StreamReaderWriter.writenamereplace_errorsStreamReader.seek
        Reset the decoder to the initial state.
        iterdecode Decodes the object input and returns a tuple (output
            object, length consumed).

            input must be an object which provides the bf_getreadbuf
            buffer slot. Python strings, buffer objects and memory
            mapped files are examples of objects providing this slot.

            errors defines the error handling to apply. It defaults to
            'strict' handling.

            The method may not store state in the Codec instance. Use
            StreamReader for codecs which have to keep state in order to
            make decoding efficient.

            The decoder must be able to handle zero length input and
            return an empty object of the output object type in this
            situation.

        StreamReaderWriter.readlinebytesencodedIncrementalEncoder.reset Creates a StreamReader instance.

            stream must be a file-like object open for reading.

            The StreamReader may use different error handling
            schemes by providing the errors keyword argument. These
            parameters are predefined:

             'strict' - raise a ValueError (or a subclass)
             'ignore' - ignore the character and continue with the next
             'replace'- replace with a suitable replacement character
             'backslashreplace' - Replace with backslashed escape sequences;

            The set of allowed parameter values can be extended via
            register_error.
        Û,   zregisterzlookupzopenzEncodedFilezBOMzBOM_BEzBOM_LEzBOM32_BEzBOM32_LEzBOM64_BEzBOM64_LEzBOM_UTF8z	BOM_UTF16zBOM_UTF16_LEzBOM_UTF16_BEz	BOM_UTF32zBOM_UTF32_LEzBOM_UTF32_BEz	CodecInfozCodeczIncrementalEncoderzIncrementalDecoderzStreamReaderzStreamWriterzStreamReaderWriterzStreamRecoderz
getencoderz
getdecoderzgetincrementalencoderzgetincrementaldecoderz	getreaderz	getwriterzencodezdecodez
iterencodez
iterdecodezstrict_errorszignore_errorszreplace_errorszxmlcharrefreplace_errorszbackslashreplace_errorsznamereplace_errorszregister_errorzlookup_error
    An IncrementalEncoder encodes an input in multiple steps. The input can
    be passed piece by piece to the encode() method. The IncrementalEncoder
    remembers the state of the encoding process between calls to encode().
    C:\msys64\mingw64\lib\python3.6\codecs.pyIncrementalDecoder.decodeBufferedIncrementalDecoder.reset
        Decode input and returns the resulting object.
        
        Return the current state of the encoder.
        bytebufferStreamReader.__exit__Codec details when looking up the codec registryBufferedIncrementalEncoder.__init__BufferedIncrementalEncoder.setstate Resets the codec buffers used for keeping state.

            Note that no stream repositioning should take place.
            This method is primarily intended to be able to recover
            from decoding errors.

        StreamReaderWriter.__getattr__StreamWriter.__getattr__BufferedIncrementalDecoder.setstate
    Encoding iterator.

    Encodes the input strings from the iterator using an IncrementalEncoder.

    errors and kwargs are passed through to the IncrementalEncoder
    constructor.
    
        Creates an IncrementalEncoder instance.

        The IncrementalEncoder may use different error handling schemes by
        providing the errors keyword argument. See the module docstring
        for a list of possible values.
        StreamReaderWriter.__iter__file_encoding
        Encodes input and returns the resulting object.
        _empty_charbuffersizehint Writes the concatenated list of strings to the stream
            using .write().
        StreamReader.readlinesCodecInfo.__new__ Inherit all other methods from the underlying stream.
        StreamRecoder.__getattr__bytesdecodedIncrementalDecoder.getstateStreamReaderWriter.__next__ÿþ Lookup up the codec for the given encoding and return
        its StreamWriter class or factory function.

        Raises a LookupError in case the encoding cannot be found.

     Defines the interface for stateless encoders/decoders.

        The .encode()/.decode() methods may use different error
        handling schemes by providing the errors argument. These
        string values are predefined:

         'strict' - raise a ValueError error (or a subclass)
         'ignore' - ignore the character and continue with the next
         'replace' - replace with a suitable replacement character;
                    Python will use the official U+FFFD REPLACEMENT
                    CHARACTER for the builtin Unicode codecs on
                    decoding and '?' on encoding.
         'surrogateescape' - replace with private code points U+DCnn.
         'xmlcharrefreplace' - Replace with the appropriate XML
                               character reference (only for encoding).
         'backslashreplace'  - Replace with backslashed escape sequences.
         'namereplace'       - Replace with \N{...} escape sequences
                               (only for encoding).

        The set of allowed values can be extended via register_error.

     Creates a StreamRecoder instance which implements a two-way
            conversion: encode and decode work on the frontend (the
            data visible to .read() and .write()) while Reader and Writer
            work on the backend (the data in stream).

            You can use these objects to do transparent
            transcodings from e.g. latin-1 to utf-8 and back.

            stream must be a file-like object.

            encode and decode must adhere to the Codec interface; Reader and
            Writer must be factory functions or classes providing the
            StreamReader and StreamWriter interfaces resp.

            Error handling is done in the same way as defined for the
            StreamWriter/Readers.

        
        Resets the encoder to the initial state.
        Failed to load the builtin codecs: %s Return a wrapped version of file which provides transparent
        encoding translation.

        Data written to the wrapped file is decoded according
        to the given data_encoding and then encoded to the underlying
        file using file_encoding. The intermediate data type
        will usually be Unicode but depends on the specified codecs.

        Bytes read from the file are decoded using file_encoding and then
        passed back to the caller encoded using data_encoding.

        If file_encoding is not given, it defaults to data_encoding.

        errors may be given to define the error handling. It defaults
        to 'strict' which causes ValueErrors to be raised in case an
        encoding error occurs.

        The returned wrapped file object provides two extra attributes
        .data_encoding and .file_encoding which reflect the given
        parameters of the same name. The attributes can be used for
        introspection by Python programs.

    
        Create an IncrementalDecoder instance.

        The IncrementalDecoder may use different error handling schemes by
        providing the errors keyword argument. See the module docstring
        for a list of possible values.
         Return the next decoded line from the input stream.newcharsdecodedbytes
    Decoding iterator.

    Decodes the input strings from the iterator using an IncrementalDecoder.

    errors and kwargs are passed through to the IncrementalDecoder
    constructor.
    StreamRecoder.readStreamRecoder.readline
    This subclass of IncrementalEncoder can be used as the baseclass for an
    incremental encoder if the encoder must keep some of the output in a
    buffer between calls to encode().
    _buffer_encode Encodes the object input and returns a tuple (output
            object, length consumed).

            errors defines the error handling to apply. It defaults to
            'strict' handling.

            The method may not store state in the Codec instance. Use
            StreamWriter for codecs which have to keep state in order to
            make encoding efficient.

            The encoder must be able to handle zero length input and
            return an empty object of the output object type in this
            situation.

        StreamRecoder.__next__ make_identity_dict(rng) -> dict

        Return a dictionary where elements of the rng sequence are
        mapped to themselves.

     Flushes and resets the codec buffers used for keeping state.

            Calling this method should ensure that the data on the
            output is put into a clean state, that allows appending
            of new fresh data without having to rescan the whole
            stream to recover state.

        IncrementalDecoder.__init__BufferedIncrementalDecoder.decodeStreamReaderWriter.__exit__ÿþ  StreamReaderWriter.writelinesBufferedIncrementalEncoder._buffer_encode_is_text_encodingfile_infoIncrementalEncoder.getstateBufferedIncrementalEncoder.encodeStreamReader.__next__StreamRecoder.__exit__srwBufferedIncrementalEncoder.getstateStreamRecoder.__iter__
        Return the current state of the decoder.

        This must be a (buffered_input, additional_state_info) tuple.
        buffered_input must be a bytes object containing bytes that
        were passed to decode() that have not yet been converted.
        additional_state_info must be a non-negative integer
        representing the state of the decoder WITHOUT yet having
        processed the contents of buffered_input.  In the initial state
        and after reset(), getstate() must return (b"", 0).
        data_infocharbuffertypeStreamRecoder.reset Read all lines available on the input stream
            and return them as a list.

            Line breaks are implemented using the codec's decoder
            method and are included in the list entries.

            sizehint, if given, is ignored since there is no efficient
            way to finding the true end-of-line.

         Lookup up the codec for the given encoding and return
        its IncrementalEncoder class or factory function.

        Raises a LookupError in case the encoding cannot be found
        or the codecs doesn't provide an incremental encoder.

    StreamRecoder.writeStreamReaderWriter.reset Lookup up the codec for the given encoding and return
        its StreamReader class or factory function.

        Raises a LookupError in case the encoding cannot be found.

     Writes the object's contents encoded to self.stream.
        BufferedIncrementalDecoder._buffer_decode Set the input stream's current position.

            Resets the codec buffers used for keeping state.
        BufferedIncrementalDecoder.getstate<module codecs>StreamWriter.__exit__ Creates a StreamWriter instance.

            stream must be a file-like object open for writing.

            The StreamWriter may use different error handling
            schemes by providing the errors keyword argument. These
            parameters are predefined:

             'strict' - raise a ValueError (or a subclass)
             'ignore' - ignore the character and continue with the next
             'replace'- replace with a suitable replacement character
             'xmlcharrefreplace' - Replace with the appropriate XML
                                   character reference.
             'backslashreplace'  - Replace with backslashed escape
                                   sequences.
             'namereplace'       - Replace with \N{...} escape sequences.

            The set of allowed parameter values can be extended via
            register_error.
        StreamReader.decodeStreamRecoder.readlinesCodec.decode Open an encoded file using the given mode and return
        a wrapped version providing transparent encoding/decoding.

        Note: The wrapped version will only accept the object format
        defined by the codecs, i.e. Unicode objects for most builtin
        codecs. Output is also codec dependent and will usually be
        Unicode as well.

        Underlying encoded files are always opened in binary mode.
        The default file mode is 'r', meaning to open the file in read mode.

        encoding specifies the encoding which is to be used for the
        file.

        errors may be given to define the error handling. It defaults
        to 'strict' which causes ValueErrors to be raised in case an
        encoding error occurs.

        buffering has the same meaning as for the builtin open() API.
        It defaults to line buffered.

        The returned wrapped file object provides an extra attribute
        .encoding which allows querying the used encoding. This
        attribute is only available if an encoding was specified as
        parameter.

    BufferedIncrementalEncoder.reset_falseStreamReader.__init__ codecs -- Python Codec Registry, API and helpers.


Written by Marc-Andre Lemburg (mal@lemburg.com).

(c) Copyright CNRI, All Rights Reserved. NO WARRANTY.

BufferedIncrementalDecoder.__init__
        Set the current state of the decoder.

        state must have been returned by getstate().  The effect of
        setstate((b"", 0)) must be equivalent to reset().
        make_encoding_mapStreamReader.__iter__StreamReaderWriter.seek_codecsdecoding_map
        Set the current state of the encoder. state must have been
        returned by getstate().
        CodecInfo.__repr__ StreamRecoder instances translate data from one encoding to another.

        They use the complete set of APIs returned by the
        codecs.lookup() function to implement their task.

        Data written to the StreamRecoder is first decoded into an
        intermediate format (depending on the "decode" codec) and then
        written to the underlying stream using an instance of the provided
        Writer class.

        In the other direction, data is read from the underlying stream using
        a Reader instance and then encoded and returned to the caller.

     StreamReaderWriter instances allow wrapping streams which
        work in both read and write modes.

        The design is such that one can use the factory functions
        returned by the codec.lookup() function to construct the
        instance.

    StreamWriter.__enter__
    An IncrementalDecoder decodes an input in multiple steps. The input can
    be passed piece by piece to the decode() method. The IncrementalDecoder
    remembers the state of the decoding process between calls to decode().
     Lookup up the codec for the given encoding and return
        its encoder function.

        Raises a LookupError in case the encoding cannot be found.

     Read one line from the input stream and return the
            decoded data.

            size, if given, is passed as size argument to the
            read() method.

        StreamReader.__enter__linebufferStreamWriter.resetStreamRecoder.__enter__ Creates an encoding map from a decoding map.

        If a target mapping in the decoding map occurs multiple
        times, then that target is mapped to None (undefined mapping),
        causing an exception when encountered by the charmap codec
        during translation.

        One example where this happens is cp875.py which decodes
        multiple character to \u001a.

     Creates a StreamReaderWriter instance.

            stream must be a Stream-like object.

            Reader, Writer must be factory functions or classes
            providing the StreamReader, StreamWriter interface resp.

            Error handling is done in the same way as defined for the
            StreamWriter/Readers.

        StreamReaderWriter.readlinesStreamReaderWriter.__init__<%s.%s object for encoding %s at %#x>Codec.encodeStreamRecoder.writelines Lookup up the codec for the given encoding and return
        its decoder function.

        Raises a LookupError in case the encoding cannot be found.

    C:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\codegen\__init__.pyasyncgen_exitasyncgen_qualname_objasyncgen_object_bodytemplates.CodeTemplatesAsyncgenscodegen.AsyncgenCodesstruct Nuitka_AsyncgenObject *C:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\codegen\AsyncgenCodes.pyasyncgen_identifier<module codegen.AsyncgenCodes>asyncgen_name_obj Code to generate and interact with compiled asyncgen objects.

getAttributeAssignmentDictSlotCodecodegen.AttributeCodesgetAttributeAssignmentClassSlotCode%s = LOOKUP_ATTRIBUTE_DICT_SLOT( %s );getattr_target%s = SET_ATTRIBUTE( %s, %s, %s );getAttributeLookupSpecialCodegetAttributeDelCode Attribute related codes.

Attribute lookup, setting.
setattr_value Code for special case target.__dict__ = value attrdel_targetassattr_targetassattr_namegetAttributeLookupCode Get code for special case target.__class__ = value %s = LOOKUP_SPECIAL( %s, %s );BUILTIN_HASATTR%s = SET_ATTRIBUTE_DICT_SLOT( %s, %s );hasattr_value%s = PyObject_DelAttr( %s, %s );BUILTIN_SETATTR%s = LOOKUP_ATTRIBUTE_CLASS_SLOT( %s );%s = SET_ATTRIBUTE_CLASS_SLOT( %s, %s );getattr_defaultsetattr_attrC:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\codegen\AttributeCodes.pysetattr_target%s = LOOKUP_ATTRIBUTE( %s, %s );getattr_attr<module codegen.AttributeCodes>getAttributeAssignmentCode%s = PyObject_HasAttr( %s, %s );BUILTIN_GETATTRStreamData.__init__StreamData.getStreamDataCode Blob codes for storing binary data semi-efficiently.

This module offers means to store and encode binary blobs in C semi
efficiently. The "StreamData" class is used in two places, for constants
and for freezing of bytecode.
StreamData.getBytescodegen.BlobCodes&constant_bin[ %d ], %dStreamData.getStreamDataOffset<module codegen.BlobCodes>C:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\codegen\BlobCodes.pyC:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\codegen\BranchCodes.pybranch_yes Branch related codes.

<module codegen.BranchCodes>branch_endbranch_noBUILTIN_OCTBUILTIN_COMPLEX2BUILTIN_COMPLEX1BUILTIN_RANGExrange_lowopen_bufferingoct_argreal_argrange3_stepBUILTIN_OPENopen_closefdTO_BOOLimag_argrange2_lowBUILTIN_RANGE3range3_highhex_arg%s = (PyObject *)%s;bytearray_stringbytearray_errorsBUILTIN_BYTEARRAY1BUILTIN_RANGE2BUILTIN_XRANGE1BUILTIN_HEXBUILTIN_BYTEARRAY3 Built-in codes

This is code generation for built-in references, and some built-ins like range,
bin, etc.
BUILTIN_SUM2bytearray_argclassmethod_argTO_FLOATbool_argsum_sequenceBUILTIN_SUM1%s = BUILTIN_TYPE3( %s, %s, %s, %s );bin_argxrange_steprange3_lowBUILTIN_XRANGE2open_encodingbytearray_encodingopen_newlineBUILTIN_CLASSMETHODfloat_argBUILTIN_STATICMETHODcodegen.BuiltinCodes<module codegen.BuiltinCodes>BUILTIN_TYPE1staticmethod_argopen_filenamexrange_highC:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\codegen\BuiltinCodes.pyBUILTIN_XRANGE3open_modeopen_errorsrange2_highopen_openersum_startBUILTIN_BINgetInstanceCallCodePosArgsQuick Code generation for calls.

The different kinds of calls get dedicated code. Most notable, calls with
only positional arguments, are attempted through helpers that might be
able to execute them without creating the argument dictionary at all.

arg_tuplequick_call_usedcalled_attribute_namecall_args_valuecall_arg_namescall_arg_elementargs_name%s = CALL_FUNCTION_WITH_KEYARGS( %s, %s );call_args_namecall_kw_name%s = CALL_METHOD_NO_ARGS( %s, %s );{
    PyObject *call_args[] = { %s };
    %s = CALL_METHOD_WITH_ARGS%d( %s, %s, call_args );
}
args_countarg_sizeheader_guard_namegetCallCodePosArgsC:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\codegen\CallCodes.py%s = CALL_FUNCTION_WITH_ARGS%d( %s, &PyTuple_GET_ITEM( %s, 0 ) );
quick_calls_usedheader_bodygetCallCodeFromTuple_generateCallCodePosOnly<module codegen.CallCodes>isExpressionAttributeLookupSpecialgetCallCodePosKeywordArgscalled_instancegetInstanceCallCodeNoArgs_generateCallCodeKwOnly_getCallCodeKeywordArgs%s = CALL_FUNCTION_NO_ARGS( %s );templates.CodeTemplatesCalls%s = CALL_FUNCTION( %s, %s, %s );%s = CALL_METHOD_WITH_POSARGS( %s, %s, %s );{
    PyObject *call_args[] = { %s };
    %s = CALL_FUNCTION_WITH_ARGS%d( %s, call_args );
}
%s = CALL_METHOD_WITH_ARGS%d( %s, %s, &PyTuple_GET_ITEM( %s, 0 ) );
quick_instance_calls_usedgetInstanceCallCodeFromTuple%s = CALL_FUNCTION_WITH_POSARGS( %s, %s );__NUITKA_CALLS_H__codegen.ClassCodesBUILTIN_ISINSTANCE<module codegen.ClassCodes>metaclass_name%s = BUILTIN_SUPER( %s, %s );C:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\codegen\ClassCodes.py%s = SELECT_METACLASS( %s ); Codes for classes.

Most the class specific stuff is solved in re-formulation. Only the selection
of the metaclass remains as specific.
 The code generation.

No language specifics at all are supposed to be present here. Instead it is
using primitives from the given generator to build code sequences (list of
strings).

As such this is the place that knows how to take a condition and two code
branches and make a code block out of it. But it doesn't contain any target
language syntax.
IdCodesReturnCodesSetCodes_generated_functionsEvalCodesCoroutineCodesgenerateFunctionBodyCodecodegen.CodeGenerationListCodesLocalsDictCodesSubscriptCodesfunction_contextRaisingCodesmodule_exception_exitPrintCodes©ÚgenerateBuiltinAnonymousRefCodeÚgenerateBuiltinBinCodeÚgenerateBuiltinBoolCodeÚgenerateBuiltinBytearray1CodeÚgenerateBuiltinBytearray3CodeÚgenerateBuiltinClassmethodCodeÚgenerateBuiltinComplex1CodeÚgenerateBuiltinComplex2CodeÚgenerateBuiltinFloatCodeÚgenerateBuiltinHexCodeÚgenerateBuiltinOctCodeÚgenerateBuiltinOpenCodeÚgenerateBuiltinRange1CodeÚgenerateBuiltinRange2CodeÚgenerateBuiltinRange3CodeÚgenerateBuiltinRefCodeÚgenerateBuiltinStaticmethodCodeÚgenerateBuiltinSum1CodeÚgenerateBuiltinSum2CodeÚgenerateBuiltinType1CodeÚgenerateBuiltinType3CodeÚgenerateBuiltinXrange1CodeÚgenerateBuiltinXrange2CodeÚgenerateBuiltinXrange3CodeLoaderCodesGlobalsLocalsCodesYieldCodesC:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\codegen\CodeGeneration.pyTryCodescalls_decl_codecalls_body_code_generateFunctionDeclCodeloader_codeImportCodes<module codegen.CodeGeneration>OperationCodesStringCodesExpressionCodesSliceCodesLoopCodesIntegerCodesgenerateStatementCodesource_reprchild_value<module codegen.CodeHelpers> Helpers for code generation.

This dispatch building of expressions and statements, as well as providing
typical support functions to building parts.

expression_dispatch_dictC:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\codegen\CodeHelpers.pystatement_dispatch_dictNo expression %r_generateExpressionCode<module codegen.CodeObjectCodes>static PyCodeObject *%s;_code_object_keyCO_NEWLOCALSCO_NOFREEcodeobj_main = %s;PyCodeObject *codeobj_main = NULL;filename_codemodule_filename_obj = MAKE_RELATIVE_PATH( %s );CO_OPTIMIZEDmodule_filename_obj = %s;/* For use in "MainProgram.c". */%s = MAKE_CODEOBJ( %s, %s, %d, %s, %d, %d, %s );C:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\codegen\CodeObjectCodes.py%s = MAKE_CODEOBJ( %s, %s, %d, %s, %d, %s ); Code generation for code objects.

Right now only the creation is done here. But more should be added later on.
exc_match_RICH_COMPARE_%scompexpr_leftcmp_%s = ( %s == %s );operator_res_nameisnotcompexpr_right%s = RICH_COMPARE_BOOL_%s( %s, %s );C:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\codegen\ComparisonCodes.py_NORECURSE%s = EXCEPTION_MATCH_BOOL( %s, %s );cmp_exception_match%s = PySequence_Contains( %s, %s );%s = BOOL_FROM( %s != %s );%s = Nuitka_IsInstance( %s, %s );%s = BOOL_FROM( %s != 0 );%s == %d<module codegen.ComparisonCodes>%s = %s( %s, %s ); Comparison related codes.

Rich comparisons, "in", and "not in", also "is", and "is not", and the
"isinstance" check as used in conditions, as well as exception matching.
%s = ( %s != %s );needs_ref2truth_nameneeds_ref1condexpr_truecompare_rightisExpressionConditionalORgetConditionCheckTrueCodeselect_endcompare_leftisExpressionBuiltinHasattrcond_valueisExpressionOperationNOTC:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\codegen\ConditionalCodes.pyselect_truehasattr_sourceleft_truthcodegen.ConditionalCodesreal_emitisExpressionBuiltinIsinstancecondexpr_endselect_falsecondexpr_false%s = CHECK_IF_TRUE( %s );<module codegen.ConditionalCodes>cond_truth©Ú	conditionÚemitÚcontextÚ	left_nameÚ
right_nameÚold_source_refÚtrue_targetÚfalse_targetÚexpression_yesÚexpression_noÚold_true_targetÚold_false_targetÚselect_trueÚselect_falseÚ
select_endÚsource_nameÚ	attr_nameÚ	inst_nameÚcls_nameÚcondition_nameÚ
truth_name Conditional statements related codes.

Branches, conditions, truth checks.
getConstantsInitCode.<locals>.<lambda>Py_hash_t hash_%s;sorted_constantsconstant_identifierUNSTREAM_STRING( %s, %d, %d )PySet_New( NULL ) Assign the constant behind the expression to to_name.min_signed_long_addConstantInitCode Return code, if possible, to create a constant.

        It's only used for module local constants, like error messages, and
        provides no caching of the values. When it returns "None", it is in
        error.
    constant_checksgetMarshalCode%s = MAKE_XRANGE( %s, %s, %s );NUITKA_PRINT_TRACE("Creating constant: %s");%s = PyLong_FromLong( %sl );isMarshalConstantcodegen.ConstantCodessys_executablesizeof_long Assign 'None' to to_name.max_unsigned_long%s = PyInt_FromLong( %sl );  // To be corrected in next line.
%s = PyNumber_InPlaceSubtract( %s, PyInt_FromLong( 1 ) );constant_initsconstant_declarationsPyList_SET_ITEM( %s, %d, %s ); Py_INCREF( %s );const_xrange_%s = UNSTREAM_BYTES( %s );PyTuple_SET_ITEM( %s, %d, %s ); Py_INCREF( %s );%s = PyLong_FromLong( %sl ); // To be corrected with -1 in-place next lines.
CHECK_OBJECT( const_int_pos_1 );
%s = PyNumber_InPlaceSubtract( %s, PyLong_FromLong( 1 ) );_match_attribute_names Assign 'Ellipsis' to to_name. Low level constant code generation.

This deals with constants, there creation, there access, and some checks about
them. Even mutable constants should not change during the course of the
program.

There are shared constants, which are created for multiple modules to use, you
can think of them as globals. And there are module local constants, which are
for a single module only.

qualifierassert( PyDict_Size( %s ) == %d );_isAttributeName%s = UNSTREAM_BYTEARRAY( %s );allocateNestedConstants.<locals>.considerForDeferralC:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\codegen\ConstantCodes.pyCHECK_OBJECT( %(constant_identifier)s );
assert( hash_%(constant_identifier)s == DEEP_HASH( %(constant_identifier)s ) );Problem with marshal of constant %r%s Py_hash_t hash_%s;%s = PyLong_FromUnsignedLong( %sul );marshal_valueneeds_deep%s = UNSTREAM_STRING( %s, %d );[a-zA-Z_][a-zA-Z0-9_]*$%s = PyObject_CallFunction((PyObject*)&PyFrozenSet_Type, NULL);getConstantInitCodes.<locals>.<lambda>PyObject *%s;extern Assign 'True' to to_name. Force the marshal of a value.

    %s = PySlice_New( %s, %s, %s );PySet_New( %s ) Decide of a constant can be created using "marshal" module methods.

        This is not the case for everything. A prominent exception is types,
        they are constants, but the "marshal" module refuses to work with
        them.
    templates.CodeTemplatesConstants%s = PyMarshal_ReadObjectFromString( (char *)%s );%s = Py_True;%s = UNSTREAM_FLOAT( %s );%s = BUILTIN_XRANGE3( %s, %s, %s );PyDict_New()decideMarshalPyDict_SetItem( %s, %s, %s );attemptToMarshalPyList_New( 0 )module_level%s = %s( NULL );PyDict_Copy( %s )BYTEARRAY_COPY( %s )getConstantsDeclCode.<locals>.<lambda>assert( PySet_Size( %s ) == %d ); Emit code for a specific constant to be prepared during init.

        This may be module or global init. Code makes sure that nested
        constants belong into the same scope.
    %s = Py_Ellipsis;<module codegen.ConstantCodes>%s PyObject *%s; Create the code code "__constants.c" file.

        This needs to create code to make all global constants (used in more
        than one module) and create them.

    hash_%(constant_identifier)s = DEEP_HASH( %(constant_identifier)s ); Assign 'False' to to_name.%s = Py_False;©ÚcontextÚemitÚcheckÚconstant_typeÚconstant_valueÚconstant_identifierÚmodule_levelÚencodedÚkeyÚvalueÚkey_nameÚ
value_nameÚcountÚelement_valueÚelement_nameÚslice1_nameÚslice2_nameÚslice3_nameÚ
range_argsÚrange1_nameÚrange2_nameÚrange3_nameÚbuiltin_nameÚbuiltin_identifier Decide if we want to use marshal to create a constant.

        The reason we do this, is because creating dictionaries with 700
        elements creates a lot of C code, while gaining usually no performance
        at all. The MSVC compiler is especially notorious about hanging like
        forever with this active, due to its optimizer not scaling.

        Therefore we use a constant "weight" (how expensive it is), and apply
        that to decide.

        If marshal is not possible, or constant "weight" is too large, we
        don't do it. Also, for some constants, marshal can fail, and return
        other values. Check that too. In that case, we have to create it.
    __addConstantInitCodeconstant_countsDEEP_COPY( %s ) Try and marshal a value, if so decided. Indicate with return value.

        See above for why marshal is only used in problematic cases.
    _getConstantInitValueCodeLIST_COPY( %s )PythonModuleContext.getOwnerTempMixin.setTrueBranchTargetconstant_use_countsetFrameGuardModePythonModuleContext.getConstantsFrameDeclarationsMixin.pushFrameHandleFrameDeclarationsMixin.getLocalsDictNamesPythonFunctionCreatedContext.isForDirectCallReturnValueNameMixinPythonFunctionOutlineContext.setFalseBranchTargetPythonGlobalContext.countConstantUsePythonModuleContext.__init__TempMixin.getLoopContinueTargetPythonContextBase.popFrameVariablesPythonGlobalContext.getConstantUseCountPythonContextBase.setExceptionEscapeTempMixin.setLoopContinueTargetPythonModuleContext.addDeclarationPythonContextBase.hasHelperCodetype_description_%dPythonChildContextBase.getFrameVariableTypeDescription_calcHashFrameDeclarationsMixin.getFrameVariableTypeDescriptions<PythonFunctionContext for %s '%s'>PythonChildContextBase.getModuleCodeNamePythonModuleContext.addHelperCodeReturnReleaseModeMixin.setReturnTargetPythonAsyncgenObjectContext.getContextObjectNamePythonContextBase.addDeclarationPythonFunctionOutlineContext.getLoopContinueTargetTempMixin.getIntResNamePythonChildContextBase.popFrameVariableshash_valueTempMixin.setFalseBranchTargetFrameDeclarationsMixin.getFrameVariableTypeDescriptionNamecodegen.ContextsPythonGeneratorObjectContext.isForCrossModuleUsagelast_source_refPythonFunctionOutlineContext.getContextObjectNameforgotten_namesframe_variables_stackPythonContextBase.allocateTempNamePythonChildContextBase.getFrameVariableTypeDescriptionsContextMetaClassPythonChildContextBase.getModuleNamePythonFunctionOutlineContext.popCleanupScopePythonFunctionOutlineContext.hasTempNameexception_keeper_value_%dPythonModuleContext.markAsNeedsModuleFilenameObjectReturnReleaseModeMixin.__init__ Set current the frame variables. PythonChildContextBase.getFrameVariableCodeNamesPythonGeneratorObjectContext.isForDirectCallPythonFunctionOutlineContext.setLoopBreakTargetPythonModuleContext.getModuleCodeNamePythonContextBase.getFrameVariableTypeDescriptionName_getConstantDefaultPopulationPythonFunctionOutlineContext.getLoopBreakTargetFrameDeclarationsMixin.addFrameDeclarationPythonChildContextBase.__init__FrameDeclarationsMixin.getFrameHandlevariable_code_typeTempMixin.getExceptionEscapeTempMixin.getFalseBranchTargetFrameDeclarationsMixin.addLocalsDictNamereturn_release_modePythonFunctionOutlineContext.getIntResNamePythonModuleContext.getDeclarationsPythonFunctionContext.__repr__exception_keeper_tb_%dFrameDeclarationsMixin.__init__PythonContextBase.getModuleCodeNamePythonChildContextBase.addDeclaration(PyObject *)PyExc_%sPythonCoroutineObjectContext.getContextObjectNamePythonFunctionOutlineContext.addFrameDeclarationC:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\codegen\Contexts.pyFrameDeclarationsMixin.popFrameVariablesTempMixin.getBoolResNamefunction_exception_exitPythonContextBase.getBoolResNamePythonContextBase.setFalseBranchTargetPythonFunctionOutlineContext.mayRecursePythonContextBase.getLoopBreakTargetCodeObjectsMixinTempMixin.getTempNameInfosPythonContextBase.addExceptionPreserverVariablesPythonFunctionContext.getOwnerPythonContextBase.setTrueBranchTarget(int)tmp_unused_exception_escapetmp_{name}_{number:d}PythonGeneratorObjectContext.getGeneratorReturnValueNamePythonFunctionOutlineContext.addLocalsDictNameFrameDeclarationsMixin.getFrameVariableTypeDescription.<locals>.<genexpr>PythonContextBase.needsCleanupPythonContextBase.popCleanupScopeTempMixin.allocateExceptionKeeperVariablesPythonContextBase.allocateLabelPythonModuleContext.getNamePythonFunctionDirectContext.isForCreatedFunctionPythonFunctionOutlineContext.setLoopContinueTargetPythonContextBase.getExceptionEscapeFrameDeclarationsMixin.popFrameHandleCodeObjectsMixin.getCodeObjectHandleCodeObjectsMixin.__init__PythonGlobalContext.getConstantsfunction_return_exitTempMixin.pushCleanupScopeFrameDeclarationsMixin.getFrameDeclarationsTempMixin.getExceptionKeeperVariablesPythonFunctionDirectContext.isForCrossModuleUsageframe_declPythonFunctionOutlineContext.getEntryPointframe_stack<PythonModuleContext instance for module %s>PythonChildContextBase.addHelperCode(PyObject *)&PyClassMethod_TypeTempMixin.setExceptionKeeperVariablesPythonContextBase.getCleanupTempnamesPythonModuleContext.hasHelperCodePythonFunctionOutlineContext.forgetTempNameframe_variable_typestmp_typesPythonFunctionOutlineContext.getExceptionKeeperVariablesloop_continueTempMixin.markAsNeedsExceptionVariables(PyObject *)&Py%s_TypeReturnValueNameMixin.getReturnValueNamePythonModuleContext.getHelperCodesPythonChildContextBase.pushFrameVariablesPythonContextBase.getIntResNamePythonModuleContext.mayRaiseExceptionexception_keepers%s%s%d%s%d%d%s%s%s%s%s%s%sPythonFunctionOutlineContext.markAsNeedsExceptionVariablescurrent_source_refkeeper_variable_countPythonContextBase.forgetTempNameframes_usedPythonContextBase.removeCleanupTempNameTempMixin.getCleanupTempnamesPythonFunctionOutlineContext.setTrueBranchTargetPythonModuleContext.isCompiledPythonModulePythonFunctionContext.getEntryPointPythonModuleContext.getFilenamePythonContextBase.addHelperCodeFrameDeclarationsMixin.getFrameVariableCodeNames(PyObject *)&PyByteArray_Type(PyObject *)&PyMemoryView_TypeÛ(   © û0Ú TFé    é   ó    z
__module__z	__class__z__name__z__package__z__metaclass__z__dict__z__doc__z__file__z__path__z	__enter__z__exit__z__builtins__z__all__z__cmp__z__iter__zinspectzcompilezrangezopenzsumzformatz
__import__z	bytearrayzstaticmethodzclassmethodznamezglobalszlocalszfromlistzlevelzreadzrbPythonFunctionOutlineContext.__init__TempMixin.formatTempNameTempMixin.forgetTempNameTempMixin.getLoopBreakTargetPythonFunctionOutlineContext.allocateExceptionKeeperVariablesPythonContextBase.getModuleNamePythonContextBase.getFalseBranchTargetTempMixin.__init__PythonFunctionOutlineContext.pushFrameHandlePythonFunctionOutlineContext.setExceptionKeeperVariablesPythonGlobalContext.__init__PythonContextBase.getFrameVariableCodeNames(PyObject *)&PyBaseObject_TypePythonFunctionOutlineContext.getExceptionEscapePythonContextBase.isUsed Code generation contexts.

ReturnReleaseModeMixin.setReturnReleaseModePythonFunctionOutlineContext.getFalseBranchTargetPythonContextBase.getTempNameInfos(PyObject *)&PyStaticMethod_TypePythonChildContextBase.getFrameVariableTypeDescriptionNameReturnReleaseModeMixin.getReturnReleaseModeNUITKA_MAY_BE_UNUSED char const *type_description_%d = NULL;PythonContextBase.setExceptionKeeperVariablesTempMixin.hasTempNamegetFramesCountPythonFunctionOutlineContext.allocateLabelContextMetaClassBasePythonModuleContext.setFrameGuardModecodeobj_%sPythonContextBase.pushFrameVariableslocals_dict_namesPythonContextBase.setCurrentSourceCodeReferencePythonFunctionContext.getCodeObjectHandle End of frame, restore previous ones. PythonFunctionOutlineContext.getCleanupTempnamesdeclaration_codesgetLastSourceCodeReferencePythonContextBase.getExceptionKeeperVariablesTempMixin.needsExceptionVariablesPythonModuleContext.needsModuleFilenameObjectPythonFunctionOutlineContext.getCodeObjectHandleframe_type_descriptionsTempMixin.addExceptionPreserverVariablesPythonFunctionOutlineContext.getTempNameInfosTempMixin.setExceptionEscapeTempMixin.setLoopBreakTargetPythonGeneratorObjectContext.isForCreatedFunctionPythonContextBase.__init__PythonContextBase.hasTempNameneeds_exception_variablesPythonFunctionOutlineContext.getOwnerPythonModuleContext.__repr__PythonContextBase.getFrameVariableTypeDescriptions<module codegen.Contexts>TempMixin.getExceptionPreserverCountsTempMixin.removeCleanupTempNamePythonContextBase.allocateExceptionKeeperVariablesPythonGlobalContext.getConstantCodePythonFunctionOutlineContext.setExceptionEscapePythonFunctionOutlineContext.addExceptionPreserverVariablesPythonContextBase.getConstantCode(PyObject *)&PyRange_Typeexception_keeper_type_%dPythonFunctionOutlineContext.getTrueBranchTargetPythonContextBase.getCurrentSourceCodeReferencePythonContextBase.getLoopContinueTargetPythonModuleContext.getEntryPointTempMixin.allocateTempNamePythonFunctionDirectContext.isForDirectCallTempMixin.getKeeperVariableCountFrameDeclarationsMixin.pushFrameVariablesPythonFunctionOutlineContext.allocateTempNamePythonFunctionOutlineContext.isForDirectCallPythonContextBase.setLoopBreakTargetPythonContextBase.getLastSourceCodeReferencePythonChildContextBase.hasHelperCodeTempMixin.getLabelCount(PyObject *)&PyBaseString_TypePythonFunctionContext.mayRecursecleanup_namesPythonFunctionOutlineContext.pushCleanupScopereturn_namePythonModuleContext.mayRecurse(PyObject *)&PyFrozenSet_TypePythonFunctionOutlineContext.popFrameHandleFrameDeclarationsMixin.setVariableTypePythonFunctionOutlineContext.addCleanupTempNamePythonContextBase.setLoopContinueTarget(PyObject *)Py_TYPE( Py_None )NamifyReturnValueNameMixin.__init__PythonContextBase.markAsNeedsExceptionVariablestmp_namesTempMixin.addCleanupTempNamePythonFunctionOutlineContext.setVariableTypePythonContextBase.pushCleanupScopePythonChildContextBase.getConstantCodeTempMixin.needsCleanupPythonFunctionOutlineContext.getBoolResNameframe_declarationsPythonFunctionOutlineContext.needsExceptionVariablesPythonFunctionCreatedContext.isForCreatedFunctionexception_keeper_lineno_%sTempMixin.allocateLabelpreserver_variable_countsPythonContextBase.addCleanupTempNamePythonGeneratorObjectContext.getContextObjectNameTempMixin.getTrueBranchTargetPythonFunctionOutlineContext.removeCleanupTempNameCodeObjectsMixin.getCodeObjectsPythonFunctionContext.getFunctionPythonFunctionContext.__init__needs_module_filename_objectReturnReleaseModeMixin.getReturnTarget(PyObject *)&PyEnum_TypeCodeObjectsMixin._calcHashPythonContextBase.needsExceptionVariablesPythonModuleContext.getConstantCodePythonFunctionOutlineContext.getFrameHandleTempMixin.popCleanupScopeloop_breakPythonFunctionOutlineContext.needsCleanuphelper_codesFrameDeclarationsMixin.getFramesCountReturnValueNameMixin.setReturnValueNamePythonContextBase.getTrueBranchTargetAWAIT_IN_HANDLERtemplates.CodeTemplatesCoroutinescodegen.CoroutineCodes%s = %s_ASYNC_ITERATOR_NEXT( %s, %s );C:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\codegen\CoroutineCodes.py<module codegen.CoroutineCodes>coroutine_object_body%s = %s_ASYNC_MAKE_ITERATOR( %s, %s );coroutine_exitstruct Nuitka_CoroutineObject * Code to generate and interact with compiled coroutine objects.

coroutine_identifierseq_name%s = TO_DICT( %s, %s );%s = DICT_GET_ITEM( %s, %s );dictdel_keykey_arg_namedictupdate_dictdict_value_namegenerateKeyCode%s = PyDict_Update( %s, %s );dictupdate_valuegetDictionaryCreationCode.<locals>.generateValueCode<module codegen.DictCodes>dictset_dict Code generation for dictionaries.

dict_seqdictdel_dictC:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\codegen\DictCodes.pygetDictionaryCreationCode.<locals>.generateKeyCodedictset_keydict_key_nameisExpressionDictOperationNOTInassert( PyDict_Check( %s ) );%s = PyDict_Contains( %s, %s );<module codegen.Emission>SourceCodeCollector.__init__ Emission of source code.

Code generation is driven via "emit", which is to receive lines of code and
this is to collect them, providing the emit implementation. Sometimes nested
use of these will occur.

emitToC:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\codegen\Emission.pySourceCodeCollector.__call__SourceCodeCollector.emitSourceCodeCollector.emitToassert( %s );ADD_EXCEPTION_CONTEXT( &%s, &%s );getErrorFormatExitBoolCode.<locals>.<genexpr>PyObject *exception_type = NULL;return NULL;name '%s' is not definedgetErrorFormatExitCodeexception_tb = NULL;getErrorExitReleaseCode.<locals>.<genexpr>temp_releasePyTracebackObject *exception_keeper_tb_%d%s;<module codegen.ErrorCodes>NORMALIZE_EXCEPTION( &exception_type, &exception_value, &exception_tb );PyObject *exception_value = NULL;NUITKA_MAY_BE_UNUSED int exception_lineno = 0;PyExc_UnboundLocalErrorfree variable '%s' referenced before assignment in enclosing scopeCHAIN_EXCEPTION( exception_value );
Py_XDECREF( %s );preserver_obj_initPyObject *exception_preserved_type_%d%s;NUITKA_MAY_BE_UNUSED int exception_keeper_lineno_%d%s;PyExc_NameErrorreturn;return MOD_RETURN_VALUE( NULL );NUITKA_CANNOT_GET_HERE( %(function_identifier)s );CHECK_OBJECT( %s );Py_INCREF( exception_type );PyTracebackObject *exception_tb = NULL;PyObject *exception_preserved_value_%d%s;C:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\codegen\ErrorCodes.pyglobal name '%s' is not defined
Py_DECREF( %s );PyObject *exception_keeper_type_%d%s;!(%s)%s = "%s"; Error codes

These are the helper functions that will emit the error exit codes. They
can abstractly check conditions or values directly. The release of statement
temporaries from context is automatic.

Also formatting errors is done here, avoiding PyErr_Format as much as
possible.

And releasing of values, as this is what the error case commonly does.

keeper_obj_initPyTracebackObject *exception_preserved_tb_%d%s;PyObject *exception_keeper_value_%d%s;exception_value = Py%s_FromFormat( %s );codegen.EvalCodeseval_localsisExpressionBuiltinExeceval_globalscompile_filenamegetBuiltinEvalCodefilename_namemode_nameflags_namedont_inherit_nameoptimize_name<module codegen.EvalCodes>eval_compiled<execfile>eval_sourcecompile_source<string at %s>compiled_nameexec_resultgetStoreLocalsCode Eval/exec/execfile/compile built-in related codes. exec_compiledsync_localsCLEAR_ERROR_OCCURRED();C:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\codegen\EvalCodes.py_generateEvalCode%s = EVAL_CODE( %s, %s, %s );source_argcompile_dont_inheritgetBuiltinCompileCode%s == NULL && !EXCEPTION_MATCH_BOOL_SINGLE( GET_ERROR_OCCURRED(), PyExc_KeyError )compile_modeisExpressionBuiltinEval%s = PyDict_GetItem( %s, %s );%s = COMPILE_CODE( %s );if ( %s != NULL )%s = PyObject_GetItem( %s, %s );PyException_SetTraceback( %s, (PyObject *)%s );PUBLISH_EXCEPTION( &%s, &%s, &%s );exception_arg_names%s = %s ? %s : Py_None;make_exception_argMAKE_TRACEBACK( %s, %s ) Exception handling.

NORMALIZE_EXCEPTION( &%s, &%s, &%s );%s = EXC_TRACEBACK(PyThreadState_GET());if ( %(keeper_tb)s != NULL )
{
    %(to_name)s = (PyObject *)%(keeper_tb)s;
    Py_INCREF( %(to_name)s );
}
else
{
    %(to_name)s = (PyObject *)%(tb_making)s;
}
%s = EXC_VALUE(PyThreadState_GET());C:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\codegen\ExceptionCodes.py%s = EXC_TYPE(PyThreadState_GET());codegen.ExceptionCodes<module codegen.ExceptionCodes> Expression codes, side effects, or statements that are an unused expression.

When you write "f()", i.e. you don't use the return value, that is an expression
only statement.

NUITKA_MAY_BE_UNUSED PyObject *C:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\codegen\ExpressionCodes.pygetStatementOnlyCodecodegen.ExpressionCodes<module codegen.ExpressionCodes>skip_nested_handlingtype_indicatorgetTypeSizeOfgetFrameGuardOnceCodeframe_exception_exittemplates.CodeTemplatesFramesgetFrameGuardHeavyCodegetFrameLocalsStorageSizenested_frame_exitPRESERVE_FRAME_EXCEPTION( %(frame_identifier)s );real_parent_exception_exitparent_return_exitframe_return_exitno_exception_exitgenerateStatementsFrameCode.<locals>.<genexpr>sizeof(nuitka_bool)local_variablesneeds_preservelocal_emit Frame codes

This is about frame stacks and their management. There are different kinds
of frames for different uses.
%s->m_framelocals_size%s:;
C:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\codegen\FrameCodes.py// Preserve existing published exception.frame_variable_refsattach_localscache_frame_frame_no_exceptionRESTORE_FRAME_EXCEPTION( %(frame_identifier)s );frame_variable_codescodegen.FrameCodesSET_CURRENT_EXCEPTION( exception_preserved_type_%(preserver_id)d, exception_preserved_value_%(preserver_id)d, exception_preserved_tb_%(preserver_id)d );frame_cache_identifiergenerateStatementsFrameCode.<locals>.search// Restore previous exception.getFrameLocalsStorageSize.<locals>.<genexpr>getFrameGuardLightCodesizeof(void *)MAX( %s, %s )getFrameAttachLocalsCodeexception_preserved_type_%(preserver_id)d = EXC_TYPE(PyThreadState_GET());
Py_XINCREF( exception_preserved_type_%(preserver_id)d );
exception_preserved_value_%(preserver_id)d = EXC_VALUE(PyThreadState_GET());
Py_XINCREF( exception_preserved_value_%(preserver_id)d );
exception_preserved_tb_%(preserver_id)d = (PyTracebackObject *)EXC_TRACEBACK(PyThreadState_GET());
Py_XINCREF( exception_preserved_tb_%(preserver_id)d );
<module codegen.FrameCodes>function_creation_argsPyObject *annotationstmp_outline_return_value_outline_resulttemplates.CodeTemplatesFunctionC:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\codegen\FunctionCodes.py%s = MAKE_FUNCTION_%s( %s );function_qualnamedefaults_namekw_defaults_nameannotations_namefunction_qualname_objstruct Nuitka_FunctionObject const *selffunction_name_objtmp_return_value = NULL;tmp_infosmaker_codegetFunctionMakerCode
{
    PyObject *dir_call_args[] = {%s};
    %s = %s( dir_call_args%s%s );
}old_exception_target©ÚcontextÚfunction_identifierÚ
parametersÚclosure_variablesÚuser_variablesÚoutline_variablesÚtemp_variablesÚfunction_docÚ
file_scopeÚneeds_exception_exitÚfunction_localsÚfunction_cleanupÚfunction_codesÚresultÚemitÚfunction_exitÚparameter_objects_declÚclosure_variableÚvariable_code_nameÚvariable_c_typePyObject *%s = NULL;generateFunctionCreationCode.<locals>.handleKwDefaultspython_pars[ %d ]getFunctionMakerDecltmp_generator_return = false;suffix_args_tmp_typeoutline_exceptionPyObject *kw_defaultsold_return_release_modePy_XDECREF( %(locals_dict)s );
NUITKA_CROSS_MODULEdefaults_first%s%s%s;function_creation_arg_specold_return_targetPyObject **python_parscodegen.FunctionCodesold_return_value_namesetupFunctionLocalVariables.<locals>.<genexpr>function_impl_identifier_getFunctionCreationArgsPy_INCREF( result->m_closure[%d] );generateFunctionCreationCode.<locals>.handleDefaultsgetFunctionCreationCodegetDirectFunctionCallCodedirect_call_arg_specsetupFunctionLocalVariables.<locals>.<lambda><module codegen.FunctionCodes>NUITKA_LOCAL_MODULE%s = %s( NULL%s%s );result->m_closure[%d] = %s;Return statement must have exited already.dircall_arg%dPyObject *defaultsgetFunctionEntryPointIdentifiergetClosureVariableProvisionCodefunction_local_typesswitch(generator->m_yield_return_index) {char const *type_description;PyObject *tmp_unused;((%s)%s)->m_closure[%d]case %(index)d: goto yield_return_%(index)d;©ÚcontextÚfunction_identifierÚclosure_variablesÚuser_variablesÚoutline_variablesÚtemp_variablesÚneeds_exception_exitÚneeds_generator_returnÚfunction_localsÚfunction_cleanupÚfunction_codesÚgenerator_exitÚfunction_dispatchÚlocal_type_declÚlocal_type_initÚlocal_realsÚdeclÚpartsÚ	type_declÚvar_name<module codegen.GeneratorCodes>templates.CodeTemplatesGeneratorFunctionassert( Py_SIZE( %s ) >= %s ); generator_identifieryield_indexgenerator_object_bodygenerator_module Get code to copy closure variables storage.

    This gets used by generator/coroutine/asyncgen with varying "closure_type".
    generator_name_objgenerator_qualname_objC:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\codegen\GeneratorCodes.pystruct Nuitka_GeneratorObject *local_variables->test_code_getLocalVariableList%s = PyDict_New();mapping_name_getVariableDictUpdateCodevariable_descgenerateBuiltinLocalsCode.<locals>._sortedPyObject_Dircodegen.GlobalsLocalsCodesdir_argvars_argisExpressionBuiltinLocalsUpdatedC:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\codegen\GlobalsLocalsCodes.py Code generation for locals and globals handling.

This also includes writing back to locals for exec statements.
getLoadGlobalsCodeaccess_codeif (%(locals_dict)s == NULL) %(locals_dict)s = PyDict_New();
%(to_name)s = PyDict_Copy( %(locals_dict)s );generateBuiltinLocalsCode.<locals>._sorted.<locals>.<lambda>if (%(locals_dict)s == NULL) %(locals_dict)s = PyDict_New();
%(to_name)s = %(locals_dict)s;
Py_INCREF( %(to_name)s );%(to_name)s = (PyObject *)moduledict_%(module_identifier)s;LOOKUP_VARS<module codegen.GlobalsLocalsCodes> Codes for id and hash

<module codegen.IdCodes>hash_argPyLong_FromVoidPtrid_argBUILTIN_HASHC:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\codegen\IdCodes.pyimport_list_namelevel_namehelper_prefix Import related codes.

That is import as expression, and star import.
C:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\codegen\ImportCodes.pygetCountedArgumentsHelperCallCode%s = PySys_GetObject( (char *)"%s" );%s = %s_KW( %s );from_arg_name%s = PyImport_ImportModule("%s");codegen.ImportCodesIMPORT_MODULEstar_imported
%(res_name)s = IMPORT_MODULE_STAR( %(locals_dict)s, false, %(module_name)s );
%s = IMPORT_MODULE_STAR( %s, true, %s );<module codegen.ImportCodes>import_name_frommin_args%s = %s%d( %s );getCountedArgumentsHelperCallCode.<locals>.<genexpr>getBuiltinImportCodeimport_level{
    PyObject *module = PyImport_ImportModule("%(module_name)s");
    if (likely( module != NULL ))
    {
        %(to_name)s = PyObject_GetAttr( module, %(import_name)s );
    }
    else
    {
        %(to_name)s = NULL;
    }
}
if ( PyModule_Check( %(from_arg_name)s ) )
{
   %(to_name)s = IMPORT_NAME_OR_MODULE(
        %(from_arg_name)s,
        (PyObject *)MODULE_DICT(%(from_arg_name)s),
        %(import_name)s,
        %(import_level)s
    );
}
else
{
   %(to_name)s = IMPORT_NAME( %(from_arg_name)s, %(import_name)s );
}
%s = IMPORT_NAME( %s, %s );vert_block_indentedCodeC:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\codegen\Indentation.py_indentedCode.<locals>.<genexpr> Indentation of code.

Language independent, the amount of the spaces is not configurable, as it needs
to be the same as in templates.
%s = PY_SSIZE_T_MAX;<module codegen.IndexCodes>%s == -1 && ERROR_OCCURRED()%s = %d; Code generation for index values.

This is not for actual subscripts (see SubscriptCodes), but to convert
generic values to indexes. Also the maximum and minimum index values
are abstracted here.

%s = 0;%s = CONVERT_TO_INDEX( %s );C:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\codegen\IndexCodes.pylong_argcodegen.IntegerCodes%s = TO_LONG2( %s, %s ); Integer related codes, long and int.

C:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\codegen\IntegerCodes.pyint_arg%s = TO_INT2( %s, %s );<module codegen.IntegerCodes>PyNumber_IntPyNumber_Longrelease_temps_2iterator_nameC:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\codegen\IteratorCodes.pyrelease_temps_1line_number_code_1attempt_namerelease_codenext_defaultbreak_indicator_codeline_number_code_2BUILTIN_ITER2BUILTIN_LENMAKE_UNPACK_ITERATORcodegen.IteratorCodes Iteration related codes.

Next variants and unpacking with related checks.
var_description_code_1len_argiter_argBUILTIN_NEXT2iterator_attemptiter_sentinel%s = UNPACK_NEXT( %s, %s );templates.CodeTemplatesIteratorsiter_callable%s = UNPACK_NEXT( %s, %s, %s );var_description_code_2ITERATOR_NEXT( %s )getUnpackNextCode<module codegen.IteratorCodes>if (!( %s )) goto %s;<module codegen.LabelCodes>C:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\codegen\LabelCodes.py C labels, small helpers.

Much things are handled with "goto" statements in the generated code, error
exits, finally blocks, etc. this provides just the means to emit a label or
the goto statement itself.
if ( %s ) goto %s;if ( %s )
{
    goto %s;
}
else
{
    goto %s;
}NUITKA_PRINT_TRACE( "Execute: " %s );source_desc Generate code that updates the source code line.

getLineNumberCodelineno_valueC:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\codegen\LineNumberCodes.pycodegen.LineNumberCodesgetCurrentLineNumberCodeexception_lineno = %s;%s->m_frame.f_lineno = %s;%s = %s->m_frame.f_lineno;getLineNumberUpdateCodegetSetLineNumberCodeRawlist_arg_nameassert( PyList_Check( %s ) );codegen.ListCodesPySequence_List%s = _PyList_Extend( (PyListObject *)%s, %s );%s = PyList_Append( %s, %s ); Code generation for lists.

Right now only the creation is done here. But more should be added later on.
<module codegen.ListCodes>list_elementC:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\codegen\ListCodes.py%s = PyObject_CallMethod(  %s, (char *)"pop", NULL );<module codegen.LoaderCodes>NUITKA_BYTECODE_FLAGMOD_INIT_DECL( %s );NUITKA_PACKAGE_FLAGmetapath_loader_inittabmetapath_module_declsother_moduletemplates.CodeTemplatesLoader Code to generate and interact with module loaders.

This is for generating the look-up table for the modules included in a binary
or distribution folder.
C:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\codegen\LoaderCodes.pygetModuleMetapathLoaderEntryCodenew_locals_name%s == NULL && CHECK_AND_CLEAR_KEY_ERROR_OCCURRED()codegen.LocalsDictCodes Code generation for locals dict handling.

These are variable handling for classes and partially also Python2 exec
statements.
%s = PyObject_SetItem( %s, %s, %s );fallback_emitset_locals%(to_name)s = PyDict_GetItem( %(locals_dict)s, %(var_name)s );

%(to_name)s = BOOL_FROM( %(to_name)s != NULL );
%(locals_dict)s = %(locals_value)s;<module codegen.LocalsDictCodes>C:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\codegen\LocalsDictCodes.pyPy_DECREF( %(locals_dict)s );
%(locals_dict)s = NULL;%(tmp_name)s = MAPPING_HAS_ITEM( %(locals_dict)s, %(var_name)s );
%(to_name)s = BOOL_FROM( %(tmp_name)s == 1 );
%s = PyObject_DelItem( %s, %s );continue_targetold_loop_break<module codegen.LoopCodes>C:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\codegen\LoopCodes.pyloop_endloop_startloop_end_label Loop codes.

Code generation for loops, breaking them, or continuing them. In Nuitka, there
are no for-loops or while-loops at this point. They have been re-formulated in
a simpler loop without a condition, and statements there-in that break under
certain conditions.

See Developer Manual for how the CPython loops are mapped to these nodes.
old_loop_continueloop_start_labelCONSIDER_THREADING() == falsemodule_exit%s = module_filename_obj;codegen.ModuleCodesmodule_code_objects_decl<module codegen.ModuleCodes>module_name_objconstant_decl_codesconstant_init_codesconstant_check_codestemps_declstatic PyObject *module_filename_obj;module_functions_codelocal_var_initsmodule_body_template_values Code to generate and interact with compiled module objects.

module_%smodule_functions_declC:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\codegen\ModuleCodes.pymodule_code_objects_initC:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\codegen\Namify.py_namifyStringint_0angle_<module codegen.Namify>complex_%schr_%danon_%sExceptionCannotNamifyint_pos_%dfloat_%sslice_%s_%s_%slong_neg_%d^([a-z]|[A-Z]|[0-9]|_){1,40}$_minus_ Namify constants.
This determines the identifier names of constants in the generated code. We
try to have readable names where possible, and resort to hash codes only when
it is really necessary.

dict_empty_isAsciifrozenset_list_emptyfloat_%s_nanlong_pos_%d_re_str_needs_no_digestset_emptytype_%sunicode_digest_tuple_emptynamifyConstant.<locals>.<genexpr>int_neg_%dCouldn't namify '%r'frozenset_emptytype_notimplementedlong_0builtin_%sPOWER_OPERATION2BINARY_OPERATION_REMAINDERUNARY_OPERATIONPOWER_OPERATION_INPLACEBINARY_OPERATION_FLOORDIV<module codegen.OperationCodes>BINARY_OPERATION_MUL_INPLACEBINARY_OPERATION_DIVgetOperationCodeBINARY_OPERATION_ADD_INPLACEC:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\codegen\OperationCodes.py%s = BINARY_OPERATION_INPLACE( %s, &%s, %s );prefix_argsimpl_helperright_arg_nameBUILTIN_DIVMODinplace%s = %s( &%s, %s );BINARY_OPERATION_SUBBINARY_OPERATION_TRUEDIVleft_arg_name Codes for operations.

There are unary and binary operations. Many of them have specializations and
of course types could play into it. Then there is also the added difficulty of
in-place assignments, which have other operation variants.
PyObject_Reprcodegen.OperatorCodesEQGTPyNumber_PositivePyNumber_NegativePyNumber_InvertC:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\codegen\OperatorCodes.pySEQUENCE_CONTAINS_NOTPyNumber_MatrixMultiplyûzLShiftzPyNumber_LshiftzRShiftzPyNumber_RshiftzBitAndzPyNumber_AndzBitOrzPyNumber_OrzBitXorzPyNumber_XorzIAddzPyNumber_InPlaceAddzISubzPyNumber_InPlaceSubtractzIMultzPyNumber_InPlaceMultiplyzIDivzPyNumber_InPlaceDividez	IFloorDivzPyNumber_InPlaceFloorDividezITrueDivzPyNumber_InPlaceTrueDividezIModzPyNumber_InPlaceRemainderzILShiftzPyNumber_InPlaceLshiftzIRShiftzPyNumber_InPlaceRshiftzIBitAndzPyNumber_InPlaceAndzIBitOrzPyNumber_InPlaceOrzIBitXorzPyNumber_InPlaceXor0 Operator code tables

These are mostly used to look up the Python C/API from operations or a wrapper used.

PyNumber_InPlaceMatrixMultiply<module codegen.OperatorCodes>PRINT_NEW_LINE() == falseC:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\codegen\PrintCodes.pyprint_code<module codegen.PrintCodes>print_valuePRINT_NEW_LINE_TO( %s ) == falsedestinationdest_nameprint_dest Print related codes.

This is broken down to to level on printing one individual item, and
a new line potentially. The heavy lifting for 'softspace', etc. is
happening in the C helper functions.

%s = PRINT_ITEM_TO( %s, %s );%s = PRINT_ITEM( %s ); Code generation for standard CPython/API calls.

This is generic stuff.
arg_expressiongetCAPIObjectCode.<locals>.<genexpr>generateCAPIObjectCodeCommon<module codegen.PythonAPICodes>C:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\codegen\PythonAPICodes.pyraise_value_nameC:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\codegen\RaisingCodes.pyraise_typeif (exception_tb && exception_tb->tb_frame == &%(frame_identifier)s->m_frame) %(frame_identifier)s->m_frame.f_lineno = exception_tb->tb_lineno;getRaiseExceptionWithValueCodeisExpressionLocalsVariableRefORFallbackgetRaiseExceptionWithCauseCode// Re-raise.
exception_type = %(keeper_type)s;
exception_value = %(keeper_value)s;
exception_tb = %(keeper_tb)s;
exception_lineno = %(keeper_lineno)s;
isStatementRaiseExceptionImplicitraise_type_nameraise_tb_nameraise_cause%(bool_res_name)s = RERAISE_EXCEPTION( &exception_type, &exception_value, &exception_tb );
if (unlikely( %(bool_res_name)s == false ))
{
    %(update_code)s
}
 Code generation for implicit and explicit exception raises.

Exceptions from other operations are consider ErrorCodes domain.

RAISE_EXCEPTION_WITH_TYPE( &exception_type, &exception_value, &exception_tb );RAISE_EXCEPTION_WITH_CAUSE( &exception_type, &exception_value, &exception_tb, %s );getReRaiseExceptionCodeRAISE_EXCEPTION_%s( &exception_type, &exception_value, &exception_tb );codegen.RaisingCodesWITH_VALUEgetRaiseExceptionWithTracebackCodeIMPLICITraise_cause_nameexception_tb = (PyTracebackObject *)%s;RAISE_EXCEPTION_WITH_TRACEBACK( &exception_type, &exception_value, &exception_tb);getRaiseExceptionWithTypeCode<module codegen.RaisingCodes>generator_return_nameC:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\codegen\ReturnCodes.py<module codegen.ReturnCodes> Return codes

This handles code generation for return statements of normal functions and of
generator functions. Also the value currently being returned, and intercepted
by a try statement is accessible this way.

%s = PySet_New( NULL );codegen.SetCodesset_elementset_arg_name%s = _PySet_Update( %s, %s );element_namesassert( PySet_Check( %s ) );frozenset_argset_element_%d%s = PySet_Add( %s, %s ); Code generation for sets.

Right now only the creation, and set add code is done here. But more should be
added later on.
<module codegen.SetCodes>C:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\codegen\SetCodes.pyslicedel_upperslice_sourcelower_nameupper_nameslice_lowerslice_uppercodegen.SliceCodesslicedel_index_lower<module codegen.SliceCodes>step_nameslicedel_lowergetSliceLookupIndexesCodesliceass_value%s = LOOKUP_SLICE( %s, %s, %s );_decideSlicingslicedel_targetsliceass_lower%s = SET_INDEX_SLICE( %s, %s, %s, %s );generateSliceRangeIdentifierisSmallNumberConstantgetSliceAssignmentCodePy_ssize_tC:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\codegen\SliceCodes.pygenerateSliceRangeIdentifier.<locals>.isSmallNumberConstantsliceass_target%s = DEL_SLICE( %s, %s, %s );getSliceDelIndexesCodegetSliceLookupCode_index_upper_lower_index_value%s = SET_SLICE( %s, %s, %s, %s );getSliceDelCode_upper_index_value%s = MAKE_SLICEOBJ3( %s, %s, %s );getSliceAssignmentIndexesCode%s = DEL_INDEX_SLICE( %s, %s, %s ); Code generation for slicing.

This is about slice lookups, assignments, and deletions. There is also a
special case, for using index values instead of objects. The slice objects
are also created here, and can be used for indexing.
sliceass_upper%s = LOOKUP_INDEX_SLICE( %s, %s, %s );PyObject_ASCIIformat_valuestr_argascii_argBUILTIN_ORD String related codes, str and unicode.

bytes_argord_argC:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\codegen\StringCodes.pytuple_temp_namePyObject_Strstring_concat_valuesBUILTIN_BYTES1unicode_errorsbytes_encoding<module codegen.StringCodes>BUILTIN_CHR%s = BUILTIN_FORMAT( %s, %s );TO_UNICODE3unicode_argunicode_encodingformat_spec_name%s = PyUnicode_Join( %s, %s );PyObject_UnicodeBUILTIN_BYTES3chr_argbytes_errorsass_subscribed%s = SET_SUBSCRIPT_CONST( %s, %s, %s, %s );ass_subscriptgetIntegerSubscriptAssignmentCode Subscript related code generation.

There is special handling for integer indexes, which can be dealt with
much faster than general subscript lookups.
ass_subvaluedelsubscr_targetdelsubscr_subscriptsubscript_namesubscript_value%s = DEL_SUBSCRIPT( %s, %s );%s = LOOKUP_SUBSCRIPT_CONST( %s, %s, %s );getSubscriptLookupCodegetIntegerSubscriptLookupCodeC:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\codegen\SubscriptCodes.pyinteger_subscriptsubscribed_namegetSubscriptAssignmentCode<module codegen.SubscriptCodes>%s = LOOKUP_SUBSCRIPT( %s, %s );ass_subscript_res%s = SET_SUBSCRIPT( %s, %s, %s );getSubscriptDelCodetried codes exits in all cases// Return handler code:no_statements// Exception handler code:handling_statementstmp_name2try_break_handler// End of try:// Tried code:next_sourcetry_continue_handlertry_end// try break handler code:tried_statementstry_return_handlercodegen.TryCodestry_except_handler%(keeper_type)s = exception_type;
%(keeper_value)s = exception_value;
%(keeper_tb)s = exception_tb;
%(keeper_lineno)s = exception_lineno;
exception_type = NULL;
exception_value = NULL;
exception_tb = NULL;
exception_lineno = 0;
isStatementConditional©Ú	statementÚemitÚcontextÚtried_blockÚexcept_handlerÚcontinue_handlerÚbreak_handlerÚreturn_handlerÚtried_block_may_raiseÚtried_handler_escapeÚold_exception_escapeÚcontinue_handler_escapeÚold_continue_targetÚbreak_handler_escapeÚold_break_targetÚreturn_handler_escapeÚold_return_targetÚ
post_labelÚold_return_value_releaseÚkeeper_typeÚkeeper_valueÚ	keeper_tbÚkeeper_linenoÚold_keepersyes_statementsisExpressionBuiltinNext1// try continue handler code:C:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\codegen\TryCodes.pyexception handler codes exits in all cases Try statement and related code generation.

For Nuitka, all try/except and try/finally are dealt with this, where the
finally block gets duplicated into handlers. So this is a common low level
structure used, where exception handling and everything is made explicit.
generateTryNextExceptStopIterationCode<module codegen.TryCodes><module codegen.TupleCodes>C:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\codegen\TupleCodes.pytuple_arggetTupleCreationCode.<locals>.<genexpr>tuple_element_areConstants Tuple codes

PySequence_Tuple_variable_c_typeC:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\codegen\VariableCodes.py_variable_code_namegetPickedCTypegetVariableDelCodegetVariableReleaseCodegenerator->m_closure[%d]closure_indexpar_getVariableAccessCode Low level variable code generation.

UPDATE_STRING_DICT%s( moduledict_%s, (Nuitka_StringObject *)%s, %s );asyncgen->m_closure[%d]enable_bool_ctype<module codegen.VariableCodes>shapescoroutine->m_closure[%d]variable_code_name_new Return type to use for specific context. self->m_closure[%d]variable_c_new_typeoutline_%d_<module codegen.YieldCodes>yield_return_labelYIELD_IN_HANDLERC:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\codegen\YieldCodes.py Yield related codes.

The normal "yield", and the Python 3.3 or higher "yield from" variant.

%(context_object_name)s->m_yield_return_index = %(yield_return_index)s;
return %(yielded_value)s;
%(yield_return_label)s:
%(to_name)s = yield_return_value;
YIELD_FROM_IN_HANDLERC:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\codegen\c_typescodegen.c_typesC:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\codegen\c_types\__init__.pyCTypeBase.getDeleteObjectCodeCTypeBase.getInitValueCTypeBase.getVariableArgReferencePassingCodeCTypeBase.getLocalVariableAssignCodeCTypeBase.getCellObjectAssignmentCode Get code to assign local variable.

        codegen.c_types.CTypeBasesCTypeBase.getVariableInitCodeCTypeBase.getVariableArgDeclarationCodeCTypeBase.getTypeIndicatorinit_value Base class for all C types.

Defines the interface to use by code generation on C types. Different
types then have to overload the class methods.
type_indicators Get assignment code to given cell object from object.

         Get code to test for uninitialized.

         Convert to init value for the type. %s%s%s = %s;C:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\codegen\c_types\CTypeBases.pyCTypeBase.getReleaseCode Get code to delete (del) local variable.

        <module codegen.c_types.CTypeBases> Get code to pass variable as reference argument.

        CTypeBase.getLocalVariableInitTestCode Get release code for given object.

         Get variable declaration code with given name.

        NUITKA_BOOL_UNASSIGNED%s == NUITKA_BOOL_TRUE ? Py_True : Py_FalseCTypeNuitkaBoolEnum.getLocalVariableInitTestCodeCTypeNuitkaBoolEnum.getLocalVariableAssignCodeswitch (%(variable_code_name)s)
{
    case NUITKA_BOOL_TRUE:
    {
        %(to_name)s = Py_True;
        break;
    }
    case NUITKA_BOOL_FALSE:
    {
        %(to_name)s = Py_False;
        break;
    }
    // case NUITKA_BOOL_UNASSIGNED: (MSVC wants default to believe it). We may
    // try to add an illegal default instead, but that may trigger warnings
    // from better compilers.
    default:
    {
#if %(needs_check)s
        %(to_name)s = NULL;
#else
        NUITKA_CANNOT_GET_HERE(%(identifier)s);
#endif
        break;
    }
} CType classes for nuitka_bool, an enum to represent True, False, unassigned.

%s != NUITKA_BOOL_UNASSIGNEDCTypeNuitkaBoolEnum.getReleaseCodeCTypeNuitkaBoolEnum.getInitValueif (%(tmp_name)s == Py_True)
{
    %(variable_code_name)s = NUITKA_BOOL_TRUE;
}
else
{
    %(variable_code_name)s = NUITKA_BOOL_FALSE;
}
        CTypeNuitkaBoolEnum.getVariableObjectAccessCode<module codegen.c_types.CTypeNuitkaBools>C:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\codegen\c_types\CTypeNuitkaBools.pyCTypeNuitkaBoolEnum.getLocalVariableObjectAccessCodeCTypeNuitkaBoolEnum.getDeleteObjectCode%s = %s == NUITKA_BOOL_UNASSIGNED;%s = NUITKA_BOOL_UNASSIGNED;CTypePyObjectPtr.getLocalVariableObjectAccessCodeCTypeCellObject.getCellObjectAssignmentCodeCPythonPyObjectPtrBase.getReleaseCodeCTypeCellObject.getDeleteObjectCodeCTypePyObjectPtrPtr.getLocalVariableObjectAccessCodeCPythonPyObjectPtrBase.getVariableObjectAccessCode%s = PyCell_NEW0( %s );CTypePyObjectPtr.getVariableArgDeclarationCodeCTypePyObjectPtr.getDeleteObjectCodeCTypeCellObject.getReleaseCode CType classes for PyObject *, PyObject **, and struct Nuitka_CellObject *

CTypeCellObject.getLocalVariableInitTestCodeCTypeCellObject.getLocalVariableAssignCodeCTypePyObjectPtrPtr.getVariableArgReferencePassingCodeCTypeCellObject.getVariableObjectAccessCodeCPythonPyObjectPtrBase.getLocalVariableAssignCodeCTypePyObjectPtr.getInitValueC:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\codegen\c_types\CTypePyObjectPtrs.pyCTypeCellObject.getInitValue->ob_refCTypeCellObject.getVariableArgDeclarationCode*%s != NULL<module codegen.c_types.CTypePyObjectPtrs>CTypePyObjectPtr.getLocalVariableInitTestCodePyCell_NEW1( %s )CTypePyObjectPtrPtr.getLocalVariableInitTestCode©Útemplate_del_local_intolerantÚtemplate_del_local_knownÚtemplate_del_local_tolerantÚtemplate_del_shared_intolerantÚtemplate_del_shared_knownÚtemplate_del_shared_tolerantÚtemplate_read_localÚtemplate_read_shared_unclearÚtemplate_release_clearÚtemplate_release_unclearÚtemplate_write_local_clear_ref0Útemplate_write_local_clear_ref1Útemplate_write_local_empty_ref0Útemplate_write_local_empty_ref1Útemplate_write_local_inplaceÚ!template_write_local_unclear_ref0Ú!template_write_local_unclear_ref1Ú template_write_shared_clear_ref0Ú template_write_shared_clear_ref1Útemplate_write_shared_inplaceÚ"template_write_shared_unclear_ref0Ú"template_write_shared_unclear_ref1CTypeCellObject.getVariableArgReferencePassingCodeCTypePyObjectPtr.getCellObjectAssignmentCodeCTypePyObjectPtr.getVariableArgReferencePassingCodeCTypePyObjectPtrPtr.getVariableArgDeclarationCodeCTypeCellObject.getLocalVariableObjectAccessCodePyCell_EMPTY() Code to access value as object.

        %s->ob_ref != NULLPyObject **%sC:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\codegen\templatescodegen.templatesC:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\codegen\templates\__init__.py
static void %(function_identifier)s( struct Nuitka_AsyncgenObject *asyncgen )
{
    CHECK_OBJECT( (PyObject *)asyncgen );
    assert( Nuitka_Asyncgen_Check( (PyObject *)asyncgen ) );

    // Local variable initialization
%(function_var_inits)s

    // Actual function code.
%(function_body)s

%(asyncgen_exit)s
}
    // Return statement must be present.
    NUITKA_CANNOT_GET_HERE( %(function_identifier)s );

%(function_cleanup)s    asyncgen->m_yielded = NULL;
    return;
 Async generator (await/async + yield) related templates.


%(to_name)s = Nuitka_Asyncgen_New(
    %(asyncgen_identifier)s,
    %(asyncgen_name_obj)s,
    %(asyncgen_qualname_obj)s,
    %(code_identifier)s,
    %(closure_count)d
);
%(closure_copy)s
<module codegen.templates.CodeTemplatesAsyncgens>C:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\codegen\templates\CodeTemplatesAsyncgens.py    // Return statement must be present.
    NUITKA_CANNOT_GET_HERE( %(function_identifier)s );

    function_exception_exit:
%(function_cleanup)s    assert( exception_type );
    RESTORE_ERROR_OCCURRED( exception_type, exception_value, exception_tb );
    asyncgen->m_yielded = NULL;
    return;
static void %(function_identifier)s( struct Nuitka_AsyncgenObject *asyncgen );
    function_return_exit:;
    asyncgen->m_yielded = NULL;
    asyncgen->m_status = status_Finished;
    return;
codegen.templates.CodeTemplatesCallsC:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\codegen\templates\CodeTemplatesCalls.py Templates for calling functions with positional args only very quickly.

extern PyObject *CALL_METHOD_WITH_ARGS%(args_count)d( PyObject *source, PyObject *attr_name, PyObject **args );extern PyObject *CALL_FUNCTION_WITH_ARGS%(args_count)d( PyObject *called, PyObject **args );PyObject *CALL_FUNCTION_WITH_ARGS%(args_count)d( PyObject *called, PyObject **args )
{
    CHECK_OBJECT( called );

    // Check if arguments are valid objects in debug mode.
#ifndef __NUITKA_NO_ASSERT__
    for( size_t i = 0; i < %(args_count)d; i++ )
    {
        CHECK_OBJECT( args[ i ] );
    }
#endif

    if ( Nuitka_Function_Check( called ) )
    {
        if (unlikely( Py_EnterRecursiveCall( (char *)" while calling a Python object" ) ))
        {
            return NULL;
        }

        struct Nuitka_FunctionObject *function = (struct Nuitka_FunctionObject *)called;
        PyObject *result;

        if ( function->m_args_simple && %(args_count)d == function->m_args_positional_count )
        {
            for( Py_ssize_t i = 0; i < %(args_count)d; i++ )
            {
                Py_INCREF( args[ i ] );
            }

            result = function->m_c_code( function, args );
        }
        else if ( function->m_args_simple && %(args_count)d + function->m_defaults_given == function->m_args_positional_count )
        {
#ifdef _MSC_VER
            PyObject **python_pars = (PyObject **)_alloca( sizeof( PyObject * ) * function->m_args_positional_count );
#else
            PyObject *python_pars[ function->m_args_positional_count ];
#endif
            memcpy( python_pars, args, %(args_count)d * sizeof(PyObject *) );
            memcpy( python_pars + %(args_count)d, &PyTuple_GET_ITEM( function->m_defaults, 0 ), function->m_defaults_given * sizeof(PyObject *) );

            for( Py_ssize_t i = 0; i < function->m_args_positional_count; i++ )
            {
                Py_INCREF( python_pars[ i ] );
            }

            result = function->m_c_code( function, python_pars );
        }
        else
        {
#ifdef _MSC_VER
            PyObject **python_pars = (PyObject **)_alloca( sizeof( PyObject * ) * function->m_args_overall_count );
#else
            PyObject *python_pars[ function->m_args_overall_count ];
#endif
            memset( python_pars, 0, function->m_args_overall_count * sizeof(PyObject *) );

            if ( parseArgumentsPos( function, python_pars, args, %(args_count)d ))
            {
                result = function->m_c_code( function, python_pars );
            }
            else
            {
                result = NULL;
            }
        }

        Py_LeaveRecursiveCall();

        return result;
    }
    else if ( Nuitka_Method_Check( called ) )
    {
        struct Nuitka_MethodObject *method = (struct Nuitka_MethodObject *)called;

        // Unbound method without arguments, let the error path be slow.
        if ( method->m_object != NULL )
        {
            if (unlikely( Py_EnterRecursiveCall( (char *)" while calling a Python object" ) ))
            {
                return NULL;
            }

            struct Nuitka_FunctionObject *function = method->m_function;

            PyObject *result;

            if ( function->m_args_simple && %(args_count)d + 1 == function->m_args_positional_count )
            {
#ifdef _MSC_VER
                PyObject **python_pars = (PyObject **)_alloca( sizeof( PyObject * ) * function->m_args_positional_count );
#else
                PyObject *python_pars[ function->m_args_positional_count ];
#endif
                python_pars[ 0 ] = method->m_object;
                Py_INCREF( method->m_object );

                for( Py_ssize_t i = 0; i < %(args_count)d; i++ )
                {
                    python_pars[ i + 1 ] = args[ i ];
                    Py_INCREF( args[ i ] );
                }

                result = function->m_c_code( function, python_pars );
            }
            else if ( function->m_args_simple && %(args_count)d + 1 + function->m_defaults_given == function->m_args_positional_count )
            {
#ifdef _MSC_VER
                PyObject **python_pars = (PyObject **)_alloca( sizeof( PyObject * ) * function->m_args_positional_count );
#else
                PyObject *python_pars[ function->m_args_positional_count ];
#endif
                python_pars[ 0 ] = method->m_object;
                Py_INCREF( method->m_object );

                memcpy( python_pars+1, args, %(args_count)d * sizeof(PyObject *) );
                memcpy( python_pars+1 + %(args_count)d, &PyTuple_GET_ITEM( function->m_defaults, 0 ), function->m_defaults_given * sizeof(PyObject *) );

                for( Py_ssize_t i = 1; i < function->m_args_overall_count; i++ )
                {
                    Py_INCREF( python_pars[ i ] );
                }

                result = function->m_c_code( function, python_pars );
            }
            else
            {
#ifdef _MSC_VER
                PyObject **python_pars = (PyObject **)_alloca( sizeof( PyObject * ) * function->m_args_overall_count );
#else
                PyObject *python_pars[ function->m_args_overall_count ];
#endif
                memset( python_pars, 0, function->m_args_overall_count * sizeof(PyObject *) );

                if ( parseArgumentsMethodPos( function, python_pars, method->m_object, args, %(args_count)d ) )
                {
                    result = function->m_c_code( function, python_pars );
                }
                else
                {
                    result = NULL;
                }
            }

            Py_LeaveRecursiveCall();

            return result;
        }
    }
    else if ( PyCFunction_Check( called ) )
    {
        // Try to be fast about wrapping the arguments.
        int flags = PyCFunction_GET_FLAGS( called ) & ~(METH_CLASS | METH_STATIC | METH_COEXIST);

        if ( flags & METH_NOARGS )
        {
#if %(args_count)d == 0
            PyCFunction method = PyCFunction_GET_FUNCTION( called );
            PyObject *self = PyCFunction_GET_SELF( called );

            // Recursion guard is not strictly necessary, as we already have
            // one on our way to here.
#ifdef _NUITKA_FULL_COMPAT
            if (unlikely( Py_EnterRecursiveCall( (char *)" while calling a Python object" ) ))
            {
                return NULL;
            }
#endif

            PyObject *result = (*method)( self, NULL );

#ifdef _NUITKA_FULL_COMPAT
            Py_LeaveRecursiveCall();
#endif

            if ( result != NULL )
            {
            // Some buggy C functions do set an error, but do not indicate it
            // and Nuitka inner workings can get upset/confused from it.
                DROP_ERROR_OCCURRED();

                return result;
            }
            else
            {
                // Other buggy C functions do this, return NULL, but with
                // no error set, not allowed.
                if (unlikely( !ERROR_OCCURRED() ))
                {
                    PyErr_Format(
                        PyExc_SystemError,
                        "NULL result without error in PyObject_Call"
                    );
                }

                return NULL;
            }
#else
            PyErr_Format(
                PyExc_TypeError,
                "%%s() takes no arguments (%(args_count)d given)",
                ((PyCFunctionObject *)called)->m_ml->ml_name
            );
            return NULL;
#endif
        }
        else if ( flags & METH_O )
        {
#if %(args_count)d == 1
            PyCFunction method = PyCFunction_GET_FUNCTION( called );
            PyObject *self = PyCFunction_GET_SELF( called );

            // Recursion guard is not strictly necessary, as we already have
            // one on our way to here.
#ifdef _NUITKA_FULL_COMPAT
            if (unlikely( Py_EnterRecursiveCall( (char *)" while calling a Python object" ) ))
            {
                return NULL;
            }
#endif

            PyObject *result = (*method)( self, args[0] );

#ifdef _NUITKA_FULL_COMPAT
            Py_LeaveRecursiveCall();
#endif

            if ( result != NULL )
            {
            // Some buggy C functions do set an error, but do not indicate it
            // and Nuitka inner workings can get upset/confused from it.
                DROP_ERROR_OCCURRED();

                return result;
            }
            else
            {
                // Other buggy C functions do this, return NULL, but with
                // no error set, not allowed.
                if (unlikely( !ERROR_OCCURRED() ))
                {
                    PyErr_Format(
                        PyExc_SystemError,
                        "NULL result without error in PyObject_Call"
                    );
                }

                return NULL;
            }
#else
            PyErr_Format(PyExc_TypeError,
                "%%s() takes exactly one argument (%(args_count)d given)",
                 ((PyCFunctionObject *)called)->m_ml->ml_name
            );
            return NULL;
#endif
        }
        else if ( flags & METH_VARARGS )
        {
            PyCFunction method = PyCFunction_GET_FUNCTION( called );
            PyObject *self = PyCFunction_GET_SELF( called );

            PyObject *pos_args = MAKE_TUPLE( args, %(args_count)d );

            PyObject *result;

            // Recursion guard is not strictly necessary, as we already have
            // one on our way to here.
#ifdef _NUITKA_FULL_COMPAT
            if (unlikely( Py_EnterRecursiveCall( (char *)" while calling a Python object" ) ))
            {
                return NULL;
            }
#endif

#if PYTHON_VERSION < 360
            if ( flags & METH_KEYWORDS )
            {
                result = (*(PyCFunctionWithKeywords)method)( self, pos_args, NULL );
            }
            else
            {
                result = (*method)( self, pos_args );
            }
#else
            if ( flags == ( METH_VARARGS | METH_KEYWORDS ) )
            {
                result = (*(PyCFunctionWithKeywords)method)( self, pos_args, NULL );
            }
            else if ( flags == METH_FASTCALL )
            {
#if PYTHON_VERSION < 370
                result = (*(_PyCFunctionFast)method)( self, &PyTuple_GET_ITEM( pos_args, 0 ), %(args_count)d, NULL );;
#else
                result = (*(_PyCFunctionFast)method)( self, &pos_args, %(args_count)d );;
#endif
            }
            else
            {
                result = (*method)( self, pos_args );
            }
#endif

#ifdef _NUITKA_FULL_COMPAT
            Py_LeaveRecursiveCall();
#endif

            if ( result != NULL )
            {
                // Some buggy C functions do set an error, but do not indicate it
                // and Nuitka inner workings can get upset/confused from it.
                DROP_ERROR_OCCURRED();

                Py_DECREF( pos_args );
                return result;
            }
            else
            {
                // Other buggy C functions do this, return NULL, but with
                // no error set, not allowed.
                if (unlikely( !ERROR_OCCURRED() ))
                {
                    PyErr_Format(
                        PyExc_SystemError,
                        "NULL result without error in PyObject_Call"
                    );
                }

                Py_DECREF( pos_args );
                return NULL;
            }
        }
    }
    else if ( PyFunction_Check( called ) )
    {
        return callPythonFunction(
            called,
            args,
            %(args_count)d
        );
    }

    PyObject *pos_args = MAKE_TUPLE( args, %(args_count)d );

    PyObject *result = CALL_FUNCTION(
        called,
        pos_args,
        NULL
    );

    Py_DECREF( pos_args );

    return result;
}
<module codegen.templates.CodeTemplatesCalls>PyObject *CALL_METHOD_WITH_ARGS%(args_count)d( PyObject *source, PyObject *attr_name, PyObject **args )
{
    CHECK_OBJECT( source );
    CHECK_OBJECT( attr_name );

    // Check if arguments are valid objects in debug mode.
#ifndef __NUITKA_NO_ASSERT__
    for( size_t i = 0; i < %(args_count)d; i++ )
    {
        CHECK_OBJECT( args[ i ] );
    }
#endif

    PyTypeObject *type = Py_TYPE( source );

    if ( type->tp_getattro == PyObject_GenericGetAttr )
    {
        // Unfortunately this is required, although of cause rarely necessary.
        if (unlikely( type->tp_dict == NULL ))
        {
            if (unlikely( PyType_Ready( type ) < 0 ))
            {
                return NULL;
            }
        }

        PyObject *descr = _PyType_Lookup( type, attr_name );
        descrgetfunc func = NULL;

        if ( descr != NULL )
        {
            Py_INCREF( descr );

#if PYTHON_VERSION < 300
            if ( PyType_HasFeature( Py_TYPE( descr ), Py_TPFLAGS_HAVE_CLASS ) )
            {
#endif
                func = Py_TYPE( descr )->tp_descr_get;

                if ( func != NULL && PyDescr_IsData( descr ) )
                {
                    PyObject *called_object = func( descr, source, (PyObject *)type );
                    Py_DECREF( descr );

                    PyObject *result = CALL_FUNCTION_WITH_ARGS%(args_count)d(
                        called_object,
                        args
                    );
                    Py_DECREF( called_object );
                    return result;
                }
#if PYTHON_VERSION < 300
            }
#endif
        }

        Py_ssize_t dictoffset = type->tp_dictoffset;
        PyObject *dict = NULL;

        if ( dictoffset != 0 )
        {
            // Negative dictionary offsets have special meaning.
            if ( dictoffset < 0 )
            {
                Py_ssize_t tsize;
                size_t size;

                tsize = ((PyVarObject *)source)->ob_size;
                if (tsize < 0)
                    tsize = -tsize;
                size = _PyObject_VAR_SIZE( type, tsize );

                dictoffset += (long)size;
            }

            PyObject **dictptr = (PyObject **) ((char *)source + dictoffset);
            dict = *dictptr;
        }

        if ( dict != NULL )
        {
            CHECK_OBJECT( dict );

            Py_INCREF( dict );

            PyObject *called_object = PyDict_GetItem( dict, attr_name );

            if ( called_object != NULL )
            {
                Py_INCREF( called_object );
                Py_XDECREF( descr );
                Py_DECREF( dict );

                PyObject *result = CALL_FUNCTION_WITH_ARGS%(args_count)d(
                    called_object,
                    args
                );
                Py_DECREF( called_object );
                return result;
            }

            Py_DECREF( dict );
        }

        if ( func != NULL )
        {
            if ( func == Nuitka_Function_Type.tp_descr_get )
            {
                PyObject *result = Nuitka_CallMethodFunctionPosArgs(
                    (struct Nuitka_FunctionObject const *)descr,
                    source,
                    args,
                    %(args_count)d
                );

                Py_DECREF( descr );

                return result;
            }
            else
            {
                PyObject *called_object = func( descr, source, (PyObject *)type );
                CHECK_OBJECT( called_object );

                Py_DECREF( descr );

                PyObject *result = CALL_FUNCTION_WITH_ARGS%(args_count)d(
                    called_object,
                    args
                );
                Py_DECREF( called_object );

                return result;
            }
        }

        if ( descr != NULL )
        {
            CHECK_OBJECT( descr );

            PyObject *result = CALL_FUNCTION_WITH_ARGS%(args_count)d(
                descr,
                args
            );
            Py_DECREF( descr );

            return result;
        }

#if PYTHON_VERSION < 300
        PyErr_Format(
            PyExc_AttributeError,
            "'%%s' object has no attribute '%%s'",
            type->tp_name,
            PyString_AS_STRING( attr_name )
        );
#else
        PyErr_Format(
            PyExc_AttributeError,
            "'%%s' object has no attribute '%%U'",
            type->tp_name,
            attr_name
        );
#endif
        return NULL;
    }
#if PYTHON_VERSION < 300
    else if ( type == &PyInstance_Type )
    {
        PyInstanceObject *source_instance = (PyInstanceObject *)source;

        // The special cases have their own variant on the code generation level
        // as we are called with constants only.
        assert( attr_name != const_str_plain___dict__ );
        assert( attr_name != const_str_plain___class__ );

        // Try the instance dict first.
        PyObject *called_object = GET_STRING_DICT_VALUE(
            (PyDictObject *)source_instance->in_dict,
            (PyStringObject *)attr_name
        );

        // Note: The "called_object" was found without taking a reference,
        // so we need not release it in this branch.
        if ( called_object != NULL )
        {
            return CALL_FUNCTION_WITH_ARGS%(args_count)d( called_object, args );
        }

        // Then check the class dictionaries.
        called_object = FIND_ATTRIBUTE_IN_CLASS(
            source_instance->in_class,
            attr_name
        );

        // Note: The "called_object" was found without taking a reference,
        // so we need not release it in this branch.
        if ( called_object != NULL )
        {
            descrgetfunc descr_get = Py_TYPE( called_object )->tp_descr_get;

            if ( descr_get == Nuitka_Function_Type.tp_descr_get )
            {
                return Nuitka_CallMethodFunctionPosArgs(
                    (struct Nuitka_FunctionObject const *)called_object,
                    source,
                    args,
                    %(args_count)d
                );
            }
            else if ( descr_get != NULL )
            {
                PyObject *method = descr_get(
                    called_object,
                    source,
                    (PyObject *)source_instance->in_class
                );

                if (unlikely( method == NULL ))
                {
                    return NULL;
                }

                PyObject *result = CALL_FUNCTION_WITH_ARGS%(args_count)d( method, args );
                Py_DECREF( method );
                return result;
            }
            else
            {
                return CALL_FUNCTION_WITH_ARGS%(args_count)d( called_object, args );
            }

        }
        else if (unlikely( source_instance->in_class->cl_getattr == NULL ))
        {
            PyErr_Format(
                PyExc_AttributeError,
                "%%s instance has no attribute '%%s'",
                PyString_AS_STRING( source_instance->in_class->cl_name ),
                PyString_AS_STRING( attr_name )
            );

            return NULL;
        }
        else
        {
            // Finally allow the "__getattr__" override to provide it or else
            // it's an error.

            PyObject *args2[] = {
                source,
                attr_name
            };

            called_object = CALL_FUNCTION_WITH_ARGS2(
                source_instance->in_class->cl_getattr,
                args2
            );

            if (unlikely( called_object == NULL ))
            {
                return NULL;
            }

            PyObject *result = CALL_FUNCTION_WITH_ARGS%(args_count)d(
                called_object,
                args
            );
            Py_DECREF( called_object );
            return result;
        }
    }
#endif
    else if ( type->tp_getattro != NULL )
    {
        PyObject *called_object = (*type->tp_getattro)(
            source,
            attr_name
        );

        if (unlikely( called_object == NULL ))
        {
            return NULL;
        }

        PyObject *result = CALL_FUNCTION_WITH_ARGS%(args_count)d(
            called_object,
            args
        );
        Py_DECREF( called_object );
        return result;
    }
    else if ( type->tp_getattr != NULL )
    {
        PyObject *called_object = (*type->tp_getattr)(
            source,
            (char *)Nuitka_String_AsString_Unchecked( attr_name )
        );

        if (unlikely( called_object == NULL ))
        {
            return NULL;
        }

        PyObject *result = CALL_FUNCTION_WITH_ARGS%(args_count)d(
            called_object,
            args
        );
        Py_DECREF( called_object );
        return result;
    }
    else
    {
        PyErr_Format(
            PyExc_AttributeError,
            "'%%s' object has no attribute '%%s'",
            type->tp_name,
            Nuitka_String_AsString_Unchecked( attr_name )
        );

        return NULL;
    }
}
codegen.templates.CodeTemplatesConstants<module codegen.templates.CodeTemplatesConstants>C:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\codegen\templates\CodeTemplatesConstants.py Templates for the constants handling.


#include "nuitka/prelude.h"

// Sentinel PyObject to be used for all our call iterator endings. It will
// become a PyCObject pointing to NULL. It's address is unique, and that's
// enough for us to use it as sentinel value.
PyObject *_sentinel_value = NULL;

%(constant_declarations)s

static void _createGlobalConstants( void )
{
    NUITKA_MAY_BE_UNUSED PyObject *exception_type, *exception_value;
    NUITKA_MAY_BE_UNUSED PyTracebackObject *exception_tb;

#ifdef _MSC_VER
    // Prevent unused warnings in case of simple programs, the attribute
    // NUITKA_MAY_BE_UNUSED doesn't work for MSVC.
    (void *)exception_type; (void *)exception_value; (void *)exception_tb;
#endif

%(constant_inits)s

#if _NUITKA_EXE
    /* Set the "sys.executable" path to the original CPython executable. */
    PySys_SetObject(
        (char *)"executable",
        %(sys_executable)s
    );
#endif
}

// In debug mode we can check that the constants were not tampered with in any
// given moment. We typically do it at program exit, but we can add extra calls
// for sanity.
#ifndef __NUITKA_NO_ASSERT__
void checkGlobalConstants( void )
{
%(constant_checks)s
}
#endif

void createGlobalConstants( void )
{
    if ( _sentinel_value == NULL )
    {
#if PYTHON_VERSION < 300
        _sentinel_value = PyCObject_FromVoidPtr( NULL, NULL );
#else
        // The NULL value is not allowed for a capsule, so use something else.
        _sentinel_value = PyCapsule_New( (void *)27, "sentinel", NULL );
#endif
        assert( _sentinel_value );

        _createGlobalConstants();
    }
}
<module codegen.templates.CodeTemplatesCoroutines>    // Return statement must be present.
    NUITKA_CANNOT_GET_HERE( %(function_identifier)s );

%(function_cleanup)s    coroutine->m_yielded = NULL;
    return;
    function_return_exit:;
    coroutine->m_yielded = NULL;
    coroutine->m_returned = tmp_return_value;
    return;
    // Return statement must be present.
    NUITKA_CANNOT_GET_HERE( %(function_identifier)s );

    function_exception_exit:
%(function_cleanup)s    assert( exception_type );
    RESTORE_ERROR_OCCURRED( exception_type, exception_value, exception_tb );
    coroutine->m_yielded = NULL;
    return;
 Coroutines function (await/async) related templates.

C:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\codegen\templates\CodeTemplatesCoroutines.py
%(to_name)s = Nuitka_Coroutine_New(
    %(coroutine_identifier)s,
    self->m_name,
    self->m_qualname,
    %(code_identifier)s,
    %(closure_count)d
);
%(closure_copy)s

static void %(function_identifier)s( struct Nuitka_CoroutineObject *coroutine )
{
    CHECK_OBJECT( (PyObject *)coroutine );
    assert( Nuitka_Coroutine_Check( (PyObject *)coroutine ) );

    // Local variable initialization
%(function_var_inits)s

    // Actual function code.
%(function_body)s

%(coroutine_exit)s
}
static void %(function_identifier)s( struct Nuitka_CoroutineObject *coroutine );
if ( %(condition)s )
{
%(release_temps)s
%(set_exception)s

%(line_number_code)s
%(var_description_code)s
    goto %(exception_exit)s;
}
if ( %(condition)s )
{
    if ( !ERROR_OCCURRED() )
    {
        exception_type = %(quick_exception)s;
        Py_INCREF( exception_type );
        exception_value = NULL;
        exception_tb = NULL;
    }
    else
    {
        FETCH_ERROR_OCCURRED( &exception_type, &exception_value, &exception_tb );
    }
%(release_temps)s

%(var_description_code)s
%(line_number_code)s
    goto %(exception_exit)s;
}<module codegen.templates.CodeTemplatesExceptions>if ( %(condition)s )
{
    assert( ERROR_OCCURRED() );

    FETCH_ERROR_OCCURRED( &exception_type, &exception_value, &exception_tb );
%(release_temps)s

%(line_number_code)s
%(var_description_code)s
    goto %(exception_exit)s;
} Templates for handling exceptions.

C:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\codegen\templates\CodeTemplatesExceptions.pyif ( %(keeper_tb)s == NULL )
{
    %(keeper_tb)s = %(tb_making)s;
}
else if ( %(keeper_lineno)s != 0 )
{
    %(keeper_tb)s = ADD_TRACEBACK( %(keeper_tb)s, %(frame_identifier)s, %(keeper_lineno)s );
}
Nuitka_Frame_AttachLocals(
    (struct Nuitka_FrameObject *)%(frame_identifier)s,
    %(type_description)s%(frame_variable_refs)s
);
MAKE_OR_REUSE_FRAME( %(frame_cache_identifier)s, %(code_identifier)s, %(module_identifier)s, %(locals_size)s );
%(context_identifier)s->m_frame = %(frame_cache_identifier)s;

// Mark the frame object as in use, ref count 1 will be up for reuse.
Py_INCREF( %(context_identifier)s->m_frame );
assert( Py_REFCNT( %(context_identifier)s->m_frame ) == 2 ); // Frame stack

#if PYTHON_VERSION >= 340
%(context_identifier)s->m_frame->m_frame.f_gen = (PyObject *)%(context_identifier)s;
#endif

Py_CLEAR( %(context_identifier)s->m_frame->m_frame.f_back );

%(context_identifier)s->m_frame->m_frame.f_back = PyThreadState_GET()->frame;
Py_INCREF( %(context_identifier)s->m_frame->m_frame.f_back );

PyThreadState_GET()->frame = &%(context_identifier)s->m_frame->m_frame;
Py_INCREF( %(context_identifier)s->m_frame );

Nuitka_Frame_MarkAsExecuting( %(context_identifier)s->m_frame );

#if PYTHON_VERSION >= 300
// Accept currently existing exception as the one to publish again when we
// yield or yield from.

PyThreadState *thread_state = PyThreadState_GET();

#if PYTHON_VERSION < 370
%(context_identifier)s->m_frame->m_frame.f_exc_type = EXC_TYPE( thread_state );
if ( %(context_identifier)s->m_frame->m_frame.f_exc_type == Py_None ) %(context_identifier)s->m_frame->m_frame.f_exc_type = NULL;
Py_XINCREF( %(context_identifier)s->m_frame->m_frame.f_exc_type );
%(context_identifier)s->m_frame->m_frame.f_exc_value = EXC_VALUE( thread_state );
Py_XINCREF( %(context_identifier)s->m_frame->m_frame.f_exc_value );
%(context_identifier)s->m_frame->m_frame.f_exc_traceback = EXC_TRACEBACK( thread_state );
Py_XINCREF( %(context_identifier)s->m_frame->m_frame.f_exc_traceback );
#else
%(context_identifier)s->m_exc_state.exc_type = EXC_TYPE( thread_state );
if ( %(context_identifier)s->m_exc_state.exc_type == Py_None ) %(context_identifier)s->m_exc_state.exc_type = NULL;
Py_XINCREF( %(context_identifier)s->m_exc_state.exc_type );
%(context_identifier)s->m_exc_state.exc_value = EXC_VALUE( thread_state );
Py_XINCREF( %(context_identifier)s->m_exc_state.exc_value );
%(context_identifier)s->m_exc_state.exc_traceback = EXC_TRACEBACK( thread_state );
Py_XINCREF( %(context_identifier)s->m_exc_state.exc_traceback );

#endif

#endif

// Framed code:
%(codes)s

Nuitka_Frame_MarkAsNotExecuting( %(context_identifier)s->m_frame );

#if PYTHON_VERSION >= 370
Py_CLEAR( %(context_identifier)s->m_exc_state.exc_type );
Py_CLEAR( %(context_identifier)s->m_exc_state.exc_value );
Py_CLEAR( %(context_identifier)s->m_exc_state.exc_traceback );
#elif PYTHON_VERSION >= 300
Py_CLEAR( %(context_identifier)s->m_frame->m_frame.f_exc_type );
Py_CLEAR( %(context_identifier)s->m_frame->m_frame.f_exc_value );
Py_CLEAR( %(context_identifier)s->m_frame->m_frame.f_exc_traceback );
#endif

// Allow re-use of the frame again.
Py_DECREF( %(context_identifier)s->m_frame );
goto %(no_exception_exit)s;
C:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\codegen\templates\CodeTemplatesFrames.pyMAKE_OR_REUSE_FRAME( cache_%(frame_identifier)s, %(code_identifier)s, %(module_identifier)s, %(locals_size)s );
%(frame_identifier)s = cache_%(frame_identifier)s;

// Push the new frame as the currently active one.
pushFrameStack( %(frame_identifier)s );

// Mark the frame object as in use, ref count 1 will be up for reuse.
assert( Py_REFCNT( %(frame_identifier)s ) == 2 ); // Frame stack

// Framed code:
%(codes)s

#if %(needs_preserve)d
RESTORE_FRAME_EXCEPTION( %(frame_identifier)s );
#endif

// Put the previous frame back on top.
popFrameStack();

goto %(no_exception_exit)s;
%(frame_exception_exit)s:;

#if %(needs_preserve)d
RESTORE_FRAME_EXCEPTION( %(frame_identifier)s );
#endif

if ( exception_tb == NULL )
{
    exception_tb = %(tb_making)s;
}
else if ( exception_tb->tb_frame != &%(frame_identifier)s->m_frame )
{
    exception_tb = ADD_TRACEBACK( exception_tb, %(frame_identifier)s, exception_lineno );
}

// Attachs locals to frame if any.
%(attach_locals)s

// Release cached frame.
if ( %(frame_identifier)s == cache_%(frame_identifier)s )
{
    Py_DECREF( %(frame_identifier)s );
}
cache_%(frame_identifier)s = NULL;

assertFrameObject( %(frame_identifier)s );

// Put the previous frame back on top.
popFrameStack();

// Return the error.
goto %(parent_exception_exit)s;
<module codegen.templates.CodeTemplatesFrames>static struct Nuitka_FrameObject *cache_%(frame_identifier)s = NULL;
%(frame_exception_exit)s:;

// If it's not an exit exception, consider and create a traceback for it.
if ( !EXCEPTION_MATCH_GENERATOR( exception_type ) )
{
    if ( exception_tb == NULL )
    {
        exception_tb = %(tb_making)s;
    }
    else if ( exception_tb->tb_frame != &%(frame_identifier)s->m_frame )
    {
        exception_tb = ADD_TRACEBACK( exception_tb, %(frame_identifier)s, exception_lineno );
    }

%(attach_locals)s

    // Release cached frame.
    if ( %(frame_identifier)s == %(frame_cache_identifier)s )
    {
        Py_DECREF( %(frame_identifier)s );
    }
    %(frame_cache_identifier)s = NULL;

    assertFrameObject( %(frame_identifier)s );
}

#if PYTHON_VERSION >= 370
Py_CLEAR( %(context_identifier)s->m_exc_state.exc_type );
Py_CLEAR( %(context_identifier)s->m_exc_state.exc_value );
Py_CLEAR( %(context_identifier)s->m_exc_state.exc_traceback );
#elif PYTHON_VERSION >= 300
Py_CLEAR( %(frame_identifier)s->m_frame.f_exc_type );
Py_CLEAR( %(frame_identifier)s->m_frame.f_exc_value );
Py_CLEAR( %(frame_identifier)s->m_frame.f_exc_traceback );
#endif

Py_DECREF( %(frame_identifier)s );
// Return the error.
goto %(parent_exception_exit)s;
struct Nuitka_FrameObject *%(frame_identifier)s;
%(frame_return_exit)s:;
#if %(needs_preserve)d
RESTORE_FRAME_EXCEPTION( %(frame_identifier)s );
#endif

// Put the previous frame back on top.
popFrameStack();

goto %(return_exit)s;
%(frame_return_exit)s:;

#if PYTHON_VERSION >= 370
Py_CLEAR( %(context_identifier)s->m_exc_state.exc_type );
Py_CLEAR( %(context_identifier)s->m_exc_state.exc_value );
Py_CLEAR( %(context_identifier)s->m_exc_state.exc_traceback );
#elif PYTHON_VERSION >= 300
Py_CLEAR( %(frame_identifier)s->m_frame.f_exc_type );
Py_CLEAR( %(frame_identifier)s->m_frame.f_exc_value );
Py_CLEAR( %(frame_identifier)s->m_frame.f_exc_traceback );
#endif

Py_DECREF( %(frame_identifier)s );
goto %(return_exit)s;
// Frame without reuse.
%(frame_identifier)s = MAKE_MODULE_FRAME( %(code_identifier)s, %(module_identifier)s );

// Push the new frame as the currently active one, and we should be exclusively
// owning it.
pushFrameStack( %(frame_identifier)s );
assert( Py_REFCNT( %(frame_identifier)s ) == 2 );

// Framed code:
%(codes)s

// Restore frame exception if necessary.
#if %(needs_preserve)d
RESTORE_FRAME_EXCEPTION( %(frame_identifier)s );
#endif
popFrameStack();

assertFrameObject( %(frame_identifier)s );

goto %(no_exception_exit)s;
%(frame_exception_exit)s:;
#if %(needs_preserve)d
RESTORE_FRAME_EXCEPTION( %(frame_identifier)s );
#endif

if ( exception_tb == NULL )
{
    exception_tb = %(tb_making)s;
}
else if ( exception_tb->tb_frame != &%(frame_identifier)s->m_frame )
{
    exception_tb = ADD_TRACEBACK( exception_tb, %(frame_identifier)s, exception_lineno );
}

// Put the previous frame back on top.
popFrameStack();

// Return the error.
goto %(parent_exception_exit)s;
%(no_exception_exit)s:; Code templates for frames of all kinds.

// This provides the frozen (compiled bytecode) files that are included if
// any.
#include <Python.h>

#include "nuitka/constants_blob.h"

// Blob from which modules are unstreamed.
#define stream_data constant_bin

// These modules should be loaded as bytecode. They may e.g. have to be loadable
// during "Py_Initialize" already, or for irrelevance, they are only included
// in this un-optimized form. These are not compiled by Nuitka, and therefore
// are not accelerated at all, merely bundled with the binary or module, so
// that CPython library can start out finding them.

struct frozen_desc {
    char const *name;
    ssize_t start;
    int size;
};

void copyFrozenModulesTo( struct _frozen *destination )
{
    struct frozen_desc frozen_modules[] = {
%(frozen_modules)s
        { NULL, 0, 0 }
    };

    struct frozen_desc *current = frozen_modules;

    for(;;)
    {
        destination->name = (char *)current->name;
        destination->code = (unsigned char *)&constant_bin[ current->start ];
        destination->size = current->size;

        if (destination->name == NULL) break;

        current += 1;
        destination += 1;
    };
}
 Templates for code to load frozen bytecode.

C:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\codegen\templates\CodeTemplatesFreezer.py<module codegen.templates.CodeTemplatesFreezer>
static PyObject *MAKE_FUNCTION_%(function_identifier)s( %(function_creation_args)s )
{
    struct Nuitka_FunctionObject *result = Nuitka_Function_New(
        %(function_impl_identifier)s,
        %(function_name_obj)s,
#if PYTHON_VERSION >= 330
        %(function_qualname_obj)s,
#endif
        %(code_identifier)s,
        %(defaults)s,
#if PYTHON_VERSION >= 300
        %(kw_defaults)s,
        %(annotations)s,
#endif
        %(module_identifier)s,
        %(function_doc)s,
        %(closure_count)d
    );
%(closure_copy)s
    return (PyObject *)result;
}
%(file_scope)s PyObject *impl_%(function_identifier)s( %(direct_call_arg_spec)s );
%(file_scope)s PyObject *impl_%(function_identifier)s( %(direct_call_arg_spec)s )
{
#ifndef __NUITKA_NO_ASSERT__
    NUITKA_MAY_BE_UNUSED bool had_error = ERROR_OCCURRED();
    assert(!had_error); // Do not enter inlined functions with error set.
#endif

    // Local variable declarations.
%(function_locals)s

    // Actual function code.
%(function_body)s

%(function_exit)s
}
static PyObject *impl_%(function_identifier)s( %(parameter_objects_decl)s )
{
    // Preserve error status for checks
#ifndef __NUITKA_NO_ASSERT__
    NUITKA_MAY_BE_UNUSED bool had_error = ERROR_OCCURRED();
#endif

    // Local variable declarations.
%(function_locals)s

    // Actual function code.
%(function_body)s

%(function_exit)s
}
static PyObject *MAKE_FUNCTION_%(function_identifier)s( %(function_creation_arg_spec)s );
function_return_exit:
%(function_cleanup)s
CHECK_OBJECT( tmp_return_value );
assert( had_error || !ERROR_OCCURRED() );
return tmp_return_value;
<module codegen.templates.CodeTemplatesFunction>function_exception_exit:
%(function_cleanup)s    assert( exception_type );
    RESTORE_ERROR_OCCURRED( exception_type, exception_value, exception_tb );

    return NULL;
 Normal function (no generator, not yielding) related templates.

C:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\codegen\templates\CodeTemplatesFunction.py%(to_name)s = Nuitka_Generator_New(
    %(generator_identifier)s_context,
    %(generator_module)s,
    %(generator_name_obj)s,
#if PYTHON_VERSION >= 350
    %(generator_qualname_obj)s,
#endif
    %(code_identifier)s,
    %(closure_count)d
);
%(closure_copy)s
    // The above won't return, but we need to make it clear to the compiler
    // as well, or else it will complain and/or generate inferior code.
    assert(false);
    return;

    function_return_exit:
#if PYTHON_VERSION >= 330
    if ( tmp_return_value != Py_None )
    {
        PyObject *args[1] = { tmp_return_value };
        PyObject *stop_value = CALL_FUNCTION_WITH_ARGS1( PyExc_StopIteration, args );
        RESTORE_ERROR_OCCURRED( PyExc_StopIteration, stop_value, NULL );
        Py_INCREF( PyExc_StopIteration );
    }
    else
    {
        Py_DECREF( tmp_return_value );
    }
#endif

#if _NUITKA_EXPERIMENTAL_GENERATOR_GOTO
    return NULL;
#else
    generator->m_yielded = NULL;
    return;
#endif
C:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\codegen\templates\CodeTemplatesGeneratorFunction.py%(function_cleanup)s#if _NUITKA_EXPERIMENTAL_GENERATOR_GOTO
    return NULL;
#else
    generator->m_yielded = NULL;
    return;
#endif

    function_exception_exit:
%(function_cleanup)s    assert( exception_type );
    RESTORE_ERROR_OCCURRED( exception_type, exception_value, exception_tb );

#if _NUITKA_EXPERIMENTAL_GENERATOR_GOTO
    return NULL;
#else
    generator->m_yielded = NULL;
    return;
#endif

#if _NUITKA_EXPERIMENTAL_GENERATOR_GOTO
struct %(function_identifier)s_locals {
%(function_local_types)s
};
#endif

#if _NUITKA_EXPERIMENTAL_GENERATOR_GOTO
static PyObject *%(function_identifier)s_context( struct Nuitka_GeneratorObject *generator, PyObject *yield_return_value )
#else
static void %(function_identifier)s_context( struct Nuitka_GeneratorObject *generator )
#endif
{
    CHECK_OBJECT( (PyObject *)generator );
    assert( Nuitka_Generator_Check( (PyObject *)generator ) );

    // Local variable initialization
%(function_var_inits)s

    // Dispatch to yield based on return label index:
%(function_dispatch)s

    // Actual function code.
%(function_body)s

%(generator_exit)s
}
 Generator function (with yield) related templates.

codegen.templates.CodeTemplatesGeneratorFunction#if _NUITKA_EXPERIMENTAL_GENERATOR_GOTO
static PyObject *%(function_identifier)s_context( struct Nuitka_GeneratorObject *generator, PyObject *yield_return_value );
#else
static void %(function_identifier)s_context( struct Nuitka_GeneratorObject *generator );
#endif
<module codegen.templates.CodeTemplatesGeneratorFunction>    // Return statement need not be present.
%(function_cleanup)s
#if _NUITKA_EXPERIMENTAL_GENERATOR_GOTO
    return NULL;
#else
    generator->m_yielded = NULL;
    return;
#endif
codegen.templates.CodeTemplatesIteratorsC:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\codegen\templates\CodeTemplatesIterators.py// Check if iterator has left-over elements.
CHECK_OBJECT( %(iterator_name)s ); assert( HAS_ITERNEXT( %(iterator_name)s ) );

%(attempt_name)s = (*Py_TYPE( %(iterator_name)s )->tp_iternext)( %(iterator_name)s );

if (likely( %(attempt_name)s == NULL ))
{
    PyObject *error = GET_ERROR_OCCURRED();

    if ( error != NULL )
    {
        if ( EXCEPTION_MATCH_BOOL_SINGLE( error, PyExc_StopIteration ))
        {
            CLEAR_ERROR_OCCURRED();
        }
        else
        {
            FETCH_ERROR_OCCURRED( &exception_type, &exception_value, &exception_tb );
%(release_temps_1)s
%(var_description_code_1)s
%(line_number_code_1)s
            goto %(exception_exit)s;
        }
    }
}
else
{
    Py_DECREF( %(attempt_name)s );

    // TODO: Could avoid PyErr_Format.
#if PYTHON_VERSION < 300
    PyErr_Format( PyExc_ValueError, "too many values to unpack" );
#else
    PyErr_Format( PyExc_ValueError, "too many values to unpack (expected %(count)d)" );
#endif
    FETCH_ERROR_OCCURRED( &exception_type, &exception_value, &exception_tb );
%(release_temps_2)s
%(var_description_code_2)s
%(line_number_code_2)s
    goto %(exception_exit)s;
}<module codegen.templates.CodeTemplatesIterators> Templates for the iterator handling.

if ( %(to_name)s == NULL )
{
    if ( CHECK_AND_CLEAR_STOP_ITERATION_OCCURRED() )
    {
%(break_indicator_code)s
        goto %(break_target)s;
    }
    else
    {
%(release_temps)s
        FETCH_ERROR_OCCURRED( &exception_type, &exception_value, &exception_tb );
%(var_description_code)s
%(line_number_code)s
        goto %(exception_target)s;
    }
}
{ (char *)"%(module_name)s", NULL, 0, 0, NUITKA_SHLIB_FLAG },{ (char *)"%(module_name)s", NULL, %(bytecode)s, %(size)d, %(flags)s },{ (char *)"%(module_name)s", MOD_INIT_NAME( %(module_identifier)s ), 0, 0, NUITKA_PACKAGE_FLAG },C:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\codegen\templates\CodeTemplatesLoader.py<module codegen.templates.CodeTemplatesLoader>{ (char *)"%(module_name)s", MOD_INIT_NAME( %(module_identifier)s ), 0, 0, NUITKA_COMPILED_MODULE },/* Code to register embedded modules for meta path based loading if any. */

#include "nuitka/unfreezing.h"

/* Table for lookup to find compiled or bytecode modules included in this
 * binary or module, or put along this binary as extension modules. We do
 * our own loading for each of these.
 */
%(metapath_module_decls)s
static struct Nuitka_MetaPathBasedLoaderEntry meta_path_loader_entries[] =
{
%(metapath_loader_inittab)s
    { NULL, NULL, 0, 0, 0 }
};

void setupMetaPathBasedLoader( void )
{
    static bool init_done = false;

    if ( init_done == false )
    {
        registerMetaPathBasedUnfreezer( meta_path_loader_entries );
        init_done = true;
    }
}
 Templates for the loading of embedded modules.

// This file contains helper functions that are automatically created from
// templates.

#include "nuitka/prelude.h"

extern PyObject *callPythonFunction( PyObject *func, PyObject **args, int count );

#ifndef %(header_guard_name)s
#define %(header_guard_name)s

%(header_body)s
#endif

#include "nuitka/prelude.h"

#include "__helpers.h"

/* The _module_%(module_identifier)s is a Python object pointer of module type. */

/* Note: For full compatibility with CPython, every module variable access
 * needs to go through it except for cases where the module cannot possibly
 * have changed in the mean time.
 */

PyObject *module_%(module_identifier)s;
PyDictObject *moduledict_%(module_identifier)s;

/* The module constants used, if any. */
%(constant_decl_codes)s

static bool constants_created = false;

static void createModuleConstants( void )
{
%(constant_init_codes)s

    constants_created = true;
}

#ifndef __NUITKA_NO_ASSERT__
void checkModuleConstants_%(module_identifier)s( void )
{
    // The module may not have been used at all.
    if (constants_created == false) return;

%(constant_check_codes)s
}
#endif

// The module code objects.
%(module_code_objects_decl)s

static void createModuleCodeObjects(void)
{
%(module_code_objects_init)s
}

// The module function declarations.
%(module_functions_decl)s

// The module function definitions.
%(module_functions_code)s


#if PYTHON_VERSION >= 300
static struct PyModuleDef mdef_%(module_identifier)s =
{
    PyModuleDef_HEAD_INIT,
    "%(module_name)s",   /* m_name */
    NULL,                /* m_doc */
    -1,                  /* m_size */
    NULL,                /* m_methods */
    NULL,                /* m_reload */
    NULL,                /* m_traverse */
    NULL,                /* m_clear */
    NULL,                /* m_free */
  };
#endif

extern PyObject *const_str_plain___package__;

#if PYTHON_VERSION >= 300
extern PyObject *const_str_dot;
#endif
#if PYTHON_VERSION >= 330
extern PyObject *const_str_plain___loader__;
extern PyObject *metapath_based_loader;
#endif
#if PYTHON_VERSION >= 330
extern PyObject *const_str_plain___spec__;
#endif

extern void _initCompiledCellType();
extern void _initCompiledGeneratorType();
extern void _initCompiledFunctionType();
extern void _initCompiledMethodType();
extern void _initCompiledFrameType();
#if PYTHON_VERSION >= 350
extern void _initCompiledCoroutineTypes();
#endif
#if PYTHON_VERSION >= 360
extern void _initCompiledAsyncgenTypes();
#endif

// The exported interface to CPython. On import of the module, this function
// gets called. It has to have an exact function name, in cases it's a shared
// library export. This is hidden behind the MOD_INIT_DECL.

MOD_INIT_DECL( %(module_identifier)s )
{
#if defined(_NUITKA_EXE) || PYTHON_VERSION >= 300
    static bool _init_done = false;

    // Modules might be imported repeatedly, which is to be ignored.
    if ( _init_done )
    {
        return MOD_RETURN_VALUE( module_%(module_identifier)s );
    }
    else
    {
        _init_done = true;
    }
#endif

#ifdef _NUITKA_MODULE
    // In case of a stand alone extension module, need to call initialization
    // the init here because that's the first and only time we are going to get
    // called here.

    // Initialize the constant values used.
    _initBuiltinModule();
    createGlobalConstants();

    /* Initialize the compiled types of Nuitka. */
    _initCompiledCellType();
    _initCompiledGeneratorType();
    _initCompiledFunctionType();
    _initCompiledMethodType();
    _initCompiledFrameType();
#if PYTHON_VERSION >= 350
    _initCompiledCoroutineTypes();
#endif
#if PYTHON_VERSION >= 360
    _initCompiledAsyncgenTypes();
#endif

#if PYTHON_VERSION < 300
    _initSlotCompare();
#endif
#if PYTHON_VERSION >= 270
    _initSlotIternext();
#endif

    patchBuiltinModule();
    patchTypeComparison();

    // Enable meta path based loader if not already done.
#ifdef _NUITKA_TRACE
    puts("%(module_name)s: Calling setupMetaPathBasedLoader().");
#endif
    setupMetaPathBasedLoader();

#if PYTHON_VERSION >= 300
    patchInspectModule();
#endif

#endif

    /* The constants only used by this module are created now. */
#ifdef _NUITKA_TRACE
    puts("%(module_name)s: Calling createModuleConstants().");
#endif
    createModuleConstants();

    /* The code objects used by this module are created now. */
#ifdef _NUITKA_TRACE
    puts("%(module_name)s: Calling createModuleCodeObjects().");
#endif
    createModuleCodeObjects();

    // puts( "in init%(module_identifier)s" );

    // Create the module object first. There are no methods initially, all are
    // added dynamically in actual code only.  Also no "__doc__" is initially
    // set at this time, as it could not contain NUL characters this way, they
    // are instead set in early module code.  No "self" for modules, we have no
    // use for it.
#if PYTHON_VERSION < 300
    module_%(module_identifier)s = Py_InitModule4(
        "%(module_name)s",       // Module Name
        NULL,                    // No methods initially, all are added
                                 // dynamically in actual module code only.
        NULL,                    // No "__doc__" is initially set, as it could
                                 // not contain NUL this way, added early in
                                 // actual code.
        NULL,                    // No self for modules, we don't use it.
        PYTHON_API_VERSION
    );
#else

    module_%(module_identifier)s = PyModule_Create( &mdef_%(module_identifier)s );
#endif

    moduledict_%(module_identifier)s = MODULE_DICT( module_%(module_identifier)s );

    // Update "__package__" value to what it ought to be.
    {
#if %(is_package)s
#if PYTHON_VERSION < 300 || PYTHON_VERSION >= 330
        PyObject *module_name = GET_STRING_DICT_VALUE( moduledict_%(module_identifier)s, (Nuitka_StringObject *)const_str_plain___name__ );

        UPDATE_STRING_DICT1(
            moduledict_%(module_identifier)s,
            (Nuitka_StringObject *)const_str_plain___package__,
            module_name
        );
#endif

#else

#if PYTHON_VERSION < 300
        PyObject *module_name = GET_STRING_DICT_VALUE( moduledict_%(module_identifier)s, (Nuitka_StringObject *)const_str_plain___name__ );
        char const *module_name_cstr = PyString_AS_STRING( module_name );

        char const *last_dot = strrchr( module_name_cstr, '.' );

        if ( last_dot != NULL )
        {
            UPDATE_STRING_DICT1(
                moduledict_%(module_identifier)s,
                (Nuitka_StringObject *)const_str_plain___package__,
                PyString_FromStringAndSize( module_name_cstr, last_dot - module_name_cstr )
            );
        }
#elif PYTHON_VERSION < 330
        UPDATE_STRING_DICT1(
            moduledict_%(module_identifier)s,
            (Nuitka_StringObject *)const_str_plain___package__,
            Py_None
        );
#else
        PyObject *module_name = GET_STRING_DICT_VALUE( moduledict_%(module_identifier)s, (Nuitka_StringObject *)const_str_plain___name__ );
        Py_ssize_t dot_index = PyUnicode_Find( module_name, const_str_dot, 0, PyUnicode_GetLength( module_name ), -1 );

        if ( dot_index != -1 )
        {
            UPDATE_STRING_DICT1(
                moduledict_%(module_identifier)s,
                (Nuitka_StringObject *)const_str_plain___package__,
                PyUnicode_Substring( module_name, 0, dot_index )
            );
        }
#endif
#endif
    }

    CHECK_OBJECT( module_%(module_identifier)s );

// Seems to work for Python2.7 out of the box, but for Python3, the module
// doesn't automatically enter "sys.modules", so do it manually.
#if PYTHON_VERSION >= 300
    {
        int r = PyObject_SetItem( PySys_GetObject( (char *)"modules" ), %(module_name_obj)s, module_%(module_identifier)s );

        assert( r != -1 );
    }
#endif

    // For deep importing of a module we need to have "__builtins__", so we set
    // it ourselves in the same way than CPython does. Note: This must be done
    // before the frame object is allocated, or else it may fail.

    if ( GET_STRING_DICT_VALUE( moduledict_%(module_identifier)s, (Nuitka_StringObject *)const_str_plain___builtins__ ) == NULL )
    {
        PyObject *value = (PyObject *)builtin_module;

        // Check if main module, not a dict then but the module itself.
#if !defined(_NUITKA_EXE) || !%(is_main_module)s
        value = PyModule_GetDict( value );
#endif

        UPDATE_STRING_DICT0( moduledict_%(module_identifier)s, (Nuitka_StringObject *)const_str_plain___builtins__, value );
    }

#if PYTHON_VERSION >= 330
    UPDATE_STRING_DICT0( moduledict_%(module_identifier)s, (Nuitka_StringObject *)const_str_plain___loader__, metapath_based_loader );
#endif

#if PYTHON_VERSION >= 340
#if %(is_main_module)s
    UPDATE_STRING_DICT0( moduledict_%(module_identifier)s, (Nuitka_StringObject *)const_str_plain___spec__, Py_None );
#else
    {
        PyObject *bootstrap_module = PyImport_ImportModule("importlib._bootstrap");
        CHECK_OBJECT( bootstrap_module );
        PyObject *module_spec_class = PyObject_GetAttrString( bootstrap_module, "ModuleSpec" );
        Py_DECREF( bootstrap_module );

        PyObject *args[] = {
            GET_STRING_DICT_VALUE( moduledict_%(module_identifier)s, (Nuitka_StringObject *)const_str_plain___name__ ),
            metapath_based_loader
        };

        PyObject *spec_value = CALL_FUNCTION_WITH_ARGS2(
            module_spec_class,
            args
        );

        UPDATE_STRING_DICT1( moduledict_%(module_identifier)s, (Nuitka_StringObject *)const_str_plain___spec__, spec_value );

        Py_DECREF( module_spec_class );
    }
#endif
#endif


    // Temp variables if any
%(temps_decl)s

    // Module code.
%(module_code)s

    return MOD_RETURN_VALUE( module_%(module_identifier)s );
%(module_exit)s
    module_exception_exit:
    RESTORE_ERROR_OCCURRED( exception_type, exception_value, exception_tb );
    return MOD_RETURN_VALUE( NULL );
} Main module code templates

This for the main program in case of executables, the module templates and
stuff related to importing, and of course the generated code license.

codegen.templates.CodeTemplatesModulesC:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\codegen\templates\CodeTemplatesModules.py<module codegen.templates.CodeTemplatesModules>/* Generated code for Python source for module '%(name)s'
 * created by Nuitka version %(version)s
 *
 * This code is in part copyright %(year)s Kay Hayen.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
{
    PyObject *old = %(identifier)s;
    %(identifier)s = %(tmp_name)s;
    Py_XDECREF( old );
}
if ( %(identifier)s )
{
    Py_XDECREF( PyCell_GET( %(identifier)s ));
    PyCell_SET( %(identifier)s, NULL );
}
assert( %(identifier)s == NULL );
%(identifier)s = %(tmp_name)s;
%(to_name)s = PyObject_GetItem( %(locals_dict)s, %(var_name)s );
<module codegen.templates.CodeTemplatesVariables>%(to_name)s = PyDict_GetItem( %(locals_dict)s, %(var_name)s );

if ( %(to_name)s == NULL )
{
%(fallback)s
}
if ( %(test_code)s )
{
    %(tmp_name)s = SET_SUBSCRIPT(
        %(mapping_name)s,
        %(var_name)s,
        %(access_code)s
    );
}
else
{
    %(tmp_name)s = true;
}
%(tmp_name)s = GET_STRING_DICT_VALUE( moduledict_%(module_identifier)s, (Nuitka_StringObject *)%(var_name)s );

if (unlikely( %(tmp_name)s == NULL ))
{
    %(tmp_name)s = GET_STRING_DICT_VALUE( dict_builtin, (Nuitka_StringObject *)%(var_name)s );
}
{
    PyObject *old = PyCell_GET( %(identifier)s );
    PyCell_SET( %(identifier)s, %(tmp_name)s );
    Py_XDECREF( old );
}
Py_DECREF( PyCell_GET( %(identifier)s ) );
PyCell_SET( %(identifier)s, NULL );
%(to_name)s = PyObject_GetItem( %(locals_dict)s, %(var_name)s );

if ( %(to_name)s == NULL )
{
    if ( CHECK_AND_CLEAR_KEY_ERROR_OCCURRED() )
    {
%(fallback)s
    }
}
template_assign_from_frame_locals{
    PyObject *old = %(identifier)s;
    assert( old != NULL );
    %(identifier)s = %(tmp_name)s;
    Py_DECREF( old );
}
%(res_name)s = PyDict_DelItem( (PyObject *)moduledict_%(module_identifier)s, %(var_name)s );
if ( %(res_name)s == -1 ) CLEAR_ERROR_OCCURRED();
if ( %(identifier)s == NULL )
{
    %(tmp_name)s = NULL;
}
else
{
    %(tmp_name)s = PyCell_GET( %(identifier)s );
}
{
    PyObject *old = %(identifier)s;
    assert( old != NULL );
    %(identifier)s = %(tmp_name)s;
    Py_INCREF( %(identifier)s );
    Py_DECREF( old );
}
assert( %(identifier)s != NULL );
%(result)s = PyCell_GET( %(identifier)s ) != NULL;
if ( %(result)s == true )
{
    Py_DECREF( PyCell_GET( %(identifier)s ) );
    PyCell_SET( %(identifier)s, NULL );
}
if ( %(test_code)s )
{
    int res = PyDict_SetItem(
        %(dict_name)s,
        %(var_name)s,
        %(access_code)s
    );

    assert( res == 0 );
}
if ( %(test_code)s )
{
    int res = PyObject_SetItem(
        %(mapping_name)s,
        %(var_name)s,
        %(access_code)s
    );

    %(tmp_name)s = res == 0;
}
else
{
    PyObject *test_value = PyObject_GetItem(
        %(mapping_name)s,
        %(var_name)s
    );

    if ( test_value )
    {
        Py_DECREF( test_value );

        int res = PyObject_DelItem(
            %(mapping_name)s,
            %(var_name)s
        );

        %(tmp_name)s = res == 0;
    }
    else
    {
        CLEAR_ERROR_OCCURRED();
        %(tmp_name)s = true;
    }
}
 Templates for the variable handling.

assert( %(identifier)s == NULL );
Py_INCREF( %(tmp_name)s );
%(identifier)s = %(tmp_name)s;
template_read_shared_knownassert( PyCell_GET( %(identifier)s ) == NULL );
PyCell_SET( %(identifier)s, %(tmp_name)s );
assert( PyCell_GET( %(identifier)s ) == NULL );
Py_INCREF( %(tmp_name)s );
PyCell_SET( %(identifier)s, %(tmp_name)s );
{
    PyObject *old = %(identifier)s;
    %(identifier)s = %(tmp_name)s;
    Py_INCREF( %(identifier)s );
    Py_XDECREF( old );
}
%(tmp_name)s = %(identifier)s;
CHECK_OBJECT( %(identifier)s );
Py_DECREF( %(identifier)s );
%(identifier)s = NULL;
if ( %(test_code)s )
{
    UPDATE_STRING_DICT0( (PyDictObject *)%(dict_name)s, (Nuitka_StringObject *)%(var_name)s, %(access_code)s );
}
else
{
    int res = PyDict_DelItem( %(dict_name)s, %(var_name)s );

    if ( res != 0 )
    {
        CLEAR_ERROR_OCCURRED();
    }
}
{
    PyObject *old = PyCell_GET( %(identifier)s );
    PyCell_SET( %(identifier)s, %(tmp_name)s );
    Py_INCREF( %(tmp_name)s );
    Py_XDECREF( old );
}
%(result)s = %(identifier)s != NULL;
if ( %(result)s == true )
{
    Py_DECREF( %(identifier)s );
    %(identifier)s = NULL;
}
C:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\codegen\templates\CodeTemplatesVariables.pyPy_XDECREF( %(identifier)s );
%(identifier)s = NULL;
CHECK_OBJECT( (PyObject *)%(identifier)s );
Py_DECREF( %(identifier)s );
%(identifier)s = NULL;
if ( %(frame_identifier)s->f_locals == NULL )
{
    %(frame_identifier)s->f_locals = PyDict_New();
}
%(to_name)s = %(frame_identifier)s->f_locals;
enableDebug.<locals>.TemplateWrapper.__mod__ Wrapper around templates.

            To better trace and control template usage.

         Nuitka templates can have more checks that the normal '%' operation.

This wraps strings with a class derived from "str" that does more checks.
enableDebug.<locals>.TemplateWrapper.__init__Extra value '%s' provided to template '%s'.<module codegen.templates.TemplateDebugWrapper>globals_dictenableDebug.<locals>.TemplateWrapper.splitC:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\codegen\templates\TemplateDebugWrapper.py%%(%s)template_nameenableDebug.<locals>.TemplateWrapper.__str__Utilities to compile possibly incomplete Python source code.

This module provides two interfaces, broadly similar to the builtin
function compile(), which take program text, a filename and a 'mode'
and:

- Return code object if the command is complete and valid
- Return None if the command is incomplete
- Raise SyntaxError, ValueError or OverflowError if the command is a
  syntax error (OverflowError and ValueError can be produced by
  malformed literals).

Approach:

First, check if the source consists entirely of blank lines and
comments; if so, replace it with 'pass', because the built-in
parser doesn't always do the right thing for these.

Compile three times: as is, with \n, and with \n\n appended.  If it
compiles as is, it's complete.  If it compiles with one \n appended,
we expect more.  If it doesn't compile either way, we compare the
error we get when compiling with \n or \n\n appended.  If the errors
are the same, the code is broken.  But if the errors are different, we
expect more.  Not intuitive; not even guaranteed to hold in future
releases; but this matches the compiler's behavior from Python 1.4
through 2.2, at least.

Caveat:

It is possible (but not likely) that the parser stops parsing with a
successful outcome before reaching the end of the source; in this
case, trailing symbols may be ignored instead of causing an error.
For example, a backslash followed by two newlines may be followed by
arbitrary garbage.  This will be fixed once the API for the parser is
better.

The two interfaces are:

compile_command(source, filename, symbol):

    Compiles a single command in the manner described above.

CommandCompiler():

    Instances of this class have __call__ methods identical in
    signature to compile_command; the difference is that if the
    instance compiles program text containing a __future__ statement,
    the instance 'remembers' and compiles all subsequent program texts
    with the statement in force.

The module also provides another class:

Compile():

    Instances of this class act like the built-in function compile,
    but with 'memory' in the sense described above.
_featureserr1err2code1code2Instances of this class behave much like the built-in compile
    function, but if one is used to compile text containing a future
    statement, it "remembers" and compiles all subsequent program texts
    with the statement in force.Compile a command and determine whether it is incomplete.

    Arguments:

    source -- the source string; may contain \n characters
    filename -- optional filename from which source was read; default
                "<input>"
    symbol -- optional grammar start symbol; "single" (default) or "eval"

    Return value / exceptions raised:

    - Return a code object if the command is complete and valid
    - Return None if the command is incomplete
    - Raise SyntaxError, ValueError or OverflowError if the command is a
      syntax error (OverflowError and ValueError can be produced by
      malformed literals).
    <module codeop>Compile.__call__Compile.__init___maybe_compileC:\msys64\mingw64\lib\python3.6\codeop.pyCommandCompiler.__init__Compile a command and determine whether it is incomplete.

        Arguments:

        source -- the source string; may contain \n characters
        filename -- optional filename from which source was read;
                    default "<input>"
        symbol -- optional grammar start symbol; "single" (default) or
                  "eval"

        Return value / exceptions raised:

        - Return a code object if the command is complete and valid
        - Return None if the command is incomplete
        - Raise SyntaxError, ValueError or OverflowError if the command is a
          syntax error (OverflowError and ValueError can be produced by
          malformed literals).
        PyCF_DONT_IMPLY_DEDENTCommandCompiler.__call___count_elementsUserList.copyUserList.extendChainMap.new_childlink_prevlink_nextUserString.casefoldfield_namesclass_definitionOrderedDict.__sizeof__od.__eq__(y) <==> od==y.  Comparison to another OD is order-sensitive
        while comparison to a regular mapping is order-insensitive.

        UserString.__le__UserString.__eq__Counter.__iand__%r: %rCounter.__neg__mapping_getUserString.swapcaseUserString.isidentifiersoft_linkdictionary is emptynamedtuple.<locals>.<genexpr>_repr_templateUserString.upper_OrderedDict__hardrootChainMap.__repr__UserDict.__getitem__Return a shallow copy.Key not found in the first mapping: {!r}C:\msys64\mingw64\lib\python3.6\collectionsdict_setitemUserList.__mul__UserString.__str__List the n most common elements and their counts from the most
        common to the least.  If n is None, then list all element counts.

        >>> Counter('abcdeabcdabcaba').most_common(3)
        [('a', 5), ('b', 4), ('c', 3)]

        UserString.__ge__Inplace add from another counter, keeping only positive counts.

        >>> c = Counter('abbb')
        >>> c += Counter('bcc')
        >>> c
        Counter({'b': 4, 'c': 2, 'a': 1})

        UserString.capitalizeUserString.splitlinesInplace subtract counter, but keep only results with positive counts.

        >>> c = Counter('abbbc')
        >>> c -= Counter('bccd')
        >>> c
        Counter({'b': 2, 'a': 1})

        ChainMap.popitemUserList.__setitem__descriptor '__init__' of 'Counter' object needs an argument_OrderedDict__rootUserString.rjustUserString.isnumericnonpositivenewcountUserList.__eq__od.__delitem__(y) <==> del od[y]Counter.updatedict_delitemod.setdefault(k[,d]) -> od.get(k,d), also set od[k]=d if k not in odMove an existing element to the end (or beginning if last==False).

        Raises KeyError if the element does not exist.
        When last=True, acts like a fast version of self[key]=self.pop(key).

        Like dict.update() but add counts instead of replacing them.

        Source can be an iterable, a dictionary, or another Counter instance.

        >>> c = Counter('which')
        >>> c.update('witch')           # add elements from another iterable
        >>> d = Counter('watch')
        >>> c.update(d)                 # add elements from another counter
        >>> c['h']                      # four 'h' in which, witch, and watch
        4

        ChainMap.parentsUserString.replaceUserDict.__init__Remove *key* from maps[0] and return its value. Raise KeyError if *key* not in maps[0].UserList.__ge__UserString.ljustChainMap.copy_OrderedDict__updateChainMap.__delitem__ChainMap.__contains__.<locals>.<genexpr>Initialize an ordered dictionary.  The signature is the same as
        regular dictionaries.  Keyword argument order is preserved.
        UserList.reverse_chainNew ChainMap with a new map followed by all previous maps.
        If no map is provided, an empty dict is used.
        UserList.insert_OrderedDictItemsViewLinkUserList.indexod.__reversed__() <==> reversed(od)Adds an empty counter, effectively stripping negative and zero countsOD.fromkeys(S[, v]) -> New ordered dictionary with keys from S.
        If not specified, the value defaults to None.

        Counter.__delitem__UserString.__hash__UserString.titleChainMap.__init__UserString.expandtabsReturns a new subclass of tuple with named fields.

    >>> Point = namedtuple('Point', ['x', 'y'])
    >>> Point.__doc__                   # docstring for the new class
    'Point(x, y)'
    >>> p = Point(11, y=22)             # instantiate with positional args or keywords
    >>> p[0] + p[1]                     # indexable like a plain tuple
    33
    >>> x, y = p                        # unpack like a regular tuple
    >>> x, y
    (11, 22)
    >>> p.x + p.y                       # fields also accessible by name
    33
    >>> d = p._asdict()                 # convert to a dictionary
    >>> d['x']
    11
    >>> Point(**d)                      # convert from a dictionary
    Point(x=11, y=22)
    >>> p._replace(x=100)               # _replace() is like str.replace() but targets named fields
    Point(x=100, y=22)

    _itemgetterUserDict.fromkeys_repeatUserList.__add__Dict subclass for counting hashable items.  Sometimes called a bag
    or multiset.  Elements are stored as dictionary keys and their counts
    are stored as dictionary values.

    >>> c = Counter('abcdeabcdabcaba')  # count elements from a string

    >>> c.most_common(3)                # three most common elements
    [('a', 5), ('b', 4), ('c', 3)]
    >>> sorted(c)                       # list all unique elements
    ['a', 'b', 'c', 'd', 'e']
    >>> ''.join(sorted(c.elements()))   # list elements with repetitions
    'aaaaabbbbcccdde'
    >>> sum(c.values())                 # total of all counts
    15

    >>> c['a']                          # count of letter 'a'
    5
    >>> for elem in 'shazam':           # update counts from an iterable
    ...     c[elem] += 1                # by adding 1 to each element's count
    >>> c['a']                          # now there are seven 'a'
    7
    >>> del c['b']                      # remove all 'b'
    >>> c['b']                          # now there are zero 'b'
    0

    >>> d = Counter('simsalabim')       # make another counter
    >>> c.update(d)                     # add in the second counter
    >>> c['a']                          # now there are nine 'a'
    9

    >>> c.clear()                       # empty the counter
    >>> c
    Counter()

    Note:  If a count is set to zero or reduced to zero, it will remain
    in the counter until the entry is deleted or the counter is cleared:

    >>> c = Counter('aaabbc')
    >>> c['b'] -= 2                     # reduce the count of 'b' by two
    >>> c.most_common()                 # 'b' is still in, but its count is zero
    [('a', 3), ('c', 1), ('b', 0)]

    repr_fmtisdecimal_field_templateCounter.__repr__Counter.__or__UserList.__le__ChainMap.__missing__UserString.isalnumUserList.__len__Counter.subtractUserList.__getitem__New ChainMap or subclass with a new copy of maps[0] and refs to maps[1:]descriptor 'subtract' of 'Counter' object needs an argumentCounter.__reduce__<module collections>ChainMap.getother_countUserString.__init__namedtuple_%sUserString.findCounter.__pos__Counter.__ior__OrderedDict.move_to_endUserString.format_mapCounter.fromkeys() is undefined.  Use Counter(iterable) instead.UserList.countUserList.sortRemove and return a (key, value) pair from the dictionary.

        Pairs are returned in LIFO order if last is true or FIFO order if false.
        _OrderedDict__markerIterator over elements repeating each as many times as its count.

        >>> c = Counter('ABCABC')
        >>> sorted(c.elements())
        ['A', 'A', 'B', 'B', 'C', 'C']

        # Knuth's example for prime factors of 1836:  2**2 * 3**3 * 17**1
        >>> prime_factors = Counter({2: 2, 3: 3, 17: 1})
        >>> product = 1
        >>> for factor in prime_factors.elements():     # loop over factors
        ...     product *= factor                       # and multiply them
        >>> product
        1836

        Note, if an element's count has been set to zero or is a negative
        number, elements() will ignore it.

        initlist Intersection is the minimum of corresponding counts.

        >>> Counter('abbb') & Counter('bcc')
        Counter({'b': 1})

        UserString.rfindCounter.__and__UserDict.__repr___UserList__cast_OrderedDictItemsView.__reversed__OrderedDict.__iter__Add counts from two counters.

        >>> Counter('abbb') + Counter('bcc')
        Counter({'b': 4, 'c': 2, 'a': 1})

        ChainMap.__setitem__UserString.islowerfield_defsnum_fieldsod.copy() -> a shallow copy of odself_getUserString.rsplit_OrderedDictKeysView.__reversed__UserString.__getnewargs___OrderedDict__mapUserString.istitleUserString.lstripUserString.startswithCounter.most_commonOrderedDict.__reduce__The count of elements not in the Counter is zero.od.__iter__() <==> iter(od)This module implements specialized container datatypes providing
alternatives to Python's general purpose built-in containers, dict,
list, set, and tuple.

* namedtuple   factory function for creating tuple subclasses with named fields
* deque        list-like container with fast appends and pops on either end
* ChainMap     dict-like class for creating a single view of multiple mappings
* Counter      dict subclass for counting hashable objects
* OrderedDict  dict subclass that remembers the order entries were added
* defaultdict  dict subclass that calls a factory function to supply missing values
* UserDict     wrapper around dictionary objects for easier dict subclassing
* UserList     wrapper around list objects for easier list subclassing
* UserString   wrapper around string objects for easier string subclassing

ChainMap.clearCounter.elementsUserString.__complex__descriptor '__init__' of 'UserDict' object needs an argument_OrderedDictValuesView.__reversed__Counter.__sub__Union is the maximum of value in either of the input counters.

        >>> Counter('abbb') | Counter('bcc')
        Counter({'b': 3, 'c': 2, 'a': 1})

        UserString.__lt__UserString.__gt__descriptor '__init__' of 'OrderedDict' object needs an argumentRemove and return an item pair from maps[0]. Raise KeyError is maps[0] is empty.Counter.__isub__UserString.__mul__UserString.__int__UserString.isupper A ChainMap groups multiple dicts (or other mappings) together
    to create a single, updateable view.

    The underlying mappings are stored in a list.  That list is public and can
    be accessed or updated using the *maps* attribute.  There is no other
    state.

    Lookups search the underlying mappings successively until a key is found.
    In contrast, writes, updates, and deletions only operate on the first
    mapping.

    _iskeywordUserList.__lt__UserString.rstripUserDict.__setitem__UserList.__delitem__UserString.__contains__od.clear() -> None.  Remove all items from od.Internal method to strip elements with a negative or zero countC:\msys64\mingw64\lib\python3.6\collections\__init__.pyisprintableUserString.lowerUserString.stripCounter.__init__UserDict.__len__UserString.translateChainMap.__len__UserList.__imul__UserString.countInplace union is the maximum of value from either counter.

        >>> c = Counter('abbb')
        >>> c |= Counter('bcc')
        >>> c
        Counter({'b': 3, 'c': 2, 'a': 1})

        UserString.__float__UserString.isdecimalUserString.index_keep_positivedescriptor 'update' of 'Counter' object needs an argumentUserString.isdigitUserDict.copyCounter.__iadd__ChainMap.fromkeysUserString.rindex{0.__class__.__name__}({1})UserString.__radd__UserList.clearUserList.__iadd__{name}=%rUserString.isalphaUserList.appendEncountered duplicate field name: %rField names cannot start with an underscore: %rCreate a ChainMap with a single dict created from the iterable.Clear maps[0], leaving maps[1:] intact._LinkUserList.__contains__Type names and field names must be stringsfrom builtins import property as _property, tuple as _tuple
from operator import itemgetter as _itemgetter
from collections import OrderedDict

class {typename}(tuple):
    '{typename}({arg_list})'

    __slots__ = ()

    _fields = {field_names!r}

    def __new__(_cls, {arg_list}):
        'Create new instance of {typename}({arg_list})'
        return _tuple.__new__(_cls, ({arg_list}))

    @classmethod
    def _make(cls, iterable, new=tuple.__new__, len=len):
        'Make a new {typename} object from a sequence or iterable'
        result = new(cls, iterable)
        if len(result) != {num_fields:d}:
            raise TypeError('Expected {num_fields:d} arguments, got %d' % len(result))
        return result

    def _replace(_self, **kwds):
        'Return a new {typename} object replacing specified fields with new values'
        result = _self._make(map(kwds.pop, {field_names!r}, _self))
        if kwds:
            raise ValueError('Got unexpected field names: %r' % list(kwds))
        return result

    def __repr__(self):
        'Return a nicely formatted representation string'
        return self.__class__.__name__ + '({repr_fmt})' % self

    def _asdict(self):
        'Return a new OrderedDict which maps field names to their values.'
        return OrderedDict(zip(self._fields, self))

    def __getnewargs__(self):
        'Return self as a plain tuple.  Used by copy and pickle.'
        return tuple(self)

{field_defs}
od.__setitem__(i, y) <==> od[i]=yUserList.__radd__ChainMap.__bool__UserString.encodeInitialize a ChainMap by setting *maps* to the given mappings.
        If no mappings are provided, a single empty dictionary is used.

        UserDict.__delitem__Passing 'dict' as keyword argument is deprecatedCounter._keep_positiveDictionary that remembers insertion orderUserString.rpartitionTally elements from the iterable.Subtracts from an empty counter.  Strips positive and zero counts,
        and flips the sign on negative counts.

        Like dict.update() but subtracts counts instead of replacing them.
        Counts can be reduced below zero.  Both the inputs and outputs are
        allowed to contain zero and negative counts.

        Source can be an iterable, a dictionary, or another Counter instance.

        >>> c = Counter('which')
        >>> c.subtract('witch')             # subtract elements from another iterable
        >>> c.subtract(Counter('watch'))    # subtract elements from another counter
        >>> c['h']                          # 2 in which, minus 1 in witch, minus 1 in watch
        0
        >>> c['w']                          # 1 in which, minus 1 in witch, minus 1 in watch
        -1

        Type names and field names cannot be a keyword: %rChainMap.__getitem__UserString.centerUserString.__mod___starmapNo keys found in the first mapping.UserList.removeChainMap.__iter__UserString.endswithUserString.zfill    {name} = _property(_itemgetter({index:d}), doc='Alias for field number {index:d}')
UserString.partition%s({%s})Return state information for picklingUserString.isprintableUserString.__add__A more or less complete user-defined wrapper around list objects.Type names and field names must be valid identifiers: %rInplace intersection is the minimum of corresponding counts.

        >>> c = Counter('abbb')
        >>> c &= Counter('bcc')
        >>> c
        Counter({'b': 1})

        Create a new, empty Counter object.  And if given, count elements
        from an input iterable.  Or, initialize the count from another mapping
        of elements to their counts.

        >>> c = Counter()                           # a new, empty counter
        >>> c = Counter('gallahad')                 # a new counter from an iterable
        >>> c = Counter({'a': 4, 'b': 2})           # a new counter from a mapping
        >>> c = Counter(a=4, b=2)                   # a new counter from keyword args

        UserList.popUserString.__len__UserList.__init__Counter.copyCounter.__missing__UserString.isspaceUserList.__gt__Like dict.__delitem__() but does not raise KeyError for missing values.UserString.joinUserDict.__contains__od.__repr__() <==> repr(od)UserList.__repr___class_templateUserString.__rmod__od.pop(k[,d]) -> v, remove specified key and return the corresponding
        value.  If key is not found, d is returned if given, otherwise KeyError
        is raised.

        {0}({1!r})Counter.__add__UserList.__castUserString.__getitem__UserDict.__iter___recursive_reprNew ChainMap from maps[1:].UserString.__repr__ Subtract count, but keep only results with positive counts.

        >>> Counter('abbbc') - Counter('bccd')
        Counter({'b': 2, 'a': 1})

        C:\msys64\mingw64\lib\python3.6\collections\abc.py<module collections.abc>C:\msys64\mingw64\lib\python3.6\concurrent\__init__.pyExecute computations asynchronously using threads or processes.<module concurrent.futures>C:\msys64\mingw64\lib\python3.6\concurrent\futuresC:\msys64\mingw64\lib\python3.6\concurrent\futures\__init__.pyFuture.set_resultadd_resultReturn the exception raised by the call that the future represents.

        Args:
            timeout: The number of seconds to wait for the exception if the
                future isn't done. If None, then there is no limit on the wait
                time.

        Returns:
            The exception raised by the call that the future represents or None
            if the call completed without raising.

        Raises:
            CancelledError: If the future was cancelled.
            TimeoutError: If the future didn't finish executing before the given
                timeout.
        num_pending_callsstop_on_exceptionSets the result of the future as being the given exception.

        Should only be used by Executor implementations and unit tests.
        _yield_finished_futuresClean-up the resources associated with the Executor.

        It is safe to call this method several times. Otherwise, no other
        methods can be called after this one.

        Args:
            wait: If True then shutdown will not return until all running
                futures have finished executing and the resources used by the
                executor have been reclaimed.
        _AllCompletedWaiterpending_countMark the future as running or process any cancel notifications.

        Should only be used by Executor implementations and unit tests.

        If the future has been cancelled (cancel() was called and returned
        True) then any threads waiting on the future completing (though calls
        to as_completed() or wait()) are notified and False is returned.

        If the future was not cancelled then it is put in the running state
        (future calls to running() will return True) and True is returned.

        This method should be called by Executor implementations before
        executing the work associated with this future. If this method returns
        False then the work should not be executed.

        Returns:
            False if the Future was cancelled, True otherwise.

        Raises:
            RuntimeError: if this method was already called or if set_result()
                or set_exception() was called.
        ref_collectfutures_setresult_iterator_AcquireFutures.__init__Invalid return condition: %rFuture.exceptionProvides the event that wait() and as_completed() block on.An iterator over the given futures that yields each as it completes.

    Args:
        fs: The sequence of Futures (possibly created by different Executors) to
            iterate over.
        timeout: The maximum number of seconds to wait. If None, then there
            is no limit on the wait time.

    Returns:
        An iterator that yields the given Futures as they complete (finished or
        cancelled). If any given Futures are duplicated, they will be returned
        once.

    Raises:
        TimeoutError: If the entire result iterator could not be generated
            before the given timeout.
    <%s at %#x state=%s raised %s><module concurrent.futures._base>_create_and_install_waiters.<locals>.<genexpr>_done_callbackswait_timeoutC:\msys64\mingw64\lib\python3.6\concurrent\futures\_base.py_AllCompletedWaiter._decrement_pending_calls_STATE_TO_DESCRIPTION_MAPFuture._invoke_callbacksCANCELLEDexception calling callback for %rRUNNING_AsCompletedWaiterExecutor.shutdownCancel the future if possible.

        Returns True if the future was cancelled, False otherwise. A future
        cannot be cancelled if it is running or has already completed.
        add_exceptionFuture.cancel<%s at %#x state=%s>Represents the result of an asynchronous computation.FINISHEDUsed by wait(return_when=FIRST_EXCEPTION and ALL_COMPLETED).add_done_callbacktotal_futures<%s at %#x state=%s returned %s>%d (of %d) futures unfinished_FirstCompletedWaiter.add_cancelledFuture in unexpected stateDoneAndNotDoneFutures_AllCompletedWaiter.__init__This is an abstract base class for concrete asynchronous executors._AcquireFutures.__enter___Waiter.add_cancelled_Waiter.__init__Return True if the future was cancelled._AS_COMPLETEDdone not_doneFuture.runningExecutor.mapSets the return value of work associated with the future.

        Should only be used by Executor implementations and unit tests.
        _FirstCompletedWaiter.add_resultFuture.__init__Future.set_exceptionA context manager that does an ordered acquire of Future conditions.Future.cancelledReturn True if the future is currently executing.Submits a callable to be executed with the given arguments.

        Schedules the callable to be executed as fn(*args, **kwargs) and returns
        a Future instance representing the execution of the callable.

        Returns:
            A Future representing the given call.
        PENDING_AcquireFutures.__exit___FUTURE_STATES_AsCompletedWaiter.__init___Waiter.add_result_AsCompletedWaiter.add_resultFuture.__repr___AsCompletedWaiter.add_exceptionExecutor.__exit__Base class for all future-related exceptions.Future.__get_resultReturns an iterator equivalent to map(fn, iter).

        Args:
            fn: A callable that will take as many arguments as there are
                passed iterables.
            timeout: The maximum number of seconds to wait. If None, then there
                is no limit on the wait time.
            chunksize: The size of the chunks the iterable will be broken into
                before being passed to a child process. This argument is only
                used by ProcessPoolExecutor; it is ignored by
                ThreadPoolExecutor.

        Returns:
            An iterator equivalent to: map(func, *iterables) but the calls may
            be evaluated out-of-order.

        Raises:
            TimeoutError: If the entire result iterator could not be generated
                before the given timeout.
            Exception: If fn(*args) raises for any values.
        as_completed.<locals>.<genexpr>Attaches a callable that will be called when the future finishes.

        Args:
            fn: A callable that will be called with this future as its only
                argument when the future completes or is cancelled. The callable
                will always be called by a thread in the same process in which
                it was added. If the future has already completed or been
                cancelled then the callable will be called immediately. These
                callables are called in the order that they were added.
        _AllCompletedWaiter.add_cancelledReturn True of the future was cancelled or finished executing.Executor.__enter__Return the result of the call that the future represents.

        Args:
            timeout: The number of seconds to wait for the result if the future
                isn't done. If None, then there is no limit on the wait time.

        Returns:
            The result of the call that the future represents.

        Raises:
            CancelledError: If the future was cancelled.
            TimeoutError: If the future didn't finish executing before the given
                timeout.
            Exception: If the call raised then that exception will be raised.
        _Future__get_resultUsed by wait(return_when=FIRST_COMPLETED)._Waiter.add_exceptionFuture.add_done_callbackUsed by as_completed().Future.doneFuture.resultCANCELLED_AND_NOTIFIEDExecutor.submitFuture.set_running_or_notify_cancel_AllCompletedWaiter.add_result
    Iterate on the list *fs*, yielding finished futures one by one in
    reverse order.
    Before yielding a future, *waiter* is removed from its waiters
    and the future is removed from each set in the collection of sets
    *ref_collect*.

    The aim of this function is to avoid keeping stale references after
    the future is yielded and before the iterator resumes.
    Wait for the futures in the given sequence to complete.

    Args:
        fs: The sequence of Futures (possibly created by different Executors) to
            wait upon.
        timeout: The maximum number of seconds to wait. If None, then there
            is no limit on the wait time.
        return_when: Indicates when this function should return. The options
            are:

            FIRST_COMPLETED - Return when any future finishes or is
                              cancelled.
            FIRST_EXCEPTION - Return when any future finishes by raising an
                              exception. If no future raises an exception
                              then it is equivalent to ALL_COMPLETED.
            ALL_COMPLETED -   Return when all futures finish or are cancelled.

    Returns:
        A named 2-tuple of sets. The first set, named 'done', contains the
        futures that completed (is finished or cancelled) before the wait
        completed. The second set, named 'not_done', contains uncompleted
        futures.
    Future %s in unexpected state: %s_FirstCompletedWaiter.add_exception_AsCompletedWaiter.add_cancelledThe Future was cancelled.Initializes the future. Should not be called by clients._AllCompletedWaiter.add_exceptionExecutor.map.<locals>.result_iteratorThe operation exceeded the given deadline.C:\msys64\mingw64\lib\python3.6\concurrent\futures\process.pychunksize must be >= 1.A process in the process pool was terminated abruptly while the future was running or pending. Iterates over zip()ed iterables in chunks. _result_queueBrokenProcessPool_CallItem.__init__
    Specialized implementation of itertools.chain.from_iterable.
    Each item in *iterable* should be a list.  This function is
    careful not to keep references to yielded objects.
    _call_queueProcessPoolExecutor.shutdowncall_item_process_worker_ExceptionWithTraceback.__reduce___queue_management_worker.<locals>.shutdown_worker.<locals>.<genexpr>_shutdown_thread Processes a chunk of an iterable passed to map.

    Runs the function passed to map() on a chunk of the
    iterable passed to map.

    This function is run in a separate process.

    _queue_management_worker.<locals>.shutting_downsentinels_adjust_process_countProcessPoolExecutor.__init__SC_SEM_NSEMS_MAX_ResultItemnsems_maxManages the communication between this process and the worker processes.

    This function is run in a local thread.

    Args:
        executor_reference: A weakref.ref to the ProcessPoolExecutor that owns
            this thread. Used to determine if the ProcessPoolExecutor has been
            garbage collected and that this function can exit.
        process: A list of the multiprocessing.Process instances used as
            workers.
        pending_work_items: A dict mapping work ids to _WorkItems e.g.
            {5: <_WorkItem...>, 6: <_WorkItem...>, ...}
        work_ids_queue: A queue.Queue of work ids e.g. Queue([5, 6, ...]).
        call_queue: A multiprocessing.Queue that will be filled with _CallItems
            derived from _WorkItems for processing by the process workers.
        result_queue: A multiprocessing.Queue of _ResultItems generated by the
            process workers.
    system provides too few semaphores (%d available, 256 necessary)Implements ProcessPoolExecutor.

The follow diagram and text describe the data-flow through the system:

|======================= In-process =====================|== Out-of-process ==|

+----------+     +----------+       +--------+     +-----------+    +---------+
|          |  => | Work Ids |    => |        |  => | Call Q    | => |         |
|          |     +----------+       |        |     +-----------+    |         |
|          |     | ...      |       |        |     | ...       |    |         |
|          |     | 6        |       |        |     | 5, call() |    |         |
|          |     | 7        |       |        |     | ...       |    |         |
| Process  |     | ...      |       | Local  |     +-----------+    | Process |
|  Pool    |     +----------+       | Worker |                      |  #1..n  |
| Executor |                        | Thread |                      |         |
|          |     +----------- +     |        |     +-----------+    |         |
|          | <=> | Work Items | <=> |        | <=  | Result Q  | <= |         |
|          |     +------------+     |        |     +-----------+    |         |
|          |     | 6: call()  |     |        |     | ...       |    |         |
|          |     |    future  |     |        |     | 4, result |    |         |
|          |     | ...        |     |        |     | 3, except |    |         |
+----------+     +------------+     +--------+     +-----------+    +---------+

Executor.submit() called:
- creates a uniquely numbered _WorkItem and adds it to the "Work Items" dict
- adds the id of the _WorkItem to the "Work Ids" queue

Local worker thread:
- reads work ids from the "Work Ids" queue and looks up the corresponding
  WorkItem from the "Work Items" dict: if the work item has been cancelled then
  it is simply removed from the dict, otherwise it is repackaged as a
  _CallItem and put in the "Call Q". New _CallItems are put in the "Call Q"
  until "Call Q" is full. NOTE: the size of the "Call Q" is kept small because
  calls placed in the "Call Q" can no longer be cancelled with Future.cancel().
- reads _ResultItems from "Result Q", updates the future stored in the
  "Work Items" dict and deletes the dict entry

Process #1..n:
- reads _CallItems from "Call Q", executes the calls, and puts the resulting
  _ResultItems in "Result Q"
_chain_from_iterable_of_lists_rebuild_exc_broken_queue_management_thread_get_chunks_RemoteTracebackA child process terminated abruptly, the process pool is not usable anymoreEvaluates calls from call_queue and places the results in result_queue.

    This worker is run in a separate process.

    Args:
        call_queue: A multiprocessing.Queue of _CallItems that will be read and
            evaluated by the worker.
        result_queue: A multiprocessing.Queue of _ResultItems that will written
            to by the worker.
        shutdown: A multiprocessing.Event that will be set as a signal to the
            worker that it should exit when call_queue is empty.
    _queue_countInitializes a new ProcessPoolExecutor instance.

        Args:
            max_workers: The maximum number of processes that can be used to
                execute the given calls. If None or not given then as many
                worker processes will be created as the machine has processors.
        _process_chunk
    Raised when a process in a ProcessPoolExecutor terminated abruptly
    while a future was in the running state.
    _check_system_limitsresult_item_system_limits_checked<module concurrent.futures.process>_RemoteTraceback.__init___ExceptionWithTraceback.__init___work_idsFills call_queue with _WorkItems from pending_work_items.

    This function never blocks.

    Args:
        pending_work_items: A dict mapping work ids to _WorkItems e.g.
            {5: <_WorkItem...>, 6: <_WorkItem...>, ...}
        work_ids: A queue.Queue of work ids e.g. Queue([5, 6, ...]). Work ids
            are consumed and the corresponding _WorkItems from
            pending_work_items are transformed into _CallItems and put in
            call_queue.
        call_queue: A multiprocessing.Queue that will be filled with _CallItems
            derived from _WorkItems.
    _start_queue_management_threadEXTRA_QUEUED_CALLSProcessPoolExecutor._start_queue_management_thread.<locals>.weakref_cbProcessPoolExecutor._adjust_process_count_RemoteTraceback.__str__nb_children_aliveReturns an iterator equivalent to map(fn, iter).

        Args:
            fn: A callable that will take as many arguments as there are
                passed iterables.
            timeout: The maximum number of seconds to wait. If None, then there
                is no limit on the wait time.
            chunksize: If greater than one, the iterables will be chopped into
                chunks of size chunksize and submitted to the process pool.
                If set to one, the items in the list will be sent one at a time.

        Returns:
            An iterator equivalent to: map(func, *iterables) but the calls may
            be evaluated out-of-order.

        Raises:
            TimeoutError: If the entire result iterator could not be generated
                before the given timeout.
            Exception: If fn(*args) raises for any values.
        _ResultItem.__init__ProcessPoolExecutor.map_add_call_item_to_queueProcessPoolExecutor.submit_pending_work_items_system_limitedThreadPoolExecutor._adjust_thread_count_WorkItem.runthread_name_prefixC:\msys64\mingw64\lib\python3.6\concurrent\futures\thread.pyException in workerwork_queueThreadPoolExecutor-%d<module concurrent.futures.thread>Initializes a new ThreadPoolExecutor instance.

        Args:
            max_workers: The maximum number of threads that can be used to
                execute the given calls.
            thread_name_prefix: An optional name prefix to give our threads.
        num_threads_thread_name_prefixImplements ThreadPoolExecutor._work_queueThreadPoolExecutor.shutdownThreadPoolExecutor._adjust_thread_count.<locals>.weakref_cbconfig.jsonvalues_to_savewriting values to assignment.jsonCan't open file for writing: write_fhC:\msys64\home\cbper\config.pyCan't open file for reading: Config.read_configConfig.get_defaultConfig.write_configConfig.set_default<module config>Config.__init__C:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\containersC:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\containers\__init__.pyOrderedDict.reverseOrderedDict.__deepcopy__OrderedDict.indexOrderedDict.byindexOrderedDict(%r)OrderedDict.updateOrderedDict.__setstate__OrderedDict.iterkeysOrderedDict.iteritemsOrderedDict.__ne__OrderedDict.sorttype object 'dict' has no attribute '__cmp__'C:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\containers\odict.pyOrderedDict.__getstate__OrderedDict.__cmp__OrderedDict.itervaluesexpected at most one positional argument This module is only an abstraction of OrderedDict as present in 2.7 and 3.x.

It is not in 2.6, for this version we are using the odict.py as mentioned in the
PEP-0372.

This can be removed safely after Python2.6 support is dropped (if ever), note
that the documentation was removed, as it's not interesting really, being
redundant to the Python 2.7 documentation.

Starting with Python 3.6, we can safely use the built-in dictionary.
OrderedDict.fromkeys.<locals>.<genexpr><module containers.odict>OrderedSet.__iter__OrderedSet.__reversed__OrderedSet.discardOrderedSet.__len__OrderedSet.__contains__OrderedSet.__repr__OrderedSet.__init__OrderedSet.popOrderedSet.__eq__set is empty<module containers.oset> This module is only an abstraction of OrderedSet which is not present in
Python at all.

It was originally downloaded from http://code.activestate.com/recipes/576694/
OrderedSet.addC:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\containers\oset.py_GeneratorContextManager.__enter__Enters the supplied context manager

        If successful, also pushes its __exit__ method as a callback and
        returns the result of the __enter__ method.
        ExitStack.callbackExitStack.pushcm_exit_exit_wrapperExitStack._push_cm_exit.<locals>._exit_wrapperpending_raisesuppress.__enter__exctbExitStack.__exit__generator didn't stop after throw()_cm_typeAbstractContextManager.__enter__ExitStack.pop_allnew_targetC:\msys64\mingw64\lib\python3.6\contextlib.pynew_stacksuppressed_excContextDecorator._recreate_cmAbstractContextManager.__subclasshook___RedirectStream.__exit__Context manager to suppress specified exceptions

    After the exception is suppressed, execution proceeds with the next
    statement following the with statement.

         with suppress(FileNotFoundError):
             os.remove(somefile)
         # Execution still resumes here if the file was already removed
    ContextDecorator.__call__AbstractContextManager.__exit__Return a recreated instance of self.

        Allows an otherwise one-shot context manager like
        _GeneratorContextManager to support use as
        a decorator via implicit recreation.

        This is a private interface just for _GeneratorContextManager.
        See issue #11647 for details.
        _GeneratorContextManager.__init__new_exc_GeneratorContextManager.__exit__ExitStack.__exit__.<locals>._fix_exception_contextredirect_stderr_RedirectStream.__enter__Helper to correctly register callbacks to __exit__ methodsRaise any exception triggered within the runtime context._RedirectStream.__init__exit_methodPreserve the context stack by transferring it to a new instanceContext manager for dynamic management of a stack of exit callbacks

    For example:

        with ExitStack() as stack:
            files = [stack.enter_context(open(fname)) for fname in filenames]
            # All opened files will automatically be closed at the end of
            # the with statement, even if attempts to open files later
            # in the list raise an exception

    _old_targetsreceived_excContext manager for temporarily redirecting stderr to another file.generator didn't yieldExitStack.callback.<locals>._exit_wrapper_exit_callbacksReturn `self` upon entering the runtime context.Registers a callback with the standard __exit__ method signature

        Can suppress exceptions the same way __exit__ methods can.

        Also accepts any object with an __exit__ method (registering a call
        to the method instead of the object itself)
        Registers an arbitrary callback and arguments.

        Cannot suppress exceptions.
        ContextDecorator.__call__.<locals>.innerAn abstract base class for context managers.suppress.__exit__ExitStack.enter_context_new_targetnew_exc_detailsfixed_ctxexcinstImmediately unwind the context stackexc_contextUtilities for with-statement contexts.  See PEP 343.suppress.__init__closing.__exit__Context to automatically close something at the end of a block.

    Code like this:

        with closing(<module>.open(<arguments>)) as f:
            <block>

    is equivalent to this:

        f = <module>.open(<arguments>)
        try:
            <block>
        finally:
            f.close()

    contextmanager.<locals>.helperclosing.__enter___cb_typeHelper for @contextmanager decorator.@contextmanager decorator.

    Typical usage:

        @contextmanager
        def some_generator(<arguments>):
            <setup>
            try:
                yield <value>
            finally:
                <cleanup>

    This makes this:

        with some_generator(<arguments>) as <variable>:
            <body>

    equivalent to this:

        <setup>
        try:
            <variable> = <value>
            <body>
        finally:
            <cleanup>

    A base class or mixin that enables context managers to work as decorators.<module contextlib>ExitStack.__init__closing.__init___GeneratorContextManager._recreate_cmExitStack.closeContext manager for temporarily redirecting stdout to another file.

        # How to send help() to stderr
        with redirect_stdout(sys.stderr):
            help(dir)

        # How to write help() to a file
        with open('help.txt', 'w') as f:
            with redirect_stdout(f):
                help(pow)
    Keeps a reference to the object x in the memo.

    Because we remember objects by their id, we have
    to assure that possibly temporary objects are kept
    alive by referencing them.
    We store a reference at the id of the memo, which should
    normally not be used unless someone tries to deepcopy
    the memo itself...
    _keep_alive_copy_immutableun(shallow)copyable object of type %s_nilcopierlistiterdictiterreductor_copy_dispatchDeep copy operation on arbitrary Python objects.

    See the module's __doc__ string for more info.
    _deepcopy_method_reconstruct.<locals>.<genexpr>C:\msys64\mingw64\lib\python3.6\copy.py<module copy>_deepcopy_listun(deep)copyable object of type %s_deepcopy_atomicShallow copy operation on arbitrary Python objects.

    See the module's __doc__ string for more info.
    _deepcopy_tuple_deepcopy_dispatch_deepcopy_dictGeneric (shallow and deep) copying operations.

Interface summary:

        import copy

        x = copy.copy(y)        # make a shallow copy of y
        x = copy.deepcopy(y)    # make a deep copy of y

For module specific errors, copy.Error is raised.

The difference between shallow and deep copying is only relevant for
compound objects (objects that contain other objects, like lists or
class instances).

- A shallow copy constructs a new compound object and then (to the
  extent possible) inserts *the same objects* into it that the
  original contains.

- A deep copy constructs a new compound object and then, recursively,
  inserts *copies* into it of the objects found in the original.

Two problems often exist with deep copy operations that don't exist
with shallow copy operations:

 a) recursive objects (compound objects that, directly or indirectly,
    contain a reference to themselves) may cause a recursive loop

 b) because deep copy copies *everything* it may copy too much, e.g.
    administrative data structures that should be shared even between
    copies

Python's deep copy operation avoids these problems by:

 a) keeping a table of objects already copied during the current
    copying pass

 b) letting user-defined classes override the copying operation or the
    set of components copied

This version does not copy types like module, class, function, method,
nor stack trace, stack frame, nor file, socket, window, nor array, nor
any similar types.

Classes can use the same interfaces to control copying that they use
to control pickling: they can define methods called __getinitargs__(),
__getstate__() and __setstate__().  See the documentation for module
"pickle" for information on these methods.
add_extensionremove_extension_HEAPTYPEob_typeclear_extension_cachekey %s is already registered with code %scode %s is already in use for key %sReturn a list of slot names for a given class.

    This needs to find slots defined by the class and its bases, so we
    can't simply return the __slots__ attribute.  We must walk down
    the Method Resolution Order and concatenate the __slots__ of each
    class found there.  (This assumes classes don't modify their
    __slots__ attribute to misrepresent their slots after the class is
    defined.)
    Unregister an extension code.  For testing only._reconstructor<module copyreg>a class that defines __slots__ without defining __getstate__ cannot be pickledconstructors must be callable_reduce_ex__slotnames__Used by pickle protocol 4, instead of __newobj__ to allow classes with
    keyword-only arguments to be pickled correctly.
    key %s is not registered with code %spickle_complexpickle_functionconstructor_obRegister an extension code.C:\msys64\mingw64\lib\python3.6\copyreg.pycan't pickle %s objectscode out of rangereduction functions must be callableHelper to provide extensibility for pickle.

This is only useful to add pickle support for extension types defined in
C, not for instances of user-defined classes.
detailed_comparison_labelpre_performanceailment_labelobjective_performance<span font='16'><span foreground='black' background='white' font_weight='bold'>â</span> {up}% not palpated
<span foreground='gray'>â</span> {slightly_down}% lightly palpated
<span foreground='blue' font_weight='bold'>â</span> {down}% deeply palpated
<span foreground='red' font_weight='bold'>â</span> {too_hard}% too hard</span>ComparativeLocationCoverageAnalysisView.fill_ailment_labelsC:\msys64\home\cbper\coverageassessment.pyno_x.pngpost_location_analysispre_location_analysis<span font='16'>Welcome!

AbSim will train you on abdominal palpation, a key skill to assess patients complaining of abdominal pain.

<span weight='bold'>When you are ready, perform an abdominal exam.</span>

Click the button when you're done.</span>vlinenew_learner_button_alignmentNormal Urinary Bladderget_current_pageyes_check.png<span font='16'>Location Analysis</span>objectivesAppendix RegionLeft Ovary RegionDeep palpationColon RegionGallbladder Regionailment_toucheddepth_reachedCoveragePostAssessment.reveal_coverage<span font='16'>Proceed to Abnormality Detection</span>finished_button_labeltab_labelleft_attachyes_check_pixbufCoveragePreAssessment.show_layoutCoverageLabelpost_assessment_coverage_view_resourcestotal_touched<span font='12'>Detailed Comparison</span>down_or_deeperCoverageLabel.__init__<span font='16'>You may now proceed to Milestone 1.</span>no_x_pixbufupdate_coverage_graphicPalpation too deepLocationCoverageAnalysisView.__init__pre_vboxCoveragePreAssessment.update_coverage_graphicLiver Regionlocation_objectives_emptyobjective_namesobjective_label.0fAssess the student's ability to do coverageright_attachstate_percentsLight
palpationCoveragePreAssessment.reveal_button_pressedCoveragePostAssessment.__init__CoveragePreAssessment.reset_pagepre_labelpost_performancefill_objective_labelsCoveragePostAssessment.reveal_button_pressedLocationCoverageAnalysisView.fill_objective_labels<span font='12'>Reveal completed exam</span>location_analysis_labelanalysis_hboxCoveragePostAssessment.reveal_comparative_tablepre_post_hboxDeep
palpationSplenic Region<span font='16' font_weight='bold'>Post-Assessment Coverage</span>Light palpationpost_vboxVSeparatorCoveragePreAssessment.build_layout<span font='16'>Reveal completed exam</span>Palpation
too deepLocationCoverageAnalyzer.depth_reachedPancreatic Regionpost_analysis_label      b@LocationCoverageAnalyzer.too_hardlocation_state_countstop_attachDistended Urinary Bladder      Y@LocationCoverageAnalyzer.ailment_touchedComparativeLocationCoverageAnalysisView.show_objective_performance<module coverageassessment>pre_analysis_labelCoveragePreAssessment.calculate_location_coverageGastric/Epigastric Regioncoverage_vis_labelCoveragePreAssessment.__init__CoveragePostAssessment.reset_pageRight Ovary Regionpost_location_analysis_tablepost_assessment_coverage_frameLocationCoverageAnalyzer.analyzeComparativeLocationCoverageAnalysisView.__init__none show_allCoveragePreAssessment.reveal_coverageCoverageAnalyzer.fill_label_with_analysis<span font='16'>Now it's time to compare your pre-assessment to your skill after training.

<span weight='bold'>When you are ready, perform an abdominal exam.</span>

Click the button when you're done.</span>LocationCoverageAnalyzer.__init__imageslocation_state_counts_emptyComparativeLocationCoverageAnalysisView.fill_objective_labels<span font='16' font_weight='bold'>Pre-Assessment Coverage</span>CoveragePostAssessment.new_learner_button_pressednew_learner_label<span font='16'>Coverage Visualization</span>bottom_attachfinished_button_alignmentCoverageTrainer.reset_pagecoverage_trainer_view<span font='16'>Now that you can palpate to proper depth, practice covering the entire abdomen.

It's better to make several passes instead of covering each centimeter in one pass.

Make several trips around the abdomen to get full coverage.

Especially ensure you check the marked locations, where abdominal abnormalities are most likely to occur.</span>none n show_allC:\msys64\home\cbper\coveragetrainer.pyCoverageTrainer.__init__max_view_frame<module coveragetrainer>LibraryLoaderuse_errnouse_last_error_FuncPtrc_wchar_p.__repr___func_flags_buftypeC:\msys64\mingw64\lib\python3.6\ctypesdlltypecoredllc_char_p.__repr__create_string_buffer(aBytes) -> character array
    create_string_buffer(anInteger) -> character array
    create_string_buffer(aBytes, anInteger) -> character array
    get_errnoFUNCFLAG_USE_ERRNOCFuncPtrc_longdoublestring_at(addr[, size]) -> string

    Return the string at addr._pointer_type_cache_check_HRESULT_win_functype_cacheget_last_error_string_at_addrWinFunctionTypeRTLD_LOCALc_uint32dlopenwstring_atpython dlllibpython%d.%d.dllFUNCFLAG_STDCALLDEFAULT_MODE_Pointersizeof(%s) wrong: %d instead of %d_reset_cache.<locals>.<lambda>What's this???Version number mismatch_FUNCFLAG_USE_ERRNOThis class represents a dll exporting functions using the
        Windows stdcall calling convention.
        <module ctypes>PyDLLdllhandle_dlltypeWINFUNCTYPE.<locals>.WinFunctionTypename_or_ordinalRTLD_GLOBAL_memmove_addrCFunctionType_restype_LibraryLoader.LoadLibraryriidresize%s(<NULL>)set_last_error_calcsizerclsidppvccomcreate and manipulate C data types in Pythoncomtypes.server.inprocserver_memset_addr_cast_addrCDLL.__getattr__libpython%d.%d%s.dllLibraryLoader.__init__CFUNCTYPEDllCanUnloadNow_dlopen_check_sizec_uint16OleDLL_FUNCFLAG_STDCALLc_boolc_uint8This type already exists in the cache_c_functype_cache_check_retval_<%s '%s', handle %x at %#x>c_voidp_FUNCFLAG_PYTHONAPISetPointerTypeCDLL.__getitem___argtypes_CDLL.__init__DllGetClassObjectc_int8c_uint64c_ssize_t_FUNCFLAG_CDECLLibraryLoader.__getitem__FUNCFLAG_USE_LASTERROR_func_restype_1.1.0_CFuncPtrc_int32from_paramPYFUNCTYPECFUNCTYPE.<locals>.CFunctionType_ctypes_versionoledllunexpected keyword argument(s) %sc_bufferCDLL.__repr__CDLL.__init__.<locals>._FuncPtrwstring_at(addr[, size]) -> string

        Return the string at addr.CFUNCTYPE(restype, *argtypes,
                 use_errno=False, use_last_error=False) -> function prototype.

    restype: the result type
    argtypes: a sequence specifying the argument types

    The function prototype can be called in different ways to create a
    callable object:

    prototype(integer address) -> foreign function
    prototype(callable) -> create and return a C callable function from callable
    prototype(integer index, method name[, paramflags]) -> foreign function calling a COM method
    prototype((ordinal number, dll object)[, paramflags]) -> foreign function exported by ordinal
    prototype((function name, dll object)[, paramflags]) -> foreign function exported by name
    This class represents the Python library itself.  It allows
    accessing Python API functions.  The GIL is not released, and
    Python exceptions are handled correctly.
    C:\msys64\mingw64\lib\python3.6\ctypes\__init__.pyPYFUNCTYPE.<locals>.CFunctionTypepydll_wstring_atpy_object.__repr__This class represents a dll exporting functions using the
        Windows stdcall calling convention, and returning HRESULT.
        HRESULT error values are automatically raised as OSError
        exceptions.
        <uninitialized>An instance of this class represents a loaded dll/shared
    library, exporting functions using the standard C calling
    convention (named 'cdecl' on Windows).

    The exported functions can be accessed as attributes, or by
    indexing with the function name.  Examples:

    <obj>.qsort -> callable object
    <obj>['qsort'] -> callable object

    Calling the functions releases the Python GIL during the call and
    reacquires it afterwards.
    c_int16create_unicode_buffer(aString) -> character array
    create_unicode_buffer(anInteger) -> character array
    create_unicode_buffer(aString, anInteger) -> character array
    _wstring_at_addrLibraryLoader.__getattr__set_errnoReturn the type with the 'other' byte order.  Simple types like
    c_int and so on already have __ctype_be__ and __ctype_le__
    attributes which contain the types, for more complicated types
    arrays and structures are supported.
    C:\msys64\mingw64\lib\python3.6\ctypes\_endian.py_array_type_OTHER_ENDIANStructure with big endian byte order_swappedbytes_Structure with little endian byte order<module ctypes._endian>_other_endian_swapped_meta_swapped_meta.__setattr__Invalid byteorderThis type does not support other endian: %sC:\msys64\mingw64\lib\python3.6\ctypes\macholibC:\msys64\mingw64\lib\python3.6\ctypes\macholib\__init__.py
Enough Mach-O to make your head spin.

See the relevant header files in /usr/include/mach-o

And also Apple's documentation.
ctypes.macholibdyld_override_search~/Library/Frameworksdyld_library_pathDYLD_IMAGE_SUFFIX
    Find a library or framework using dyld semantics
    /usr/local/libexecutable_path/usr/libDYLD_FALLBACK_FRAMEWORK_PATHdyld_framework_path.framework~/libtest_dyld_find<module ctypes.macholib.dyld>framework_find
dyld emulation
fallback_library_pathdyld_image_suffix_searchdylib %s could not be founddyld_fallback_framework_path_injectC:\msys64\mingw64\lib\python3.6\ctypes\macholib\dyld.pyDEFAULT_LIBRARY_FALLBACK.dylibdyld_fallback_library_path/System/Library/FrameworksFor a potential path iterator, add DYLD_IMAGE_SUFFIX semanticsDYLD_FRAMEWORK_PATHdyld_image_suffix_search.<locals>._injectdyld_envDYLD_LIBRARY_PATHDYLD_FALLBACK_LIBRARY_PATHdyld_default_search/usr/lib/libSystem.dylibfmwk_indexDEFAULT_FRAMEWORK_FALLBACKdyld_executable_path_search/Network/Library/Frameworks/System/Library/Frameworks/System.framework/System
    Find a framework using dyld semantics in a very loose manner.

    Will take input such as:
        Python
        Python.framework
        Python.framework/Versions/Current
    P/Foo.A.dylib
    A dylib name can take one of the following four forms:
        Location/Name.SomeVersion_Suffix.dylib
        Location/Name.SomeVersion.dylib
        Location/Name_Suffix.dylib
        Location/Name.dylib

    returns None if not found or a mapping equivalent to:
        dict(
            location='Location',
            name='Name.SomeVersion_Suffix.dylib',
            shortname='Name',
            version='SomeVersion',
            suffix='Suffix',
        )

    Note that SomeVersion and Suffix are optional and may be None
    if not present.
    Foo.dylib(?x)
(?P<location>^.*)(?:^|/)
(?P<name>
    (?P<shortname>\w+?)
    (?:\.(?P<version>[^._]+))?
    (?:_(?P<suffix>[^._]+))?
    \.dylib$
)
P/Foo.A_debug.dylibcompletely/invalide_debugFoo_debug.A.dylibDYLIB_REis_dylibP/Foo.dylibtest_dylib_info.<locals>.dP/Foo_debug.A.dylib
Generic dylib path manipulation
P/Foo_debug.dylibC:\msys64\mingw64\lib\python3.6\ctypes\macholib\dylib.py<module ctypes.macholib.dylib>test_framework_infoF.framework/Versions/A/FF.framework/Versions/A/F_debugP/F.framework/Versions/AF.framework/F
    A framework name can take one of the following four forms:
        Location/Name.framework/Versions/SomeVersion/Name_Suffix
        Location/Name.framework/Versions/SomeVersion/Name
        Location/Name.framework/Name_Suffix
        Location/Name.framework/Name

    returns None if not found, or a mapping equivalent to:
        dict(
            location='Location',
            name='Name.framework/Versions/SomeVersion/Name_Suffix',
            shortname='Name',
            version='SomeVersion',
            suffix='Suffix',
        )

    Note that SomeVersion and Suffix are optional and may be None
    if not present
    test_framework_info.<locals>.dP/F.framework/_debugP/F.framework/F(?x)
(?P<location>^.*)(?:^|/)
(?P<name>
    (?P<shortname>\w+).framework/
    (?:Versions/(?P<version>[^/]+)/)?
    (?P=shortname)
    (?:_(?P<suffix>[^_]+))?
)$
completely/invalid/_debugSTRICT_FRAMEWORK_REP/F.framework/Versions/A/FP/F.framework/Versions/A/F_debug<module ctypes.macholib.framework>is_framework
Generic framework path manipulation
F.framework/F_debugC:\msys64\mingw64\lib\python3.6\ctypes\macholib\framework.pyP/F.framework/F_debug_get_build_versionlibc6,x86-64cryptlibfilex86_64-64ppc64-64libc6,64bitsparc64-64s390x-64ia64-64libc6,IA-64majorVersionminorVersionmach_mapabi_typeDefault Library Path (ELF):libpath/usr/bin/crle/usr/ccs/bin/dumplibcrypto.dyliblibcrypt.so.dynamiclibm.sois64libm.dylib_findLib_gccfind_msvcrtobjdump\s+(lib%s\.[^\s]+)\s+\(%slib%s.dylib_get_soname      $@_num_versionnumssunos5msvcr%dlibnamedragonfly\sSONAME\s+([^\s]+)[^\(\)\s]*lib%s\.[^\(\)\s]*:-l%s\.\S+ => \S*/(lib%s\.\S+)C:\msys64\mingw64\lib\python3.6\ctypes\util.pyReturn the name of the VC runtime dll_findLib_crle_findSoname_ldconfig-Wl,-t_findLib_ld<module ctypes.util>clibname\[.*\]\sSONAME\s+([^\s]+)%s.framework/%slib%s.soMSC v.Return the version of MSVC that was used to build Python.

        For Python 2.3 and up, the version number is included in
        sys.version.  For earlier versions, assume the compiler is MSVC 6.
        -LpvATOMPBOOLPBYTEHICONPUSHORTLCTYPELPBOOLULONGPULARGE_INTEGERLPFILETIME<module ctypes.wintypes>_ULARGE_INTEGER_LARGE_INTEGER_RECTLHRGNLANGIDWPARAMHDCC:\msys64\mingw64\lib\python3.6\ctypes\wintypes.pyHPALETTEHFONTHTASKTopRGBHDESKhWndcxWIN32_FIND_DATAWLPRECTLPHANDLEHINSTANCEtagMSGBottomtagSIZECOLORREFcFileNamecAlternateFileNamePOINTLnFileSizeHighPFLOATHCOLORSPACEPUINTHKLHLOCALHGLOBALPSHORTLPARAMLPPOINTPWCHARWIN32_FIND_DATAAdwHighDateTimedwLowDateTimeLPSC_HANDLEPWIN32_FIND_DATAAHMODULELPSIZELLPHKL_POINTLLPWORDHMENULPSTRftLastAccessTimeOLESTRVARIANT_BOOL.__repr__SERVICE_STATUS_HANDLEPLONGLPMSGwParamdwReserved0HDWPLPINTHWINSTAHBRUSHLPCOLORREFHKEYPLARGE_INTEGERHSTRLPWIN32_FIND_DATAWnFileSizeLow_SMALL_RECTdwFileAttributesHMONITORLPLONGHPENHMETAFILE_FILETIMELCIDPDWORDtagPOINTHRSRCPHKEYLPWIN32_FIND_DATAAHGDIOBJPULONGPSMALL_RECTLPUINTlParamLPCOLESTRHBITMAPHACCEL_COORDftCreationTimePLCIDLGRPIDHHOOKHWNDtagRECTPBOOLEANHENHMETAFILEPPOINTLLPOLESTRftLastWriteTimedwReserved1PCHARdatetime.tzinfofromutc() requires a non-None utcoffset() result_check_date_fieldsmillisecondsdatetime.astimezonedatetime.__hash__firstdayConvert to formal string, for repr().

        >>> dt = datetime(2010, 1, 1)
        >>> repr(dt)
        'datetime.datetime(2010, 1, 1, 0, 0)'

        >>> dt = datetime(2010, 1, 1, tzinfo=timezone.utc)
        >>> repr(dt)
        'datetime.datetime(2010, 1, 1, 0, 0, tzinfo=datetime.timezone.utc)'
        timezone.__hash__time.__le__hour (0-23)Construct a datetime from a POSIX timestamp (like time.time()).

        A timezone info object may be passed in as well.
        datetime.folddatetime.tzname%06dtimedelta.__pos__fromutc() argument must be a datetime instance or None{:02d}_microsecondHash._DI4Ydatetime.strptimetzinfo.%s() must return a whole number of seconds, got %s_Omittedtime.replacedate.isoformat_format_timezreplacemicrosecond must be in 0..999999_datetime__setstatedate.__gt__whole minutetimezone.utcoffset_check_int_fieldtimedelta.__floordiv__timezone.__eq__timedelta.__divmod__Return a new time with new values for the specified fields.daysecondsfractimespectimedelta.__gt__datetime.utcnowAdd a date to a timedelta.mytzmyoffsetdnumoffset must be a timedelta_secondReturn 0 if DST is not in effect, or the DST offset (in minutes
        eastward) if DST is in effect.

        This is purely informational; the DST offset has already been added to
        the UTC offset returned by utcoffset() if applicable, so there's no
        need to consult dst() unless you're interested in displaying the DST
        info.
        timezone.__new__Construct a datetime from a given date and a given time.__int__ returned non-int (type %s)time argument must be a time instance_seconds_microseconds_hashcodetimedelta.__le__Return proleptic Gregorian ordinal for the year, month and day.

        January 1 of year 1 is day 1.  Only the year, month and day values
        contribute to the result.
        base_comparetimezone.dst_time__setstate%s.%s(%d, %d%s)newformatinteger argument expected, got float_mktimetime.__gt__tzinfo.tznameFormat using strftime().  The date part of the timestamp passed
        to underlying strftime should not be used.
        cannot mix naive and timezone-aware timeyhius2us3us1basestatedate._cmpdays1secs1secs2otofftimezone.__str__hour must be in 0..23date.monthtzinfo.dsttime.minuteReturn the timezone offset in minutes east of UTC (negative west of
        UTC).tzinfo.__reduce__othhmm%c%02d%02ddatetime.secondReturn integer POSIX timestamp.datetime.__sub__C:\msys64\mingw64\lib\python3.6\datetime.pydatetime.utcfromtimestampepochgreater_than_halfdatetime.timetz_ord2ymd    °¦GA_to_microsecondsdatetime -> minutes east of UTC (negative for west of UTC){:02d}:{:02d}:{:02d}.{:03d}_tzstrdate.__reduce__allow_mixedottzmyhhmmtime.dstReturn the time part, with same tzinfo.datetime.__ge__datetime.__lt__year (1-9999)isocalendarReturn the timezone name.

        Note that the name is 100% informational -- there's no requirement that
        it mean anything in particular. For example, "GMT", "UTC", "-500",
        "-5:00", "EDT", "US/Eastern", "America/New York" are all valid replies.
        :%02ddatetime._mktime.<locals>.local_DI400Ydatetime.replacen1_check_time_fieldsConstruct a naive UTC datetime from a POSIX timestamp.divide a by b and round result to the nearest integer

    When the ratio is exactly half-way between two integers,
    the even integer is returned.
    must be str, not %s%04d-%02d-%02dtimedelta.__repr__%s.%s(%d, %d, %d)    @Adstflagwdaycombinebad tzinfo state arg_maxoffsetsecond (0-59).%06d_fromtimestampdate.todaydate argument must be a date instance%s.%s(%r)date.fromtimestamptimedelta.__eq__Zreplace%04d-%02d-%02d%cdate.isoweekdaytimedelta.__ge__timedelta.__truediv__tzinfo.%s() must return None or timedelta, not '%s', tzinfo=%rdayfracdaysecondswholeusdoublefromutc() requires a non-None dst() resultfromutc(): dt.dst gave inconsistent results; cannot converttime._getstate_tzinfo_classConcrete date/time and related types.

See http://www.iana.org/time-zones/repository/tz-link.html for
time zone and DST data sources.
max_fold_secondsConstruct a date from time.time().date.__sub__Return POSIX timestamp as float_days_in_monthdatetime.dsttimedelta.__str__datetime.__gt__datetime.__add__datetime.__str__microsecond (0-999999)datetime.__repr___check_utc_offset_time_classReturn the time formatted according to ISO.

        The full format looks like 'YYYY-MM-DD HH:MM:SS.mmmmmm'.
        By default, the fractional part is omitted if self.microsecond == 0.

        If self.tzinfo is not None, the UTC offset is also attached, giving
        giving a full format of 'YYYY-MM-DD HH:MM:SS.mmmmmm+HH:MM'.

        Optional argument sep specifies the separator between date and
        time, default 'T'.

        The optional argument timespec specifies the number of additional
        terms of the time to include.
        timedelta._cmptimezone._createtzinfo subclass must override utcoffset()timedelta.__mul__dst() argument must be a datetime instance or Nonetzinfo.fromutcReturn a new datetime with new values for the specified fields.Return the time formatted according to ISO.

        The full format is 'HH:MM:SS.mmmmmm+zz:zz'. By default, the fractional
        part is omitted if self.microsecond == 0.

        The optional argument timespec specifies the number of additional
        terms of the time to include.
        _date__setstatetimedelta.daystzinfo argument must be None or of a tzinfo subclassoffset must be a timedelta strictly between -timedelta(hours=24) and timedelta(hours=24).datetime.__eq__date.strftimetimezone.fromutc_cmperrortime.__new__date.daydate.__add___days_before_monthtimedelta.__new___MAXORDINALdate.toordinaldate.ctimedate.__setstatetimedelta.__lt__astimezone() requires an aware datetimecannot compare naive and aware datetimes_isoweek1monday<module datetime>time._cmp%s%02d:%02ddatetime.__setstatestring, format -> new datetime parsed from a string (like time.strptime()).n400time.utcoffset%d day%s, timezone.tznametimedelta.__neg__datetime -> string name of time zone.cannot compare naive and aware timesfromutc: dt.tzinfo is not selfdtdst%d:%02d:%02dTotal seconds in the duration.datetime._cmpordinal -> (year, month, day), considering 01-Jan-0001 as day 1.utctimetuple_date_classMINYEARReturn local time tuple compatible with time.localtime().Return the date formatted according to ISO.

        This is 'YYYY-MM-DD'.

        References:
        - http://www.w3.org/TR/NOTE-datetime
        - http://www.cl.cam.ac.uk/~mgk25/iso-time.html
        date.replacedatetime._local_timezoneReturn the date part.date.timetupletimedelta._getstateRepresent the difference between two datetime objects.

    Supported operators:

    - add, subtract timedelta
    - unary plus, minus, abs
    - compare to timedelta
    - multiply, divide by int

    In addition, datetime supports subtraction of two datetime objects
    returning a timedelta, and addition or subtraction of a datetime
    and a timedelta giving a datetime.

    Representation: (days, seconds, microseconds).  Why?  Because I
    felt like it.
    time.__format__datetime.now{:02d}:{:02d}:{:02d}.{:06d}Return a new date with new values for the specified fields.year must be in %d..%ddate.__eq__%s%02d%s%02d_minutedate.__new___name_from_offset_check_tznameday must be in 1..%dfromutc() requires a datetime argument_minoffsettzinfo.tzname() must return None or string, not '%s'jdayyear, month -> number of days in that month in that year.datetime -> DST offset in minutes east of UTC.

        Return 0 if DST not in effect.  utcoffset() must include the DST
        offset.
        tzinfo subclass must override dst()year, month -> number of days in year preceding first day of month.UTC{}{:02d}:{:02d}year -> number of days before January 1st of year.Return a 3-tuple containing ISO year, week number, and weekday.

        The first ISO week of the year is the (Mon-Sun) week
        containing the year's first Thursday; everything else derives
        from that.

        The first week is 1; Monday is 1 ... Sunday is 7.

        ISO calendar algorithm taken from
        http://www.phys.uu.nl/~vgent/calendar/isocalendar.htm
        (used with permission)
        Add a datetime and a timedelta.time.hourtz argument must be an instance of tzinfo_DAYNAMESleapyeartime.strftime%s()=%s, must be strictly between -timedelta(hours=24) and timedelta(hours=24)Return day of the week, where Monday == 1 ... Sunday == 7._divide_and_round_DAYS_IN_MONTH_is_leapminute must be in 0..59datetime._fromtimestampReturn the time part, with tzinfo None.an integer is required (got type %s)©ÚclsÚtÚutcÚtzÚfracÚusÚ	converterÚyÚmÚdÚhhÚmmÚssÚweekdayÚjdayÚdstÚresultÚmax_fold_secondsÚprobe1ÚtransÚprobe2tzinfo.utcoffset_wrap_strftimeReturn day of the week, where Monday == 0 ... Sunday == 6.Subtract two datetimes, or a datetime and a timedelta.%s %s %2d %02d:%02d:%02d %04ddate.__hash__month must be in 1..12date.__ge__offset must be a timedelta representing a whole number of minutesdatetime.microsecond_DI100YConvert to formal string, for repr().

        >>> tz = timezone.utc
        >>> repr(tz)
        'datetime.timezone.utc'
        >>> tz = timezone(timedelta(hours=-5), 'EST')
        >>> repr(tz)
        "datetime.timezone(datetime.timedelta(-1, 68400), 'EST')"
        _build_struct_time%s %s %2d 00:00:00 %04ddatetime.isoformatdatetime(year, month, day[, hour[, minute[, second[, microsecond[,tzinfo]]]]])

    The year, month and day arguments are required. tzinfo may be None, or an
    instance of a tzinfo subclass. The remaining arguments may be ints.
    modfdatetime.__new__Constructor.

        Arguments:

        hour, minute (required)
        second, microsecond (default to zero)
        tzinfo (default to None)
        fold (keyword only, default to zero)
        tzname() argument must be a datetime instance or Nonedatetime.hourdatetime._getstatedate.isocalendardate._getstatetimedelta.__str__.<locals>.pluraldatetime.combinesecond must be in 0..59time.__reduce__timedelta.total_secondsdatetime.minutedate.fromordinalyear -> 1 if leap year, else 0.Unknown timespec valuedatetime.fromtimestampConstructor.

        Arguments:

        year, month, day (required, base 1)
        timedelta.microsecondstimezone.__repr___ymd2orddatetime.__reduce_ex__timedelta.__sub__Concrete date type.

    Constructors:

    __new__()
    fromtimestamp()
    today()
    fromordinal()

    Operators:

    __repr__, __str__
    __eq__, __le__, __lt__, __ge__, __gt__, __hash__
    __add__, __radd__, __sub__ (add/radd only with timedelta arg)

    Methods:

    timetuple()
    toordinal()
    weekday()
    isoweekday(), isocalendar(), isoformat()
    ctime()
    strftime()

    Properties (readonly):
    year, month, day
    datetime.utctimetupletimedelta # of days is too large: %ddate_string_check_tzinfo_argdate.weekdayConstruct a datetime from time.time() and optional time zone info.dtoff, fold=1)timezone.__getinitargs__timedelta.__rsub__%s.%s(%r, %r)_DAYS_BEFORE_MONTHtimedelta.__add__time._tzstrutcoffset() argument must be a datetime instance or NoneTime with time zone.

    Constructors:

    __new__()

    Operators:

    __repr__, __str__
    __eq__, __le__, __lt__, __ge__, __gt__, __hash__

    Methods:

    strftime()
    isoformat()
    utcoffset()
    tzname()
    dst()

    Properties (readonly):
    hour, minute, second, microsecond, tzinfo, fold
    Subtract two dates, or a date and a timedelta.datetime.timetupleresult out of rangeConstruct a date from a proleptic Gregorian ordinal.

        January 1 of year 1 is day 1.  Only the year, month and day are
        non-zero in the result.
        Construct a UTC datetime from time.time().Convert to string, for str().date.__le__Return UTC time tuple compatible with time.gmtime().timedelta._to_microsecondsdatetime.utcoffset%s.%s(%d, %d)Return formatted timezone offset (+xx:xx) or None.Construct a date from a POSIX timestamp (like time.time()).can't compare '%s' to '%s'Abstract base class for time zone info classes.

    Subclasses must override the name(), utcoffset() and dst() methods.
    date.__repr__fold must be either 0 or 1timedelta.__abs__%s.%s(%d)n100timedelta.secondstzinfo subclass must override tzname()timedelta.__hash__minute (0-59)datetime.ctimedatetime.__reduce__timedelta.__bool__datetime.timestampdatetime in UTC -> datetime in local time.year, month, day -> ordinal, considering 01-Jan-0001 as day 1.date.__format__timedelta.__mod__Return ctime() style string._MONTHNAMEStimedelta.__reduce___days_before_year     õ@datetime.__le__date.yeartimezone._name_from_offsetdate.__lt__next_migration_functionsDBMigrator.migrate_to_1PRAGMA user_version = 1;. Updating.C:\msys64\home\cbper\dbmigrator.pynewest_versionPRAGMA user_version;
            CREATE TABLE coverage_assessments
            (
                exam_id INTEGER PRIMARY KEY AUTOINCREMENT,
                student_id TEXT,
                time_in TEXT,
                coverage BLOB
            )
        DBMigrator.get_versionCould not migrate assessment.db to version  is up to date.migrate_to_newest<module dbmigrator>assessment.db is version DBMigrator.migrate_to_newest
Migrates database versions to the newest versions, or creates the db if none exists.
DBMigrator.__init__get_vadjustmentDDXPractice.__init__DDXPractice.build_answer_boxwidth-requestprototype_scrollerset_layoutexpander8WRAP_WORDexpander6button-press-event<span font='20' fgcolor='#000000'><b>Best diagnosis
below</b></span>ddx_answer_box<span font='14'><span font='20' fgcolor='#1E9D1C'><b>You chose the
best diagnosis</b></span>C:\msys64\home\cbper\ddxpractice.pyexpander3expander7press_eventlist_of_expandersexpander2BUTTONBOX_STARTget_objectDDXPractice.build_interfacecase_text_scroller_vadjustmentVButtonBoxypadexpander1DDXPractice.on_next_case_buttonDDXPractice.build_case_text_viewDDXPractice.build_prototype_text_viewDDXPractice.reset_pageset_spacingexpander5DDXPractice.new_selected_caseexp_objectexpander9DDXPractice.ddx_chosencurrent_case_blockexpander10DDXPractice.build_glade_filesDDXPractice.show_feedbackprototype_scroller_vadjustmentexpander4<module ddxpractice><module decimal>C:\msys64\mingw64\lib\python3.6\decimal.pyDepthTrainer.reset_pageDepthTrainer.__init__C:\msys64\home\cbper\depthtrainer.py<span font='16'>In this milestone, practice palpating to the correct depth.

<span foreground='gray' font_weight='bold'>â</span> Gray circles indicate <span foreground='gray' font_weight='bold'>light palpation</span>, appropriate for beginning an abdominal exam, but insufficient to detect significant abdominal disorders.

<span foreground='blue' font_weight='bold'>â</span> Blue circles indicate <span foreground='blue' font_weight='bold'>deep palpation</span>, good for detecting serious disorders of the abdomen. 

<span foreground='red' font_weight='bold'>â</span> Red circles indicate <span foreground='red' font_weight='bold'>too deep</span>, causing unnecessary pain, even in a patient with no abnormalities. This can result in voluntary guarding for the rest of the exam, leading to confusing findings.

Instructors may adjust pressure sensitivity in the <span font_weight='bold'>Settings > Pressure Sensitivity</span> menu.</span><module depthtrainer>depth_trainer_viewHtmlDiff._line_wrapperIS_LINE_JUNKfromline<td class="diff_header"%s>%s</td><td nowrap="nowrap">%s</td>
Module difflib -- helpers for computing deltas between objects.

Function get_close_matches(word, possibilities, n=3, cutoff=0.6):
    Use SequenceMatcher to return list of the best "good enough" matches.

Function context_diff(a, b):
    For two lists of strings, return a delta in context diff format.

Function ndiff(a, b):
    Return a delta: the difference between `a` and `b` (lists of strings).

Function restore(delta, which):
    Return one of the two sequences that generated an ndiff delta.

Function unified_diff(a, b):
    For two lists of strings, return a delta in unified diff format.

Class SequenceMatcher:
    A flexible class for comparing pairs of sequences of any type.

Class Differ:
    For producing human-readable deltas from sequences of lines of text.

Class HtmlDiff:
    For producing HTML side by side comparison with change highlights.
next_idnewj2lenConstruct a SequenceMatcher.

        Optional arg isjunk is None (the default), or a one-argument
        function that takes a sequence element and returns true iff the
        element is junk.  None is equivalent to passing "lambda x: 0", i.e.
        no elements are considered to be junk.  For example, pass
            lambda x: x in " \t"
        if you're comparing lines as sequences of characters, and don't
        want to synch up on blanks or hard tabs.

        Optional arg a is the first of two sequences to be compared.  By
        default, an empty string.  The elements of a must be hashable.  See
        also .set_seqs() and .set_seq1().

        Optional arg b is the second of two sequences to be compared.  By
        default, an empty string.  The elements of b must be hashable. See
        also .set_seqs() and .set_seq2().

        Optional arg autojunk should be set to False to disable the
        "automatic junk heuristic" that treats popular elements as junk
        (see module documentation for more information).
        _charjunk©ÚaÚbÚfromfileÚtofileÚfromfiledateÚ
tofiledateÚnÚlinetermÚprefixÚstartedÚgroupÚfromdateÚtodateÚfirstÚlastÚfile1_rangeÚtagÚi1Úi2Ú_ÚlineÚfile2_rangeÚj1Új2
    Compare `a` and `b` (lists of strings); return a `Differ`-style delta.

    Optional keyword parameters `linejunk` and `charjunk` are for filter
    functions, or can be None:

    - linejunk: A function that should accept a single string argument and
      return true iff the string is junk.  The default is None, and is
      recommended; the underlying SequenceMatcher class has an adaptive
      notion of "noise" lines.

    - charjunk: A function that accepts a character (string of length
      1), and returns true iff the character is junk. The default is
      the module-level function IS_CHARACTER_JUNK, which filters out
      whitespace characters (a blank or tab; note: it's a bad idea to
      include newline in this!).

    Tools/scripts/ndiff.py is a command-line front-end to this function.

    Example:

    >>> diff = ndiff('one\ntwo\nthree\n'.splitlines(keepends=True),
    ...              'ore\ntree\nemu\n'.splitlines(keepends=True))
    >>> print(''.join(diff), end="")
    - one
    ?  ^
    + ore
    ?  ^
    - two
    - three
    ?  -
    + tree
    + emu
    _tab_newline_replace_qformat_line_iterator
    Generate one of the two sequences that generated a delta.

    Given a `delta` produced by `Differ.compare()` or `ndiff()`, extract
    lines originating from file 1 or 2 (parameter `which`), stripping off line
    prefixes.

    Examples:

    >>> diff = ndiff('one\ntwo\nthree\n'.splitlines(keepends=True),
    ...              'ore\ntree\nemu\n'.splitlines(keepends=True))
    >>> diff = list(diff)
    >>> print(''.join(restore(diff, 1)), end="")
    one
    two
    three
    >>> print(''.join(restore(diff, 2)), end="")
    ore
    tree
    emu
    j2lenget_default_prefixdata_listfromlinestolinesfrom_lineto_linefound_difffromDiffto_diff@@ -{} +{} @@{}? %s%s
_mdiff.<locals>._make_line.<locals>.record_sub_info	{}
    Compare two sequences of lines; generate the delta as a context diff.

    Context diffs are a compact way of showing line changes and a few
    lines of context.  The number of context lines is set by 'n' which
    defaults to three.

    By default, the diff control lines (those with *** or ---) are
    created with a trailing newline.  This is helpful so that inputs
    created from file.readlines() result in diffs that are suitable for
    file.writelines() since both the inputs and outputs have trailing
    newlines.

    For inputs that do not have trailing newlines, set the lineterm
    argument to "" so that the output will be uniformly newline free.

    The context diff format normally has a header for filenames and
    modification times.  Any or all of these may be specified using
    strings for 'fromfile', 'tofile', 'fromfiledate', and 'tofiledate'.
    The modification times are normally expressed in the ISO 8601 format.
    If not specified, the strings default to blanks.

    Example:

    >>> print(''.join(context_diff('one\ntwo\nthree\nfour\n'.splitlines(True),
    ...       'zero\none\ntree\nfour\n'.splitlines(True), 'Original', 'Current')),
    ...       end="")
    *** Original
    --- Current
    ***************
    *** 1,4 ****
      one
    ! two
    ! three
      four
    --- 1,4 ----
    + zero
      one
    ! tree
      four
    _collect_lines<a href="#difflib_chg_%s_%d">n</a> -HtmlDiff instance initializer

        Arguments:
        tabsize -- tab stop spacing, defaults to 8.
        wrapcolumn -- column number where lines are broken and wrapped,
            defaults to None where lines are not wrapped.
        linejunk,charjunk -- keyword arguments passed into ndiff() (used by
            HtmlDiff() to generate the side by side HTML differences).  See
            ndiff() documentation for argument default values and descriptions.
        fromprefixto%d_<td></td><td>&nbsp;No Differences Found&nbsp;</td>_mdiff.<locals>._line_iteratorHtmlDiff._format_linechange_reSequenceMatcher.quick_ratiofromdatatodatafromtexttotextHtmlDiff._make_prefixReturns HTML markup of "from" / "to" text lines

        side -- 0 or 1 indicating "from" or "to" text
        flag -- indicates if difference on line
        linenum -- line number (used for line number column)
        text -- line text to be marked up
        bestsizeReturns HTML file of side by side comparison with change highlights

        Arguments:
        fromlines -- list of "from" lines
        tolines -- list of "to" lines
        fromdesc -- "from" file column header string
        todesc -- "to" file column header string
        context -- set to True for contextual differences (defaults to False
            which shows full differences).
        numlines -- number of context lines.  When context is set True,
            controls number of lines displayed before and after the change.
            When context is False, controls the number of lines to place
            the "next" link anchors before the next change (so click of
            "next" link jumps to just before the change).
        charset -- charset of the HTML document
        bestiYields from/to lines of text with a change indication.

        This function is an iterator.  It itself pulls lines from the line
        iterator.  Its difference from that iterator is that this function
        always yields a pair of from/to text lines (with the change
        indication).  If necessary it will collect single from/to lines
        until it has a matching pair from/to pair to yield.

        Note, this function is purposefully not defined at the module scope so
        that data it needs from its parent function (within whose context it
        is defined) does not need to be of module scope.
        unknown delta choice (must be 1 or 2): %rb2jahinum_chgSequenceMatcher.ratioflaglistReturn list of triples describing matching subsequences.

        Each triple is of the form (i, j, n), and means that
        a[i:i+n] == b[j:j+n].  The triples are monotonically increasing in
        i and in j.  New in Python 2.5, it's also guaranteed that if
        (i, j, n) and (i', j', n') are adjacent triples in the list, and
        the second is not the last triple in the list, then i+n != i' or
        j+n != j'.  IOW, adjacent triples never describe adjacent equal
        blocks.

        The last triple is a dummy, (len(a), len(b), 0), and is the only
        triple with n==0.

        >>> s = SequenceMatcher(None, "abxcd", "abcd")
        >>> list(s.get_matching_blocks())
        [Match(a=0, b=0, size=2), Match(a=3, b=2, size=2), Match(a=5, b=4, size=0)]
        find_longest_matchbhiisbjunkbestj(\++|\-+|\^+)context_linesHtmlDiff._tab_newline_replace.<locals>.expand_tabs id="%s%s"SequenceMatcher.real_quick_ratio<span class="diff_sub">Convert range to the "ed" formatdiff_lines_iteratorHtmlDiff._convert_flagsmake_tableatags*** {} ****{}Generate comparison results for a same-tagged range.header_rowSet the two sequences to be compared.

        >>> s = SequenceMatcher()
        >>> s.set_seqs("abcd", "bcde")
        >>> s.ratio()
        0.75
         ^<span class="diff_chg"> Isolate change clusters by eliminating ranges with no changes.

        Return a generator of groups with up to n lines of context.
        Each group is in the same format as returned by get_opcodes().

        >>> from pprint import pprint
        >>> a = list(map(str, range(1,40)))
        >>> b = a[:]
        >>> b[8:8] = ['i']     # Make an insertion
        >>> b[20] += 'x'       # Make a replacement
        >>> b[23:28] = []      # Make a deletion
        >>> b[30] += 'y'       # Make another replacement
        >>> pprint(list(SequenceMatcher(None,a,b).get_grouped_opcodes()))
        [[('equal', 5, 8, 5, 8), ('insert', 8, 8, 8, 9), ('equal', 8, 11, 9, 12)],
         [('equal', 16, 19, 17, 20),
          ('replace', 19, 20, 20, 21),
          ('equal', 20, 22, 21, 23),
          ('delete', 22, 27, 23, 23),
          ('equal', 27, 30, 23, 26)],
         [('equal', 31, 34, 27, 30),
          ('replace', 34, 35, 30, 31),
          ('equal', 35, 38, 31, 34)]]
        Return list of 5-tuples describing how to turn a into b.

        Each tuple is of the form (tag, i1, i2, j1, j2).  The first tuple
        has i1 == j1 == 0, and remaining tuples have i1 == the i2 from the
        tuple preceding it, and likewise for j1 == the previous j2.

        The tags are strings, with these meanings:

        'replace':  a[i1:i2] should be replaced by b[j1:j2]
        'delete':   a[i1:i2] should be deleted.
                    Note that j1==j2 in this case.
        'insert':   b[j1:j2] should be inserted at a[i1:i1].
                    Note that i1==i2 in this case.
        'equal':    a[i1:i2] == b[j1:j2]

        >>> a = "qabxcd"
        >>> b = "abycdf"
        >>> s = SequenceMatcher(None, a, b)
        >>> for tag, i1, i2, j1, j2 in s.get_opcodes():
        ...    print(("%7s a[%d:%d] (%s) b[%d:%d] (%s)" %
        ...           (tag, i1, i2, a[i1:i2], j1, j2, b[j1:j2])))
         delete a[0:1] (q) b[0:0] ()
          equal a[1:3] (ab) b[0:2] (ab)
        replace a[3:4] (x) b[2:3] (y)
          equal a[4:6] (cd) b[3:5] (cd)
         insert a[6:6] () b[5:6] (f)
        Differ.__init__lines to compare must be str, not %s (%r)SequenceMatcher.set_seq1--?+HtmlDiff.make_tableUse SequenceMatcher to return list of the best "good enough" matches.

    word is a sequence for which close matches are desired (typically a
    string).

    possibilities is a list of sequences against which to match word
    (typically a list of strings).

    Optional arg n (default 3) is the maximum number of close matches to
    return.  n must be > 0.

    Optional arg cutoff (default 0.6) is a float in [0, 1].  Possibilities
    that don't score at least that similar to word are ignored.

    The best (no more than n) matches among the possibilities are returned
    in a list, sorted by similarity score, most similar first.

    >>> get_close_matches("appel", ["ape", "apple", "peach", "puppy"])
    ['apple', 'ape']
    >>> import keyword as _keyword
    >>> get_close_matches("wheel", _keyword.kwlist)
    ['while']
    >>> get_close_matches("Apple", _keyword.kwlist)
    []
    >>> get_close_matches("accept", _keyword.kwlist)
    ['except']
    _wrapcolumn\s*(?:#\s*)?$<module difflib>
    <table class="diff" id="difflib_chg_%(prefix)s_top"
           cellspacing="0" cellpadding="0" rules="groups" >
        <colgroup></colgroup> <colgroup></colgroup> <colgroup></colgroup>
        <colgroup></colgroup> <colgroup></colgroup> <colgroup></colgroup>
        %(header_row)s
        <tbody>
%(data_rows)s        </tbody>
    </table>ntestidxs<th colspan="2" class="diff_header">%s</th>_legend©ÚselfÚlaÚlbÚqueueÚmatching_blocksÚaloÚahiÚbloÚbhiÚiÚjÚkÚxÚi1Új1Úk1Únon_adjacentÚi2Új2Úk2+++ {}{}{}fullbcountavailhas        </tbody>        
        <tbody>
_count_leading-?+?toprefix
    Return number of `ch` characters at the start of `line`.

    Example:

    >>> _count_leading('   abc', ' ')
    3
    _styles
        Format "?" output and deal with leading tabs.

        Example:

        >>> d = Differ()
        >>> results = d._qformat('\tabcDefghiJkl\n', '\tabcdefGhijkl\n',
        ...                      '  ^ ^  ^      ', '  ^ ^  ^      ')
        >>> for line in results: print(repr(line))
        ...
        '- \tabcDefghiJkl\n'
        '? \t ^ ^  ^\n'
        '+ \tabcdefGhijkl\n'
        '? \t ^ ^  ^\n'
        -+?_fancy_replaceCollects mdiff output into separate lists

        Before storing the mdiff from/to data into a list, it is converted
        into a single line of text with HTML markup.
        For producing HTML side by side comparison with change highlights.

    This class can be used to create an HTML table (or a complete HTML file
    containing the table) showing a side by side, line by line comparison
    of text with inter-line and intra-line change highlights.  The table can
    be generated in either full or contextual difference mode.

    The following methods are provided for HTML generation:

    make_table -- generates HTML for a single side by side table
    make_file -- generates complete HTML file with a single side by side table

    See tools/scripts/diff.py for an example usage of this class.
    num_blanks_pendingnum_blanks_to_yieldcutoff must be in [0.0, 1.0]: %rcontext_diff.<locals>.<genexpr>format_keynum_linesalineblinebtagsfrom%d_in_change
    Return 1 for ignorable line: iff `line` is blank or contains a single '#'.

    Examples:

    >>> IS_LINE_JUNK('\n')
    True
    >>> IS_LINE_JUNK('  #   \n')
    True
    >>> IS_LINE_JUNK('hello\n')
    False
    <span class="diff_add">*** {}{}{}_check_typesDiffer._plain_replacea b sizeSequenceMatcher.__chain_b_line_pair_iterator_tabsizeMakes list of "next" linksSet the first sequence to be compared.

        The second sequence to be compared is not changed.

        >>> s = SequenceMatcher(None, "abcd", "bcde")
        >>> s.ratio()
        0.75
        >>> s.set_seq1("bcde")
        >>> s.ratio()
        1.0
        >>>

        SequenceMatcher computes and caches detailed information about the
        second sequence, so if you want to compare one sequence S against
        many sequences, use .set_seq2(S) once and call .set_seq1(x)
        repeatedly for each of the other sequences.

        See also set_seqs() and set_seq2().
        crunchernext_href
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
          "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html>

<head>
    <meta http-equiv="Content-Type"
          content="text/html; charset=%(charset)s" />
    <title></title>
    <style type="text/css">%(styles)s
    </style>
</head>

<body>
    %(table)s%(legend)s
</body>

</html>Return an upper bound on ratio() very quickly.

        This isn't defined beyond that it is an upper bound on .ratio(), and
        is faster to compute than either .ratio() or .quick_ratio().
        _linejunk333333ã?
    Differ is a class for comparing sequences of lines of text, and
    producing human-readable differences or deltas.  Differ uses
    SequenceMatcher both to compare sequences of lines, and to compare
    sequences of characters within similar (near-matching) lines.

    Each line of a Differ delta begins with a two-letter code:

        '- '    line unique to sequence 1
        '+ '    line unique to sequence 2
        '  '    line common to both sequences
        '? '    line not present in either input sequence

    Lines beginning with '? ' attempt to guide the eye to intraline
    differences, and were not present in either input sequence.  These lines
    can be confusing if the sequences contain tab characters.

    Note that Differ makes no claim to produce a *minimal* diff.  To the
    contrary, minimal diffs are often counter-intuitive, because they synch
    up anywhere possible, sometimes accidental matches 100 pages apart.
    Restricting synch points to contiguous matches preserves some notion of
    locality, at the occasional cost of producing a longer diff.

    Example: Comparing two texts.

    First we set up the texts, sequences of individual single-line strings
    ending with newlines (such sequences can also be obtained from the
    `readlines()` method of file-like objects):

    >>> text1 = '''  1. Beautiful is better than ugly.
    ...   2. Explicit is better than implicit.
    ...   3. Simple is better than complex.
    ...   4. Complex is better than complicated.
    ... '''.splitlines(keepends=True)
    >>> len(text1)
    4
    >>> text1[0][-1]
    '\n'
    >>> text2 = '''  1. Beautiful is better than ugly.
    ...   3.   Simple is better than complex.
    ...   4. Complicated is better than complex.
    ...   5. Flat is better than nested.
    ... '''.splitlines(keepends=True)

    Next we instantiate a Differ object:

    >>> d = Differ()

    Note that when instantiating a Differ object we may pass functions to
    filter out line and character 'junk'.  See Differ.__init__ for details.

    Finally, we compare the two:

    >>> result = list(d.compare(text1, text2))

    'result' is a list of strings, so let's pretty-print it:

    >>> from pprint import pprint as _pprint
    >>> _pprint(result)
    ['    1. Beautiful is better than ugly.\n',
     '-   2. Explicit is better than implicit.\n',
     '-   3. Simple is better than complex.\n',
     '+   3.   Simple is better than complex.\n',
     '?     ++\n',
     '-   4. Complex is better than complicated.\n',
     '?            ^                     ---- ^\n',
     '+   4. Complicated is better than complex.\n',
     '?           ++++ ^                      ^\n',
     '+   5. Flat is better than nested.\n']

    As a single multi-line string it looks like this:

    >>> print(''.join(result), end="")
        1. Beautiful is better than ugly.
    -   2. Explicit is better than implicit.
    -   3. Simple is better than complex.
    +   3.   Simple is better than complex.
    ?     ++
    -   4. Complex is better than complicated.
    ?            ^                     ---- ^
    +   4. Complicated is better than complex.
    ?           ++++ ^                      ^
    +   5. Flat is better than nested.

    Methods:

    __init__(linejunk=None, charjunk=None)
        Construct a text differencer, with optional filters.

    compare(a, b)
        Compare two sequences of lines; generate the resulting delta.
    ©ÚaÚbÚfromfileÚtofileÚfromfiledateÚ
tofiledateÚnÚlinetermÚstartedÚgroupÚfromdateÚtodateÚfirstÚlastÚfile1_rangeÚfile2_rangeÚtagÚi1Úi2Új1Új2Úline_format_range_contextdiff_bytesSequenceMatcher.set_seq2Differ._dump_format_range_unifiedSequenceMatcher.set_seqs
    Return 1 for ignorable character: iff `ch` is a space or tab.

    Examples:

    >>> IS_CHARACTER_JUNK(' ')
    True
    >>> IS_CHARACTER_JUNK('\t')
    True
    >>> IS_CHARACTER_JUNK('\n')
    False
    >>> IS_CHARACTER_JUNK('x')
    False
    _table_templateReturn a measure of the sequences' similarity (float in [0,1]).

        Where T is the total number of elements in both sequences, and
        M is the number of matches, this is 2.0*M / T.
        Note that this is 1 if the sequences are identical, and 0 if
        they have nothing in common.

        .ratio() is expensive to compute if you haven't already computed
        .get_matching_blocks() or .get_opcodes(), in which case you may
        want to try .quick_ratio() or .real_quick_ratio() first to get an
        upper bound.

        >>> s = SequenceMatcher(None, "abcd", "bcde")
        >>> s.ratio()
        0.75
        >>> s.quick_ratio()
        0.75
        >>> s.real_quick_ratio()
        1.0
        Returns line of text with user's change markup and line formatting.

        lines -- list of lines from the ndiff generator to produce a line of
                 text from.  When producing the line of text to return, the
                 lines used are removed from this list.
        format_key -- '+' return first line in list with "add" markup around
                          the entire line.
                      '-' return first line in list with "delete" markup around
                          the entire line.
                      '?' return first line in list with add/delete/change
                          intraline markup (indices obtained from second line)
                      None return first line in list with no markup
        side -- indice into the num_lines list (0=from,1=to)
        num_lines -- from/to current line number.  This is NOT intended to be a
                     passed parameter.  It is present as a keyword argument to
                     maintain memory of the current line numbers between calls
                     of this function.

        Note, this function is purposefully not defined at the module scope so
        that data it needs from its parent function (within whose context it
        is defined) does not need to be of module scope.
        ®Gáz®ç?bpopular<a href="#difflib_chg_%s_top">t</a>all arguments must be bytes, not %s (%r)Returns generator yielding marked up from/to side by side differences.

    Arguments:
    fromlines -- list of text lines to compared to tolines
    tolines -- list of text lines to be compared to fromlines
    context -- number of context lines to display on each side of difference,
               if None, all from/to text lines will be generated.
    linejunk -- passed on to ndiff (see ndiff documentation)
    charjunk -- passed on to ndiff (see ndiff documentation)

    This function returns an iterator which returns a tuple:
    (from line tuple, to line tuple, boolean flag)

    from/to line tuple -- (line num, line text)
        line num -- integer or None (to indicate a context separation)
        line text -- original line text with following markers inserted:
            '\0+' -- marks start of added text
            '\0-' -- marks start of deleted text
            '\0^' -- marks start of changed text
            '\1' -- marks end of added/deleted/changed text

    boolean flag -- None indicates context separation, True indicates
        either "from" or "to" line contains a change, otherwise False.

    This function/iterator was originally developed to generate side by side
    file difference for making HTML pages (see HtmlDiff class for example
    usage).

    Note, this function utilizes the ndiff function to generate the side by
    side difference markup.  Optional ndiff arguments may be passed to this
    function and they in turn will be passed to ndiff.
    all arguments must be str, not: %rSequenceMatcher.ratio.<locals>.<genexpr>_mdiff.<locals>._line_pair_iteratorDiffer._qformatHtmlDiff._collect_lines
    Compare `a` and `b`, two sequences of lines represented as bytes rather
    than str. This is a wrapper for `dfunc`, which is typically either
    unified_diff() or context_diff(). Inputs are losslessly converted to
    strings so that `dfunc` only has to worry about strings, and encoded
    back to bytes on return. This is necessary to compare files with
    unknown or inconsistent encoding. All other inputs (except `n`) must be
    bytes rather than str.
    <th class="diff_next"><br /></th>n must be > 0: %r            <tr><td class="diff_next"%s>%s</td>%s<td class="diff_next">%s</td>%s</tr>
SequenceMatcher.get_opcodes +<td></td><td>&nbsp;Empty File&nbsp;</td>diff_bytes.<locals>.decodeYields from/to lines of text with a change indication.

        This function is an iterator.  It itself pulls lines from a
        differencing iterator, processes them and yields them.  When it can
        it yields both a "from" and a "to" line, otherwise it will yield one
        or the other.  In addition to yielding the lines of from/to text, a
        boolean flag is yielded to indicate if the text line(s) have
        differences in them.

        Note, this function is purposefully not defined at the module scope so
        that data it needs from its parent function (within whose context it
        is defined) does not need to be of module scope.
        contextLinesmatch_objectSequenceMatcher.get_grouped_opcodes--- {}{}{}_nlargestBuilds list of text lines by splitting text lines at wrap point

        This function will determine if the input text line needs to be
        wrapped (split) into separate lines.  If so, the first wrap point
        will be determined and the first line appended to the output
        text line list.  This function is used recursively to handle
        the second part of the split line to further split it.
        
        Construct a text differencer, with optional filters.

        The two optional keyword parameters are for filter functions:

        - `linejunk`: A function that should accept a single string argument,
          and return true iff the string is junk. The module-level function
          `IS_LINE_JUNK` may be used to filter out lines without visible
          characters, except for at most one splat ('#').  It is recommended
          to leave linejunk None; the underlying SequenceMatcher class has
          an adaptive notion of "noise" lines that's better than any static
          definition the author has ever been able to craft.

        - `charjunk`: A function that should accept a string of length 1. The
          module-level function `IS_CHARACTER_JUNK` may be used to filter out
          whitespace characters (a blank or tab; **note**: bad idea to include
          newline in this!).  Use of IS_CHARACTER_JUNK is recommended.
        Differ._fancy_helper
        table.diff {font-family:Courier; border:medium;}
        .diff_header {background-color:#e0e0e0}
        td.diff_header {text-align:right}
        .diff_next {background-color:#c0c0c0}
        .diff_add {background-color:#aaffaa}
        .diff_chg {background-color:#ffff77}
        .diff_sub {background-color:#ffaaaa}Returns iterator that splits (wraps) mdiff text lines--- {} ----{}lines_to_writeSet the second sequence to be compared.

        The first sequence to be compared is not changed.

        >>> s = SequenceMatcher(None, "abcd", "bcde")
        >>> s.ratio()
        0.75
        >>> s.set_seq2("abcd")
        >>> s.ratio()
        1.0
        >>>

        SequenceMatcher computes and caches detailed information about the
        second sequence, so if you want to compare one sequence S against
        many sequences, use .set_seq2(S) once and call .set_seq1(x)
        repeatedly for each of the other sequences.

        See also set_seqs() and set_seq1().
        
        Compare two sequences of lines; generate the resulting delta.

        Each sequence must contain individual single-line strings ending with
        newlines. Such sequences can be obtained from the `readlines()` method
        of file-like objects.  The delta generated also consists of newline-
        terminated strings, ready to be printed as-is via the writeline()
        method of a file-like object.

        Example:

        >>> print(''.join(Differ().compare('one\ntwo\nthree\n'.splitlines(True),
        ...                                'ore\ntree\nemu\n'.splitlines(True))),
        ...       end="")
        - one
        ?  ^
        + ore
        ?  ^
        - two
        - three
        ?  -
        + tree
        + emu
        SequenceMatcher.get_matching_blocksSequenceMatcher.__init__HtmlDiff._split_line
        When replacing one block of lines with another, search the blocks
        for *similar* lines; the best-matching pair (if any) is used as a
        synch point, and intraline difference marking is done on the
        similar pair. Lots of work, but often worth it.

        Example:

        >>> d = Differ()
        >>> results = d._fancy_replace(['abcDefghiJkl\n'], 0, 1,
        ...                            ['abcdefGhijkl\n'], 0, 1)
        >>> print(''.join(results), end="")
        - abcDefghiJkl
        ?    ^  ^  ^
        + abcdefGhijkl
        ?    ^  ^  ^
        Returns HTML table of side by side comparison with change highlights

        Arguments:
        fromlines -- list of "from" lines
        tolines -- list of "to" lines
        fromdesc -- "from" file column header string
        todesc -- "to" file column header string
        context -- set to True for contextual differences (defaults to False
            which shows full differences).
        numlines -- number of context lines.  When context is set True,
            controls number of lines displayed before and after the change.
            When context is False, controls the number of lines to place
            the "next" link anchors before the next change (so click of
            "next" link jumps to just before the change).
        <thead><tr>%s%s%s%s</tr></thead>{},{}HtmlDiff.__init__HtmlDiff.make_file--++©ÚselfÚaÚaloÚahiÚbÚbloÚbhiÚ
best_ratioÚcutoffÚcruncherÚeqiÚeqjÚjÚbjÚiÚaiÚbest_iÚbest_jÚaeltÚbeltÚatagsÚbtagsÚtagÚai1Úai2Úbj1Úbj2ÚlaÚlbReturns from/to line lists with tabs expanded and newlines removed.

        Instead of tab characters being replaced by the number of spaces
        needed to fill in to the next tab stop, this function will fill
        the space with tab characters.  This is done so that the difference
        algorithms can identify changes in a file when tabs are replaced by
        spaces and vice versa.  At the end of the HTML generation, the tab
        characters will be replaced with a nonbreakable space.
        
    <table class="diff" summary="Legends">
        <tr> <th colspan="2"> Legends </th> </tr>
        <tr> <td> <table border="" summary="Colors">
                      <tr><th> Colors </th> </tr>
                      <tr><td class="diff_add">&nbsp;Added&nbsp;</td></tr>
                      <tr><td class="diff_chg">Changed</td> </tr>
                      <tr><td class="diff_sub">Deleted</td> </tr>
                  </table></td>
             <td> <table border="" summary="Links">
                      <tr><th colspan="2"> Links </th> </tr>
                      <tr><td>(f)irst change</td> </tr>
                      <tr><td>(n)ext change</td> </tr>
                      <tr><td>(t)op</td> </tr>
                  </table></td> </tr>
    </table>Find longest matching block in a[alo:ahi] and b[blo:bhi].

        If isjunk is not defined:

        Return (i,j,k) such that a[i:i+k] is equal to b[j:j+k], where
            alo <= i <= i+k <= ahi
            blo <= j <= j+k <= bhi
        and for all (i',j',k') meeting those conditions,
            k >= k'
            i <= i'
            and if i == i', j <= j'

        In other words, of all maximal matching blocks, return one that
        starts earliest in a, and of all those maximal matching blocks that
        start earliest in a, return the one that starts earliest in b.

        >>> s = SequenceMatcher(None, " abcd", "abcd abcd")
        >>> s.find_longest_match(0, 5, 0, 9)
        Match(a=0, b=4, size=5)

        If isjunk is defined, first the longest matching block is
        determined as above, but with the additional restriction that no
        junk element appears in the block.  Then that block is extended as
        far as possible by matching (only) junk elements on both sides.  So
        the resulting block never matches on junk except as identical junk
        happens to be adjacent to an "interesting" match.

        Here's the same example as before, but considering blanks to be
        junk.  That prevents " abcd" from matching the " abcd" at the tail
        end of the second sequence directly.  Instead only the "abcd" can
        match, and matches the leftmost "abcd" in the second sequence:

        >>> s = SequenceMatcher(lambda x: x==" ", " abcd", "abcd abcd")
        >>> s.find_longest_match(0, 5, 0, 9)
        Match(a=1, b=0, size=4)

        If no blocks match, return (alo, blo, 0).

        >>> s = SequenceMatcher(None, "ab", "c")
        >>> s.find_longest_match(0, 2, 0, 1)
        Match(a=0, b=0, size=0)
        Differ._fancy_replace<a href="#difflib_chg_%s_0">f</a> id="difflib_chg_%s_%d"Return an upper bound on ratio() relatively quickly.

        This isn't defined beyond that it is an upper bound on .ratio(), and
        is faster to compute.
        _calculate_ratio_file_templateCreate unique anchor prefixes
    SequenceMatcher is a flexible class for comparing pairs of sequences of
    any type, so long as the sequence elements are hashable.  The basic
    algorithm predates, and is a little fancier than, an algorithm
    published in the late 1980's by Ratcliff and Obershelp under the
    hyperbolic name "gestalt pattern matching".  The basic idea is to find
    the longest contiguous matching subsequence that contains no "junk"
    elements (R-O doesn't address junk).  The same idea is then applied
    recursively to the pieces of the sequences to the left and to the right
    of the matching subsequence.  This does not yield minimal edit
    sequences, but does tend to yield matches that "look right" to people.

    SequenceMatcher tries to compute a "human-friendly diff" between two
    sequences.  Unlike e.g. UNIX(tm) diff, the fundamental notion is the
    longest *contiguous* & junk-free matching subsequence.  That's what
    catches peoples' eyes.  The Windows(tm) windiff has another interesting
    notion, pairing up elements that appear uniquely in each sequence.
    That, and the method here, appear to yield more intuitive difference
    reports than does diff.  This method appears to be the least vulnerable
    to synching up on blocks of "junk lines", though (like blank lines in
    ordinary text files, or maybe "<P>" lines in HTML files).  That may be
    because this is the only method of the 3 that has a *concept* of
    "junk" <wink>.

    Example, comparing two strings, and considering blanks to be "junk":

    >>> s = SequenceMatcher(lambda x: x == " ",
    ...                     "private Thread currentThread;",
    ...                     "private volatile Thread currentThread;")
    >>>

    .ratio() returns a float in [0, 1], measuring the "similarity" of the
    sequences.  As a rule of thumb, a .ratio() value over 0.6 means the
    sequences are close matches:

    >>> print(round(s.ratio(), 3))
    0.866
    >>>

    If you're only interested in where the sequences match,
    .get_matching_blocks() is handy:

    >>> for block in s.get_matching_blocks():
    ...     print("a[%d] and b[%d] match for %d elements" % block)
    a[0] and b[0] match for 8 elements
    a[8] and b[17] match for 21 elements
    a[29] and b[38] match for 0 elements

    Note that the last tuple returned by .get_matching_blocks() is always a
    dummy, (len(a), len(b), 0), and this is the only case in which the last
    tuple element (number of elements matched) is 0.

    If you want to know how to change the first sequence into the second,
    use .get_opcodes():

    >>> for opcode in s.get_opcodes():
    ...     print("%6s a[%d:%d] b[%d:%d]" % opcode)
     equal a[0:8] b[0:8]
    insert a[8:8] b[8:17]
     equal a[8:29] b[17:38]

    See the Differ class for a fancy human-friendly file differencer, which
    uses SequenceMatcher both to compare sequences of lines, and to compare
    sequences of characters within similar (near-matching) lines.

    See also function get_close_matches() in this module, which shows how
    simple code building on SequenceMatcher can be used to do useful work.

    Timing:  Basic R-O is cubic time worst case and quadratic time expected
    case.  SequenceMatcher is quadratic time for the worst case and has
    expected-case behavior dependent in a complicated way on how many
    elements the sequences have in common; best case time is linear.

    Methods:

    __init__(isjunk=None, a='', b='')
        Construct a SequenceMatcher.

    set_seqs(a, b)
        Set the two sequences to be compared.

    set_seq1(a)
        Set the first sequence to be compared.

    set_seq2(b)
        Set the second sequence to be compared.

    find_longest_match(alo, ahi, blo, bhi)
        Find longest matching block in a[alo:ahi] and b[blo:bhi].

    get_matching_blocks()
        Return list of triples describing matching subsequences.

    get_opcodes()
        Return list of 5-tuples describing how to turn a into b.

    ratio()
        Return a measure of the sequences' similarity (float in [0,1]).

    quick_ratio()
        Return an upper bound on .ratio() relatively quickly.

    real_quick_ratio()
        Return an upper bound on ratio() very quickly.
    
    Compare two sequences of lines; generate the delta as a unified diff.

    Unified diffs are a compact way of showing line changes and a few
    lines of context.  The number of context lines is set by 'n' which
    defaults to three.

    By default, the diff control lines (those with ---, +++, or @@) are
    created with a trailing newline.  This is helpful so that inputs
    created from file.readlines() result in diffs that are suitable for
    file.writelines() since both the inputs and outputs have trailing
    newlines.

    For inputs that do not have trailing newlines, set the lineterm
    argument to "" so that the output will be uniformly newline free.

    The unidiff format normally has a header for filenames and modification
    times.  Any or all of these may be specified using strings for
    'fromfile', 'tofile', 'fromfiledate', and 'tofiledate'.
    The modification times are normally expressed in the ISO 8601 format.

    Example:

    >>> for line in unified_diff('one two three four'.split(),
    ...             'zero one tree four'.split(), 'Original', 'Current',
    ...             '2005-01-26 23:30:50', '2010-04-02 10:20:52',
    ...             lineterm=''):
    ...     print(line)                 # doctest: +NORMALIZE_WHITESPACE
    --- Original        2005-01-26 23:30:50
    +++ Current         2010-04-02 10:20:52
    @@ -1,4 +1,4 @@
    +zero
     one
    -two
    -three
    +tree
     four
    _SequenceMatcher__chain_bC:\msys64\mingw64\lib\python3.6\difflib.pySequenceMatcher.find_longest_matchHelper to get optional details about named references

       Returns the dereferenced name as both value and repr if the name
       list is defined.
       Otherwise returns the name index and its repr().
    new_source_linebyte_incrementsline_incrementslastlinenoVariable names:varnamesshow_linenolineno_widthis_current_instrconst_list_disassemble_bytesDisassembly of %s:%%%ddCell variables:_disassemble_stri_ci_nûé   z	OPTIMIZEDé   z	NEWLOCALSé   zVARARGSé   zVARKEYWORDSé   zNESTEDé    z	GENERATORé@   zNOFREEé   z	COROUTINEé   zITERABLE_COROUTINEi   zASYNC_GENERATOR0Bytecode.__repr__%4d: %r_line_offsetConstants:argreprFormat instruction details for inclusion in disassembly output

        *lineno_width* sets the width of the line number field (0 omits it)
        *mark_as_current* inserts a '-->' marker arrow as part of the line
        Details for a bytecode operation

       Defined fields:
         opname - human readable name for operation
         opcode - numeric code for operation
         arg - numeric argument to operation (if any), otherwise None
         argval - resolved arg value (if known), otherwise same as arg
         argrepr - human readable description of operation argument
         offset - start index of operation within bytecode sequence
         starts_line - line started by this opcode (if any), otherwise None
         is_jump_target - True if other code jumps to here, otherwise False
    extended_argSimple test program to disassemble a file._get_name_info_try_compileHuman readable description of operation argumentFilename:          %sCompile the source string, then disassemble the code object.show_code<disassembly>Number of locals:  %sBytecode.from_tracebackcode_infodistbfindlabelsget_instructionsInstructionBytecode.infoDisassemble a code object.C:\msys64\mingw64\lib\python3.6\dis.pyBytecode.disIterator for the opcodes in methods, functions or code

    Generates a series of Instruction named tuples giving the details of
    each operations in the supplied code.

    If *first_line* is not None, it indicates the line number that should
    be reported for the first source line in the disassembled code.
    Otherwise, the source line information (if any) is taken directly from
    the disassembled code object.
    cell_namespretty_flagsdon't know how to disassemble %s objectsHelper to handle methods, functions, generators, strings and raw code objectsHuman readable name for operationInstruction._disassemble{}({!r})Formatted details of methods, functions, or code.Disassembler of Python byte code into mnemonics.with formatconst_index_InstructionFree variables:_linestartsStart index of operation within bytecode sequencecurrent_offsetopname opcode arg argval argrepr offset starts_line is_jump_targetSorry:name_listNames:_get_const_infoName:              %sNumeric code for operation<dis>Argument count:    %s_cell_namesResolved arg value (if known), otherwise same as argKw-only arguments: %sThe bytecode operations of a piece of code

    Instantiate this with a function, method, string of code, or a code object
    (as returned by compile()).

    Iterating over this yields the bytecode operations as Instruction instances.
    lineno_fmtBytecode.__init__Attempts to compile the given source, first as an expression and
       then as a statement if the first approach fails.

       Utility function to accept strings in functions that otherwise
       expect code objects
    _get_instructions_bytesStack size:        %sBytecode.__iter__name_indexLine started by this opcode (if any), otherwise NoneFlags:             %sDisassemble classes, methods, functions, generators, or code.

    With no argument, disassemble the last traceback.

    Numeric argument to operation (if any), otherwise None_format_code_infoReturn pretty representation of code flags.Return a formatted view of the bytecode operations._unpack_opargs Construct a Bytecode from the given traceback Helper to get optional details about const references

       Returns the dereferenced constant and its repr if the constant
       list is defined.
       Otherwise returns the constant index and its repr().
    _opcodes_all<module dis>Disassemble a traceback (default: last traceback).Return formatted information about the code object._get_code_objectDetect all offsets in a byte code which are jump targets.

    Return the list of offsets.

    Print details of methods, functions, or code to *file*.

    If *file* is not provided, the output is printed on stdout.
    _have_code_original_objectFind the offsets in a byte code which are start of lines in the source.

    Generate pairs (offset, lineno) as described in Python/compile.c.

    %4d: %sIterate over the instructions in a bytecode string.

    Generates a sequence of Instruction namedtuples giving the details of each
    opcode.  Additional information about the code's runtime environment
    (e.g. variable names, constants) can be specified using optional
    arguments.

    no last traceback to disassembleget_doctestexamplenumDocTestCase.__eq__^([ ]*)(?=\S)optionflags--fail-fastcompileflagsclear_globssave_tracesave_set_traceDocTestFinder.find: __test__ values must be strings, functions, methods, classes, or modules: %rOutputChecker.check_outputline %r of the doctest for %s has an option directive on a line with no example: %rDocTestFinder._findset_unittest_reportflagssource_lineswant_linesexc_msg_DocTestRunner__patched_linecache_getlinesModule doctest -- a framework for running examples in docstrings.

In simplest use, end each module M to be tested with:

def _test():
    import doctest
    doctest.testmod()

if __name__ == "__main__":
    _test()

Then running the module as a script will cause the examples in the
docstrings to get executed and verified:

python M.py

This won't display anything unless an example fails, in which case the
failing example(s) and the cause(s) of the failure(s) are printed to stdout
(why not stderr? because stderr is a lame hack <0.2 wink>), and the final
line of output is "Test failed.".

Run it with the -v switch instead:

python M.py -v

and a detailed report of all examples tried is printed to stdout, along
with assorted summaries at the end.

You can force verbose mode by passing "verbose=True" to testmod, or prohibit
it by passing "verbose=False".  In either of those cases, sys.argv is not
examined by testmod.

There are a variety of other ways to run doctests, including integration
with the unittest framework, and support for running non-Python text
files containing doctests.  There are also many ways to override parts
of doctest's default behaviors.  See the Library Reference Manual for
details.
TestResultsA DocTest example has failed in debugging mode.

    The exception instance has variables:

    - test: the DocTest object being run

    - example: the Example object that failed

    - got: the actual output
    _ellipsis_match_INDENT_RE *$SkipDocTestCase.setUpDocTestParserDocTestCase.tearDownDocTestRunner.summarize_exclude_emptyDifferences (%s):
DocTestFinder._get_test(^|.*:)\s*\w*("|\')
        Return a dictionary containing option overrides extracted from
        option directives in the given source string.

        `name` is the string's name, and `lineno` is the line number
        where the example starts; both are used for error messages.
        _toAsciiDocTestRunner.__runDocTestCase.format_failureTrying:
DocTestFinder.find: name must be given when obj.__name__ doesn't exist: %r_dt_testExtract script from text with examples.

       Converts text with examples to a Python script.  Example input is
       converted to regular code.  Example output and all other words
       are converted to comments:

       >>> text = '''
       ...       Here are examples of simple math.
       ...
       ...           Python has super accurate integer addition
       ...
       ...           >>> 2 + 2
       ...           5
       ...
       ...           And very friendly error messages:
       ...
       ...           >>> 1/0
       ...           To Infinity
       ...           And
       ...           Beyond
       ...
       ...           You can use logic if you want:
       ...
       ...           >>> if 0:
       ...           ...    blah
       ...           ...    blah
       ...           ...
       ...
       ...           Ho hum
       ...           '''

       >>> print(script_from_examples(text))
       # Here are examples of simple math.
       #
       #     Python has super accurate integer addition
       #
       2 + 2
       # Expected:
       ## 5
       #
       #     And very friendly error messages:
       #
       1/0
       # Expected:
       ## To Infinity
       ## And
       ## Beyond
       #
       #     You can use logic if you want:
       #
       if 0:
          blah
          blah
       #
       #     Ho hum
       <BLANKLINE>
       SKIP_TestClass.__init__DocTest.__hash__
    A specialized version of the python debugger that redirects stdout
    to a given stream when interacting with the user.  Stdout is *not*
    redirected when traced code is executed.
    reStructuredText en<doctest %s[%d]>Debug a single doctest docstring, in argument `src`'
                Blank lines can be marked with <BLANKLINE>:
                    >>> print('foo\n\nbar\n')
                    foo
                    <BLANKLINE>
                    bar
                    <BLANKLINE>
            DebugRunnerSkipDocTestCase.shortDescriptionSets the unittest option flags.

    The old flag is returned so that a runner could restore the old
    value if it wished to:

      >>> import doctest
      >>> old = doctest._unittest_reportflags
      >>> doctest.set_unittest_reportflags(REPORT_NDIFF |
      ...                          REPORT_ONLY_FIRST_FAILURE) == old
      True

      >>> doctest._unittest_reportflags == (REPORT_NDIFF |
      ...                                   REPORT_ONLY_FIRST_FAILURE)
      True

    Only reporting flags can be set:

      >>> doctest.set_unittest_reportflags(ELLIPSIS)
      Traceback (most recent call last):
      ...
      ValueError: ('Only reporting flags allowed', 8)

      >>> doctest.set_unittest_reportflags(old) == (REPORT_NDIFF |
      ...                                   REPORT_ONLY_FIRST_FAILURE)
      True
    BOOM_DocTestRunner__runDONT_ACCEPT_TRUE_FOR_1valnameDocTestFailure
    Add the given number of space characters to the beginning of
    every non-blank line in `s`, and return the result.
    _from_modulereport_unexpected_exception_OutputRedirectingPdb__debugger_usedunified diff with -expected +actual_OPTION_DIRECTIVE_RE_recurse
        Extract all doctest examples from the given string, and
        collect them into a `DocTest` object.

        `globs`, `name`, `filename`, and `lineno` are attributes for
        the new `DocTest` object.  See the documentation for `DocTest`
        for more information.
        Expected a module: %rUnexpectedException_IS_BLANK_OR_COMMENTDocTestFailure.__str__master
    A single doctest example, consisting of source code and expected
    output.  `Example` defines the following attributes:

      - source: A single Python statement, always ending with a newline.
        The constructor adds a newline if needed.

      - want: The expected output from running the source code (either
        from stdout, or a traceback in case of exception).  `want` ends
        with a newline unless it's empty, in which case it's an empty
        string.  The constructor adds a newline if needed.

      - exc_msg: The exception message generated by the example, if
        the example is expected to generate an exception; or `None` if
        it is not expected to generate an exception.  This exception
        message is compared against the return value of
        `traceback.format_exception_only()`.  `exc_msg` ends with a
        newline unless it's `None`.  The constructor adds a newline
        if needed.

      - lineno: The line number within the DocTest string containing
        this Example where the Example begins.  This line number is
        zero-based, with respect to the beginning of the DocTest.

      - indent: The example's indentation in the DocTest string.
        I.e., the number of space characters that precede the
        example's first prompt.

      - options: A dictionary mapping from option flags to True or
        False, which is used to override default options for this
        example.  Any option flags not contained in this dictionary
        are left at their default value (as specified by the
        DocTestRunner's optionflags).  By default, no options are set.
    UnexpectedException.__str__DocFileCase.format_failureREPORTING_FLAGSpassed andfile containing the tests to runtest_finderLine %s, in %sExpected a module, string, or None
        Find tests for the given object and any contained objects, and
        add them to `tests`.
        stop running tests after first failure (this is a shorthand for -o FAIL_FAST, and is in addition to any other -o options)test_skip
    Return a string containing a traceback message for the given
    exc_info tuple (as returned by sys.exc_info()).
    print very verbose output for all testsDebug a single doctest docstring.

    Provide the module (or dotted name of the module) containing the
    test to be debugged and the name (within the module) of the object
    with the docstring with tests to be debugged.
    ok
^[ ]*(#.*)?$whitespace normalizationrun_docstring_examplesException raised:
DocFileTestDocTestRunner.report_success
                If the ellipsis flag is used, then '...' can be used to
                elide substrings in the desired output:
                    >>> print(list(range(1000))) #doctest: +ELLIPSIS
                    [0, 1, 2, ..., 999]
            
        Report that the test runner is about to process the given
        example.  (Only displays a message if verbose=True)
        Doctest: Run doc tests but raise an exception as soon as there is a failure.

       If an unexpected exception occurs, an UnexpectedException is raised.
       It contains the test, the example, and the original exception:

         >>> runner = DebugRunner(verbose=False)
         >>> test = DocTestParser().get_doctest('>>> raise KeyError\n42',
         ...                                    {}, 'foo', 'foo.py', 0)
         >>> try:
         ...     runner.run(test)
         ... except UnexpectedException as f:
         ...     failure = f

         >>> failure.test is test
         True

         >>> failure.example.want
         '42\n'

         >>> exc_info = failure.exc_info
         >>> raise exc_info[1] # Already has the traceback
         Traceback (most recent call last):
         ...
         KeyError

       We wrap the original exception to give the calling application
       access to the test and example information.

       If the output doesn't match, then a DocTestFailure is raised:

         >>> test = DocTestParser().get_doctest('''
         ...      >>> x = 1
         ...      >>> x
         ...      2
         ...      ''', {}, 'foo', 'foo.py', 0)

         >>> try:
         ...    runner.run(test)
         ... except DocTestFailure as f:
         ...    failure = f

       DocTestFailure objects provide access to the test:

         >>> failure.test is test
         True

       As well as to the example:

         >>> failure.example.want
         '2\n'

       and the actual output:

         >>> failure.got
         '1\n'

       If a failure or error occurs, the globals are left intact:

         >>> del test.globs['__builtins__']
         >>> test.globs
         {'x': 1}

         >>> test = DocTestParser().get_doctest('''
         ...      >>> x = 2
         ...      >>> raise KeyError
         ...      ''', {}, 'foo', 'foo.py', 0)

         >>> runner.run(test)
         Traceback (most recent call last):
         ...
         doctest.UnexpectedException: <DocTest foo from foo.py:0 (2 examples)>

         >>> del test.globs['__builtins__']
         >>> test.globs
         {'x': 2}

       But the globals are cleared if there is no error:

         >>> test = DocTestParser().get_doctest('''
         ...      >>> x = 2
         ...      ''', {}, 'foo', 'foo.py', 0)

         >>> runner.run(test)
         TestResults(failed=0, attempted=1)

         >>> test.globs
         {}

       
        Create a new test runner.

        Optional keyword arg `checker` is the `OutputChecker` that
        should be used to compare the expected outputs and actual
        outputs of doctest examples.

        Optional keyword arg 'verbose' prints lots of stuff if true,
        only failures if false; by default, it's true iff '-v' is in
        sys.argv.

        Optional argument `optionflags` can be used to control how the
        test runner compares expected output to actual output, and how
        it displays failures.  See the documentation for `testmod` for
        more information.
        val -> _TestClass object with associated value val.

        >>> t = _TestClass(123)
        >>> print(t.get())
        123
        __displayhook__DIVIDER
        Record the fact that the given DocTest (`test`) generated `f`
        failures out of `t` tried examples.
        test_pathExpected:
%sGot:
%sTest passed.DocTestParser.get_doctestDocTest no longer accepts str; use DocTestParser insteadtestsourceDocTestRunner.report_startDocFileCase.id_name2ftmin_indentcharnondiff with -expected +actualDocTestRunner.run.<locals>.out
    Return the compiler-flags associated with the future features that
    have been imported into the given namespace (globs).
    noteststotalttotalf_normalize_moduleexcoutreport_failureDocTestParser._min_indentREPORT_CDIFF
                      Example of a string object, searched as-is.
                      >>> x = 1; y = 2
                      >>> x + y, x * y
                      (3, 2)
                      OutputChecker._do_a_fancy_diffDocTestParser.get_examples__docformat__Can't resolve paths relative to the module %r (it has no __file__)DocTestFinder._from_moduleSkipDocTestCase.__init__module_relativetestsrcline %r of the doctest for %s has an invalid option: %r<]>^\s*class\s*%s\b
        Return a DocTest for the given object, if it defines a docstring;
        otherwise, return None.
        _dt_checkerfile_contents_extract_future_flagsextraglobsraise_on_error
        Given the lines of a source string (including prompts and
        leading indentation), check to make sure that every prompt is
        followed by a space character.  If any line is not followed by
        a space character, then raise ValueError.
        
        # Grab the traceback header.  Different versions of Python have
        # said different things on the first traceback line.
        ^(?P<hdr> Traceback\ \(
            (?: most\ recent\ call\ last
            |   innermost\ last
            ) \) :
        )
        \s* $                # toss trailing whitespace on the header.
        (?P<stack> .*?)      # don't blink: absorb stuff until...
        ^ (?P<msg> \w+ .*)   #     a line *starts* with alphanum.
        DocTest.__repr___exception_tracebackDocTestRunner.report_unexpected_exceptionDocTestParser._find_optionsUnexpectedException.__init__DocTestCase.idDONT_ACCEPT_BLANKLINE
    A class used to run DocTest test cases, and accumulate statistics.
    The `run` method is used to process a single DocTest case.  It
    returns a tuple `(f, t)`, where `t` is the number of test cases
    tried, and `f` is the number of test cases that failed.

        >>> tests = DocTestFinder().find(_TestClass)
        >>> runner = DocTestRunner(verbose=False)
        >>> tests.sort(key = lambda test: test.name)
        >>> for test in tests:
        ...     print(test.name, '->', runner.run(test))
        _TestClass -> TestResults(failed=0, attempted=2)
        _TestClass.__init__ -> TestResults(failed=0, attempted=2)
        _TestClass.get -> TestResults(failed=0, attempted=2)
        _TestClass.square -> TestResults(failed=0, attempted=1)

    The `summarize` method prints a summary of all the test cases that
    have been run by the runner, and returns an aggregated `(f, t)`
    tuple:

        >>> runner.summarize(verbose=1)
        4 items passed all tests:
           2 tests in _TestClass
           2 tests in _TestClass.__init__
           2 tests in _TestClass.get
           1 tests in _TestClass.square
        7 tests in 4 items.
        7 passed and 0 failed.
        Test passed.
        TestResults(failed=0, attempted=7)

    The aggregated number of tried examples and failed examples is
    also available via the `tries` and `failures` attributes:

        >>> runner.tries
        7
        >>> runner.failures
        0

    The comparison between expected outputs and actual outputs is done
    by an `OutputChecker`.  This comparison may be customized with a
    number of option flags; see the documentation for `testmod` for
    more information.  If the option flags are insufficient, then the
    comparison may also be customized by passing a subclass of
    `OutputChecker` to the constructor.

    The test runner's display output can be controlled in two ways.
    First, an output function (`out) can be passed to
    `TestRunner.run`; this function will be called with strings that
    should be displayed.  It defaults to `sys.stdout.write`.  If
    capturing the output is not sufficient, then the display output
    can be also customized by subclassing DocTestRunner, and
    overriding the methods `report_start`, `report_success`,
    `report_unexpected_exception`, and `report_failure`.
     %3d tests in %s_OutputRedirectingPdb.set_continue_module_relative_pathitems had no tests:***Test Failed***DocTestParser._parse_exampleobj_mod_OutputRedirectingPdb.__init___EXCEPTION_REDocFileCase.__repr__
                If the whitespace normalization flag is used, then
                differences in whitespace are ignored.
                    >>> print(list(range(30))) #doctest: +NORMALIZE_WHITESPACE
                    [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14,
                     15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26,
                     27, 28, 29]
            
    Return the module specified by `module`.  In particular:
      - If `module` is a module, then return module.
      - If `module` is a string, then import and return the
        module with that name.
      - If `module` is None, then return the calling module.
        The calling module is assumed to be the module of
        the stack frame at the given depth in the call stack.
    Run the test case without results and without catching exceptions

           The unit test framework includes a debug method on test cases
           and test suites to support post-mortem debugging.  The test code
           is run in such a way that errors are not caught.  This way a
           caller can catch the errors and initiate post-mortem debugging.

           The DocTestCase provides a debug method that raises
           UnexpectedException errors if there is an unexpected
           exception:

             >>> test = DocTestParser().get_doctest('>>> raise KeyError\n42',
             ...                {}, 'foo', 'foo.py', 0)
             >>> case = DocTestCase(test)
             >>> try:
             ...     case.debug()
             ... except UnexpectedException as f:
             ...     failure = f

           The UnexpectedException contains the test, the example, and
           the original exception:

             >>> failure.test is test
             True

             >>> failure.example.want
             '42\n'

             >>> exc_info = failure.exc_info
             >>> raise exc_info[1] # Already has the traceback
             Traceback (most recent call last):
             ...
             KeyError

           If the output doesn't match, then a DocTestFailure is raised:

             >>> test = DocTestParser().get_doctest('''
             ...      >>> x = 1
             ...      >>> x
             ...      2
             ...      ''', {}, 'foo', 'foo.py', 0)
             >>> case = DocTestCase(test)

             >>> try:
             ...    case.debug()
             ... except DocTestFailure as f:
             ...    failure = f

           DocTestFailure objects provide access to the test:

             >>> failure.test is test
             True

           As well as to the example:

             >>> failure.example.want
             '2\n'

           and the actual output:

             >>> failure.got
             '1\n'

           
        Report that the given example ran successfully.  (Only
        displays a message if verbose=True)
        --option
    A pointless class, for sanity-checking of docstring testing.

    Methods:
        square()
        get()

    >>> _TestClass(13).get() + _TestClass(-12).get()
    1
    >>> hex(_TestClass(13).square().get())
    '0xa9'
    (?m)^%s\s*?$
        Run the examples in `test`, and display the results using the
        writer function `out`.

        The examples are run in the namespace `test.globs`.  If
        `clear_globs` is true (the default), then this namespace will
        be cleared after the test runs, to help with garbage
        collection.  If you would like to examine the namespace after
        the test completes, then use `clear_globs=False`.

        `compileflags` gives the set of flags that should be used by
        the Python compiler when running the examples.  If not
        specified, then it will default to the set of future-import
        flags that apply to `globs`.

        The output of each example is checked using
        `DocTestRunner.check_output`, and the results are formatted by
        the `DocTestRunner.report_*` methods.
        get() -> return TestClass's associated value.

        >>> x = _TestClass(-42)
        >>> print(x.get())
        -42
        DocTestRunner.mergegot_linesDocFileSuitedebug_src_comment_line
        Run the examples in `test`.  Write the outcome of each example
        with one of the `DocTestRunner.report_*` methods, using the
        writer function `out`.  `compileflags` is the set of compiler
        flags that should be used to execute examples.  Return a tuple
        `(f, t)`, where `t` is the number of examples tried, and `f`
        is the number of examples that failed.  The examples are run
        in the namespace `test.globs`.
        _dt_tearDownDocTestSuite<doctest (?P<name>.+)\[(?P<examplenum>\d+)\]>$no examples
        Convert string to hex-escaped ASCII string.
         %3d of %3d in %s<%s %s from %s:%s (%s)>object must be a class or functionExtract the test sources from a doctest docstring as a script.

    Provide the module (or dotted name of the module) containing the
    test to be debugged and the name (within the module) of the object
    with the doc string with tests to be debugged.
    context diff with expected followed by actualExpecting:
DocTestRunner.report_failure_SpoofOut.getvalueOPTIONFLAGS_BY_NAMEgettrace_DocTestRunner__record_outcomespecify a doctest option flag to apply to the test run; may be specified more than once to apply multiple optionsOutputChecker.output_differenceDocTestFinder.find: __test__ keys must be strings: %rDocTestSuite will not work with -O2 and aboveDocTest.__lt__Expected nothing
Got nothing
Failed example:
        Given a regular expression match from `_EXAMPLE_RE` (`m`),
        return a pair `(source, want)`, where `source` is the matched
        example's source code (with prompts and indentation stripped);
        and `want` is the example's expected output (with indentation
        stripped).

        `name` is the string's name, and `lineno` is the line number
        where the example starts; both are used for error messages.
        Return a commented form of the given lineCOMPARISON_FLAGSbool-int equivalence_strip_exception_detailstestfilesfullpathReturn the minimum indentation of any non-blank line in `s`DocTestCase.runTest1 exampleExample.__hash___dt_setUpPackage may only be specified for module-relative paths.**********************************************************************Expecting nothing

        Check that every line in the given list starts with the given
        prefix; if any line does not, then raise a ValueError.
        
    A class used to parse strings containing doctest examples.
    DocTestRunner.__patched_linecache_getlines(?m)^(?!$)DocTestFailure.__init__failed attempted
        Return True iff the actual output from an example (`got`)
        matches the expected output (`want`).  These strings are
        always considered to match if they are identical; but
        depending on what option flags the test runner is using,
        several non-exact match types are also possible.  See the
        documentation for `TestRunner` for more information about
        option flags.
        DocTest.__eq__#\s*doctest:\s*([^\n\'"]*)$_OutputRedirectingPdb__outoriginal_optionflags
        Divide the given string into examples and intervening text,
        and return them as a list of alternating Examples and strings.
        Line numbers for the Examples are 0-based.  The optional
        argument `name` is a name identifying this string, and is only
        used for error messages.
        Bad diff option%s.__test__.%sIGNORE_EXCEPTION_DETAIL©ÚselfÚtestÚcompileflagsÚoutÚfailuresÚtriesÚoriginal_optionflagsÚSUCCESSÚFAILUREÚBOOMÚcheckÚ
examplenumÚexampleÚquietÚ
optionflagÚvalÚfilenameÚ	exceptionÚgotÚoutcomeÚexc_msg
        Return a list of the DocTests that are defined by the given
        object's docstring, or by any of its contained objects'
        docstrings.

        The optional parameter `module` is the module that contains
        the given object.  If the module is not specified or is None, then
        the test finder will attempt to automatically determine the
        correct module.  The object's module is used:

            - As a default namespace, if `globs` is not specified.
            - To prevent the DocTestFinder from extracting DocTests
              from objects that are imported from other modules.
            - To find the name of the file containing the object.
            - To help find the line number of the object within its
              file.

        Contained objects whose module does not match `module` are ignored.

        If `module` is False, no attempt to find the module will be made.
        This is obscure, of use mostly in tests:  if `module` is False, or
        is None but cannot be found automatically, then all objects are
        considered to belong to the (non-existent) module, so all contained
        objects will (recursively) be searched for doctests.

        The globals for each DocTest is formed by combining `globs`
        and `extraglobs` (bindings in `extraglobs` override bindings
        in `globs`).  A new copy of the globals dictionary is created
        for each DocTest.  If `globs` is not specified, then it
        defaults to the module's `__dict__`, if specified, or {}
        otherwise.  If `extraglobs` is not specified, then it defaults
        to {}.

        DocTestFinder._find_linenoA unittest suite for one or more doctest files.

    The path to each doctest file is given as a string; the
    interpretation of that string depends on the keyword argument
    "module_relative".

    A number of options may be provided as keyword arguments:

    module_relative
      If "module_relative" is True, then the given file paths are
      interpreted as os-independent module-relative paths.  By
      default, these paths are relative to the calling module's
      directory; but if the "package" argument is specified, then
      they are relative to that package.  To ensure os-independence,
      "filename" should use "/" characters to separate path
      segments, and may not be an absolute path (i.e., it may not
      begin with "/").

      If "module_relative" is False, then the given file paths are
      interpreted as os-specific paths.  These paths may be absolute
      or relative (to the current working directory).

    package
      A Python package or the name of a Python package whose directory
      should be used as the base directory for module relative paths.
      If "package" is not specified, then the calling module's
      directory is used as the base directory for module relative
      filenames.  It is an error to specify "package" if
      "module_relative" is False.

    setUp
      A set-up function.  This is called before running the
      tests in each file. The setUp function will be passed a DocTest
      object.  The setUp function can access the test globals as the
      globs attribute of the test passed.

    tearDown
      A tear-down function.  This is called after running the
      tests in each file.  The tearDown function will be passed a DocTest
      object.  The tearDown function can access the test globals as the
      globs attribute of the test passed.

    globs
      A dictionary containing initial global variables for the tests.

    optionflags
      A set of doctest option flags expressed as an integer.

    parser
      A DocTestParser (or subclass) that should be used to extract
      tests from the files.

    encoding
      An encoding that will be used to convert the files to unicode.
    DocTestParser._check_prefixExample.__eq__DocTestRunner.__init___failure_headerdebug_scriptitems had failures:_DocTestRunner__LINECACHE_FILENAME_REunknown outcome_fakeout_load_testfileC:\msys64\mingw64\lib\python3.6\doctest.pyExample.__init__DebugRunner.runDocTest.__init__REPORT_UDIFFOutputChecker._toAsciiline %r of the docstring for %s has inconsistent leading whitespace: %rDebugRunner.report_failure_check_prompt_blankunknown line numberFailed doctest test for %s
  File "%s", line %s, in %s

%sDocTestRunner.__record_outcome
    A class used to extract the DocTests that are relevant to a given
    object, from its docstring and the docstrings of its contained
    objects.  Doctests can currently be extracted from the following
    object types: modules, functions, classes, methods, staticmethods,
    classmethods, and properties.
    BLANKLINE_MARKER
        Return a string describing the differences between the
        expected output for a given example (`example`) and the actual
        output (`got`).  `optionflags` is the set of option flags used
        to compare `want` and `got`.
        m=None, name=None, globs=None, verbose=None, report=True,
       optionflags=0, extraglobs=None, raise_on_error=False,
       exclude_empty=False

    Test examples in docstrings in functions and classes reachable
    from module m (or the current module if m is not supplied), starting
    with m.__doc__.

    Also test examples reachable from dict m.__test__ if it exists and is
    not None.  m.__test__ maps names to functions, classes and strings;
    function and class docstrings are tested even if the name is private;
    strings are tested directly, as if they were docstrings.

    Return (#failures, #tests).

    See help(doctest) for an overview.

    Optional keyword arg "name" gives the name of the module; by default
    use m.__name__.

    Optional keyword arg "globs" gives a dict to be used as the globals
    when executing examples; by default, use m.__dict__.  A copy of this
    dict is actually used for each docstring, so that each docstring's
    examples start with a clean slate.

    Optional keyword arg "extraglobs" gives a dictionary that should be
    merged into the globals that are used to execute examples.  By
    default, no extra globals are used.  This is new in 2.4.

    Optional keyword arg "verbose" prints lots of stuff if true, prints
    only failures if false; by default, it's true iff "-v" is in sys.argv.

    Optional keyword arg "report" prints a summary at the end when true,
    else prints nothing at the end.  In verbose mode, the summary is
    detailed, else very brief (in fact, empty if all tests passed).

    Optional keyword arg "optionflags" or's together module constants,
    and defaults to 0.  This is new in 2.3.  Possible values (see the
    docs for details):

        DONT_ACCEPT_TRUE_FOR_1
        DONT_ACCEPT_BLANKLINE
        NORMALIZE_WHITESPACE
        ELLIPSIS
        SKIP
        IGNORE_EXCEPTION_DETAIL
        REPORT_UDIFF
        REPORT_CDIFF
        REPORT_NDIFF
        REPORT_ONLY_FIRST_FAILURE

    Optional keyword arg "raise_on_error" raises an exception on the
    first unexpected exception or failure. This allows failures to be
    post-mortem debugged.

    Advanced tomfoolery:  testmod runs methods of a local instance of
    class doctest.Tester, then merges the results into (or creates)
    global Tester instance doctest.master.  Methods of doctest.master
    can be called directly too, if you want to do something unusual.
    Passing report=0 to testmod is especially useful then, to delay
    displaying a summary.  Invoke doctest.master.summarize(verbose)
    when you're done fiddling.
    
        Return a line number of the given object's docstring.  Note:
        this method assumes that the object has a docstring.
        
    A collection of doctest examples that should be run in a single
    namespace.  Each `DocTest` defines the following attributes:

      - examples: the list of examples.

      - globs: The namespace (aka globals) that the examples should
        be run in.

      - name: A name identifying the DocTest (typically, the name of
        the object whose docstring this DocTest was extracted from).

      - filename: The name of the file that this DocTest was extracted
        from, or `None` if the filename is unknown.

      - lineno: The line number within filename where this DocTest
        begins, or `None` if the line number is unavailable.  This
        line number is zero-based, with respect to the beginning of
        the file.

      - docstring: The string that the examples were extracted from,
        or `None` if the string is unavailable.
    
        Report that the given example raised an unexpected exception.
        A DocTest example has encountered an unexpected exception

    The exception instance has variables:

    - test: the DocTest object being run

    - example: the Example object that failed

    - exc_info: the exception info
    fail_fast_OutputRedirectingPdb.set_traceDocTestCase.__hash__testmod: module required; %r<module doctest>(?m)^\s*?$
    Essentially the only subtle case:
    >>> _ellipsis_match('aa...aa', 'aaa')
    False
    _OutputRedirectingPdb.trace_dispatchFinding tests in %s
    Test examples in the given file.  Return (#failures, #tests).

    Optional keyword arg "module_relative" specifies how filenames
    should be interpreted:

      - If "module_relative" is True (the default), then "filename"
         specifies a module-relative path.  By default, this path is
         relative to the calling module's directory; but if the
         "package" argument is specified, then it is relative to that
         package.  To ensure os-independence, "filename" should use
         "/" characters to separate path segments, and should not
         be an absolute path (i.e., it may not begin with "/").

      - If "module_relative" is False, then "filename" specifies an
        os-specific path.  The path may be absolute or relative (to
        the current working directory).

    Optional keyword arg "name" gives the name of the test; by default
    use the file's basename.

    Optional keyword argument "package" is a Python package or the
    name of a Python package whose directory should be used as the
    base directory for a module relative filename.  If no package is
    specified, then the calling module's directory is used as the base
    directory for module relative filenames.  It is an error to
    specify "package" if "module_relative" is False.

    Optional keyword arg "globs" gives a dict to be used as the globals
    when executing examples; by default, use {}.  A copy of this dict
    is actually used for each docstring, so that each docstring's
    examples start with a clean slate.

    Optional keyword arg "extraglobs" gives a dictionary that should be
    merged into the globals that are used to execute examples.  By
    default, no extra globals are used.

    Optional keyword arg "verbose" prints lots of stuff if true, prints
    only failures if false; by default, it's true iff "-v" is in sys.argv.

    Optional keyword arg "report" prints a summary at the end when true,
    else prints nothing at the end.  In verbose mode, the summary is
    detailed, else very brief (in fact, empty if all tests passed).

    Optional keyword arg "optionflags" or's together module constants,
    and defaults to 0.  Possible values (see the docs for details):

        DONT_ACCEPT_TRUE_FOR_1
        DONT_ACCEPT_BLANKLINE
        NORMALIZE_WHITESPACE
        ELLIPSIS
        SKIP
        IGNORE_EXCEPTION_DETAIL
        REPORT_UDIFF
        REPORT_CDIFF
        REPORT_NDIFF
        REPORT_ONLY_FIRST_FAILURE

    Optional keyword arg "raise_on_error" raises an exception on the
    first unexpected exception or failure. This allows failures to be
    post-mortem debugged.

    Optional keyword arg "parser" specifies a DocTestParser (or
    subclass) that should be used to extract tests from the files.

    Optional keyword arg "encoding" specifies an encoding that should
    be used to convert the file to unicode.

    Advanced tomfoolery:  testmod runs methods of a local instance of
    class doctest.Tester, then merges the results into (or creates)
    global Tester instance doctest.master.  Methods of doctest.master
    can be called directly too, if you want to do something unusual.
    Passing report=0 to testmod is especially useful then, to delay
    displaying a summary.  Invoke doctest.master.summarize(verbose)
    when you're done fiddling.
    Expected:
%sGot nothing
DocTestCase.__repr__doctest runner
        Return true if the given object is defined in the given
        module.
        %d examples
                                    In 2.2, boolean expressions displayed
                                    0 or 1.  By default, we still accept
                                    them.  This can be disabled by passing
                                    DONT_ACCEPT_TRUE_FOR_1 to the new
                                    optionflags argument.
                                    >>> 4 == 4
                                    1
                                    >>> 4 == 4
                                    True
                                    >>> 4 > 4
                                    0
                                    >>> 4 > 4
                                    False
                                    
        Print a summary of all the test cases that have been run by
        this DocTestRunner, and return a tuple `(f, t)`, where `f` is
        the total number of failed examples, and `t` is the total
        number of tried examples.

        The optional `verbose` argument controls how detailed the
        summary is.  If the verbosity is not specified, then the
        DocTestRunner's verbosity is used.
        exec(%r)DocTestParser._check_prompt_blankModule-relative files may not have absolute paths_dt_optionflagsSkipDocTestCase.test_skipSkipping tests from %sDebug a test script.  `src` is the script, as a string.DocTestFinder.__init__
    Convert doctest tests for a module to a unittest test suite.

    This converts each documentation string in a module that
    contains doctest tests to a unittest test case.  If any of the
    tests in a doc string fail, then the test case fails.  An exception
    is raised showing the name of the file containing the test and a
    (sometimes approximate) line number.

    The `module` argument provides the module to be tested.  The argument
    can be either a module or a module name.

    If no argument is given, the calling module is used.

    A number of options may be provided as keyword arguments:

    setUp
      A set-up function.  This is called before running the
      tests in each file. The setUp function will be passed a DocTest
      object.  The setUp function can access the test globals as the
      globs attribute of the test passed.

    tearDown
      A tear-down function.  This is called after running the
      tests in each file.  The tearDown function will be passed a DocTest
      object.  The tearDown function can access the test globals as the
      globs attribute of the test passed.

    globs
      A dictionary containing initial global variables for the tests.

    optionflags
       A set of doctest option flags expressed as an integer.
    
        # Source consists of a PS1 line followed by zero or more PS2 lines.
        (?P<source>
            (?:^(?P<indent> [ ]*) >>>    .*)    # PS1 line
            (?:\n           [ ]*  \.\.\. .*)*)  # PS2 lines
        \n?
        # Want consists of any non-blank lines that do not start with PS1.
        (?P<want> (?:(?![ ]*$)    # Not a blank line
                     (?![ ]*>>>)  # Not a line starting with PS1
                     .+$\n?       # But any other line
                  )*)
        save_linecache_getlinesDocTestCase.debugnot found in testsÛ!   zregister_optionflagzDONT_ACCEPT_TRUE_FOR_1zDONT_ACCEPT_BLANKLINEzNORMALIZE_WHITESPACEzELLIPSISzSKIPzIGNORE_EXCEPTION_DETAILzCOMPARISON_FLAGSzREPORT_UDIFFzREPORT_CDIFFzREPORT_NDIFFzREPORT_ONLY_FIRST_FAILUREzREPORTING_FLAGSz	FAIL_FASTzExamplezDocTestzDocTestParserzDocTestFinderzDocTestRunnerzOutputCheckerzDocTestFailurezUnexpectedExceptionzDebugRunnerztestmodztestfilezrun_docstring_exampleszDocTestSuitezDocFileSuitezset_unittest_reportflagszscript_from_examplesz
testsourcez	debug_srczdebugDebugRunner.report_unexpected_exception_SpoofOut.truncate
    A class used to check the whether the actual output from a doctest
    example matches the expected output.  `OutputChecker` defines two
    methods: `check_output`, which compares a given pair of outputs,
    and returns true if they match; and `output_difference`, which
    returns a string describing the differences between two outputs.
    _DocTestSuite._removeTestAtIndex
    Test examples in the given object's docstring (`f`), using `globs`
    as globals.  Optional argument `name` is used in failure messages.
    If the optional argument `verbose` is true, then generate output
    even if there are no failures.

    `compileflags` gives the set of flags that should be used by the
    Python compiler when running the examples.  If not specified, then
    it will default to the set of future-import flags that apply to
    `globs`.

    Optional keyword arg `optionflags` specifies options for the
    testing and output.  See the documentation for `testmod` for more
    information.
    Failed doctest test for %s
  File "%s", line 0

%s
        Create a new DocTest containing the given examples.  The
        DocTest's globals are initialized with a copy of `globs`.
        
        Extract all doctest examples from the given string, and return
        them as a list of `Example` objects.  Line numbers are
        0-based, because it's most common in doctests that nothing
        interesting appears on the same line as opening triple-quote,
        and so the first interesting line is called "line 1" then.

        The optional argument `name` is a name identifying this
        string, and is only used for error messages.
        ELLIPSIS_MARKER(?m)^[ ]*(?=
)square() -> square TestClass's associated value

        >>> _TestClass(13).square().get()
        169
        
        Create a new doctest finder.

        The optional argument `parser` specifies a class or
        function that should be used to create new DocTest objects (or
        objects that implement the same interface as DocTest).  The
        signature for this factory function should match the signature
        of the DocTest constructor.

        If the optional argument `recurse` is false, then `find` will
        only examine the given object, and not any contained objects.

        If the optional argument `exclude_empty` is false, then `find`
        will include tests for objects with empty docstrings.
        
        Report that the given example failed.
        DocTestRunner._failure_headerExpected nothing
Got:
%sline %r of the docstring for %s lacks blank after %s: %rDocTestParser.parsespinnerDoNotTouchWarning.connect_signalsDoNotTouchWarning.idleTouchAlerter.currently_touched.<locals>.<genexpr>TensionerDoNotTouchWarning.connect_signalsblue_countTensionerDoNotTouchWarning.__init__all_devices_idle received. ClosingEmits emergency_stop when presses are detected while CNC is moving.pressure_pointsSpinnerC:\msys64\home\cbper\donottouch.pyTouchAlerter.__init__all_devices_idle signal received. Closing do_not_touch.set_modaldisable_protectionnew_pressure_data_frametouch_label<span font='16'>Setting up new case.</span>
<span font='20' foreground='red'>DO NOT TOUCH!</span>TouchAlerter.disable_protectionprotection_enabledTouchAlerter.enable_protection<module donottouch>DoNotTouchWarning.restartTouchAlerter.new_pressure_data_frame<module dummy_threading>_dummy_threading_dummy__threading_localheld_threadsys_modulesheld__threading_localheld_threadingholding__threading_localholding_threadFaux ``threading`` version using ``dummy_thread`` instead of ``thread``.

The module ``_dummy_threading`` is added to ``sys.modules`` in order
to not have ``threading`` considered imported.  Had ``threading`` been
directly imported it would have made all subsequent imports succeed
regardless of whether ``_thread`` was available which is not desired.

holding_threadingC:\msys64\mingw64\lib\python3.6\dummy_threading.pymessage_from_fileC:\msys64\mingw64\lib\python3.6\emailmimemessage_from_binary_fileRead a file and parse its contents into a Message object model.

    Optional _class and strict are passed to the Parser constructor.
    A package for parsing, handling, and generating email messages.C:\msys64\mingw64\lib\python3.6\email\__init__.pymessage_from_bytesParse a bytes string into a Message object model.

    Optional _class and strict are passed to the Parser constructor.
    Parse a string into a Message object model.

    Optional _class and strict are passed to the Parser constructor.
    Read a binary file and parse its contents into a Message object model.

    Optional _class and strict are passed to the Parser constructor.
    _q_byte_subber=([a-fA-F0-9]{2})encode_qdecode_qlen_qlen_bencode_q.<locals>.<genexpr> Routines for manipulating RFC2047 encoded words.

This is currently a package-private API, but will be considered for promotion
to a public API if there is demand.

_QByteMapUnknown charset {} in encoded word; decoded as unknown bytes_cte_encode_lengthcte_stringlen_q.<locals>.<genexpr>_q_byte_mapEncode string using the CTE encoding that produces the shorter result.

    Produces an RFC 2047/2243 encoded word of the form:

        =?charset*lang?cte?encoded_string?=

    where '*lang' is omitted unless the 'lang' parameter is given a value.
    Optional argument charset (defaults to utf-8) specifies the charset to use
    to encode the string to binary before CTE encoding it.  Optional argument
    'encoding' is the cte specifier for the encoding that should be used ('q'
    or 'b'); if it is None (the default) the encoding which produces the
    shortest encoded sequence is used, except that 'q' is preferred if it is up
    to five characters longer.  Optional argument 'lang' (default '') gives the
    RFC 2243 language string to specify in the encoded word.

    Decode encoded word and return (string, charset, lang, defects) tuple.

    An RFC 2047/2243 encoded word has the form:

        =?charset*lang?cte?encoded_string?=

    where '*lang' may be omitted but the other parts may not be.

    This function expects exactly such a string (that is, it does not check the
    syntax and may raise errors if the string is not well formed), and returns
    the encoded_string decoded first from its Content Transfer Encoding and
    then from the resulting bytes into unicode using the specified charset.  If
    the cte-decoded string does not successfully decode using the specified
    character set, a defect is added to the defects list and the unknown octets
    are replaced by the unicode 'unknown' character \uFDFF.

    The specified charset and language are returned.  The default for language,
    which is rarely if ever encountered, is the empty string.

    ={:02X}_QByteMap.__missing__pad_err_cte_decodersEncoded word contains bytes not decodable using {} charsetblenunexpected binascii.Error=?{}{}?{}?{}?=<module email._encoded_words>padded_encodedC:\msys64\mingw64\lib\python3.6\email\_encoded_words.py_cte_encodersattrtextget_mailbox.<locals>.<genexpr>TokenList.__repr__ group = display-name ":" [group-list] ";" [CFWS]

     mailbox = name-addr / addr-spec

    group_listangle-addrvcharshad_qpAngleAddr.routeencoded word format invalid: '{}'_steal_trailing_WSP_if_existsExpected RFC2231 char/lang encoding delimiter, but found {}get_addressExtra text after content transfer encodingbare_quoted_stringis_tlexcess_get_ptext_to_endchars_refold_parse_treePHRASE_ENDSGroupListTrue if all top level tokens of this part may be RFC2047 encoded.AddressList.addressesWhiteSpaceTerminal.valueencoded_part_non_attribute_end_matcherend of input inside domain-literalcfwsParameter marked as extended but appears to have a quoted string value that is non-encodedInvalid leading '.' in local partduplicate parameter name; duplicate(s) ignoredTokenList.valueObsRoute.domainsBareQuotedString.__str__.<locals>.<genexpr>mailboxesTokenList.__init__LocalPartend of header in group mechanism

    address-list entry with no contentto_encode_validate_xtextlocal-part is not dot-atom, quoted-string, or obs-local-partMissing content type specificationParameterizedHeaderValue.paramsgroup-list with empty entriesppstrtext_spaceApparent initial-extended-value but attribute was not marked as extended or was not initial sectionExpected MIME version number but found only CFWS local-part = dot-atom / quoted-string / obs-local-part

    FWS = 1*WSP

    This isn't the RFC definition.  We're using fws to represent tokens where
    folding can be done, but when we are parsing the *un*folding has already
    been done so we don't need to watch out for CRLF.

    end-of-obs-route-marker addr-spec = local-part "@" domain

     dot-text = 1*atext *("." 1*atext)

    QuotedString.stripped_value{}*={}''{} Defects: {}[\x00-\x20\x7F]get_extended_attrtextInvalidMailbox.display_namefirst_partIf input token contains ASCII non-printables, register a defect.get_cfwsget_group_listReturn string of contents of parse_tree folded according to RFC rules.

    quoted-string = [CFWS] <bare-quoted-string> [CFWS]

    'bare-quoted-string' is an intermediate class defined by this
    parser and not by the RFC grammar.  It is the quoted string
    without any attached CFWS.
    mtokenParameter not followed by '='Mailbox.domainmaxcharsIncomplete parameterget_commentobsolete route specification in angle-addrUnstructuredTokenListget_qcontentget_attrtextexpected atom but found '{}'Excess non-CFWS text after MIME versionencode_as_ewTerminal._ppexpected name-addr but found '{}'invalid parameter {!r} '*' digits

    The formal BNF is more complicated because leading 0s are not allowed.  We
    check for that and add a defect.  We also assume no CFWS is allowed between
    the '*' and the digits, though the RFC is not crystal clear on that.
    The caller should already have dealt with leading CFWS.

    TSPECIALS'\' character outside of quoted-string/ccontentnull addr-spec in angle-addrstartswith_fwshave_wsget_encoded_wordexpected extended attrtext but found {!r}domain_literalNameAddrParameter contains name ({}) but no valueinvalid-mailboxend of header inside comment_check_for_early_dl_end dtext = <printable ascii except \ [ ]> / obs-dtext
        obs-dtext = obs-NO-WS-CTL / quoted-pair

    We allow anything except the excluded characters, but if we find any
    ASCII other than the RFC defined printable ASCII, a NonPrintableDefect is
    added to the token's defects list.  Quoted pairs are converted to their
    unquoted values, so what is returned is a ptext token, in this case a
    ValueTerminal.  If there were quoted-printables, an ObsoleteHeaderDefect is
    added to the returned token's defect list.

    end of header in group-listdot_atominner_valueaddress-at-symbolEncodedWordComment.content.<locals>.<genexpr>DomainLiteral.domainCFWS_LEADERget_parameterNon-ASCII characters found in header tokenlocal-part contains non-ASCII characters)appendtoqstringsemi_validget_dtextpop_trailing_wsdisp_headerend_ew_not_allowedcontent-type-separatorget_domain_literalget_bare_quoted_string address_list = (address *("," address)) / obs-addr-list
        obs-addr-list = *([CFWS] ",") address *("," [address / CFWS])

    We depart from the formal grammar here by continuing to parse until the end
    of the input, assuming the input to be entirely composed of an
    address-list.  This is always true in email parsing, and allows us
    to skip invalid addresses to parse additional valid ones.

    encoded word inside quoted stringEWWhiteSpaceTerminal{}{}/{}(parameter entry with no content_non_token_end_matcherheader-labelDisplayNameWhiteSpaceTerminal.startswith_fwsexpected angle-addr but found '{}'mailbox_listQuoted string value for extended parameter is invalidMimeParameters.__str__ObsLocalPartobs_local_partTokenList.foldlast_non_ws_was_dotValueTerminal.value dot-atom = [CFWS] dot-atom-text [CFWS]

    Any place we can have a dot atom, we could instead have an rfc2047 encoded
    word.
    last_ewew_combine_allowedleading_wsptrailing_wspnew_last_ewremaining_spaceexpected atom at end of dot-atom-text but found '{}'Incomplete MIME version; found only major number mime-version = [CFWS] 1*digit [CFWS] "." [CFWS] 1*digit [CFWS]

    _wsp_splittertoken = [CFWS] 1*ttext [CFWS]

    The RFC equivalent of ttext is any US-ASCII chars except space, ctls, or
    tspecials.  We also exclude tabs even though the RFC doesn't.

    The RFC implies the CFWS but is not explicit about it in the BNF.

    Group.mailboxesMissing content dispositionDotAtom domain = dot-atom / domain-literal / obs-domain
        obs-domain = atom *("." atom))

     maintype "/" subtype *( ";" parameter )

    The maintype and substype are tokens.  Theoretically they could
    be checked against the official IANA list + x-token, but we
    don't do that.
    get_obs_local_partTokenList._ppobs_routegroup-terminatorcomment = "(" *([FWS] ccontent) [FWS] ")"
       ccontent = ctext / quoted-pair / comment

    We handle nested comments here, and quoted-pair in our qp-ctext routine.
    quoted_value encoded-word = "=?" charset "?" encoding "?" encoded-text "?="

    get_qp_ctextDo our best to find the parameters in an invalid MIME header

    whitespace inside encoded wordExpected section but found {}missing '.' between wordsTerminal.all_defectsexpected ':' marking end of obs-route but found '{}'([{}]+)parameter-separatorComment.quotewrap_as_ew_blockedinvalid_mailbox display-name = phrase

    Because this is simply a name-rule, we don't return a display-name
    token containing a phrase, but rather a display-name token with
    the content of the phrase.

    get_obs_routeparse_mime_parametersroute-component-markerASPECIALSTOKEN_ENDSGroupList.all_mailboxesqcontent = qtext / quoted-pair

    We allow anything except the DQUOTE character, but if we find any ASCII
    other than the RFC defined printable ASCII, a NonPrintableDefect is
    added to the token's defects list.  Any quoted pairs are converted to their
    unquoted values, so what is returned is a 'ptext' token.  In this case it
    is a ValueTerminal.

    mailbox-listlist-separatorMissing required charset/lang delimitersphrase does not start with wordextended-attributedomain-literal-endmime_versionAddressList.all_mailboxes.<locals>.<genexpr>Expected content transfer encoding but found {!r}expected attrtext but found {!r}_fold_as_ewadd-spec local part with no domainget_attributeperiod in 'phrase'invalid_parameterword = atom / quoted-string

    Either atom or quoted-string may start with CFWS.  We have to peel off this
    CFWS first to determine which type of word to parse.  Afterward we splice
    the leading CFWS, if any, into the parsed sub-token.

    If neither an atom or a quoted-string is found before the next special, a
    HeaderParseError is raised.

    The token returned is either an Atom or a QuotedString, as appropriate.
    This means the 'word' level of the formal grammar is not represented in the
    parse tree; this is because having that extra layer when manipulating the
    parse tree is more confusing than it is helpful.

    Expected 'atom' or 'quoted-string' but found '{}'QuotedString.contentexpected '"' but found '{}'CFWS = (1*([FWS] comment) [FWS]) / FWS

    ctext = <printable ascii except \ ( )>

    This is not the RFC ctext, since we are handling nested comments in comment
    and unquoting quoted-pairs here.  We allow anything except the '()'
    characters, but if we find any ASCII other than the RFC defined printable
    ASCII, a NonPrintableDefect is added to the token's defects list.  Since
    quoted pairs are converted to their unquoted values, what is returned is
    a 'ptext' token.  In this case it is a WhiteSpaceTerminal, so it's value
    is ' '.

    get_display_nameInvalid content typeTerminal.pop_trailing_wsAngleAddr.domaingroup-display-name-terminatorinvalid mailbox in mailbox-listget_mailbox_listMissing content transfer encodingempty element in address-list domain-literal = [CFWS] "[" *([FWS] dtext) [FWS] "]" [CFWS]

    Mailbox.addr_specContentDispositionexpected mailbox but found '{}'expected local-part but found '{}'MailboxListLocalPart.valueAddress.all_mailboxesTerminal.__getnewargs__get_atextcomment found without atomTokenList.as_ew_allowedATTRIBUTE_ENDSExpected RFC2231 char/lang encoding delimiter, but found {!r}splitpointTokenList.startswith_fwsextended-parameter-markerRouteComponentMarkerTerminal.__new__TokenList.pprintinvalid-obs-local-partmissing whitespace before encoded wordget_name_addrExpected content subtype but found {!r}want_encodingnewpartsexpected domain but found '{}'quoted printable found in domain-literalDotAtomTextNameAddr.local_partAddrSpec.domainExpected value but found only {}mime-parametersget_extended_attribute{}{}/{}({}){}Comment.commentsNameAddr.display_nameAddressList.mailboxes_non_extended_attribute_end_matcher address = mailbox / group

    Note that counter-intuitively, an address can be either a single address or
    a list of addresses (a group).  This is why the returned Address object has
    a 'mailboxes' attribute which treats a single address as a list of length
    one.  When you need to differentiate between to two cases, extract the single
    element, which is either a mailbox or a group token.

    Value.stripped_valueListSeparatorAddress.mailboxestokenlistchrome_lenNameAddr.domainC:\msys64\mingw64\lib\python3.6\email\_header_value_parser.pyLocalPart.local_partremstrvtextget_sectionbare-quoted-string = DQUOTE *([FWS] qcontent) [FWS] DQUOTE

    A quoted-string without the leading or trailing white space.  Its
    value is the text between the quote marks, with whitespace
    preserved and quoted pairs decoded.
    Missing MIME version number (eg: 1.0)inconsistent RFC2231 parameter numberingMIMEVersionMailbox.local_partMailbox.routeangle_addrdot_atom_textlocal-part is not a dot-atom (contains CFWS)Invalid trailing '.' in local partinvalid address in address-listget_dot_atommissing trailing '>' on angle-addrangle-addr-startExpected content maintype but found {!r}Group.all_mailboxesTokenList.__str__ group-list = mailbox-list / CFWS / obs-group-list
        obs-group-list = 1*([CFWS] ",") [CFWS]

    ,;Expected MIME major version number but found {!r}domain is not a dot-atom (contains CFWS)expected domain-literalExpected value but found end of stringend of header while parsing obs-routesection numberhas an invalid leading 0MimeParameters.paramsunstructured = (*([FWS] vchar) *WSP) / obs-unstruct
       obs-unstruct = *((*LF *CR *(obs-utext) *LF *CR)) / FWS)
       obs-utext = %d0 / obs-NO-WS-CTL / LF / CR

       obs-NO-WS-CTL is control characters except WSP/CR/LF.

    So, basically, we have printable runs, plus control characters or nulls in
    the obsolete syntax, separated by whitespace.  Since RFC 2047 uses the
    obsolete syntax in its specification, but requires whitespace on either
    side of the encoded words, I can see no reason to need to separate the
    non-printable-non-whitespace from the printable runs if they occur, so we
    parse this into xtext tokens separated by WSP tokens.

    Because an 'unstructured' value must by definition constitute the entire
    value, this 'get' routine does not return a remaining value, only the
    parsed TokenList.

    Fold string to_encode into lines as encoded word, combining if allowed.
    Return the new value for last_ew, or None if ew_combine_allowed is False.

    If there is already an encoded word in the last line of lines (indicated by
    a non-None value for last_ew) and ew_combine_allowed is true, decode the
    existing ew, combine it with to_encode, and re-encode.  Otherwise, encode
    to_encode.  In either case, split to_encode as necessary so that the
    encoded segments fit within maxlen.

    expected ']' at end of domain-literal but found '{}'expected atext but found '{}'expected atom at a start of dot-atom-text but found '{}' phrase = 1*word / obs-phrase
        obs-phrase = word *(word / "." / CFWS)

    This means a phrase can be a sequence of words, periods, and CFWS in any
    order as long as it starts with at least one word.  If anything other than
    words is detected, an ObsoleteHeaderDefect is added to the token's defect
    list.  We also accept a phrase that starts with CFWS followed by a dot;
    this is registered as an InvalidHeaderDefect, since it is not supported by
    even the obsolete grammar.

    end of header inside quoted stringNameAddr.routeend of header before group-list    !! invalid element in token list: {!r}expected ttext but found '{}'parameter with invalid trailing text {!r}TokenList.ppstrExpected content disposition but found {!r}Fold TokenList 'part' into the 'lines' list as mime parameters.

    Using the decoded list of parameters and values, format them according to
    the RFC rules, including using RFC2231 encoding if the value cannot be
    expressed in 'encoding' and/or the parameter+value is too long to fit
    within 'maxlen'.

    Domain.domainBareQuotedString.value.<locals>.<genexpr>section-markerWhiteSpaceTokenList.valueHeader value parser implementing various email-related RFC parsing rules.

The parsing methods defined in this module implement various email related
parsing rules.  Principal among them is RFC 5322, which is the followon
to RFC 2822 and primarily a clarification of the former.  It also implements
RFC 2047 encoded word decoding.

RFC 5322 goes to considerable trouble to maintain backward compatibility with
RFC 822 in the parse phase, while cleaning up the structure on the generation
phase.  This parser supports correct RFC 5322 generation by tagging white space
as folding white space only when folding is allowed in the non-obsolete rule
sets.  Actually, the parser is even more generous when accepting input than RFC
5322 mandates, following the spirit of Postel's Law, which RFC 5322 encourages.
Where possible deviations from the standard are annotated on the 'defects'
attribute of tokens that deviate.

The general structure of the parser follows RFC 5322, and uses its terminology
where there is a direct correspondence.  Where the implementation requires a
somewhat different structure than that used by the formal grammar, new terms
that mimic the closest existing terms are used.  Thus, it really helps to have
a copy of RFC 5322 handy when studying this code.

Input to the parser is a string that has already been unfolded according to
RFC 5322 rules.  According to the RFC this unfolding is the very first step, and
this parser leaves the unfolding step to a higher level message parser, which
will have already detected the line breaks that need unfolding while
determining the beginning and end of each header.

The output of the parser is a TokenList object, which is a list subclass.  A
TokenList is a recursive data structure.  The terminal nodes of the structure
are Terminal objects, which are subclasses of str.  These do not correspond
directly to terminal objects in the formal grammar, but are instead more
practical higher level combinations of true terminals.

All TokenList and Terminal objects have a 'value' attribute, which produces the
semantically meaningful value of that part of the parse subtree.  The value of
all whitespace tokens (no matter how many sub-tokens they may contain) is a
single space, as per the RFC rules.  This includes 'CFWS', which is herein
included in the general class of whitespace tokens.  There is one exception to
the rule that whitespace tokens are collapsed into single spaces in values: in
the value of a 'bare-quoted-string' (a quoted-string with no leading or
trailing whitespace), any whitespace that appeared between the quotation marks
is preserved in the returned value.  Note that in all Terminal strings quoted
pairs are turned into their unquoted values.

All TokenList and Terminal objects also have a string value, which attempts to
be a "canonical" representation of the RFC-compliant form of the substring that
produced the parsed subtree, including minimal use of quoted pair quoting.
Whitespace runs are not collapsed.

Comment tokens also have a 'content' attribute providing the string found
between the parens (including any nested comments) with whitespace preserved.

All TokenList and Terminal objects have a 'defects' attribute which is a
possibly empty list all of the defects found while creating the token.  Defects
may appear on any token in the tree, and a composite list of all defects in the
subtree is available through the 'all_defects' attribute of any node.  (For
Terminal notes x.defects == x.all_defects.)

Each object in a parse tree is called a 'token', and each has a 'token_type'
attribute that gives the name from the RFC 5322 grammar that it represents.
Not all RFC 5322 nodes are produced, and there is one non-RFC 5322 node that
may be produced: 'ptext'.  A 'ptext' is a string of printable ascii characters.
It is returned in place of lists of (ctext/quoted-pair) and
(qtext/quoted-pair).

XXX: provide complete list of token types.
MailboxList.mailboxesdomain-literal-startexpected '(' but found '{}' name-addr = [display-name] angle-addr

     [CFWS] 1*attrtext [CFWS]

    This version of the BNF makes the CFWS explicit, and as usual we use a
    value terminal for the actual run of characters.  The RFC equivalent of
    attrtext is the token characters, with the subtraction of '*', "'", and '%'.
    We include tab in the excluded set just as we do for token.

    TokenList.value.<locals>.<genexpr>empty element in mailbox-listExpected MIME minor version number but found {!r}extended-attrtextvalue_partsexpected address but found '{}'DisplayName.display_name_refold_parse_tree.<locals>.<genexpr>Parameter.param_valueinvalid repeated '.'AddrSpec.local_partAngleAddr.addr_specget_wordexpected addr-spec or obs-route but found '{}'TokenList.all_defectsinvalid-parameterexpected ':' at end of group display name but found '{}'AddrSpec.valueexpected token but found '{}'first_paramget_angle_addrEWWhiteSpaceTerminal.valueerror_handlerencoding_requiredencoded_valueextra_chrome Read everything up to one of the chars in endchars.

    This is outside the formal grammar.  The InvalidMailbox TokenList that is
    returned acts like a Mailbox, but the data attributes are None.

    GroupList.mailboxesQuotedString.quoted_value mailbox-list = (mailbox *("," mailbox)) / obs-mbox-list
        obs-mbox-list = *([CFWS] ",") mailbox *("," [mailbox / CFWS])

    For this routine we go outside the formal grammar in order to improve error
    handling.  We recognize the end of the mailbox list only at the end of the
    value or at a ';' (the group terminator).  This is so that we can turn
    invalid mailboxes into InvalidMailbox tokens and continue parsing any
    remaining valid mailboxes.  We also allow all mailbox entries to be null,
    and this condition is handled appropriately at a higher level.

    angle-addr-endWhiteSpaceTokenList.commentsAddressList.mailboxes.<locals>.<genexpr>duplicate parameter name; duplicate ignoredInvalidParameterATOM_ENDSmisplaced-special quoted-string / attribute

    AddrSpec.addr_spec Read everything up to the next ';'.

    This is outside the formal grammar.  The InvalidParameter TokenList that is
    returned acts like a Parameter, but the data attributes are None.

    _fold_mime_parameters_find_mime_parametersget_phrase [CFWS] 1*extended_attrtext [CFWS]

    This is like the non-extended version except we allow % characters, so that
    we can pick up an encoded value as a single string.

    _non_atom_end_matcher obs-local-part = word *("." word)
    section_numbersyntactic_breakDomainLiteral.ipexpected '[' at start of domain-literal but found '{}'email._header_value_parserversion-separatorEXTENDED_ATTRIBUTE_ENDScte_headerget_dot_atom_textexpected ';' at end of group but found {}ValueTerminal.startswith_fwsMailboxList.all_mailboxesatom = [CFWS] 1*atext [CFWS]

    An atom could be an rfc2047 encoded word.
    expected encoded word but found {}ContentTypeget_local_part obs-route = obs-domain-list ":"
        obs-domain-list = *(CFWS / ",") "@" domain *("," [CFWS] ["@" domain])

        Returns an obs-route token with the appropriate sub-tokens (that is,
        there is no obs-domain-list in the parse tree).
    get_invalid_parameterAngleAddr.local_partOnly parameters are valid after content type, but found {!r}PhraseTerminal.commentsRFC2231-delimiterget_ttextDisplayName.valueContentTransferEncoding {}*{}*={}{}TokenList.as_ew_allowed.<locals>.<genexpr> disposition-type *( ";" parameter )

    NameAddr.addr_spec<module email._header_value_parser>get_fwsTokenList.all_defects.<locals>.<genexpr>Comment.__str__last_is_tlattrtext = 1*(any non-ATTRIBUTE_ENDS character plus '%')

    This is a special parsing routine so that we get a value that
    includes % escapes as a single string (which we decode as a single
    string later).

    get_invalid_mailboxOnly parameters are valid after content disposition, but found {!r}Terminal.__repr__EWWhiteSpaceTerminal.__str__ttext = <matches _ttext_matcher>

    We allow any non-TOKEN_ENDS in ttext, but add defects to the token's
    defects list if we find non-ttext characters.  We also register defects for
    *any* non-printables even though the RFC doesn't exclude all of them,
    because we follow the spirit of RFC 5322.

    Attribute.stripped_value[^{}]+_non_printable_finder attribute [section] ["*"] [CFWS] "=" value

    The CFWS is implied by the RFC but not made explicit in the BNF.  This
    simplified form of the BNF from the RFC is made to conform with the RFC BNF
    through some extra checks.  We do it this way because it makes both error
    recovery and working with the resulting parse tree easier.
    sectionedParameter.section_number parameter *( ";" parameter )

    That BNF is meant to indicate this routine should only be called after
    finding and handling the leading ';'.  There is no corresponding rule in
    the formal RFC grammar, but it is more convenient for us for the set of
    parameters to be treated as its own TokenList.

    This is 'parse' routine because it consumes the reminaing value, but it
    would never be called to parse a full header.  Instead it is called to
    parse everything after the non-parameter value of a specific MIME header.

    Expected section number but found {}TokenList.__str__.<locals>.<genexpr> angle-addr = [CFWS] "<" addr-spec ">" [CFWS] / obs-angle-addr
        obs-angle-addr = [CFWS] "<" obs-route addr-spec ">" [CFWS]

    get_quoted_stringTerminal.pprintatext = <matches _atext_matcher>

    We allow any non-ATOM_ENDS in atext, but add an InvalidATextDefect to
    the token's defects list if we find non-atext characters.
    expected obs-route domain but found '{}'Scan printables/quoted-pairs until endchars and return unquoted ptext.

    This function turns a run of qcontent, ccontent-without-comments, or
    dtext-with-quoted-printables into a single string by unquoting any
    quoted printables.  It returns the string, the remaining value, and
    a flag that is True iff there were any quoted printables decoded.

    get_atomattrtext = 1*(any non-ATTRIBUTE_ENDS character)

    We allow any non-ATTRIBUTE_ENDS in attrtext, but add defects to the
    token's defects list if we find non-attrtext characters.  We also register
    defects for *any* non-printables even though the RFC doesn't exclude all of
    them, because we follow the spirit of RFC 5322.

    returnlistgetdomaingetaddrspecAddrlistClass.getquoteallowcommentsC:\msys64\mingw64\lib\python3.6\email\_parseaddr.pyadlistGet a parenthesis-delimited fragment from self's field.preserve_wsAddrlistClass.__init__Parse an RFC 2822 atom.

        Optional atomends specifies a different set of end token delimiters
        (the default is to use self.atomends).  This is used e.g. in
        getphraselist() since phrase endings must not include the `.' (which
        is legal in phrases).tmmtzsignatomlistPrepare string to be used in a quoted string.

    Turns backslash and double quote characters into quoted pairs.  These
    are the only characters that need to be quoted inside a quoted string.
    Does not add the surrounding double quotes.
    Skip white space and extract comments.AddrlistClass.gotonextfieldlen"sdlistParse a header fragment delimited by special characters.

        `beginchar' is the start character for the fragment.
        If self is not looking at an instance of `beginchar' then
        getdelimited returns the empty string.

        `endchars' is a sequence of allowable end-delimiting characters.
        Parsing stops when one of these is encountered.

        If `allowcomments' is non-zero, embedded RFC 2822 comments are allowed
        within the parsed fragment.
        getaddressParse the next address.AddressList.__isub__getdomainliteralAddrlistClass.getaddrlistgetcommentParse an RFC 2822 domain-literal.expectrouteAddrlistClass.getphraselistParse all addresses.

        Returns a list containing all of the addresses.
        commentlistAddrlistClass.getcommentphraseendsAddressList.__sub__<module email._parseaddr>Get the complete domain name from an address.Address parser class by Ben Escoto.

    To understand what this class does, it helps to have a copy of RFC 2822 in
    front of you.

    Note: this class interface is deprecated and may be removed in the future.
    Use email.utils.AddressList instead.
    An AddressList encapsulates a list of parsed RFC 2822 addresses.Parse a sequence of RFC 2822 phrases.

        A phrase is a sequence of words, which are in turn either RFC 2822
        atoms or quoted-strings.  Phrases are canonicalized by squeezing all
        runs of continuous whitespace into one space.
        ]AddressList.__len__)Convert a date string to a time tuple.

    Accounts for military timezones.
    newaddroldclaslistÛ   zjanzfebzmarzaprzmayzjunzjulzaugzsepzoctznovzdeczjanuaryzfebruaryzmarchzaprilzmayzjunezjulyzaugustz	septemberzoctoberznovemberzdecembergetatomoldposParse a route address (Return-path value).

        This method just skips all the route stuff and returns the addrspec.
        AddrlistClass.getdomainAddressList.__add__Convert date to extended time tuple.

    The last (additional) element is the time zone offset in seconds, except if
    the timezone was specified as -0000.  In that case the last element is
    None.  This indicates a UTC timestamp that explicitly declaims knowledge of
    the source timezone, as opposed to a +0000 timestamp that indicates the
    source timezone really was UTC.

    ()<>@,:;."[]AddressList.__init___daynamesParse an RFC 2822 addr-spec.AddrlistClass.getatomConvert a time string to a time tuple.AddressList.__iadd__Get a quote-delimited fragment from self's field.getrouteaddrAddrlistClass.getdomainliteralAddrlistClass.getaddrspec_timezonesAddrlistClass.getrouteaddrwslist_monthnamesInitialize a new instance.

        `field' is an unparsed address header field, containing
        one or more addresses.
        LWSEmail address parsing code.

Lifted directly from rfc822.py.  This should eventually be rewritten.
AddrlistClass.getaddressAddressList.__getitem__Turn a 10-tuple as returned by parsedate_tz() into a POSIX timestamp.AddrlistClass.getdelimitedûzUTé    zUTCr   zGMTr   ÚZr   zASTipþÿÿzADTiÔþÿÿzESTiþÿÿzEDTipþÿÿzCSTi¨ýÿÿzCDTiþÿÿzMSTiDýÿÿzMDTi¨ýÿÿzPSTiàüÿÿzPDTiDýÿÿ0Compat32.header_fetch_parseGiven the header name and the value from the model, return a string
        containing linesep characters that implement the folding of the header
        according to the policy controls.  The value passed in by the email
        package may contain surrogateescaped binary data if the lines were
        parsed by a BytesParser.  The returned value should not contain any
        surrogateescaped data.

        Return the maximum allowed number of headers named 'name'.

        Called when a header is added to a Message object.  If the returned
        value is not 0 or None, and there are already a number of headers with
        the name 'name' equal to the value returned, a ValueError is raised.

        Because the default behavior of Message's __setitem__ is to append the
        value to the list of headers, it is easy to create duplicate headers
        without realizing it.  This method allows certain headers to be limited
        in the number of instances of that header that may be added to a
        Message programmatically.  (The limit is not observed by the parser,
        which will faithfully produce as many headers as exist in the message
        being parsed.)

        The default implementation returns None for all header names.
        Compat32.fold_binaryPolicy.header_store_parse+
        Headers are folded using the Header folding algorithm, which preserves
        existing line breaks in the value, and wraps each resulting line to the
        max_line_length.  Non-ASCII binary data are CTE encoded using the
        unknown-8bit charset.

        Based on policy, either raise defect or call register_defect.

            handle_defect(obj, defect)

        defect should be a Defect subclass, but in any case must be an
        Exception subclass.  obj is the object on which the defect should be
        registered if it is not raised.  If the raise_on_defect is True, the
        defect is raised as an error, otherwise the object and the defect are
        passed to register_defect.

        This method is intended to be called by parsers that discover defects.
        The email package parsers always call it with Defect instances.

        Given the header name and the value from the model, return binary
        data containing linesep characters that implement the folding of the
        header according to the policy controls.  The value passed in by the
        email package may contain surrogateescaped binary data.

        _append_docGiven a list of linesep terminated strings constituting the lines of
        a single header, return the (name, value) tuple that should be stored
        in the model.  The input lines should retain their terminating linesep
        characters.  The lines passed in by the email package may contain
        surrogateescaped binary data.
        _PolicyBase.__setattr__Compat32._sanitize_headerPolicy Object basic framework.

    This class is useless unless subclassed.  A subclass should define
    class attributes with defaults for any values that are to be
    managed by the Policy object.  The constructor will then allow
    non-default values to be set for these attributes at instance
    creation time.  The instance will be callable, taking these same
    attributes keyword arguments, and returning a new instance
    identical to the called instance except for those values changed
    by the keyword arguments.  Instances may be added, yielding new
    instances with any non-default values from the right hand
    operand overriding those in the left hand operand.  That is,

        A + B == A(<non-default values of B>)

    The repr of an instance can be used to reconstruct the object
    if and only if the repr of the values can be used to reconstruct
    those values.

    _extend_docstrings.<locals>.<genexpr>Compat32.header_store_parse_PolicyBase.clonePolicy.handle_defectPolicy framework for the email package.

Allows fine grained feature control of how the package parses and emits data.
_PolicyBase.__add__added_docNon-default values from right operand override those from left.

        The object returned is a new instance of the subclass.

        +
        The name is parsed as everything up to the ':' and returned unmodified.
        The value is determined by stripping leading whitespace off the
        remainder of the first line, joining all subsequent lines together, and
        stripping any trailing carriage return or linefeed characters.

        Policy.register_defectCompat32._foldnewpolicy+
        If the value contains binary data, it is converted into a Header object
        using the unknown-8bit charset.  Otherwise it is returned unmodified.
        Return a new instance with specified attributes changed.

        The new instance has the same attribute values as the current object,
        except for the changes passed in as keyword arguments.

        +
        The name and value are returned unmodified.
        {!r} is an invalid keyword argument for {}Create new Policy, possibly overriding some defaults.

        See class docstring for a list of overridable attributes.

        C:\msys64\mingw64\lib\python3.6\email\_policybase.py+
    This particular policy is the backward compatibility Policy.  It
    replicates the behavior of the email package version 5.1.
    Policy.fold_binary{!r} object attribute {!r} is read-onlyCompat32.header_source_parsePolicy.header_source_parsePolicy.header_max_countControls for how messages are interpreted and formatted.

    Most of the classes and many of the methods in the email package accept
    Policy objects as parameters.  A Policy object contains a set of values and
    functions that control how input is interpreted and how output is rendered.
    For example, the parameter 'raise_on_defect' controls whether or not an RFC
    violation results in an error being raised or not, while 'max_line_length'
    controls the maximum length of output lines when a Message is serialized.

    Any valid attribute may be overridden when a Policy is created by passing
    it as a keyword argument to the constructor.  Policy objects are immutable,
    but a new Policy object can be created with only certain values changed by
    calling the Policy instance with keyword arguments.  Policy objects can
    also be added, producing a new Policy object in which the non-default
    attributes set in the right hand operand overwrite those specified in the
    left operand.

    Settable attributes:

    raise_on_defect     -- If true, then defects should be raised as errors.
                           Default: False.

    linesep             -- string containing the value to use as separation
                           between output lines.  Default '\n'.

    cte_type            -- Type of allowed content transfer encodings

                           7bit  -- ASCII only
                           8bit  -- Content-Transfer-Encoding: 8bit is allowed

                           Default: 8bit.  Also controls the disposition of
                           (RFC invalid) binary data in headers; see the
                           documentation of the binary_fold method.

    max_line_length     -- maximum length of lines, excluding 'linesep',
                           during serialization.  None or 0 means no line
                           wrapping is done.  Default is 78.

    mangle_from_        -- a flag that, when True escapes From_ lines in the
                           body of the message by putting a `>' in front of
                           them. This is used when the message is being
                           serialized by a generator. Default: True.

    message_factory     -- the class to use to create new message objects.
                           If the value is None, the default is Message.

    {!r} object has no attribute {!r}<module email._policybase>Policy.header_fetch_parse_PolicyBase.__init__+
        Headers are folded using the Header folding algorithm, which preserves
        existing line breaks in the value, and wraps each resulting line to the
        max_line_length.  If cte_type is 7bit, non-ascii binary data is CTE
        encoded using the unknown-8bit charset.  Otherwise the original source
        header is used, with its existing line breaks and/or binary data.

        Given the header name and the value from the model, return the value
        to be returned to the application program that is requesting that
        header.  The value passed in by the email package may contain
        surrogateescaped binary data if the lines were parsed by a BytesParser.
        The returned value should not contain any surrogateescaped data.

        _PolicyBase.__repr__Given the header name and the value provided by the application
        program, return the (name, value) that should be stored in the model.
        Record 'defect' on 'obj'.

        Called by handle_defect if raise_on_defect is False.  This method is
        part of the Policy API so that Policy subclasses can implement custom
        defect handling.  The default implementation calls the append method of
        the defects attribute of obj.  The objects used by the email package by
        default that get passed to this method will always have a defects
        attribute with an append method.

        encvecC:\msys64\mingw64\lib\python3.6\email\base64mime.pyMISC_LENReturn the length of s when it is encoded with base64.max_unencodedEncode a single header line with Base64 encoding in a given charset.

    charset names the character set to use to encode the header.  It defaults
    to iso-8859-1.  Base64 encoding is defined in RFC 2045.
    Decode a raw base64 string, returning a bytes object.

    This function does not parse a full MIME header value encoded with
    base64 (like =?iso-8859-1?b?bmloISBuaWgh?=) -- please use the high
    level email.header class for that functionality.
    Encode a string with base64.

    Each line will be wrapped at, at most, maxlinelen characters (defaults to
    76 characters).

    Each line of encoded text will end with eol, which defaults to "\n".  Set
    this to "\r\n" if you will be using the result of this function directly
    in an email.
    Base64 content transfer encoding per RFCs 2045-2047.

This module handles the content transfer encoding method defined in RFC 2045
to encode arbitrary 8-bit data using the three 8-bit bytes in four 7-bit
characters encoding known as Base64.

It is used in the MIME standards for email to attach images, audio, and text
using some 8-bit character sets to messages.

This module provides an interface to encode and decode both headers and bodies
with Base64 encoding.

RFC 2045 defines a method for including character set information in an
`encoded-word' in a header.  This method is commonly used for 8-bit real names
in To:, From:, Cc:, etc. fields, as well as Subject: lines.

This module does not do the line wrapping or end-of-line character conversion
necessary for proper internationalized headers; it only does dumb encoding and
decoding.  To deal with the various line wrapping issues, use the email.header
module.
<module email.base64mime>=?%s?b?%s?=Return the content-transfer-encoding used for body encoding.

        This is either the string `quoted-printable' or `base64' depending on
        the encoding used, or it is a function in which case you should call
        the function with a single argument, the Message object being
        encoded.  The function should then set the Content-Transfer-Encoding
        header itself to whatever is appropriate.

        Returns "quoted-printable" if self.body_encoding is QP.
        Returns "base64" if self.body_encoding is BASE64.
        Returns conversion function otherwise.
        SHORTESTCharset.header_encode_linesRFC2047_CHROME_LENAdd a codec that map characters in the given charset to/from Unicode.

    charset is the canonical name of a character set.  codecname is the name
    of a Python codec, as appropriate for the second argument to the unicode()
    built-in, or to the encode() method of a Unicode string.
    Charset.__init__iso-8859-9add_codeceuc-jpCharset._get_encoderthis_lineiso-8859-10Map character sets to their email properties.

    This class provides information about the requirements imposed on email
    for a specific character set.  It also provides convenience routines for
    converting between character sets, given the availability of the
    applicable codecs.  Given a character set, it will do its best to provide
    information on how to use that character set in an email in an
    RFC-compliant way.

    Certain character sets must be encoded with quoted-printable or base64
    when used in email headers or bodies.  Certain character sets must be
    converted outright, and are not allowed in email.  Instances of this
    module expose the following information about a character set:

    input_charset: The initial character set specified.  Common aliases
                   are converted to their `official' email names (e.g. latin_1
                   is converted to iso-8859-1).  Defaults to 7-bit us-ascii.

    header_encoding: If the character set must be encoded before it can be
                     used in an email header, this attribute will be set to
                     Charset.QP (for quoted-printable), Charset.BASE64 (for
                     base64 encoding), or Charset.SHORTEST for the shortest of
                     QP or BASE64 encoding.  Otherwise, it will be None.

    body_encoding: Same as header_encoding, but describes the encoding for the
                   mail message's body, which indeed may be different than the
                   header encoding.  Charset.SHORTEST is not allowed for
                   body_encoding.

    output_charset: Some character sets must be converted before they can be
                    used in email headers or bodies.  If the input_charset is
                    one of them, this attribute will contain the name of the
                    charset output will be converted to.  Otherwise, it will
                    be None.

    input_codec: The name of the Python codec used to convert the
                 input_charset to Unicode.  If no conversion codec is
                 necessary, this attribute will be None.

    output_codec: The name of the Python codec used to convert Unicode
                  to the output_charset.  If no conversion codec is necessary,
                  this attribute will have the same value as the input_codec.
    iso-8859-14SHORTEST not allowed for body_encCODEC_MAPBody-encode a string by converting it first to bytes.

        The type of encoding (base64 or quoted-printable) will be based on
        self.body_encoding.  If body_encoding is None, we assume the
        output charset is a 7bit encoding, so re-encoding the decoded
        string using the ascii codec produces the correct string version
        of the content.
        gb2312eucgb2312_cnbig5big5_twDEFAULT_CHARSETjoined_lineadd_charsetlen64Add character set properties to the global registry.

    charset is the input character set, and must be the canonical name of a
    character set.

    Optional header_enc and body_enc is either Charset.QP for
    quoted-printable, Charset.BASE64 for base64 encoding, Charset.SHORTEST for
    the shortest of qp or base64 encoding, or None for no encoding.  SHORTEST
    is only valid for header_enc.  It describes how message headers and
    message bodies in the input charset are to be encoded.  Default is no
    encoding.

    Optional output_charset is the character set that the output should be
    in.  Conversions will proceed from input charset, to Unicode, to the
    output charset when the method Charset.convert() is called.  The default
    is to output in the same character set as the input.

    Both input_charset and output_charset must have Unicode codec entries in
    the module's charset-to-codec mapping; use add_codec(charset, codecname)
    to add codecs the module does not know about.  See the codecs module's
    documentation for more information.
    iso-8859-3Add a character set alias.

    alias is the alias name, e.g. latin-1
    canonical is the character set's canonical name, e.g. iso-8859-1
    add_aliasencoder_moduleûzlatin_1z
iso-8859-1zlatin-1z
iso-8859-1zlatin_2z
iso-8859-2zlatin-2z
iso-8859-2zlatin_3z
iso-8859-3zlatin-3z
iso-8859-3zlatin_4z
iso-8859-4zlatin-4z
iso-8859-4zlatin_5z
iso-8859-9zlatin-5z
iso-8859-9zlatin_6ziso-8859-10zlatin-6ziso-8859-10zlatin_7ziso-8859-13zlatin-7ziso-8859-13zlatin_8ziso-8859-14zlatin-8ziso-8859-14zlatin_9ziso-8859-15zlatin-9ziso-8859-15zlatin_10ziso-8859-16zlatin-10ziso-8859-16zcp949zks_c_5601-1987zeuc_jpzeuc-jpzeuc_krzeuc-krzasciizus-ascii0<module email.charset>lenqpCHARSETSCharset.__eq__Header-encode a string by converting it first to bytes.

        This is similar to `header_encode()` except that the string is fit
        into maximum line lengths as given by the argument.

        :param string: A unicode string for the header.  It must be possible
            to encode this string to bytes using the character set's
            output codec.
        :param maxlengths: Maximum line length iterator.  Each element
            returned from this iterator will provide the next maximum line
            length.  This parameter is used as an argument to built-in next()
            and should never be exhausted.  The maximum line lengths should
            not count the RFC 2047 chrome.  These line lengths are only a
            hint; the splitter does the best it can.
        :return: Lines of encoded strings, each with RFC 2047 chrome.
        current_lineshift_jisHeader-encode a string by converting it first to bytes.

        The type of encoding (base64 or quoted-printable) will be based on
        this charset's `header_encoding`.

        :param string: A unicode string for the header.  It must be possible
            to encode this string to bytes using the character set's
            output codec.
        :return: The encoded string, with RFC 2047 chrome.
        Charset.body_encodekoi8-rCharset.__str__Charset.get_body_encodingiso-2022-jpC:\msys64\mingw64\lib\python3.6\email\charset.pyvisciiCharset.get_output_charsetwindows-1252Return the output character set.

        This is self.output_charset if that is not None, otherwise it is
        self.input_charset.
        _encode_text.<locals>.<genexpr>ContentManager.add_get_handlerget_text_contentC:\msys64\mingw64\lib\python3.6\email\contentmanager.pymessage/Invalid header: {}typekeyget_non_text_contentUnknown content transfer encoding {}full_path_for_error_encode_text.<locals>.embedded_bodyset_text_contentset_handlersset_message_contentnormal_bodysniffsniff_qpsniff_base64unencoded_bytes_per_lineadd_set_handlermessage/rfc822 parts do not support cte={}_finalize_setget_and_fixup_unknown_message_content_prepare_setContentManager.add_set_handlerset_bytes_contentaudio image video application_find_set_handlerexternal-bodyrfc822 external-bodyget_message_contentContent-IDset_content not valid on multipart_encode_text.<locals>.normal_body<module email.contentmanager>message/partial is not supported for Message objectsmessage/external-body parts do not support cte={}ContentManager.__init__ContentManager._find_set_handlerContentManager.set_contentget_handlersContentManager.get_contentencdataEncode the message's payload in quoted-printable.

    Also, add an appropriate Content-Transfer-Encoding header.
    Encode the message's payload in Base64.

    Also, add an appropriate Content-Transfer-Encoding header.
    C:\msys64\mingw64\lib\python3.6\email\encoders.py_encodestringencode_noopencode_quopriencode_base64Do nothing._qencode<module email.encoders>Set the Content-Transfer-Encoding header to 7bit or 8bit.Encodings and related functions.HeaderDefect.__init__A message claimed to be a multipart but had no boundary parameter.MessageErroremail package exception classes.C:\msys64\mingw64\lib\python3.6\email\errors.py<module email.errors>base64 encoded sequence had characters not in base64 alphabetAn illegal charset was given.Error while parsing headers.An invalid content transfer encoding was set on the multipart itself.A 'Unix-from' header was found in the middle of a header block.MalformedHeaderDefectBase class for message parsing errors.the following ASCII non-printables found in header: {}base64 encoded sequence had an incorrect lengthNonPrintableDefect.__str__A message claimed to be a multipart but no subparts were found.MessageParseErrorlocal_part contains non-ASCII charactersBase class for errors in the email package.Conversion to a multipart is prohibited.Header uses syntax declared obsolete by RFC 5322ASCII characters outside the ascii-printable range foundA start boundary was found, but not the corresponding close boundary.The claimed start boundary was never found.BoundaryErrorCouldn't find terminating boundary.A message had a continuation line as its first header line.A header that must have a value had noneHeader contained bytes that could not be decodedMessageDefect.__init__Base class for a message defect.Found line with no leading whitespace and no colon before blank line.NonPrintableDefect.__init__MultipartConversionErrorHeader is not valid, message gives details.Base class for a header defect.BufferedSubFile.__iter__Parse all remaining data and return the root message object._new_message_parse_headersFeedParser._new_message_headersonlyC:\msys64\mingw64\lib\python3.6\email\feedparser.pyFrom _msgstackmessage/delivery-statusBufferedSubFile.pushlinesLike FeedParser, but feed accepts bytes.ateofFeedParser._call_parseFeedParser - An email feed parser.

The feed parser implements an interface for incrementally parsing an email
message, line by line.  This has advantages for certain applications, such as
those reading email messages off a socket.

FeedParser.feed() is the primary interface for pushing new data into the
parser.  It returns when there's nothing more it can do with the available
data.  When you have no more data to push into the parser, call .close().
This completes the parsing and returns the root message object.

The other advantage of this parser is that it will never raise a parsing
exception.  Instead, when it finds something unexpected, it adds a 'defect' to
the current message.  Defects are just instances that live on the message
object's .defects attribute.
BufferedSubFile.__init__(\r\n|\r|\n)\ZA feed-style parser of email._eofstackFeedParser._set_headersonly<module email.feedparser>_factory is called with no arguments to create a new message obj

        The policy keyword specifies a policy object that controls a number of
        aspects of the parser's operation.  The default policy maintains
        backward compatibility.

        multipart/digestBufferedSubFile.closeBufferedSubFile.__next__©ÚselfÚheadersÚlineÚdefectÚlinesÚretvalÚmsgÚboundaryÚ	separatorÚ
boundaryreÚcapturing_preambleÚpreambleÚlinesepÚclose_boundary_seenÚmoÚlastlineÚeolmoÚepilogueÚendÚpayloadÚ	firstlineÚbolmoBufferedSubFile.push_eof_matcherBufferedSubFile.unreadlineFeedParser._parse_headers_parsegenlastheaderNeedMoreDataPush some new data into this object.Push more data into the parser.NLCRE_eolMissing header name._parse_headers fed line with no : and no leading WSBufferedSubFile.readlineFeedParser.__init__A file-ish object that can have new data loaded into it.

    You can also push and pop line-matching predicates onto a stack.  When the
    current predicate matches the current line, a false EOF response
    (i.e. empty string) is returned instead.  This lets the parser adhere to a
    simple abstraction -- it parses until EOF closes the current message.
    ^(From |[\041-\071\073-\176]*:|[\t ])headerREFeedParser._pop_messageFeedParser._parsegenBufferedSubFile.pop_eof_matcherNLCRE_crackFeedParser.closelastvalueNLCRE_bol(?P<sep>BytesFeedParser.feed)(?P<end>--)?(?P<ws>[ \t]*)(?P<linesep>\r\n|\r|\n)?$_old_style_factory[no encoding]_handle_message_delivery_statusBytesGenerator.writeContent-Description[no description]_encoded_NLGenerator._handle_message_delivery_statusBytesGenerator._write_headers_encoded_EMPTYGenerator._handle_textDecodedGenerator._dispatchsfpGenerator.flattenoldfpmunge_cte^From _mangle_from_Like Generator.__init__() except that an additional optional
        argument is allowed.

        Walks through all subparts of a message.  If the subpart is of main
        type `text', then it prints the decoded payload of the subpart.

        Otherwise, fmt is a format string that is used instead of the message
        payload.  fmt is expanded with the following keywords (in
        %(keyword)s format):

        type       : Full MIME type of the non-text part
        maintype   : Main MIME type of the non-text part
        subtype    : Sub-MIME type of the non-text part
        filename   : Filename of the non-text part
        description: Description associated with the non-text part
        encoding   : Content transfer encoding of the non-text part

        The default value for fmt is None, meaning

        [Non-text (%(type)s) part of message omitted, filename %(filename)s]
        BytesGenerator._handle_text(--)?$Generates output from a Message object tree.

    This basic generator writes the message to the given file object as plain
    text.
    Clone this generator with the exact same options.Generator._handle_multipart_signedstring payload expected: %sCreate the generator for message flattening.

        outfp is the output file-like object for writing the message to.  It
        must have a write() method.

        Optional mangle_from_ is a flag that, when True (the default if policy
        is not set), escapes From_ lines in the body of the message by putting
        a `>' in front of them.

        Optional maxheaderlen specifies the longest length for a non-continued
        header.  When a header line is longer (in characters, with tabs
        expanded to 8 spaces) than maxheaderlen, the header will split as
        defined in the Header class.  Set maxheaderlen to zero to disable
        header wrapping.  The default is 78, as recommended (but not required)
        by RFC 2822.

        The policy keyword specifies a policy object that controls a number of
        aspects of the generator's operation.  If no policy is specified,
        the policy associated with the Message object passed to the
        flatten method is used.

        old_msg_policy>From old_gen_policyufromUNDERSCOREbody_partGenerates a text representation of a message.

    Like the Generator base class, except that non-text parts are substituted
    with a format string representing the part.
    [no filename]_munge_cte%%0%ddPrint the message object tree rooted at msg to the output file
        specified when the Generator instance was created.

        unixfrom is a flag that forces the printing of a Unix From_ delimiter
        before the first object in the message tree.  If the original message
        has no From_ delimiter, a `standard' one is crafted.  By default, this
        is False to inhibit the printing of any From_ delimiter.

        Note that for subobjects, no From_ line is printed.

        linesep specifies the characters used to indicate a new line in
        the output.  The default value is determined by the policy specified
        when the Generator instance was created or, if none was specified,
        from the policy associated with the msg.

        C:\msys64\mingw64\lib\python3.6\email\generator.pyBytesGenerator._new_buffer_FMTBytesGenerator._encodemsgtextsalltextGenerator._make_boundaryGenerator.cloneFrom nobody _compile_reDecodedGenerator.__init__Classes to generate plain text from a message object tree.Generator._write_linesBytesGenerator._compile_re^--Generates a bytes version of a Message object tree.

    Functionally identical to the base Generator except that the output is
    bytes and not string.  When surrogates were used in the input to encode
    bytes, these are decoded back to bytes for output.  If the policy has
    cte_type set to 7bit, then the message is transformed such that the
    non-ASCII bytes are properly content transfer encoded, using the charset
    unknown-8bit.

    The outfp object must accept bytes in its write method.
    <module email.generator>_writeBodydecode_headerHeader._nonctextdecoded_seq_current_linecontinuation_wslastcsend_of_line_continuation_ws_lensplitcharsprevpartpop_fromC:\msys64\mingw64\lib\python3.6\email\header.pyCreate a MIME-compliant header that can contain many character sets.

        Optional s is the initial header value.  If None, the initial header
        value is not set.  You can later append to the header with .append()
        method calls.  s may be a byte string or a Unicode string, but see the
        .append() documentation for semantics.

        Optional charset serves two purposes: it has the same meaning as the
        charset argument to the .append() method.  It also sets the default
        character set for all subsequent .append() calls that omit the charset
        argument.  If charset is not provided in the constructor, the us-ascii
        charset is used both as s's initial charset and as the default for
        subsequent .append() calls.

        The maximum line length can be specified explicitly via maxlinelen. For
        splitting the first line to a shorter value (to account for the field
        header which isn't included in s, e.g. `Subject') pass in the name of
        the field in header_name.  The default maxlinelen is 78 as recommended
        by RFC 2822.

        continuation_ws must be RFC 2822 compliant folding whitespace (usually
        either a space or a hard tab) which will be prepended to continuation
        lines.

        errors is passed through to the .append() call.
        make_header_ValueFormatter._ascii_splitinitial_sizeHeader.__str___Accumulator.__len___splitcharsReturn the string value of the header._ValueFormatter._str[\041-\176]+:$_ValueFormatter.add_transitionCreate a Header from a sequence of pairs as returned by decode_header()

    decode_header() takes a header value string and returns a sequence of
    pairs of the format (decoded_string, charset) where charset is the string
    name of the character set.

    This function takes one of those sequence of pairs and returns a Header
    instance.  Optional maxlinelen, header_name, and continuation_ws are as in
    the Header constructor.
    last_charset_ValueFormatter._maxlengths
  =\?                   # literal =?
  (?P<charset>[^?]*?)   # non-greedy up to the next ? is the charset
  \?                    # literal ?
  (?P<encoding>[qb])    # either a "q" or a "b", case insensitive
  \?                    # literal ?
  (?P<encoded>.*?)      # non-greedy up to the next ?= is the encoded string
  \?=                   # literal ?=
  _ValueFormatter.newline<module email.header>©ÚheaderÚwordsÚlineÚpartsÚfirstÚ	unencodedÚcharsetÚencodingÚencodedÚdroplistÚnÚwÚdÚdecoded_wordsÚencoded_stringÚwordÚpaderrÚ	collapsedÚ	last_wordÚlast_charset_append_chunk_ValueFormatter.__str___ValueFormatter._append_chunk_Accumulator.popis_onlywsHeader._normalize_Accumulator.__len__.<locals>.<genexpr>Header.encodeUnexpected encoding: Header.__eq__uchunkslastspacenextcshasspaceDecode a message header value without converting charset.

    Returns a list of (string, charset) pairs containing each of the decoded
    parts of the header.  Charset is None for non-encoded parts of the header,
    otherwise a lower-case string containing the name of the character set
    specified in the encoded string.

    header may be a string that may or may not contain RFC2047 encoded words,
    or it may be a Header object.

    An email.errors.HeaderParseError may be raised when certain decoding error
    occurs (e.g. a base64 decoding exception).
    _embedded_header_Accumulator.__str__Header encoding and decoding functionality._Accumulator.reset_Accumulator.part_countlast_chunk_Accumulator.__init___Accumulator.pushTrue if string s is not a ctext character of RFC822.
        \n[^ \t]+:_maxlinelenHeader.__init___ValueFormatter.__init__Header.append_initial_size_ValueFormatter.feed_Accumulator.pop_from_Accumulator.is_onlyws;, 	_headerlenAppend a string to the MIME header.

        Optional charset, if given, should be a Charset instance or the name
        of a character set (which will be converted to a Charset instance).  A
        value of None (the default) means that the charset given in the
        constructor is used.

        s may be a byte string or a Unicode string.  If it is a byte string
        (i.e. isinstance(s, str) is false), then charset is the encoding of
        that byte string, and a UnicodeError will be raised if the string
        cannot be decoded with that charset.  If s is a Unicode string, then
        charset is a hint specifying the character set of the characters in
        the string.  In either case, when producing an RFC 2822 compliant
        header using RFC 2047 rules, the string will be encoded using the
        output codec of the charset.  If the string cannot be encoded to the
        output codec, a UnicodeError will be raised.

        Optional `errors' is passed as the errors argument to the decode
        call if s is a byte string.
        SPACE8MAXLINELENheader value appears to contain an embedded header: {!r}Base64 decoding errorstartvalEncode a message header into an RFC-compliant format.

        There are many issues involved in converting a given string for use in
        an email header.  Only certain character sets are readable in most
        email clients, and as header strings can only contain a subset of
        7-bit ASCII, care must be taken to properly convert and encode (with
        Base64 or quoted-printable) header strings.  In addition, there is a
        75-character length limit on any given encoded header field, so
        line-wrapping must be performed, even with double-byte character sets.

        Optional maxlinelen specifies the maximum length of each generated
        line, exclusive of the linesep string.  Individual lines may be longer
        than maxlinelen if a folding point cannot be found.  The first line
        will be shorter by the length of the header name plus ": " if a header
        name was specified at Header construction time.  The default value for
        maxlinelen is determined at header construction time.

        Optional splitchars is a string containing characters which should be
        given extra weight by the splitting algorithm during normal header
        wrapping.  This is in very rough support of RFC 2822's `higher level
        syntactic breaks':  split points preceded by a splitchar are preferred
        during line splitting, with the characters preferred in the order in
        which they appear in the string.  Space and tab may be included in the
        string to indicate whether preference should be given to one over the
        other as a split point when other split chars do not appear in the line
        being split.  Splitchars does not affect RFC 2047 encoded lines.

        Optional linesep is a string to be used to separate the lines of
        the value.  The default value is the most useful for typical
        Python applications, but it can be set to \r\n to produce RFC-compliant
        line separators when needed.
        _Accumulator.__str__.<locals>.<genexpr>BSPACEUSASCIIBase class for message headers.

    Implements generic behavior and provides tools for subclasses.

    A subclass must define a classmethod named 'parse' that takes an unfolded
    value string and a dictionary as its arguments.  The dictionary will
    contain one key, 'defects', initialized to an empty list.  After the call
    the dictionary must contain two additional keys: parse_tree, set to the
    parse tree obtained from parsing the header, and 'decoded', set to the
    string value of the idealized representation of the data from the value.
    (That is, encoded words are decoded, and values that have canonical
    representations are so represented.)

    The defects key is intended to collect parsing defects, which the message
    parser will subsequently dispose of as appropriate.  The parser should not,
    insofar as practical, raise any errors.  Defects should be added to the
    list instead.  The standard header parsers register defects for RFC
    compliance issues, for obsolete RFC syntax, and for unrecoverable parsing
    errors.

    The parse method may add additional keys to the dictionary.  In this case
    the subclass must define an 'init' method, which will be passed the
    dictionary as its keyword arguments.  The method should use (usually by
    setting them as the value of similarly named attributes) and remove all the
    extra keys added by its parse method, and then use super to call its parent
    class with the remaining arguments and keywords.

    The subclass should also make sure that a 'max_count' attribute is defined
    that is either None or 1. XXX: need to better define this API.

    resent-tosenderMIMEVersionHeaderRepresenting and manipulating email headers via custom objects.

This module provides an implementation of the HeaderRegistry API.
The implementation is designed to flexibly follow RFC5322 rules.

Eventually HeaderRegistry will be a public API, but it isn't yet,
and will probably change some before that happens.

map_to_typeHeaderRegistry.__getitem__DateHeader.parseBaseHeader.defects_default_header_mapAddress.domainAddressHeader.initC:\msys64\mingw64\lib\python3.6\email\headerregistry.pySingleAddressHeaderParameterizedMIMEHeaderresent-ccUnstructuredHeaderheader-nameAddressHeader.parseUniqueUnstructuredHeaderresent-senderContentTypeHeaderContentTypeHeader.maintypethis should not happenadrstr_addressesuse_default_mapBaseHeader.nameMIMEVersionHeader.version_content_dispositionDateHeader.datetimeCreate a header instance for header 'name' from 'value'.

        Creates a header instance by creating a specialized class for parsing
        and representing the specified header by combining the factory
        base_class with a specialized class from the registry or the
        default_class, and passing the name and value to the constructed
        class's constructor.

        ContentTypeHeader.content_typeFold header according to policy.

        The parsed representation of the header is folded according to
        RFC5322 rules, as modified by the policy.  If the parse tree
        contains surrogateescaped bytes, the bytes are CTE encoded using
        the charset 'unknown-8bit".

        Any non-ASCII characters in the parse tree are CTE encoded using
        charset utf-8. XXX: make this a policy setting.

        The returned value is an ASCII-only string possibly containing linesep
        characters, and ending with a linesep character.  The string includes
        the header name and the ': ' separator.

        HeaderRegistry.map_to_typeMIMEVersionHeader.parseBaseHeader.initheader-sepSingleAddressHeader.address_reconstruct_headerGroup.addressesContentTransferEncodingHeader.cte{}:{};HeaderRegistry.__call__Address.usernameContentTypeHeader.initBaseHeader.__reduce__Group.__eq__value of single address header {} is not a single address_minorRegister cls as the specialized class for handling "name" headers.

        AddressHeader.groupsMIMEVersionHeader.minorDateHeader.initContentDispositionHeader.content_dispositionAddress.__init__{}(display_name={!r}, username={!r}, domain={!r})Create an object representing a full email address.

        An address can have a 'display_name', a 'username', and a 'domain'.  In
        addition to specifying the username and domain separately, they may be
        specified together by using the addr_spec keyword *instead of* the
        username and domain keywords.  If an addr_spec string is specified it
        must be properly quoted according to RFC 5322 rules; an error will be
        raised if it is not.

        An Address object has display_name, username, domain, and addr_spec
        attributes, all of which are read-only.  The addr_spec and the string
        value of the object are both quoted according to RFC5322 rules, but
        without any Content Transfer Encoding.

        orig-dateMIMEVersionHeader.majorHeader whose value consists of a single timestamp.

    Provides an additional attribute, datetime, which is either an aware
    datetime using a timezone, or a naive datetime if the timezone
    in the input string is -0000.  Also accepts a datetime as input.
    The 'value' attribute is the normalized form of the timestamp,
    which means it is the output of format_datetime on the datetime.
    BaseHeader.foldUnstructuredHeader.parseParameterizedMIMEHeader.parseresent-from_majorBaseHeader.__new__ParameterizedMIMEHeader.initContentTypeHeader.subtypeContentTransferEncodingHeader.initAddress.__repr__UniqueAddressHeaderreply-toAddressHeader.value_parserBaseHeader._reconstructGroup.__str__Create a header_factory that works with the Policy API.

        base_class is the class that will be the last class in the created
        header class's __bases__ list.  default_class is the class that will be
        used if "name" (see __call__) does not appear in the registry.
        use_default_map controls whether or not the default mapping of names to
        specialized classes is copied in to the registry when the factory is
        created.  The default is True.

        _usernameUniqueSingleAddressHeaderresent-bccAddress.addr_specContentTransferEncodingHeader.parseA header_factory and header registry.ContentDispositionHeader.initGroup.__repr__UniqueDateHeaderMIMEVersionHeader.initAddress.__eq__Invalid addr_spec; only '{}' could be parsed from '{}'{} <{}>Address.__str___maintype<module email.headerregistry>ParameterizedMIMEHeader.paramsresent-dateaddrspec specified when username and/or domain also specifiedCreate an object representing an address group.

        An address group consists of a display_name followed by colon and a
        list of addresses (see Address) terminated by a semi-colon.  The Group
        is created by specifying a display_name and a possibly empty list of
        Address objects.  A Group can also be used to represent a single
        address that is not in a group, which is convenient when manipulating
        lists that are a combination of Groups and individual Addresses.  In
        this case the display_name should be set to None.  In particular, the
        string representation of a Group whose display_name is None is the same
        as the Address object, if there is one and only one Address object in
        the addresses list.

        AddressHeader.addressesGroup.__str__.<locals>.<genexpr>{}(display_name={!r}, addresses={!r}HeaderRegistry.__init__The addr_spec (username@domain) portion of the address, quoted
        according to RFC 5322 rules, but with no Content Transfer Encoding.
        body_line_iteratortyped_subpart_iteratorinclude_defaultA handy debugging aidVarious types of useful iterators and generators. [%s]Iterate over the parts, returning string payloads line-by-line.

    Optional decode (default False) is passed through to .get_payload().
    _structureWalk over the message tree, yielding each subpart.

    The walk is performed in depth-first order.  This method is a
    generator.
    Iterate over the subparts with a given MIME type.

    Use `maintype' as the main MIME type to match against; this defaults to
    "text".  Optional `subtype' is the MIME subtype to match against; if
    omitted, only the main type is matched.
    C:\msys64\mingw64\lib\python3.6\email\iterators.py<module email.iterators>failobjdisallowed_subtypesMIMEPart.as_stringReturn the parameter value if found in the Content-Type header.

        Optional failobj is the object to return if there is no Content-Type
        header, or the Content-Type header has no such parameter.  Optional
        header is the header to search instead of Content-Type.

        Parameter keys are always compared case insensitively.  The return
        value can either be a string, or a 3-tuple if the parameter was RFC
        2231 encoded.  When it's a 3-tuple, the elements of the value are of
        the form (CHARSET, LANGUAGE, VALUE).  Note that both CHARSET and
        LANGUAGE can be None, in which case you should consider VALUE to be
        encoded in the us-ascii charset.  You can usually ignore LANGUAGE.
        The parameter value (either the returned string, or the VALUE item in
        the 3-tuple) is always unquoted, unless unquote is set to False.

        If your application doesn't care whether the parameter was RFC 2231
        encoded, it can turn the return value into a string as follows:

            rawparam = msg.get_param('foo')
            param = email.utils.collapse_rfc2231_value(rawparam)

        _find_bodymake_mixedMessage.get_unixfrom<module email.message>_body_typesMessage.set_charsetMessage.__init__Message.__contains__Return a reference to the payload.

        The payload will either be a list object or a string.  If you mutate
        the list object, you modify the message's payload in place.  Optional
        i returns that index into the payload.

        Optional decode is a flag indicating whether the payload should be
        decoded or not, according to the Content-Transfer-Encoding header
        (default is False).

        When True and the message is not a multipart, the payload will be
        decoded if this header's value is `quoted-printable' or `base64'.  If
        some other encoding is used, or the header is missing, or if the
        payload has bogus data (i.e. bogus base64 or uuencoded data), the
        payload is returned as-is.

        If the message is a multipart and the decode flag is True, then None
        is returned.
        Message.get_charsetMessage.valuesrequotenew_ctypeMessage.as_bytesGet a header value.

        Like __getitem__() but return failobj instead of None when the field
        is missing.
        Set the value of a header.

        Note: this does not overwrite an existing header with the same field
        name.  Use __delitem__() first to delete any existing headers.
        Message.get_filenameReturn an iterator over the non-main parts of a multipart.

        Skip the first of each occurrence of text/plain, text/html,
        multipart/related, or multipart/alternative in the multipart (unless
        they have a 'Content-Disposition: attachment' header) and include all
        remaining subparts in the returned iterator.  When applied to a
        multipart/related, return all parts except the root part.  Return an
        empty iterator when applied to a multipart/alternative or a
        non-multipart.
        del_paramMIMEPart.clearReturn a list of all the values for the named field.

        These will be sorted in the order they appeared in the original
        message, and may contain duplicates.  Any fields deleted and
        re-inserted are always appended to the header list.

        If no such fields exist, failobj is returned (defaults to None).
        Return the entire formatted message as a bytes object.
        Message.set_boundaryMessage.get_paramGet all the message's header fields and values.

        These will be sorted in the order they appeared in the original
        message, or were added to the message, and may contain duplicates.
        Any fields deleted and re-inserted are always appended to the header
        list.
        MIMEPart._add_multipartget_content_charsetappend_paramMessage.del_paramMessage.get_content_subtypeStore name and value in the model without modification.

        This is an "internal" API, intended only for use by a parser.
        Return the (name, value) header pairs without modification.

        This is an "internal" API, intended only for use by a generator.
        Message.get_boundarySEMISPACEReturn the message's Content-Type parameters, as a list.

        The elements of the returned list are 2-tuples of key/value pairs, as
        split on the `=' sign.  The left hand side of the `=' is the key,
        while the right hand side is the value.  If there is no `=' sign in
        the parameter the value is the empty string.  The value is as
        described in the get_param() method.

        Optional failobj is the object to return if there is no Content-Type
        header.  Optional header is the header to search instead of
        Content-Type.  If unquote is True, the value is unquoted.
        best_prioReturn the entire formatted message as a string.
        iter_partsSet a parameter in the Content-Type header.

        If the parameter already exists in the header, its value will be
        replaced with the new value.

        If header is Content-Type and has not yet been defined for this
        message, it will be set to "text/plain" and the new parameter and
        value will be appended as per RFC 2045.

        An alternate header can be specified in the header argument, and all
        parameters will be quoted as necessary unless requote is False.

        If charset is specified, the parameter will be encoded according to RFC
        2231.  Optional language specifies the RFC 2231 language, defaulting
        to the empty string.  Both charset and language should be strings.
        Delete all occurrences of a header, if present.

        Does not raise an exception if the header is missing.
        Message.get_paramsGet a header value.

        Return None if the header is missing instead of raising an exception.

        Note that if the header appeared multiple times, exactly which
        occurrence gets returned is undefined.  Use get_all() to get all
        the values matching a header field name.
        pcharsetReturn a list of all the message's header values.

        These will be sorted in the order they appeared in the original
        message, or were added to the message, and may contain duplicates.
        Any fields deleted and re-inserted are always appended to the header
        list.
        MIMEPart.get_contentReturn the entire formatted message as a bytes object.

        Optional 'unixfrom', when true, means include the Unix From_ envelope
        header.  'policy' is passed to the BytesGenerator instance used to
        serialize the message; if not specified the policy associated with
        the message instance is used.
        Message.get_content_charsetSet the main type and subtype for the Content-Type header.

        type must be a string in the form "maintype/subtype", otherwise a
        ValueError is raised.

        This method replaces the Content-Type header, keeping all the
        parameters in place.  If requote is False, this leaves the existing
        header's quoting as is.  Otherwise, the parameters will be quoted (the
        default).

        An alternative header can be specified in the header argument.  When
        the Content-Type header is set, we'll always also add a MIME-Version
        header.
        MIMEPart._make_multipartMessage.set_payloadkeep_headersexisting_subtypepart_headersSet the boundary parameter in Content-Type to 'boundary'.

        This is subtly different than deleting the Content-Type header and
        adding a new one with a new boundary parameter via add_header().  The
        main difference is that using the set_boundary() method preserves the
        order of the Content-Type header in the original message.

        HeaderParseError is raised if the message has no Content-Type header.
        Return the message's content type.

        The returned string is coerced to lower case of the form
        `maintype/subtype'.  If there was no Content-Type header in the
        message, the default type as given by get_default_type() will be
        returned.  Since according to RFC 2045, messages always have a default
        type this will always return a value.

        RFC 2045 defines a message's default type to be text/plain unless it
        appears inside a multipart/digest container, in which case it would be
        message/rfc822.
        MIMEPart.iter_attachmentsbpayloadSet the charset of the payload to a given character set.

        charset can be a Charset instance, a string naming a character set, or
        None.  If it is a string it will be converted to a Charset instance.
        If charset is None, the charset parameter will be removed from the
        Content-Type field.  Anything else will generate a TypeError.

        The message will be assumed to be of type text/* encoded with
        charset.input_charset.  It will be converted to charset.output_charset
        and encoded properly, if needed, when generating the plain text
        representation of the message.  MIME headers (MIME-Version,
        Content-Type, Content-Transfer-Encoding) will be added as needed.
        x-uuencodeMessage.add_headerMessage.keysReturns the message's sub-content type.

        This is the `subtype' part of the string returned by
        get_content_type().
        MIMEPart.__init__Message.attachpreferencelistold_paramMessage.get_charsetsReturn the entire formatted message as a string.

        Optional 'unixfrom', when true, means include the Unix From_ envelope
        header.  For backward compatibility reasons, if maxheaderlen is
        not specified it defaults to 0, so you must override it explicitly
        if you want a different maxheaderlen.  'policy' is passed to the
        Generator instance used to serialize the mesasge; if it is not
        specified the policy associated with the message instance is used.

        If the message object contains binary data that is not encoded
        according to RFC standards, the non-compliant data will be replaced by
        unicode "unknown character" code points.
        Expected list, got %scontent-idMessage.__bytes__Message.replace_headerMessage.get_content_dispositionnewparamsfoundppkMIMEPart.iter_partsMessage.__getitem__Message.get_content_maintypeMIMEPart.add_relatedReturn the entire formatted message as a string.

        Optional 'unixfrom', when true, means include the Unix From_ envelope
        header.  maxheaderlen is retained for backward compatibility with the
        base Message class, but defaults to None, meaning that the policy value
        for max_line_length controls the header maximum length.  'policy' is
        passed to the Generator instance used to serialize the mesasge; if it
        is not specified the policy associated with the message instance is
        used.
        MIMEPart.make_mixedNo Content-Type header foundMIMEPart.clear_contentReturn the message's main content type.

        This is the `maintype' part of the string returned by
        get_content_type().
        Message.__str__Return a list containing the charset(s) used in this message.

        The returned list of items describes the Content-Type headers'
        charset parameter for this message and all the subparts in its
        payload.

        Each item will either be a string (the value of the charset parameter
        in the Content-Type header of that part) or the value of the
        'failobj' parameter (defaults to None), if the part does not have a
        main MIME type of "text", or the charset is not defined.

        The list will contain one string for each part of the message, plus
        one for the container message (i.e. self), so that a non-multipart
        message will still return a list of length 1.
        Message.as_stringReturn best candidate mime part for display as 'body' of message.

        Do a depth first search, starting with self, looking for the first part
        matching each of the items in preferencelist, and return the part
        corresponding to the first item that has a match, or None if no items
        have a match.  If 'related' is not included in preferencelist, consider
        the root part of any multipart/related encountered as a candidate
        match.  Ignore parts with 'Content-Disposition: attachment'.
        Return True if the message consists of multiple parts.MIMEPart.is_attachmentMessage.__iter__Message.get_default_typeRemove the given parameter completely from the Content-Type header.

        The header will be re-written in place without the parameter or its
        value. All values will be quoted as necessary unless requote is
        False.  Optional header specifies an alternative to the Content-Type
        header.
        Set the payload to the given value.

        Optional charset sets the message's default character set.  See
        set_charset() for details.
        Message.items_parseparamReturn the message's content-disposition if it exists, or None.

        The return values can be either 'inline', 'attachment' or None
        according to the rfc2183.
        MIMEPart.get_body%s="%s"EmailMessage.set_content[ \(\)<>@,;:\\"/\[\]\?=]C:\msys64\mingw64\lib\python3.6\email\message.pyMessage._get_params_preserveMIMEPart.set_contentMessage.__delitem__Message.set_default_typeConvenience function to format and return a key=value pair.

    This will quote the value if needed or if quote is true.  If value is a
    three tuple (charset, language, value), it will be encoded according
    to RFC2231 rules.  If it contains non-ascii characters it will likewise
    be encoded according to RFC2231 rules, using the utf-8 charset and
    a null language.
    Replace a header.

        Replace the first matching header found in the message, retaining
        header order and case.  If no matching header was found, a KeyError is
        raised.
        Cannot convert {} to {}Basic message object for the email package object model.MIMEPart.make_relatedMessage.set_typeBasic message object.

    A message object is defined as something that has a bunch of RFC 2822
    headers and a payload.  It may optionally have an envelope header
    (a.k.a. Unix-From or From_ header).  If the message is a container (i.e. a
    multipart or a message/rfc822), then the payload is a list of Message
    objects, otherwise it is a string.

    Message objects implement part of the `mapping' interface, which assumes
    there is exactly one occurrence of the header per message.  Some headers
    do in fact appear multiple times (e.g. Received) and for those headers,
    you must use the explicit API to set or get all the headers.  Not all of
    the mapping methods are implemented.
    Set the `default' content type.

        ctype should be either "text/plain" or "message/rfc822", although this
        is not enforced.  The default content type is not stored in the
        Content-Type header.
        Message.get_allThere may be at most {} {} headers in a messageReturn the boundary associated with the payload if present.

        The boundary is extracted from the Content-Type header's `boundary'
        parameter, and it is unquoted.
        Return the filename associated with the payload if present.

        The filename is extracted from the Content-Disposition header's
        `filename' parameter, and it is unquoted.  If that header is missing
        the `filename' parameter, this method falls back to looking for the
        `name' parameter.
        Return an iterator over all immediate subparts of a multipart.

        Return an empty iterator for a non-multipart.
        add_attachment_splitparamMessage.__len__Message.get_content_typeMIMEPart.make_alternative_unquotevalueAdd the given payload to the current payload.

        The current payload will always be a list of objects after this method
        is called.  If you want to set the payload to a scalar object, use
        set_payload() instead.
        Return a list of all the message's header field names.

        These will be sorted in the order they appeared in the original
        message, or were added to the message, and may contain duplicates.
        Any fields deleted and re-inserted are always appended to the header
        list.
        MIMEPart._find_bodyReturn the `default' content type.

        Most messages have a default content type of text/plain, except for
        messages that are subparts of multipart/digest containers.  Such
        subparts have a default content type of message/rfc822.
        _formatparamMessage.set_unixfromMIMEPart.add_alternativeAttach is not valid on a message with a non-multipart payloadMessage.set_rawMessage.is_multipartExtended header setting.

        name is the header field to add.  keyword arguments can be used to set
        additional parameters for the header field, with underscores converted
        to dashes.  Normally the parameter will be added as key="value" unless
        value is None, in which case only the key will be added.  If a
        parameter value contains non-ASCII characters it can be specified as a
        three-tuple of (charset, language, value), in which case it will be
        encoded according to RFC2231 rules.  Otherwise it will be encoded using
        the utf-8 charset and a language of ''.

        Examples:

        msg.add_header('content-disposition', 'attachment', filename='bud.gif')
        msg.add_header('content-disposition', 'attachment',
                       filename=('utf-8', '', FuÃballer.ppt'))
        msg.add_header('content-disposition', 'attachment',
                       filename='FuÃballer.ppt'))
        Message.get_payloadMessage.raw_itemsMessage.__setitem__Return the total number of headers, including duplicates.Return the Charset instance associated with the message's payload.
        MIMEPart.add_attachmentReturn the charset parameter of the Content-Type header.

        The returned string is always coerced to lower case.  If there is no
        Content-Type header, or if that header has no charset parameter,
        failobj is returned.
        Message.set_paramMIMEPart.__str__Create a message structure from a string.

        Returns the root of the message structure.  Optional headersonly is a
        flag specifying whether to stop parsing after reading the headers or
        not.  The default is False, meaning it parses the entire contents of
        the file.
        Parser of binary RFC 2822 and MIME email messages.

        Creates an in-memory object tree representing the email message, which
        can then be manipulated and turned over to a Generator to return the
        textual representation of the message.

        The input must be formatted as a block of RFC 2822 headers and header
        continuation lines, optionally preceded by a `Unix-from' header.  The
        header block is terminated either by the end of the input or by a
        blank line.

        _class is the class to instantiate for new message objects when they
        must be created.  This class must have a constructor that can take
        zero arguments.  Default is Message.Message.
        <module email.parser>BytesHeaderParser.parsebytesBytesParser.parsebytesParser of RFC 2822 and MIME email messages.

        Creates an in-memory object tree representing the email message, which
        can then be manipulated and turned over to a Generator to return the
        textual representation of the message.

        The string must be formatted as a block of RFC 2822 headers and header
        continuation lines, optionally preceded by a `Unix-from' header.  The
        header block is terminated either by the end of the string or by a
        blank line.

        _class is the class to instantiate for new message objects when they
        must be created.  This class must have a constructor that can take
        zero arguments.  Default is Message.Message.

        The policy keyword specifies a policy object that controls a number of
        aspects of the parser's operation.  The default policy maintains
        backward compatibility.

        C:\msys64\mingw64\lib\python3.6\email\parser.pyCreate a message structure from the data in a binary file.

        Reads all the data from the file and returns the root of the message
        structure.  Optional headersonly is a flag specifying whether to stop
        parsing after reading the headers or not.  The default is False,
        meaning it parses the entire contents of the file.
        BytesParser.__init__Parser.parsestrHeaderParser.parsestrCreate a message structure from a byte string.

        Returns the root of the message structure.  Optional headersonly is a
        flag specifying whether to stop parsing after reading the headers or
        not.  The default is False, meaning it parses the entire contents of
        the file.
        A parser of RFC 2822 and MIME email messages.Create a message structure from the data in a file.

        Reads all the data from the file and returns the root of the message
        structure.  Optional headersonly is a flag specifying whether to stop
        parsing after reading the headers or not.  The default is False,
        meaning it parses the entire contents of the file.
        This will be the home for the policy that hooks in the new
code that adds all the email6 features.
refold_binary+
        If the value has a 'name' attribute, it is returned to unmodified.
        Otherwise the name and the value with any linesep characters removed
        are passed to the header_factory method, and the resulting custom
        header object is returned.  Any surrogateescaped bytes get turned
        into the unicode unknown-character glyph.

        +
    PROVISIONAL

    The API extensions enabled by this policy are currently provisional.
    Refer to the documentation for details.

    This policy adds new header parsing and folding algorithms.  Instead of
    simple strings, headers are custom objects with custom attributes
    depending on the type of the field.  The folding algorithm fully
    implements RFCs 2047 and 5322.

    In addition to the settable attributes listed above that apply to
    all Policies, this policy adds the following additional attributes:

    utf8                -- if False (the default) message headers will be
                           serialized as ASCII, using encoded words to encode
                           any non-ASCII characters in the source strings.  If
                           True, the message headers will be serialized using
                           utf8 and will not contain encoded words (see RFC
                           6532 for more on this serialization format).

    refold_source       -- if the value for a header in the Message object
                           came from the parsing of some source, this attribute
                           indicates whether or not a generator should refold
                           that value when transforming the message back into
                           stream form.  The possible values are:

                           none  -- all source values use original folding
                           long  -- source values that have any line that is
                                    longer than max_line_length will be
                                    refolded
                           all  -- all values are refolded.

                           The default is 'long'.

    header_factory      -- a callable that takes two arguments, 'name' and
                           'value', where 'name' is a header field name and
                           'value' is an unfolded header field value, and
                           returns a string-like object that represents that
                           header.  A default header_factory is provided that
                           understands some of the RFC5322 header field types.
                           (Currently address fields and date fields have
                           special treatment, while all other fields are
                           treated as unstructured.  This list will be
                           completed before the extension is marked stable.)

    content_manager     -- an object with at least two methods: get_content
                           and set_content.  When the get_content or
                           set_content method of a Message object is called,
                           it calls the corresponding method of this object,
                           passing it the message object as its first argument,
                           and any arguments or keywords that were passed to
                           it as additional arguments.  The default
                           content_manager is
                           :data:`~email.contentmanager.raw_data_manager`.

    EmailPolicy._foldSMTPUTF8EmailPolicy.header_source_parseEmailPolicy.__init__EmailPolicy.header_store_parseEmailPolicy.fold+
        The name is parsed as everything up to the ':' and returned unmodified.
        The value is determined by stripping leading whitespace off the
        remainder of the first line, joining all subsequent lines together, and
        stripping any trailing carriage return or linefeed characters.  (This
        is the same as Compat32).

        Header values may not contain linefeed or carriage return charactersEmailPolicy.fold_binary+
        The same as fold if cte_type is 7bit, except that the returned value is
        bytes.

        If cte_type is 8bit, non-ASCII binary data is converted back into
        bytes.  Headers with binary data are not refolded, regardless of the
        refold_header setting, since there is no way to know whether the binary
        data consists of single byte characters or multibyte characters.

        If utf8 is true, headers are encoded to utf8, otherwise to ascii with
        non-ASCII unicode rendered as encoded words.

        EmailPolicy._fold.<locals>.<genexpr>EmailPolicy.header_max_count+
        The implementation for this class returns the max_count attribute from
        the specialized header class that would be used to construct a header
        of type 'name'.
        linesep_splitter+
        Header folding is controlled by the refold_source policy setting.  A
        value is considered to be a 'source value' if and only if it does not
        have a 'name' attribute (having a 'name' attribute means it is a header
        object of some sort).  If a source value needs to be refolded according
        to the policy, it is converted into a custom header object by passing
        the name and the value with any linesep characters removed to the
        header_factory method.  Folding of a custom header object is done by
        calling its fold method with the current policy.

        Source values are split into lines using splitlines.  If the value is
        not to be refolded, the lines are rejoined using the linesep from the
        policy and returned.  The exception is lines containing non-ascii
        binary data.  In that case the value is refolded regardless of the
        refold_source setting, which causes the binary data to be CTE encoded
        using the unknown-8bit charset.

        C:\msys64\mingw64\lib\python3.6\email\policy.pyEmailPolicy.header_fetch_parse+
        The name is returned unchanged.  If the input value has a 'name'
        attribute and it matches the name ignoring case, the value is returned
        unchanged.  Otherwise the name and value are passed to header_factory
        method, and the resulting custom header object is returned as the
        value.  In this case a ValueError is raised if the input value contains
        CR or LF characters.

        <module email.policy>soft_breakmaxlinelen1encoded_bodylaststartroomEncode with quoted-printable, wrapping at maxlinelen characters.

    Each line of encoded text will end with eol, which defaults to "\n".  Set
    this to "\r\n" if you will be using the result of this function directly
    in an email.

    Each line will be wrapped at, at most, maxlinelen characters before the
    eol string (maxlinelen defaults to 76 characters, the maximum value
    permitted by RFC 2045).  Long lines will have the 'soft line break'
    quoted-printable character "=" appended to them, so the decoded text will
    be identical to the original text.

    The minimum maxlinelen is 4 to have room for a quoted character ("=XX")
    followed by a soft line break.  Smaller values will generate a
    ValueError.

    _QUOPRI_HEADER_MAPbody_checkEncode a single header line with quoted-printable (like) encoding.

    Defined in RFC 2045, this `Q' encoding is similar to quoted-printable, but
    used specifically for email header fields to allow charsets with mostly 7
    bit characters (and some 8 bit) to remain more or less readable in non-RFC
    2045 aware mail clients.

    charset names the character set to use in the RFC 2046 header.  It
    defaults to iso-8859-1.
     !"#$%&'()*+,-./0123456789:;<>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\]^_`abcdefghijklmnopqrstuvwxyz{|}~	=%02XReturn True if the octet should be escaped with body quopri.Return True if the octet should be escaped with header quopri.Quoted-printable content transfer encoding per RFCs 2045-2047.

This module handles the content transfer encoding method defined in RFC 2045
to encode US ASCII-like 8-bit data called `quoted-printable'.  It is used to
safely encode text that is in a character set similar to the 7-bit US ASCII
character set, but that includes some 8-bit characters that are normally not
allowed in email bodies or headers.

Quoted-printable is very space-inefficient for encoding binary files; use the
email.base64mime module for that instead.

This module provides an interface to encode and decode both headers and bodies
with quoted-printable encoding.

RFC 2045 defines a method for including character set information in an
`encoded-word' in a header.  This method is commonly used for 8-bit real names
in To:/From:/Cc: etc. fields, as well as Subject: lines.

This module does not do the line wrapping or end-of-line character
conversion necessary for proper internationalized headers; it only
does dumb encoding and decoding.  To deal with the various line
wrapping issues, use the email.header module.
=?%s?q?%s?=Turn a match in the form =AB to the ASCII character with value 0xab_unquote_matchbody_length.<locals>.<genexpr>Decode a quoted-printable string.

    Lines are separated with eol, which defaults to \n.
    _QUOPRI_BODY_ENCODE_MAP=[a-fA-F0-9]{2}header_length.<locals>.<genexpr>_QUOPRI_BODY_MAPC:\msys64\mingw64\lib\python3.6\email\quoprimime.pyheader_checkReturn a header quoted-printable encoding length.

    Note that this does not include any RFC 2047 chrome added by
    `header_encode()`.

    :param bytearray: An array of bytes (a.k.a. octets).
    :return: The length in bytes of the byte array when it is encoded with
        quoted-printable for headers.
    _QUOPRI_MAPDecode a string encoded with RFC 2045 MIME header `Q' encoding.

    This function does not parse a full MIME header value encoded with
    quoted-printable (like =?iso-8859-1?q?Hello_World?=) -- please use
    the high level email.header class for that functionality.
    <module email.quoprimime>Turn a string in the form =AB to the ASCII character with value 0xabReturn a body quoted-printable encoding length.

    :param bytearray: An array of bytes (a.k.a. octets).
    :return: The length in bytes of the byte array when it is encoded with
        quoted-printable for bodies.
    maxlinelen must be at least 4UEMPTYSTRINGrfc2231_params%z%s'%s'%sRemove quotes from a string.specialsremsgidDecode parameters list according to RFC 2231.

    params is a sequence of 2-tuples containing (param name, string value).
    Returns a date string as specified by RFC 2822, e.g.:

    Fri, 09 Nov 2001 01:08:47 -0000

    Optional timeval if given is a floating point time value as accepted by
    gmtime() and localtime(), otherwise the current time is used.

    Optional localtime is a flag that when True, interprets timeval, and
    returns a date relative to the local timezone instead of UTC, properly
    taking daylight savings time into account.

    Optional argument usegmt means that the timezone is written out as
    an ascii string, not numeric one (so "GMT" instead of "+0000"). This
    is needed for HTTP, and is only used when localtime==False.
    encoded_nameReturn True if s contains surrogate-escaped binary data.fallback_charsetrawbytes
  =\?                   # literal =?
  (?P<charset>[^?]*?)   # non-greedy up to the next ? is the charset
  \?                    # literal ?
  (?P<encoding>[qb])    # either a "q" or a "b", case insensitive
  \?                    # literal ?
  (?P<atom>.*?)         # non-greedy up to the next ?= is the atom
  \?=                   # literal ?=
  TICK[\\"]Turn a datetime into a date string as specified in RFC 2822.

    If usegmt is True, dt must be an aware datetime with an offset of zero.  In
    this case 'GMT' will be rendered instead of the normal +0000 required by
    RFC2822.  This is to support HTTP headers involving date stamps.
    formataddr^(?P<name>\w+)\*((?P<num>[0-9]+)\*?)?$escapesre%s%s%s <%s>Returns a string suitable for RFC 2822 compliant Message-ID, e.g:

    <142480216486.20800.16526388040877946887@nightshade.la.mastaler.com>

    Optional idstring if given is a string used to strengthen the
    uniqueness of the message id.  Optional domain if given provides the
    portion of the message id after the '@'.  It defaults to the locally
    defined hostname.
    altzoneDecode string according to RFC 2231make_msgidReturn a list of (REALNAME, EMAIL) for each fieldvalue.isdst%s, %02d %s %04d %02d:%02d:%02d %sEncode string according to RFC 2231.

    If neither charset nor language is given, then s is returned as-is.  If
    charset is given but not language, the string is encoded using the empty
    string for language.
    <module email.utils><%d.%d.%d%s@%s>[][\\()<>@,:;".]tm_isdst_format_timetuple_and_zonefieldvaluesThe inverse of parseaddr(), this takes a 2-tuple of the form
    (realname, email_address) and returns the string value suitable
    for an RFC 2822 From, To or Cc header.

    If the first element of pair is false, then the second element is
    returned unmodified.

    Optional charset if given is the character set that is used to encode
    realname in case realname is not ASCII safe.  Can be an instance of str or
    a Charset-like object which has a header_encode method.  Default is
    'utf-8'.
    getaddressesC:\msys64\mingw64\lib\python3.6\email\utils.pyrfc2231_continuation_AddressListusegmt option requires a UTC datetime
    Parse addr into its constituent realname and email address parts.

    Return a tuple of realname and email address, unless the parse fails, in
    which case return a 2-tuple of ('', '').
    decode_rfc2231Return local time as an aware datetime object.

    If called without arguments, return current time.  Otherwise *dt*
    argument should be a datetime instance, and it is converted to the
    local time zone according to the system time zone database.  If *dt* is
    naive (that is, dt.tzinfo is None), it is assumed to be in local time.
    In this case, a positive or zero value for *isdst* causes localtime to
    presume initially that summer time (for example, Daylight Saving Time)
    is or is not (respectively) in effect for the specified time.  A
    negative value for *isdst* causes the localtime() function to attempt
    to divine whether summer time is in effect for the specified time.

    continuations\\\g<0>Miscellaneous utilities._aliases<module encodings>C:\msys64\mingw64\lib\python3.6\encodingsincompatible codecs in module "%s" (%s)getaliasesCodecRegistryErrormodnamespunct_alias_mbcsmodule "%s" (%s) failed to registersearch_functionC:\msys64\mingw64\lib\python3.6\encodings\__init__.py Standard "encodings" Package

    Standard Python encoding modules are stored in this package
    directory.

    Codec modules must have names corresponding to normalized encoding
    names as defined in the normalize_encoding() function below, e.g.
    'utf-8' must be implemented by the module 'utf_8.py'.

    Each codec module must export the following interface:

    * getregentry() -> codecs.CodecInfo object
    The getregentry() API must return a CodecInfo object with encoder, decoder,
    incrementalencoder, incrementaldecoder, streamwriter and streamreader
    atttributes which adhere to the Python Codec Interface Standard.

    In addition, a module may optionally also define the following
    APIs which are then used by the package's codec search function:

    * getaliases() -> sequence of encoding name strings to use as aliases

    Alias names returned by getaliases() must be normalized encoding
    names as defined by normalize_encoding().

Written by Marc-Andre Lemburg (mal@lemburg.com).

(c) Copyright CNRI, All Rights Reserved. NO WARRANTY.

_import_tailaliased_encodingcodecaliasesencodings. Normalize an encoding name.

        Normalization works as follows: all non-alphanumeric
        characters except the dot used for Python package names are
        collapsed and replaced with a single underscore, e.g. '  -;#'
        becomes '_'. Leading and trailing underscores are removed.

        Note that encoding names should be ASCII only; if they do use
        non-ASCII characters, these must be Latin-1 compatible.

    --unknown--ûz646zasciizansi_x3.4_1968zasciizansi_x3_4_1968zasciizansi_x3.4_1986zasciizcp367zasciizcsasciizasciizibm367zasciiz	iso646_uszasciiziso_646.irv_1991zasciiziso_ir_6zasciizuszasciizus_asciizasciizbase64zbase64_codeczbase_64zbase64_codeczbig5_twzbig5zcsbig5zbig5z
big5_hkscsz	big5hkscszhkscsz	big5hkscszbz2z	bz2_codecz037zcp037zcsibm037zcp037zebcdic_cp_cazcp037zebcdic_cp_nlzcp037zebcdic_cp_uszcp037zebcdic_cp_wtzcp037zibm037zcp037zibm039zcp037z1026zcp1026z	csibm1026zcp1026zibm1026zcp1026z1125zcp1125zibm1125zcp1125zcp866uzcp1125zrusciizcp1125z1140zcp1140zibm1140zcp1140z1250zcp1250zwindows_1250zcp1250z1251zcp1251zwindows_1251zcp1251z1252zcp1252zwindows_1252zcp1252z1253zcp1253zwindows_1253zcp1253z1254zcp1254zwindows_1254zcp1254z1255zcp1255zwindows_1255zcp1255z1256zcp1256zwindows_1256zcp1256z1257zcp1257zwindows_1257zcp1257z1258zcp1258zwindows_1258zcp1258z273zcp273zibm273zcp273zcsibm273zcp273z424zcp424zcsibm424zcp424zebcdic_cp_hezcp424zibm424zcp424z437zcp437zcspc8codepage437zcp437zibm437zcp437z500zcp500zcsibm500zcp500zebcdic_cp_bezcp500zebcdic_cp_chzcp500zibm500zcp500z775zcp775zcspc775balticzcp775zibm775zcp775z850zcp850zcspc850multilingualzcp850zibm850zcp850z852zcp852zcspcp852zcp852zibm852zcp852z855zcp855zcsibm855zcp855zibm855zcp855z857zcp857zcsibm857zcp857zibm857zcp857z858zcp858zcsibm858zcp858zibm858zcp858z860zcp860zcsibm860zcp860zibm860zcp860z861zcp861zcp_iszcp861zcsibm861zcp861zibm861zcp861z862zcp862zcspc862latinhebrewzcp862zibm862zcp862z863zcp863zcsibm863zcp863zibm863zcp863z864zcp864zcsibm864zcp864zibm864zcp864z865zcp865zcsibm865zcp865zibm865zcp865z866zcp866zcsibm866zcp866zibm866zcp866z869zcp869zcp_grzcp869zcsibm869zcp869zibm869zcp869z932zcp932zms932zcp932zmskanjizcp932zms_kanjizcp932z949zcp949zms949zcp949zuhczcp949z950zcp950zms950zcp950zjisx0213zeuc_jis_2004z
eucjis2004zeuc_jis_2004zeuc_jis2004zeuc_jis_2004zeucjisx0213zeuc_jisx0213zeucjpzeuc_jpzujiszeuc_jpzu_jiszeuc_jpzeuckrzeuc_krzkoreanzeuc_krzksc5601zeuc_krz	ks_c_5601zeuc_krzks_c_5601_1987zeuc_krzksx1001zeuc_krz	ks_x_1001zeuc_krzgb18030_2000zgb18030zchinesezgb2312zcsiso58gb231280zgb2312zeuc_cnzgb2312zeuccnzgb2312zeucgb2312_cnzgb2312zgb2312_1980zgb2312z	gb2312_80zgb2312z	iso_ir_58zgb2312z936zgbkzcp936zgbkzms936zgbkzhexz	hex_codeczroman8z	hp_roman8zr8z	hp_roman8z
csHPRoman8z	hp_roman8zhzgbzhzzhz_gbzhzz
hz_gb_2312zhzzcsiso2022jpz
iso2022_jpz	iso2022jpz
iso2022_jpziso_2022_jpz
iso2022_jpziso2022jp_1ziso2022_jp_1ziso_2022_jp_1ziso2022_jp_1ziso2022jp_2ziso2022_jp_2ziso_2022_jp_2ziso2022_jp_2ziso_2022_jp_2004ziso2022_jp_2004ziso2022jp_2004ziso2022_jp_2004ziso2022jp_3ziso2022_jp_3ziso_2022_jp_3ziso2022_jp_3ziso2022jp_extziso2022_jp_extziso_2022_jp_extziso2022_jp_extzcsiso2022krz
iso2022_krz	iso2022krz
iso2022_krziso_2022_krz
iso2022_krzcsisolatin6z
iso8859_10ziso_8859_10z
iso8859_10ziso_8859_10_1992z
iso8859_10z
iso_ir_157z
iso8859_10zl6z
iso8859_10zlatin6z
iso8859_10zthaiz
iso8859_11ziso_8859_11z
iso8859_11ziso_8859_11_2001z
iso8859_11ziso_8859_13z
iso8859_13zl7z
iso8859_13zlatin7z
iso8859_13ziso_8859_14z
iso8859_14ziso_8859_14_1998z
iso8859_14z
iso_celticz
iso8859_14z
iso_ir_199z
iso8859_14zl8z
iso8859_14zlatin8z
iso8859_14ziso_8859_15z
iso8859_15zl9z
iso8859_15zlatin9z
iso8859_15ziso_8859_16z
iso8859_16ziso_8859_16_2001z
iso8859_16z
iso_ir_226z
iso8859_16zl10z
iso8859_16zlatin10z
iso8859_16zcsisolatin2z	iso8859_2z
iso_8859_2z	iso8859_2ziso_8859_2_1987z	iso8859_2z
iso_ir_101z	iso8859_2zl2z	iso8859_2zlatin2z	iso8859_2zcsisolatin3z	iso8859_3z
iso_8859_3z	iso8859_3ziso_8859_3_1988z	iso8859_3z
iso_ir_109z	iso8859_3zl3z	iso8859_3zlatin3z	iso8859_3zcsisolatin4z	iso8859_4z
iso_8859_4z	iso8859_4ziso_8859_4_1988z	iso8859_4z
iso_ir_110z	iso8859_4zl4z	iso8859_4zlatin4z	iso8859_4zcsisolatincyrillicz	iso8859_5zcyrillicz	iso8859_5z
iso_8859_5z	iso8859_5ziso_8859_5_1988z	iso8859_5z
iso_ir_144z	iso8859_5zarabicz	iso8859_6zasmo_708z	iso8859_6zcsisolatinarabicz	iso8859_6zecma_114z	iso8859_6z
iso_8859_6z	iso8859_6ziso_8859_6_1987z	iso8859_6z
iso_ir_127z	iso8859_6zcsisolatingreekz	iso8859_7zecma_118z	iso8859_7zelot_928z	iso8859_7zgreekz	iso8859_7zgreek8z	iso8859_7z
iso_8859_7z	iso8859_7ziso_8859_7_1987z	iso8859_7z
iso_ir_126z	iso8859_7zcsisolatinhebrewz	iso8859_8zhebrewz	iso8859_8z
iso_8859_8z	iso8859_8ziso_8859_8_1988z	iso8859_8z
iso_ir_138z	iso8859_8zcsisolatin5z	iso8859_9z
iso_8859_9z	iso8859_9ziso_8859_9_1989z	iso8859_9z
iso_ir_148z	iso8859_9zl5z	iso8859_9zlatin5z	iso8859_9zcp1361zjohabzms1361zjohabzcskoi8rzkoi8_rzkz_1048zkz1048zrk1048zkz1048zstrk1048_2002zkz1048z8859zlatin_1zcp819zlatin_1zcsisolatin1zlatin_1zibm819zlatin_1ziso8859zlatin_1z	iso8859_1zlatin_1z
iso_8859_1zlatin_1ziso_8859_1_1987zlatin_1z
iso_ir_100zlatin_1zl1zlatin_1zlatinzlatin_1zlatin1zlatin_1zmaccyrilliczmac_cyrilliczmacgreekz	mac_greekz
macicelandzmac_icelandzmaccentraleuropez
mac_latin2z	maclatin2z
mac_latin2z	macintoshz	mac_romanzmacromanz	mac_romanz
macturkishzmac_turkishzansizmbcszdbcszmbcsz	csptcp154zptcp154zpt154zptcp154zcp154zptcp154zcyrillic_asianzptcp154zquoprizquopri_codeczquoted_printablezquopri_codeczquotedprintablezquopri_codeczrot13zrot_13z
csshiftjisz	shift_jiszshiftjisz	shift_jiszsjisz	shift_jiszs_jisz	shift_jiszshiftjis2004zshift_jis_2004z	sjis_2004zshift_jis_2004z
s_jis_2004zshift_jis_2004zshiftjisx0213zshift_jisx0213z	sjisx0213zshift_jisx0213z
s_jisx0213zshift_jisx0213ztis260ztactisztis620ztis_620z	tis_620_0ztis_620ztis_620_2529_0ztis_620ztis_620_2529_1ztis_620z
iso_ir_166ztis_620zu16zutf_16zutf16zutf_16zunicodebigunmarkedz	utf_16_bezutf_16bez	utf_16_bezunicodelittleunmarkedz	utf_16_lezutf_16lez	utf_16_lezu32zutf_32zutf32zutf_32zutf_32bez	utf_32_bezutf_32lez	utf_32_lezu7zutf_7zutf7zutf_7zunicode_1_1_utf_7zutf_7zu8zutf_8zutfzutf_8zutf8zutf_8z	utf8_ucs2zutf_8z	utf8_ucs4zutf_8zuuzuu_codeczzipz
zlib_codeczzlibz
zlib_codeczx_mac_japanesez	shift_jiszx_mac_koreanzeuc_krzx_mac_simp_chinesezgb2312zx_mac_trad_chinesezbig50 Encoding Aliases Support

    This module is used by the encodings package search function to
    map encodings names to module names.

    Note that the search function normalizes the encoding names before
    doing the lookup, so the mapping will have to map normalized
    encoding names to module names.

    Contents:

        The following aliases dictionary contains mappings of all IANA
        character set names for which the Python core library provides
        codecs. In addition to these, a few Python specific codec
        aliases have also been added.

C:\msys64\mingw64\lib\python3.6\encodings\aliases.pymbcs_decode<module encodings.mbcs>mbcs_encode Python 'mbcs' Codec for Windows


Cloned by Mark Hammond (mhammond@skippinet.com.au) from ascii.py,
which was written by Marc-Andre Lemburg (mal@lemburg.com).

(c) Copyright CNRI, All Rights Reserved. NO WARRANTY.

C:\msys64\mingw64\lib\python3.6\encodings\mbcs.pynew enumerations must be created as `ClassName([mixin_type,] enum_type)`EnumMetapseudo_member
        Generate the next value when not given.

        name: the name of the member
        start: the initital start value or None
        count: the number of existing members
        last_value: the last value assigned or None
        __getnewargs_ex__The name of the Enum member._make_class_unpicklableInvalid Flag value: %rEnum.name_find_new_member_value
        Create a composite member iff value contains only members.
        Returns the type for creating enum members, and the first inherited
        enum class.

        bases: the tuple of bases that was given to __new__

        added_behaviormember_type_EnumDictalias_details_member_map__auto_nullEnumMeta.__contains__classdictfirst_enumuse_args<%s.%s: %r>The value of the Enum member.EnumMeta.__len__inverted_members
    Instances are replaced with an appropriate value in Enum class suites.
    Enum.__format__Cannot reassign members.flag_value_decompose.<locals>.<lambda>uncovered_is_sunderEnum.__repr__need_to_create_order__create_pseudo_member__generate_next_value_IntFlag.__xor__%s.%r<module enum>_is_descriptorReturns a mapping of member name->value.

        This mapping lists all enum members, including aliases. Note that this
        is a read-only view of the internal mapping.

        Support for flagsFlag._create_pseudo_member_Changes anything not dundered or not a descriptor.

        If an enum member name is used twice, an error is raised; duplicate
        values are not checked for.

        Single underscore (sunder) names are reserved.

        ©ÚclsÚ
class_nameÚnamesÚmoduleÚqualnameÚtypeÚstartÚmetaclsÚbasesÚ_Ú
first_enumÚ	classdictÚoriginal_namesÚlast_valuesÚcountÚnameÚvalueÚitemÚmember_nameÚmember_valueÚ
enum_classÚexcFlag._missing__member_names__make_class_unpicklable.<locals>._break_on_call_reducemember order does not match _order_Enum._convert.<locals>.<lambda>Metaclass for EnumAn enumeration.enum_dictEnumMeta.__prepare__Enum._missing_Enum.__reduce_ex__high_bit_member_type_extra_flagsIntFlag._create_pseudo_member_Extract all members from the value.Enum.__str__returns index of highest bit, or -1 if value is zero or negativeEnumMeta.__reversed__Enum.valueIntFlag.__or__EnumMeta.__iter__EnumMeta.__delattr__EnumMeta.__bool__Flag.__contains__EnumMeta.__setattr____new_member__Block attempts to reassign Enum members.

        A simple assignment to the class namespace only changes one of the
        several possible ways to get an Enum member from the Enum class,
        resulting in an inconsistent Enumeration.

        EnumMeta._get_mixins_Return the enum member matching `name`

        We use __getattr__ instead of descriptors or inserting into the enum
        class' __dict__ in order to support `name` and `value` being both
        properties for enum members (which live in the class' __dict__) and
        enum members themselves.

        IntFlag.__and__IntFlag.__invert___last_values_reduce_ex_by_nameEnumMeta.__repr__EnumMeta._create_Attempted to reuse key: %rC:\msys64\mingw64\lib\python3.6\enum.pyFlag._generate_next_value_EnumMeta._find_new_Enum.__hash__duplicate values found in %r: %sSupport for integer-based Flags<enum %r>possible_member__order__%r is not a valid %sFlag.__repr__EnumMeta.__dir__Enum where members are also (and must be) ints_value2member_map_Track enum member order and ensure member names are not reused.

    EnumMeta will use the names found in self._member_names as the
    enumeration member names.

    EnumMeta.__call__Returns the __new__ to be used for creating the enum members.

        classdict: the class dictionary given to __new__
        member_type: the data type whose __new__ will be used by default
        first_enum: enumeration to check for an overriding __new__

        EnumMeta.__members__%r already defined as: %r%s: cannot delete Enum member.Class decorator for enumerations ensuring unique member values.EnumMeta.__iter__.<locals>.<genexpr>EnumMeta.__new__EnumMeta.__getattr__
        classes/types should always be True.
        _is_dunderEnumMeta.__getitem__Returns True if obj is a descriptor, False otherwise._EnumDict.__init__Make the given class un-picklable.Enum._generate_next_value_not_covered_names_ are reserved for future Enum useEnumMeta.__new__.<locals>.<genexpr>flags_to_check_EnumDict.__setitem__Generic enumeration.

    Derive from this class to define new enumerations.

    Flag.__str__
        Create a new Enum subclass that replaces a collection of global constants
        Convenience method to create a new Enum class.

        `names` can be:

        * A string containing member names, separated either with spaces or
          commas.  Values are incremented by 1 from `start`.
        * An iterable of member names.  Values are incremented by 1 from `start`.
        * An iterable of (member name, value) pairs.
        * A mapping of member name -> value pairs.

        Either returns an existing member, or creates a new enum class.

        This method is used both when an enum class is given a value to match
        to an enumeration member (i.e. Color(3)) and for the functional API
        (i.e. Color = Enum('Color', names='RED GREEN BLUE')).

        When used for the functional API:

        `value` will be the name of the new class.

        `names` should be either a string of white-space/comma delimited names
        (values will start at `start`), or an iterator/mapping of name, value pairs.

        `module` should be set to the module this class is being created in;
        if it is not set, an attempt to find that module will be made, but if
        it fails the class will not be picklable.

        `qualname` should be set to the actual location this class can be found
        at in its module; by default it is set to the global scope.  If this is
        not correct, unpickling will fail in some circumstances.

        `type`, if set, will be mixed in as the first base class.

        Returns True if a __dunder__ name, False otherwise.Enum.__new__Cannot extend enumerationsInvalid enum member name: {0}EnumMeta.__reversed__.<locals>.<genexpr>IntFlag._missing_Returns True if a _sunder_ name, False otherwise.©ÚmetaclsÚclsÚbasesÚ	classdictÚmember_typeÚ
first_enumÚ__new__Úsave_newÚuse_argsÚenum_membersÚnameÚ_order_Úinvalid_namesÚ
enum_classÚbase_attributesÚmethodsÚmember_nameÚvalueÚargsÚenum_memberÚcanonical_memberÚclass_methodÚ
obj_methodÚenum_methodÚ	__class__Enum.__dir___power_of_twoFlag.__bool__%r cannot be pickleddircmp.reporta_statb_stata_type<module filecmp>.hgDEFAULT_IGNORESUtilities for comparing files and directories.

Classes:
    dircmp

Functions:
    cmp(f1, f2, shallow=True) -> int
    cmpfiles(a, b, common) -> ([], [], [])
    clear_cache()

phase4_closureneed exactly two argsRCSCVS.git.bzr_darcsA class that manages the comparison of 2 directories.

    dircmp(a, b, ignore=None, hide=None)
      A and B are directories.
      IGNORE is a list of names to ignore,
        defaults to DEFAULT_IGNORES.
      HIDE is a list of names to hide,
        defaults to [os.curdir, os.pardir].

    High level usage:
      x = dircmp(dir1, dir2)
      x.report() -> prints a report on the differences between dir1 and dir2
       or
      x.report_partial_closure() -> prints report on differences between dir1
            and dir2, and reports on common immediate subdirectories.
      x.report_full_closure() -> like report_partial_closure,
            but fully recursive.

    Attributes:
     left_list, right_list: The files in dir1 and dir2,
        filtered by hide and ignore.
     common: a list of names in both dir1 and dir2.
     left_only, right_only: names only in dir1, dir2.
     common_dirs: subdirectories in both dir1 and dir2.
     common_files: files in both dir1 and dir2.
     common_funny: names in both dir1 and dir2 where the type differs between
        dir1 and dir2, or the name is not stat-able.
     same_files: list of identical files.
     diff_files: list of filenames which differ.
     funny_files: list of files which could not be compared.
     subdirs: a dictionary of dircmp objects, keyed by names in common_dirs.
     dircmp.__getattr__flistCommon funny cases :Trouble with common files :b_xphase2dircmp.phase3dircmp.phase4_closurephase1Common subdirectories :dircmp.report_partial_closurea_x_do_cmpDiffering files :dircmp.phase1dircmp.phase2dircmp.phase0C:\msys64\mingw64\lib\python3.6\filecmp.pyCompare common files in two directories.

    a, b -- directory names
    common -- list of file names found in both directories
    shallow -- if true, do comparison based solely on stat() information

    Returns a tuple of three lists:
      files that compare equal
      files that are different
      filenames that aren't regular files.

    Compare two files.

    Arguments:

    f1 -- First file name

    f2 -- Second file name

    shallow -- Just check stat signature (do not read the files).
               defaults to True.

    Return value:

    True if the files are the same, False otherwise.

    This function uses a cache for past comparisons and the results,
    with cache entries invalidated if their stat information
    changes.  The cache may be cleared by calling clear_cache().

    _filterClear the filecmp cache.methodmapOnly indircmp.report_full_closuredircmp.__init__Identical files :C:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\finalizations\__init__.py<module finalizations.Finalization> Finalizations. Last steps directly before code creation is called.

Here the final tasks are executed. Things normally volatile during optimization
can be computed here, so the code generation can be quick and doesn't have to
check it many times.

C:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\finalizations\Finalization.pyC:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\finalizations\FinalizeBase.pyfinalizations.FinalizeBase<module finalizations.FinalizeBase> Base for all finalization modules

Provides a class that all finalization visitors should inherit from.
Unresolved '__import__' call at '%s' may require use of '--recurse-directory'.isExpressionFunctionCallin_tried_blockisStatementTryimported_namesFinalizeMarkups.onEnterNodeC:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\finalizations\FinalizeMarkups.pyisExpressionAsyncWait<module finalizations.FinalizeMarkups> Finalize the markups

Set flags on functions and classes to indicate if a locals dict is really
needed.

Set a flag on loops if they really need to catch Continue and Break exceptions
or if it can be more simple code.

Set a flag on return statements and functions that require the use of
"ReturnValue" exceptions, or if it can be more simple code.

Set a flag on re-raises of exceptions if they can be simple throws or if they
are in another context.

isStatementPublishExceptionlast_searchisExpressionYieldFromnode_moduletarget_varFinalizeMarkups._onEnterNoderes_strfnmatchcase(?s:%s)\ZFilename matching with shell patterns.

fnmatch(FILENAME, PATTERN) matches according to the local convention.
fnmatchcase(FILENAME, PATTERN) always takes case in account.

The functions operate by translating the pattern into a regular
expression.  They cache the compiled regular expressions for speed.

The function translate(PATTERN) returns a regular expression
corresponding to PATTERN.  (It does not compile it.)
Test whether FILENAME matches PATTERN.

    Patterns are Unix shell style:

    *       matches everything
    ?       matches any single character
    [seq]   matches any character in seq
    [!seq]  matches any char not in seq

    An initial period in FILENAME is not special.
    Both FILENAME and PATTERN are first case-normalized
    if the operating system requires it.
    If you don't want this, use fnmatchcase(FILENAME, PATTERN).
    Return the subset of the list NAMES that match PAT.pat_str<module fnmatch>Translate a shell PATTERN to a regular expression.

    There is no way to quote meta-characters.
    C:\msys64\mingw64\lib\python3.6\fnmatch.py%s[%s]Test whether FILENAME matches PATTERN, including case.

    This is a version of fnmatch() which doesn't case-normalize
    its arguments.
    _compile_patternISO-8859-1C:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\freezerC:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\freezer\__init__.py<module freezer.BytecodeModuleFreezer>frozen_defsC:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\freezer\BytecodeModuleFreezer.py
Freezer for bytecode compiled modules. Not real C compiled modules.

This is including modules as bytecode and mostly intended for modules, where
we know compiling it useless or does not make much sense, or for standalone
mode to access modules during CPython library init that cannot be avoided.

The level of compatibility for C compiled stuff is so high that this is not
needed except for technical reasons.
{{ "{module_name}", {start}, {size} }},Embedded as frozen module '%s'.nuitka_depends_dirDownloading '%s'depends_urlC:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\freezer\DependsExe.py<module freezer.DependsExe>Problem with the downloaded zip file, deleting it.Nuitka does not work in --standalone on Windows without.depends.exenuitka_app_dirnuitka_depends_ziphttp://dependencywalker.com/depends22_x86.zipFailed to download '%s'.Contents should manually be extracted to '%s'.http://dependencywalker.com/depends22_x64.zipNuitka will make use of Dependency Walker (http://dependencywalker.com) tool
to analyze the dependencies of Python extension modules. Is it OK to download
and put it in "%s".
No installer needed, cached, one time question.

Proceed and download? [Yes]/No  Return the path of depends.exe (for Windows).

        Will prompt the user to download if not already cached in AppData
        directory for Nuitka.
    Error, need '%s' as extracted from '%s'. Interface to depends.exe on Windows.

We use depends.exe to investigate needed DLLs of Python DLLs.

Extracting to '%s'fixupBinaryDLLPathssourcefilescan_dirsFreeBSDshlib_modulereduced_pathtmp_filetmp_filenamefirst_onescache_filePREFIXES = [sys.prefix, sys.exec_prefix]library_depsoriginal_dirsEXT-MS-WIN-nuitka.importing.Importingreadelfearly_namescp65001@loader_path/.dwpexpatreader.pyrpath
imports = %r

failed = set()

class ImportBlocker(object):
    def find_module(self, fullname, path = None):
        if fullname in failed:
            return self

        return None

    def load_module(self, name):
        raise ImportError("%%s has failed before" %% name)

sys.meta_path.insert(0, ImportBlocker())

for imp in imports:
    try:
        __import__(imp)
    except (ImportError, SyntaxError):
        failed.add(imp)

    for fail in failed:
        if fail in sys.modules:
            del sys.modules[fail]
install_name_tool-f1@rpath/dwp_filedetectUsedDLLs.<locals>.addDLLInfoimport_pathdef main():def main():return

if 0:
 def _unused():detectEarlyImports.<locals>.<lambda>original_filenameused_dllsPREFIXES = []is_main_executable Pack and copy files for standalone mode.

This is still under heavy evolution, but expected to work for
MacOS, Windows, and Linux. Patches for other platforms are
very welcome.
-ot%sensurepiplibc.so.libpthread.so.libm.so.libdl.so.original_pathhashed_valuecache_dirpopen_fork.pyError, please report the issue with above output._detectBinaryPathDLLsLinuxBSDFinished detecting early imports._detectedShlibFileIncluded used shared library '%s' (used by %s).-ps1idlelibsub_resultignore_modulesimport inspect;popen_forkserver.py_parseDependsExeOutputremoved_dllsdll_filename1sources1dll_filename2sources2target_pathstandalone_entry_point_original_path©ÀzSHELL32.DLLz
USER32.DLLzKERNEL32.DLLz	NTDLL.DLLzNETUTILS.DLLzLOGONCLI.DLLz	GDI32.DLLz
RPCRT4.DLLzADVAPI32.DLLzSSPICLI.DLLzSECUR32.DLLzKERNELBASE.DLLzWINBRAND.DLLz
DSROLE.DLLz
DNSAPI.DLLz
SAMCLI.DLLz
WKSCLI.DLLz
SAMLIB.DLLzWLDAP32.DLLzNTDSAPI.DLLzCRYPTBASE.DLLzW32TOPLz
WS2_32.DLLzSPPC.DLLzMSSIGN32.DLLzCERTCLI.DLLzWEBSERVICES.DLLz	AUTHZ.DLLzCERTENROLL.DLLzVAULTCLI.DLLz
REGAPI.DLLzBROWCLI.DLLz
WINNSI.DLLzDHCPCSVC6.DLLz	PCWUM.DLLzCLBCATQ.DLLzIMAGEHLP.DLLz
MSASN1.DLLzDBGHELP.DLLz
DEVOBJ.DLLzDRVSTORE.DLLzCABINET.DLLz
SCECLI.DLLz	SPINF.DLLzSPFILEQ.DLLz	GPAPI.DLLzNETJOIN.DLLzW32TOPL.DLLzNETBIOS.DLLzDXGI.DLLz
DWRITE.DLLz	D3D11.DLLzWLANAPI.DLLzWLANUTIL.DLLzONEX.DLLzEAPPPRXY.DLLz
MFPLAT.DLLzAVRT.DLLzELSCORE.DLLzINETCOMM.DLLzMSOERT2.DLLzIEUI.DLLz	MSCTF.DLLzMSFEEDS.DLLzUIAUTOMATIONCORE.DLLz	PSAPI.DLLz
EFSADU.DLLz
MFC42U.DLLz
ODBC32.DLLz
OLEDLG.DLLzNETAPI32.DLLzLINKINFO.DLLz	DUI70.DLLzADVPACK.DLLzNTSHRUI.DLLzWINSPOOL.DRVzEFSUTIL.DLLzWINSCARD.DLLzSHDOCVW.DLLzIEFRAME.DLLzD2D1.DLLzGDIPLUS.DLLzOCCACHE.DLLzIEADVPACK.DLLz	MLANG.DLLzMSI.DLLz
MSHTML.DLLzCOMDLG32.DLLzPRINTUI.DLLz
PUIAPI.DLLz	ACLUI.DLLzWTSAPI32.DLLzFMS.DLLz
DFSCLI.DLLz	HLINK.DLLzMSRATING.DLLzPRNTVPT.DLLzIMGUTIL.DLLz
MSLS31.DLLzVERSION.DLLzNORMALIZ.DLLzIERTUTIL.DLLzWININET.DLLzWINTRUST.DLLzXMLLITE.DLLzAPPHELP.DLLzPROPSYS.DLLzRSTRTMGR.DLLz
NCRYPT.DLLz
BCRYPT.DLLzMMDEVAPI.DLLzMSILTCFG.DLLz
DEVMGR.DLLz
DEVRTL.DLLz
NEWDEV.DLLzVPNIKEAPI.DLLzWINHTTP.DLLz	WEBIO.DLLzNSI.DLLzDHCPCSVC.DLLzCRYPTUI.DLLz	ESENT.DLLzDAVHLPR.DLLz
CSCAPI.DLLzATL.DLLzOLEAUT32.DLLz
SRVCLI.DLLz
RASDLG.DLLz
MPRAPI.DLLzRTUTILS.DLLz
RASMAN.DLLz
MPRMSG.DLLzSLC.DLLzCRYPTSP.DLLzRASAPI32.DLLz
TAPI32.DLLzEAPPCFG.DLLz
NDFAPI.DLLzWDI.DLLzCOMCTL32.DLLzUXTHEME.DLLz	IMM32.DLLz
OLEACC.DLLz	WINMM.DLLzWINDOWSCODECS.DLLz
DWMAPI.DLLz	DUSER.DLLzPROFAPI.DLLz
URLMON.DLLzSHLWAPI.DLLzLPK.DLLz	USP10.DLLzCFGMGR32.DLLzMSIMG32.DLLzPOWRPROF.DLLzSETUPAPI.DLLz
WINSTA.DLLzCRYPT32.DLLzIPHLPAPI.DLLzMPR.DLLz
CREDUI.DLLzNETPLWIZ.DLLz	OLE32.DLLzACTIVEDS.DLLzADSLDPC.DLLzUSERENV.DLLzAPPREPAPI.DLLzBCP47LANGS.DLLzBCRYPTPRIMITIVES.DLLz
CERTCA.DLLz
CHARTV.DLLzCOMBASE.DLLz	COML2.DLLz	DCOMP.DLLz	DPAPI.DLLzDSPARSE.DLLzFECLIENT.DLLzFIREWALLAPI.DLLz
FLTLIB.DLLzMRMCORER.DLLz
NTASN1.DLLzSECHOST.DLLzSETTINGSYNCPOLICY.DLLz
SHCORE.DLLzTBS.DLLzTWINAPI.APPCORE.DLLzTWINAPI.DLLzVIRTDISK.DLLzWEBSOCKET.DLLzWEVTAPI.DLLzWINMMBASE.DLLzWMICLNT.DLLKnownDLLs
%(original_dirs)s
SysPath
32BitSysDir
16BitSysDir
OSDir
AppPath
SxS
detectEarlyImports.<locals>.<genexpr>import sys; sys.path = %s; sys.real_prefix = sys.prefix;-d:%s444RPATH| Module List |C:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\freezer\Standalone.pystdlib_modulesbsddbdetectBinaryDLLssystem_paths Detect the DLLs used by a binary.

        Using "ldd" (Linux), "depends.exe" (Windows), or "otool" (MacOS) the list
        of used DLLs is retrieved.
    _detectedSourceFile For MacOS, the binary needs to be told to use relative DLL paths -changeError, conflicting DLLs for '%s'.
%s used by:
   %s
different from
%s used by
   %sto_removeprecompiledantigravity.py-pa1Error reading shared library path for %s, tool said %rencoding_name_detectBinaryPathDLLsMacOS_getCacheFilenameturtledemopopen_spawn_posix.pystdlib_diris_exedist_pathldd_result_cache__file__ = (__nuitka_binary_dir + '%s%s') if '__nuitka_binary_dir' in dict(__builtins__ ) else '<frozen>';%schrpathcp65001.pycache_filenameRUNPATH755scons-report.txtAPI-MS-WIN-Freezing module '%s' (from '%s')._detectImportsThere is a problem with detecting imports, CPython said:xml.sax_detectBinaryPathDLLsWindowsDetecting imports:Running depends.exe for %s took %%.2f secondsdepends_exe_processprecompiled_filenameoem
print("\n".join(sorted("import " + module.__name__ + " # sourcefile " + module.__file__ for module in sys.modules.values() if hasattr(module, "__file__") and module.__file__ not in (None, "<frozen>"))), file = sys.stderr)Error, needs 'chrpath' on your system, due to 'RPATH' settings in used shared
libraries that need to be removed.windows_lock;import locale;| Module Dependency Tree |worker_pool_detectBinaryPathDLLsWindows.<locals>.<genexpr>.<locals>.<genexpr>lib2to3getSharedLibraryRPATH<module freezer.Standalone>_detectedPrecompiledFileRemoving 'RPATH' setting from '%s'.encoding_names_detected_python_rpathimport_codeimport encodings.%s_withLockscanStandardLibraryPathlib-removeSharedLibraryRPATHUserDir %sColliding DLL names for %s, checking identity of '%s' <-> '%s'.loadCodeObjectDatasourcehostRetrieve the size of a file.context and keyfile arguments are mutually exclusiveFTP.retrlinesCDUPFTP.deleteFTP.rmdsourcenametargetnamesourceporttreplysreplyFTP.getlineFTP.sendcmdkeyfile and certfile are deprecated, use acustom context instead*welcome*not using TLSFTP.cwdFTP.storbinaryFTP.pwdNo account -- using anonymous login.FTP.getwelcomeuseridDELE FTP.__enter__passiveserverReturn current working directory.USER Store a file in binary mode.  A new port is created for you.

        Args:
          cmd: A STOR command.
          fp: A file-like object with a read(num_bytes) method.
          blocksize: The maximum data size to read from fp and send over
                     the connection at once.  [default: 8192]
          callback: An optional single parameter callable that is called on
                    each block of data after it is sent.  [default: None]
          rest: Passed to transfercmd().  [default: None]

        Returns:
          The response code.
        CWDerror_protoA FTP subclass which adds TLS support to FTP as described
        in RFC-4217.

        Connect as usual to port 21 implicitly securing the FTP control
        connection before authenticating.

        Securing the data connection requires user to explicitly ask
        for it by calling prot_p() method.

        Usage example:
        >>> from ftplib import FTP_TLS
        >>> ftps = FTP_TLS('ftp.python.org')
        >>> ftps.login()  # login anonymously previously securing control channel
        '230 Guest login ok, access restrictions apply.'
        >>> ftps.prot_p()  # switch to secure data connection
        '200 Protection level set to P'
        >>> ftps.retrlines('LIST')  # list directory content securely
        total 9
        drwxr-xr-x   8 root     wheel        1024 Jan  3  1994 .
        drwxr-xr-x   8 root     wheel        1024 Jan  3  1994 ..
        drwxr-xr-x   2 root     wheel        1024 Jan  3  1994 bin
        drwxr-xr-x   2 root     wheel        1024 Jan  3  1994 etc
        d-wxrwxr-x   2 ftp      wheel        1024 Sep  5 13:43 incoming
        drwxr-xr-x   2 root     wheel        1024 Nov 17  1993 lib
        drwxr-xr-x   6 1094     wheel        1024 Sep 13 19:07 pub
        drwxr-xr-x   3 root     wheel        1024 Jan  3  1994 usr
        -rw-r--r--   1 root     root          312 Aug  1  1994 welcome.msg
        '226 Transfer complete.'
        >>> ftps.quit()
        '221 Goodbye.'
        >>>
        Set up secure data connection.mkdFTP_TLS.__init__FTP.putcmdlastresp150 .* \((\d+) bytes\)netrcobjSend new account name.426PROT PPWDrcfileacct225B_CRLFFTP.voidrespDefault retrlines callback to print a line.FTP.makeport*cmd*Use passive or active mode for data transfers.
        With a false argument, use the normal PORT mode,
        With a true argument, use the PASV command.getmultilinean illegal newline character should not be containedABOROPTS MLST set_pasvFTP.__exit__Send a PORT command with the current host and the given
        port number.
        QUITerror_replyerror_tempFTP.renameSet up clear text data connection.Store a file in line mode.  A new port is created for you.

        Args:
          cmd: A STOR command.
          fp: A file-like object with a readline() method.
          callback: An optional single parameter callable that is called on
                    each line after it is sent.  [default: None]

        Returns:
          The response code.
        parse227Set the debugging level.
        The required argument level means:
        0: no debugging output (default)
        1: print commands and responses but not body text etc.
        2: also print raw lines read and sent before stripping CR/LFSIZE _227_reAn FTP client class.

    To create a connection, call the class using these arguments:
            host, user, passwd, acct, timeout

    The first four arguments are all strings, and have default value ''.
    timeout must be numeric and defaults to None if not passed,
    meaning that no timeout will be set on any ftp socket(s)
    If a timeout is passed, then this is now the default timeout for all ftp
    socket operations for this instance.

    Then use self.connect() with optional host and port argument.

    To download a file, use ftp.retrlines('RETR ' + filename),
    or ftp.retrbinary() with slightly different arguments.
    To upload a file, use ftp.storlines() or ftp.storbinary(),
    which have an open file as argument (see their definitions
    below for details).
    The download/upload functions first issue appropriate TYPE
    and PORT or PASV commands.
    tonameEPSVfactscontext and certfile arguments are mutually exclusivemlsdDelete a file.FTP.retrbinaryTYPE IFTP_TLS.ntransfercmdPROT CRename a file.MLSDRNTO FTP.getrespPASS FTP.transfercmdMLSD %sRemove a directory.makepasvhbytespbytesprot_cCCCFTP.voidcmdRNFR print_lineCreate a new socket and send a PORT command for it.*get*FTP.putlineMSG_OOBFTP.closenlstAn FTP client class and some helper functions.

Based on RFC 959: File Transfer Protocol (FTP), by J. Postel and J. Reynolds

Example:

>>> from ftplib import FTP
>>> ftp = FTP('ftp.python.org') # connect to host, default port
>>> ftp.login() # default, i.e.: user anonymous, passwd anonymous@
'230 Guest login ok, access restrictions apply.'
>>> ftp.retrlines('LIST') # list directory contents
total 9
drwxr-xr-x   8 root     wheel        1024 Jan  3  1994 .
drwxr-xr-x   8 root     wheel        1024 Jan  3  1994 ..
drwxr-xr-x   2 root     wheel        1024 Jan  3  1994 bin
drwxr-xr-x   2 root     wheel        1024 Jan  3  1994 etc
d-wxrwxr-x   2 ftp      wheel        1024 Sep  5 13:43 incoming
drwxr-xr-x   2 root     wheel        1024 Nov 17  1993 lib
drwxr-xr-x   6 1094     wheel        1024 Sep 13 19:07 pub
drwxr-xr-x   3 root     wheel        1024 Jan  3  1994 usr
-rw-r--r--   1 root     root          312 Aug  1  1994 welcome.msg
'226 Transfer complete.'
>>> ftp.quit()
'221 Goodbye.'
>>>

A nice test that reveals some of the network dialogue would be:
python ftplib.py -d localhost -l -p -l
AI_PASSIVEExpect a response beginning with '2'.FTP_TLS.abort*retr*FTP.ntransfercmd<module ftplib>AUTH SSLAlready using TLSLogin, default anonymous.FTP_TLS.prot_pFTP.quitFTP.storlinesSend an EPRT command with the current host and the given port number.unsupported address familyAUTH TLSFTP.sizefacts_foundGet the welcome message from the server.
        (this is read and squirreled away by connect())Copy file from one FTP-instance to another.FTP_TLS.cccParse the '257' response for a MKD or PWD request.
    This is a response to a MKD or PWD request: a directory name.
    Returns the directoryname in the 257 reply.Quit, and close the connection.C:\msys64\mingw64\lib\python3.6\ftplib.pysendportFTP.set_pasvMake a directory, return its full pathname.FTP.mlsdFTP_TLS.loginSend a command and expect a response beginning with '2'.FTP.sendeprtFTP.abortSwitch back to a clear-text control connection.sockaddrAbort a file transfer.  Uses out-of-band data.
        This does not follow the procedure from the RFC to send Telnet
        IP and Synch; that doesn't seem to work with the servers I've
        tried.  Instead, just send the ABOR command as OOB data.Retrieve data in line mode.  A new port is created for you.

        Args:
          cmd: A RETR, LIST, or NLST command.
          callback: An optional single parameter callable that is called
                    for each line with the trailing CRLF stripped.
                    [default: print_line()]

        Returns:
          The response code.
        List a directory in a standardized format by using MLSD
        command (RFC-3659). If path is omitted the current directory
        is assumed. "facts" is a list of strings representing the type
        of information desired (e.g. ["type", "size", "perm"]).

        Return a generator object yielding a tuple of two elements
        for every file found in path.
        First element is the file name, the second one is a dictionary
        including a variable number of "facts" depending on the server
        and whether "facts" argument has been provided.
        FTP_TLS.auth*put urgent*Could not open account file -- using anonymous login.Change to a directory.ftpcp229parse229Test program.
    Usage: ftp [-d] [-r[file]] host [-l[dir]] [-d[dir]] [-p] [file] ...

    -d dir
    -l list
    -p password
    Send a command and return the response.RMD FTP.dirFTP.__init__got more than %d bytes*resp*PBSZ 0FTP.set_debuglevel_prot_p(\d+),(\d+),(\d+),(\d+),(\d+),(\d+)FTP.loginCWD nextlinepeer_SSLSocketParse the '150' response for a RETR request.
    Returns the expected transfer size or None; size is not guaranteed to
    be present in the 150 message.
    ACCT Parse the '229' response for an EPSV request.
    Raises error_proto if it does not contain '(|||port|)'
    Return ('host.addr.as.numbers', port#) tuple.Close the connection without assuming anything about it.FTP.sanitizeConnect to host.  Arguments are:
         - host: hostname to connect to (string, default previous host)
         - port: port to connect to (integer, default previous port)
         - timeout: the timeout to set against the ftp socket(s)
         - source_address: a 2-tuple (host, port) for the socket to bind
           to as its source address before connecting.
        Retrieve data in binary mode.  A new port is created for you.

        Args:
          cmd: A RETR command.
          callback: A single parameter callable to be called on each
                    block of data read.
          blocksize: The maximum number of bytes to read from the
                     socket at one time.  [default: 8192]
          rest: Passed to transfercmd().  [default: None]

        Returns:
          The response code.
        Initiate a transfer over the data connection.

        If the transfer is active, send a port command and the
        transfer command, and accept the connection.  If the server is
        passive, send a pasv command, connect to it, and start the
        transfer command.  Either way, return the socket for the
        connection and the expected size of the transfer.  The
        expected size may be None if it could not be determined.

        Optional `rest' argument can be a string that is sent as the
        argument to a REST command.  This is essentially a server
        marker used to tell the server to skip over any data up to the
        given marker.
        Set up secure control connection by using TLS/SSL.REST %sFTP_TLS.prot_c*put*FTP.makepasvLike ntransfercmd() but returns only the socket.FTP.connectFTP.acctReturn a list of files in a given directory (default the current).FTP.nlstFTP.getmultilineFTP.mkdparse150Parse the '227' response for a PASV request.
    Raises error_proto if it does not contain '(h1,h2,h3,h4,p1,p2)'
    Return ('host.addr.as.numbers', port#) tuple._150_reparse257List a directory in long form.
        By default list current directory to stdout.
        Optional last argument is callback function; all
        non-empty arguments before it are concatenated to the
        LIST command.  (This *should* only be used for a pathname.)FTP.sendport_ge_from_le_lru_cache_wrapperthe first argument must be callableis_relatedClear the cache and cache statistics_compose_mro.<locals>.is_relatedSingle-dispatch generic function decorator.

    Transforms a function into a generic function, which can have different
    behaviours depending upon the type of its first argument. The decorated
    function acts as the default implementation, and additional
    implementations can be registered using the register() attribute of the
    generic function.

    Return a <= b.  Computed by @total_ordering from (not a >= b) or (a == b).Return a > b.  Computed by @total_ordering from (not a <= b).Calculates the method resolution order for a given class *cls*.

    Includes relevant abstract base classes (with their respective bases) from
    the *types* iterable. Uses a modified C3 linearization algorithm.

    partial.__new__Method descriptor with partial application of the given arguments
    and keywords.

    Supports wrapping existing descriptors and handles non-descriptor
    callables as instance methods.
    Computes the method resolution order using extended C3 linearization.

    If no *abcs* are given, the algorithm works exactly like the built-in C3
    linearization used for method resolution.

    If given, *abcs* is a list of abstract base classes that should be inserted
    into the resulting MRO. Unrelated ABCs are ignored and don't end up in the
    result. The algorithm inserts ABCs where their functionality is introduced,
    i.e. issubclass(cls, abc) returns True for the class itself but returns
    False for all its direct base classes. Implicit ABCs for a given class
    (either registered or inferred from the presence of a special method like
    __len__) are inserted directly after the last ABC explicitly listed in the
    MRO of said class. If two implicit ABCs end up next to each other in the
    resulting MRO, their ordering depends on the order of types in *abcs*.

    _le_from_ge_ge_from_gt_HashedSeqcmp_to_key.<locals>.K.__init__cache_tokendispatch_cachekwd_mark©Úuser_functionÚmaxsizeÚtypedÚ
_CacheInfoÚsentinelÚmake_keyÚPREVÚNEXTÚKEYÚRESULTÚcacheÚhitsÚmissesÚfullÚ	cache_getÚ	cache_lenÚlockÚrootÚwrapperÚ
cache_infoÚcache_clearReturn a >= b.  Computed by @total_ordering from (not a < b).update_wrapperReturn a > b.  Computed by @total_ordering from (a >= b) and (a != b).partialmethod.__repr__op_resultis_strict_base_clear_cachedescriptor '__new__' of partial needs an argumentsingledispatch.<locals>.register_HashedSeq.__hash___lru_cache_wrapper.<locals>.wrapper_lt_from_gtcmp_to_key.<locals>.K.__gt__explicit_basessingledispatch.<locals>.wrappercurrsize_make_keydescriptor '__call__' of partial needs an argument©ÚargsÚkwdsÚrootÚhitsÚmissesÚfullÚkeyÚlinkÚ	link_prevÚ	link_nextÚ_keyÚresultÚlastÚoldrootÚoldkeyÚ	oldresultÚmake_keyÚtypedÚlockÚ	cache_getÚNEXTÚPREVÚuser_functionÚcacheÚKEYÚRESULTÚ	cache_lenÚmaxsizepartialmethod.__get__Least-recently-used cache decorator.

    If *maxsize* is set to None, the LRU features are disabled and the cache
    can grow without bound.

    If *typed* is True, arguments of different types will be cached separately.
    For example, f(3.0) and f(3) will be treated as distinct calls with
    distinct results.

    Arguments to the cached function must be hashable.

    View the cache statistics named tuple (hits, misses, maxsize, currsize)
    with f.cache_info().  Clear the cache and statistics with f.cache_clear().
    Access the underlying function with f.__wrapped__.

    See:  http://en.wikipedia.org/wiki/Cache_algorithms#Least_Recently_Used

    new_funcExpected maxsize to be an integer or None_find_impltmpkwnewkeywordstype_setcurrent_tokenDecorator factory to apply update_wrapper() to a wrapper function

       Returns a decorator that invokes update_wrapper() with the decorated
       function as the wrapper argument and the arguments to wraps() as the
       remaining arguments. Default arguments are as for update_wrapper().
       This is a convenience function to simplify applying partial() to
       update_wrapper().
    mycmpC:\msys64\mingw64\lib\python3.6\functools.pypartial.__repr__.<locals>.<genexpr>_make_unbound_methodexpected 4 items in state, got _gt_from_ltpartialmethod.__init__Make a cache key from optionally typed positional and keyword arguments

    The key is constructed in a way that is flat as possible rather than
    as a nested structure that would take more memory.

    If there is only a single argument and its data type is known to cache
    its hash value, then that argument is returned without a wrapper.  This
    saves space and improves lookup speed.

    _lt_from_le{!r} is not callable or a descriptor_c3_mergepartialmethod.__isabstractmethod__Convert a cmp= function into a key= functionsubclsWRAPPER_UPDATESsingledispatch.<locals>.dispatchAmbiguous dispatch: {} or {}fasttypes_gt_from_leWRAPPER_ASSIGNMENTSpartial.__call___le_from_ltpartialmethod._make_unbound_method.<locals>._methodReturn a < b.  Computed by @total_ordering from (a <= b) and (a != b).call_keywordscls_or_self_ge_from_ltinvalid partial stategeneric_func.register(cls, func) -> func

        Registers a new implementation for the given *cls* on a *generic_func*.

         This class guarantees that hash() will be called no more than once
        per element.  This is important because the lru_cache() will hash
        the key multiple times on a cache miss.

    Return a <= b.  Computed by @total_ordering from (not a > b).other_c3_mros<module functools>_HashedSeq.__init___make_key.<locals>.<genexpr>Return a <= b.  Computed by @total_ordering from (a < b) or (a == b)._lru_cache_wrapper.<locals>.cache_infoNew function with partial application of the given arguments
    and keywords.
    opfunccmp_to_key.<locals>.K.__ge__partialmethod.__repr__.<locals>.<genexpr>Update a wrapper function to look like the wrapped function

       wrapper is the function to be updated
       wrapped is the original function
       assigned is a tuple naming the attributes assigned directly
       from the wrapped function to the wrapper function (defaults to
       functools.WRAPPER_ASSIGNMENTS)
       updated is a tuple naming the attributes of the wrapper that
       are updated with the corresponding attribute from the wrapped
       function (defaults to functools.WRAPPER_UPDATES)
    explicit_c3_mros{module}.{cls}({func}, {args}, {keywords})cmp_to_key.<locals>.K.__le__must define at least one ordering operation: < > <= >=partial.__setstate___le_from_gtsingledispatch.<locals>.register.<locals>.<lambda>Merges MROs in *sequences* to a single MRO using the C3 algorithm.

    Adapted from http://www.python.org/download/releases/2.3/mro/.

    Return a > b.  Computed by @total_ordering from (not a < b) and (a != b).cmp_to_key.<locals>.K.__lt__Report cache statistics_gt_from_geInconsistent hierarchyReturn a < b.  Computed by @total_ordering from (not a >= b).lru_cache.<locals>.decorating_function_lt_from_geClass decorator that fills in missing ordering methods_lru_cache_wrapper.<locals>.cache_clearabstract_basesother_basesabstract_c3_mrosReturn a >= b.  Computed by @total_ordering from (not a <= b) or (a == b)._compose_mro.<locals>.is_strict_baseReturns the best matching implementation from *registry* for type *cls*.

    Where there is no registered implementation for a specific type, its method
    resolution order is used to find a more generic implementation.

    Note: if *registry* does not contain an implementation for the base
    *object* type, this function may return None.

    generic_func.dispatch(cls) -> <function implementation>

        Runs the dispatch algorithm to return the best available implementation
        for the given *cls* registered on *generic_func*.

        hashvaluefunctools.py - Tools for working with functions and callable objects
Return a >= b.  Computed by @total_ordering from (a > b) or (a == b).type 'partial' takes at least one argumentpartial.__reduce__cmp_to_key.<locals>.K.__eq___c3_mro.<locals>.<genexpr>Return a < b.  Computed by @total_ordering from (not a > b) and (a != b).argument to __setstate__ must be a tupleTest whether a path is a regular filesameopenfileReturn the last modification time of a file, reported by os.stat().%s() argument must be str or bytes, not %rgetctimeTest whether two pathnames reference the same actual filehasbytesReturn the metadata change time of a file, reported by os.stat().Return true if the pathname refers to an existing directory.Return the last access time of a file, reported by os.stat().hasstrsepIndexaltsepIndexdotIndexfilenameIndexgetatimegetmtimegetsizeSplit the extension from a pathname.

    Extension is everything from the last dot to the end, ignoring
    leading dots.  Returns "(root, ext)"; ext may be empty.Test whether two stat buffers reference the same fileReturn the size of a file, reported by os.stat().Given a list of pathnames, returns the longest common leading componentC:\msys64\mingw64\lib\python3.6\genericpath.pyTest whether a path exists.  Returns False for broken symbolic linksCan't mix strings and bytes in path components<module genericpath>
Path operations common to more than one OS
Do not use directly.  The OS specific modules import the appropriate
functions from this module themselves.
Test whether two open file objects reference the same filest_atimest_ctimelongoptsunique_matchhas_arggetopt(args, options[, long_options]) -> opts, args

    This function works like getopt(), except that GNU style scanning
    mode is used by default. This means that option and non-option
    arguments may be intermixed. The getopt() function stops
    processing options as soon as a non-option argument is
    encountered.

    If the first character of the option string is `+', or if the
    environment variable POSIXLY_CORRECT is set, then option
    processing stops as soon as a non-option argument is encountered.

    Parser for command line options.

This module helps scripts to parse the command line arguments in
sys.argv.  It supports the same conventions as the Unix getopt()
function (including the special meanings of arguments of the form `-'
and `--').  Long options similar to those supported by GNU software
may be used as well via an optional third argument.  This module
provides two functions and an exception:

getopt() -- Parse command line options
gnu_getopt() -- Like getopt(), but allow option and non-option arguments
to be intermixed.
GetoptError -- exception (class) raised with 'opt' attribute, which is the
option involved with the exception.
optstringshortoptsoption --%s not a unique prefixoption -%s requires argumentoption -%s not recognized<module getopt>option --%s must not have an argumentdo_shortsoption --%s requires argumentoption --%s not recognizedlong_has_argsshort_has_argGetoptError.__init__prog_argsall_options_firstgetopt(args, options[, long_options]) -> opts, args

    Parses command line options and parameter list.  args is the
    argument list to be parsed, without the leading reference to the
    running program.  Typically, this means "sys.argv[1:]".  shortopts
    is the string of option letters that the script wants to
    recognize, with options that require an argument followed by a
    colon (i.e., the same format that Unix getopt() uses).  If
    specified, longopts is a list of strings with the names of the
    long options which should be supported.  The leading '--'
    characters should not be included in the option name.  Options
    which require an argument should be followed by an equal sign
    ('=').

    The return value consists of two elements: the first is a list of
    (option, value) pairs; the second is the list of program arguments
    left after the option list was stripped (this is a trailing slice
    of the first argument).  Each option-and-value pair returned has
    the option as its first element, prefixed with a hyphen (e.g.,
    '-x'), and the option argument as its second element, or an empty
    string if the option has no argument.  The options occur in the
    list in the same order in which they were found, thus allowing
    multiple occurrences.  Long and short options may be mixed.

    GetoptError.__str__C:\msys64\mingw64\lib\python3.6\getopt.pydo_longsPrompt for a password, with echo turned off.

    Args:
      prompt: Written on stream to ask for the input.  Default: 'Password: '
      stream: A writable file object to display the prompt.  Defaults to
              the tty.  If no tty is available defaults to sys.stderr.
    Returns:
      The seKr3t input.
    Raises:
      EOFError: If our input tty or stdin was closed.
      GetPassWarning: When we were unable to turn echo off on the input.

    Always restores terminal settings before returning.
    USERNAMEUtilities to get a password and/or the current user name.

getpass(prompt[, stream]) - Prompt for a password, with echo turned off.
getuser() - Get the user name from the environment or password database.

GetPassWarning - This UserWarning is issued when getpass() cannot prevent
                 echoing of the password contents while reading.

On Windows, the msvcrt module will be used.

Can not control echo on the terminal.unix_getpassputwchfallback_getpassLOGNAMEgetwchwin_getpasstcsetattr_flags_raw_inputC:\msys64\mingw64\lib\python3.6\getpass.pyPrompt for password with echo off, using Windows getch().__stdin__Get the username from the environment or password database.

    First try various environment variables, then the password
    database.  This works on Windows as long as USERNAME is set.

    <module getpass>/dev/ttyWarning: Password input may be echoed.TCSASOFT_c2py_opslocaledirlanguagesenvarnelangsmofileterritorycodeset>4ICOMPONENT_TERRITORYGNUTranslations._get_versionsdgettextNullTranslationslngettextunexpected token in plural form: %sNullTranslations.set_output_charsetNullTranslations.charset<module gettext>mofilesplural=plural form expression is too complex_binary_opsNullTranslations.lgettextWHITESPACESmsgid1msgid2_default_localedirNullTranslations.gettextNo translation file found for domainprioritynexttokif_trueif_falseldgettextNullTranslations.install%s if %s else %sVERSIONSldngettextlastgroupFile is corruptOverride this method to support alternative .mo formats._translationsGNUTranslations.ngettextadd_fallback_catalogGNUTranslations._parse.<locals>.<lambda>plural-forms_localecodesets_token_patternCOMPONENT_CODESET%s.moINVALIDCatalogNullTranslations.__init__if True:
            def func(n):
                if not isinstance(n, int):
                    n = _as_int(n)
                return int(%s)
            Plural value must be an integer, got %sunbalanced parenthesis in plural form_expand_langNullTranslations.lngettextNullTranslations._parseReturns a tuple of major version, minor version>IIGNUTranslations.gettextunexpected end of plural formBE_MAGIC
        (?P<WHITESPACES>[ \t]+)                    | # spaces and horizontal tabs
        (?P<NUMBER>[0-9]+\b)                       | # decimal integer
        (?P<NAME>n\b)                              | # only n is allowed
        (?P<PARENTHESIS>[()])                      |
        (?P<OPERATOR>[-*/%+?:]|[><!]=?|==|&&|\|\|) | # !, *, /, %, +, -, <, >,
                                                     # <=, >=, ==, !=, &&, ||,
                                                     # ? :
                                                     # unary and bitwise ops
                                                     # not allowed
        (?P<INVALID>\w+|.)                           # invalid token
    NullTranslations.add_fallbackNullTranslations.ngettextplural form expression is too longBad magic numberC:\msys64\mingw64\lib\python3.6\gettext.pyBad version number GNUTranslations.lngettextNullTranslations.output_charset©"ÚselfÚfpÚunpackÚfilenameÚcatalogÚbufÚbuflenÚmagicÚversionÚmsgcountÚ	masteridxÚtransidxÚiiÚmajor_versionÚminor_versionÚiÚmlenÚmoffÚmendÚtlenÚtoffÚtendÚmsgÚtmsgÚlastkÚb_itemÚitemÚkÚvÚpluralÚcharsetÚmsgid1Úmsgid2ÚxGets a C expression as used in PO files for plural forms and returns a
    Python function that implements an equivalent expression.
    NullTranslations.infoLE_MAGICGNUTranslations.lgettextinvalid token in plural form: %sCOMPONENT_MODIFIER_localedirsInternationalization and localization support.

This module provides internationalization (I18N) and localization (L10N)
support for your Python programs by providing an interface to the GNU gettext
message catalog library.

I18N refers to the operation by which a program is made aware of multiple
languages.  L10N refers to the adaptation of your program, once
internationalized, to the local language and cultural habits.

<4I_current_domainC:\msys64\mingw64\lib\python3.6\site-packages\giNamespace %s not available for version %spygobject_version Utility function for consolidating multiple `gi.require_version()` calls.

    :param requires: The names and versions of modules to require.
    :type requires: dict

    :Example:

    .. code-block:: python

        import gi
        gi.require_versions({'Gtk': '3.0', 'GLib': '2.0', 'Gio': '2.0'})
    Namespace %s already requires version %smodule_version_DummyStaticModule Ensures the correct versions are loaded when importing `gi` modules.

    :param namespace: The name of module to require.
    :type namespace: str
    :param version: The version of module to require.
    :type version: str
    :raises ValueError: If module/version is already loaded, already required, or unavailable.

    :Example:

    .. code-block:: python

        import gi
        gi.require_version('Gtk', '3.0')

    _gobjectrequire_foreign_DummyStaticModule.__getattr__loaded_version<module gi>_static_binding_erroravailable_versionsWhen using gi.repository you must not import static modules like "gobject". Please change all occurrences of "import gobject" to "from gi.repository import GObject". See: https://bugzilla.gnome.org/show_bug.cgi?id=709183Namespace version needs to be a string.Namespace %s is already loaded with version %spygobject's version %s required, and available version %s is not recent enough_PyGObject_APIget_loaded_namespacescheck_versionversion_listC:\msys64\mingw64\lib\python3.6\site-packages\gi\__init__.py_overridesdirEnsure the given foreign marshaling module is available and loaded.

    :param str namespace:
        Introspection namespace of the foreign module (e.g. "cairo")
    :param symbol:
        Optional symbol typename to ensure a converter exists.
    :type symbol: str or None
    :raises: ImportError

    :Example:

    .. code-block:: python

        import gi
        import cairo
        gi.require_foreign('cairo')

    gchararrayGStrvTYPE_UNICHARgint64guchargpointerguint64type_from_name<module gi._constants>gulonggfloatgbooleanGVariantGTypeGParamglongC:\msys64\mingw64\lib\python3.6\site-packages\gi\_constants.pytype_is_aPARAM_READWRITE_readonly_setter_get_maximumProperty.__repr__G_MINLONGG_MAXLONGProperty._get_maximumProperty._get_defaultProperty.__init__
    Scans the given class for instances of Property and merges them
    into the classes __gproperties__ dict if it exists or adds it if not.
    nickobj_get_propertyobject types does not have default values©Ú	TYPE_NONEÚTYPE_INTERFACEÚ	TYPE_CHARÚ
TYPE_UCHARÚTYPE_BOOLEANÚTYPE_INTÚ	TYPE_UINTÚ	TYPE_LONGÚ
TYPE_ULONGÚ
TYPE_INT64ÚTYPE_UINT64Ú	TYPE_ENUMÚ
TYPE_FLAGSÚ
TYPE_FLOATÚTYPE_DOUBLEÚTYPE_STRINGÚTYPE_POINTERÚ
TYPE_BOXEDÚ
TYPE_PARAMÚTYPE_OBJECTÚTYPE_PYOBJECTÚ
TYPE_GTYPEÚ	TYPE_STRVÚTYPE_VARIANTProperty %s was already found in __gproperties__G_MAXDOUBLECreates a new Property which when used in conjunction with
    GObject subclass will create a Python property accessor for the
    GObject ParamSpec.

    :param callable getter:
        getter to get the value of the property
    :param callable setter:
        setter to set the value of the property
    :param type type:
        type of property
    :param default:
        default value, must match the property type.
    :param str nick:
        short description
    :param str blurb:
        long description
    :param GObject.ParamFlags flags:
        parameter flags
    :keyword minimum:
        minimum allowed value (int, float, long only)
    :keyword maximum:
        maximum allowed value (int, float, long only)

    .. code-block:: python

         class MyObject(GObject.Object):
             prop = GObject.Property(type=str)

         obj = MyObject()
         obj.prop = 'value'

         obj.prop  # now is 'value'

    The API is similar to the builtin :py:func:`property`:

    .. code-block:: python

        class AnotherObject(GObject.Object):
            value = 0

            @GObject.Property
            def prop(self):
                'Read only property.'
                return 1

            @GObject.Property(type=int)
            def propInt(self):
                'Read-write integer property.'
                return self.value

            @propInt.setter
            def propInt(self, value):
                self.value = value
    flags value %s must be an instance of %rAllows application of the getter along with init arguments.install_properties.<locals>.obj_set_property<class 'GObject.Property'>Property._default_getterinstall_properties.<locals>.obj_get_propertyProperty.__call__Property.getterSet the setter function to fset. For use as a decorator._check_default<module gi._propertyhelper>Property._readonly_setterProperty.__set__(uninitialized)_default_setterG_MAXINTnick must be a stringget_pspec_args_min_value_lookupProperty._check_defaultG_MAXFLOAT_type_from_pythonProperty._writeonly_getterblurb must be a stringStrv value %s must be a list_default_lookupProperty.get_pspec_args_type_from_pytype_lookupC:\msys64\mingw64\lib\python3.6\site-packages\gi\_propertyhelper.pydefault must be True or False, not %rProperty.__metaclass__.__repr__Unsupported type: %rG_MININT_get_minimumGObject subclass %r defines do_get/set_property and it also uses a property with a custom setter or getter. This is not alloweddo_get_property_basestring%s property of %s is read-only_property_helper_Property._type_from_pythonProperty.setter_max_value_lookup<GObject Property %s (%s)>%s property of %s is write-onlySet the getter function to fget. For use as a decorator.Property._get_minimumProperty._default_setterMinimum for type %s cannot be lower than %dG_MAXUINTenum properties needs a default valueG_MAXULONGenum value %s must be an instance of %rStrv value %s must contain only stringsvariant value %s must be an instance of %rProperty.__get__Maximum for type %s cannot be higher than %dGType types does not have default valuesdo_set_propertyhandler_id
        Temporary binding object which can be used for connecting signals
        without specifying the signal name string to connect.
        SignalOverrideReturns a tuple of: (flags, return_type, arg_types, accumulator, accu_data)Same as GObject.Object.connect except there is no need to specify
            the signal name.Signal.__get__Returns a BoundSignal when accessed on an object instance.Attempt pulling python 3 function annotations off of 'func' for
    use as a signals type information. Returns an ordered nested tuple
    of (return_type, (arg_type1, arg_type2, ...)). If the given function
    does not have annotations then (None, tuple()) is returned.
    Signal.__call__newsignalsSignal.copy<module gi._signalhelper>newNameSignal.BoundSignal.__repr__Returns the string 'override'.Signal.BoundSignal.__init__connect_detailedObject which gives a nice API for creating and binding signals.

    :param name:
        Name of signal or callable closure when used as a decorator.
    :type name: str or callable
    :param callable func:
        Callable closure method.
    :param GObject.SignalFlags flags:
        Flags specifying when to run closure.
    :param type return_type:
        Return type of the Signal.
    :param list arg_types:
        List of argument types specifying the signals function signature
    :param str doc:
        Documentation of signal object.
    :param callable accumulator:
        Accumulator method with the signature:
        func(ihint, return_accu, handler_return, accu_data) -> boolean
    :param object accu_data:
        User data passed to the accumulator.

    :Example:

    .. code-block:: python

        class Spam(GObject.Object):
            velocity = 0

            @GObject.Signal
            def pushed(self):
                self.velocity += 1

            @GObject.Signal(flags=GObject.SignalFlags.RUN_LAST)
            def pulled(self):
                self.velocity -= 1

            stomped = GObject.Signal('stomped', arg_types=(int,))

            @GObject.Signal
            def annotated_signal(self, a:int, b:str):
                "Python3 annotation support for parameter types.

        def on_pushed(obj):
            print(obj)

        spam = Spam()
        spam.pushed.connect(on_pushed)
        spam.pushed.emit()
    Same as GObject.Object.disconnect.Signal "%s" has already been registered.Signal.__new__get_signal_annotationsAllows for instantiated Signals to be used as a decorator or calling
        of the underlying signal method.get_signal_argsSignal.get_signal_argsSignal.BoundSignal.__call__Adds Signal instances on a GObject derived class into the '__gsignals__'
    dictionary to be picked up and registered as real GObject signals.
    signalNameC:\msys64\mingw64\lib\python3.6\site-packages\gi\_signalhelper.pyReturns a renamed copy of the Signal.Signal.BoundSignal.disconnectSignal.BoundSignal.__new__Same as GObject.Object.emit except there is no need to specify
            the signal name.Specialized sub-class of Signal which can be used as a decorator for overriding
    existing signals on GObjects.

    :Example:

    .. code-block:: python

        class MyWidget(Gtk.Widget):
            @GObject.SignalOverride
            def configure_event(self):
                pass
    SignalOverride.get_signal_argsSignal.BoundSignal.connectSignal.BoundSignal.emitSame as GObject.Object.connect except there is no need to specify
            the signal name. In addition concats "::<detail>" to the signal name
            when connecting; for use with notifications like "notify" when a property
            changes.
            get_signal_annotations.<locals>.<genexpr>Signal.BoundSignal.connect_detailedCall the signals closure.BoundSignal("%s")GHASHhint_blacklist%s(%s) -> %sSet doc string generator function

    :param callable func:
        Callable which takes a GIInfoStruct and returns documentation for it.
    TypeTagis_methodINT32get_tag_as_string_generate_class_info_docignore_indicesINT8(**properties)
_type_tag_to_py_typeget_typeDirection_generate_doc_string_funcin_args_strget_array_lengthVOIDmay_be_nullGSLISTReturns the currently registered doc string generator.user_data_indicesis_optional_generate_doc_dispatch<module gi.docstring>get_destroyinfo_namereturn_hintmay_return_nullout_args_strsUINT16UINT32get_interfacegi_typeifaceGLISTargstrGenerate a doc string given a GIInfoStruct.

    :param gi.types.BaseInfo info:
        GI info instance to generate documentation for.
    :returns:
        Generated documentation as a string.
    :rtype: str

    This passes the info struct to the currently registered doc string
    generator and returns the result.
    _generate_callable_info_docC:\msys64\mingw64\lib\python3.6\site-packages\gi\docstring.py_get_pytype_hintin_args_strsset_doc_string_generatorskip_return=<optional>get_return_typeget_doc_string_generatorget_directionget_closure
:Constructors:

::

UINT8get_import_stacklevel<module gi.importer>DynamicImporter.__init__is_registeredReturns the stacklevel value for warnings.warn() for when the warning
    gets emitted by an imported module, but the warning should point at the
    code doing the import.

    Pass import_hook=True if the warning gets generated by an import hook
    (warn() gets called in load_module(), see PEP302)
    _check_require_versioncannot import name %s, introspection typelib not foundDynamicImporter.load_moduleRepositoryErrorDynamicImporter.find_moduleA context manager which tries to give helpful warnings
    about missing gi.require_version() which could potentially
    break code if only an older version than expected is installed
    or a new version gets introduced.

    ::

        with _check_require_version("Gtk", stacklevel):
            load_namespace_and_overrides()
    get_immediate_dependenciesC:\msys64\mingw64\lib\python3.6\site-packages\gi\importer.py%(namespace)s was imported without specifying a version first. Use gi.require_version('%(namespace)s', '%(version)s') before import to ensure that the right version gets loaded.dynamic_modulewas_loadedCallbackInfoget_typelib_pathget_interfacesget_name_unescapedIntrospectionModulenamespace_infosenum_register_new_gtype_and_add
    :Returns:
        An object directly wrapping the gi module without overrides.

    Might raise gi._gi.RepositoryError
    interface_infoabcdefgjhijklmnopqrstuvwxyzUnionInfoEnumInfoenum_add_introspection_modulesC:\msys64\mingw64\lib\python3.6\site-packages\gi\module.pyflags_addABCDEFGJHIJKLMNOPQRSTUVWXYZConstantInfo%r object has no attribute %rIntrospectionModule.__repr__IntrospectionModule.__dir__object_infoparent_object_infoRegisteredTypeInfoBoxedCCallbackflags_register_new_gtype_and_addget_infosIntrospectionModule.__init__unable to create a wrapper for %s.%sis_flagsget_parent_for_objectascii_upper_transvalue_info<IntrospectionModule %r from %r><module gi.module>IntrospectionModule.__getattr___have_py3IntrospectionModule.__dir__.<locals>.<genexpr>get_interfaces_for_objectAn object which wraps an introspection typelib.

    This wrapping creates a python module like representation of the typelib
    using gi repository as a foundation. Accessing attributes of the module
    will dynamically pull them in and create wrappers for the members.
    These members are then cached on this introspection module.
    find_by_nameIntrospectionModule.__getattr__.<locals>.<genexpr>OverridesProxyModule.__init__OverridesProxyModule.__getattr__Can not override a type %s, which is not in a gobject introspection typelibnew_initold_moduledeprecated_defaultssuper_init_funcYou have tried override outside of the overrides module. This is not allowed (%s, %s)%s is deprecated; use %s insteadwraps.<locals>.assign_DeprecatedAttribute.__get__override_package_nameoverridefuncdefaults_usedfunc must be a gi function, got %sC:\msys64\mingw64\lib\python3.6\site-packages\gi\overrides_deprecated_attrsaliases_usedcall failedLoads overrides for an introspection module.

    Either returns the same module again in case there are no overrides or a
    proxy module including overrides. Doesn't cache the result.
    %s.%s is deprecated; use %s insteadstrip_boolean_result.<locals>.wrappedexc_strnew_kwargs_DeprecatedAttribute.__delete__deprecated_aliasesWrapper for deprecating GObject based __init__ methods which specify
    defaults already available or non-standard defaults.

    :param callable super_init_func:
        Initializer to wrap.
    :param list arg_names:
        Ordered argument name list.
    :param list ignore:
        List of argument names to ignore when calling the wrapped function.
        This is useful for function which take a non-standard keyword that is munged elsewhere.
    :param dict deprecated_aliases:
        Dictionary mapping a keyword alias to the actual g_object_newv keyword.
    :param dict deprecated_defaults:
        Dictionary of non-standard defaults that will be used when the
        keyword is not explicitly passed.
    :param Exception category:
        Exception category of the error.
    :param int stacklevel:
        Stack level for the deprecation passed on to warnings.warn
    :returns: Wrapped version of ``super_init_func`` which gives a deprecation
        warning when non-keyword args or aliases are used.
    :rtype: callable
    Using positional arguments with the GObject constructor has been deprecated. Please specify keyword(s) for "%s" or use a class specific constructor. See: https://wiki.gnome.org/PyGObject/InitializerDeprecations%s was set deprecated but wasn't added to __all__Wraps a introspection module and contains all overridesfail_retmodule_keyhas_oldoverride_loaderoverride_modDecorator for marking methods and classes as deprecated<module gi.overrides>deprecated_init.<locals>.new_init.<locals>.<genexpr>Marks a module level attribute as deprecated. Accessing it will emit
    a PyGIDeprecationWarning warning.

    e.g. for ``deprecated_attr("GObject", "STATUS_FOO", "GLib.Status.FOO")``
    accessing GObject.STATUS_FOO will emit:

        "GObject.STATUS_FOO is deprecated; use GLib.Status.FOO instead"

    :param str namespace:
        The namespace of the override this is called in.
    :param str namespace:
        The attribute name (which gets added to __all__).
    :param str replacement:
        The replacement text which will be included in the warning.
    override.<locals>.wrapper_DeprecatedAttribute.__set__deprecated.<locals>.wrappedOverridesProxyModule.__dir__Initializer for a GObject based classes with support for property
        sets through the use of explicit keyword arguments.
        Initializer is relying on deprecated non-standard defaults. Please update to explicitly use: %s See: https://wiki.gnome.org/PyGObject/InitializerDeprecationsA deprecation descriptor for OverridesProxyModule subclasses.

    Emits a PyGIDeprecationWarning on every access and tries to act as a
    normal instance attribute (can be replaced and deleted).
    The keyword(s) "%s" have been deprecated in favor of "%s" respectively. See: https://wiki.gnome.org/PyGObject/InitializerDeprecationsC:\msys64\mingw64\lib\python3.6\site-packages\gi\overrides\__init__.py_overrides_module_DeprecatedAttribute.__init__Translate method's return value for stripping off success flag.

    There are a lot of methods which return a "success" boolean and have
    several out arguments. Translate such a method to return the out arguments
    on success and None on failure.
    OverridesProxyModule.__repr__Decorator for registering an override.

    Other than objects added to __all__, these can get referenced in the same
    override module via the gi.repository module (get_parent_for_object() does
    for example), so they have to be added to the module immediately.
    Armenian_ellipsisArmenian_en_dashC:\msys64\mingw64\lib\python3.6\site-packages\gi\overrides\keysyms.pyArmenian_commaArmenian_guillemotleftArmenian_eternityArmenian_guillemotright_keysyms_modnameArmenian_section_signArmenian_dotkeysyms has been deprecated. Please use Gdk.KEY_<name> instead.Armenian_em_dashArmenian_parenleftgi.overrides.keysyms<module gi.overrides.keysyms>Armenian_mijaketgi.pygtkcompat is being deprecated in favor of using "pygtkcompat" directly.C:\msys64\mingw64\lib\python3.6\site-packages\gi\pygtkcompat.py<module gi.pygtkcompat>C:\msys64\mingw64\lib\python3.6\site-packages\gi\repository<module gi.repository>C:\msys64\mingw64\lib\python3.6\site-packages\gi\repository\__init__.pyis_gi_definedis_python_definedvfunc_nameaklass([a-z0-9])([A-Z])Meta class used for GI GObject based types.Meta class used for GI Struct based types._setup_vfuncsCompute the class precedence list (mro) according to C3, with GObject
    interface considerations.

    We override Python's MRO calculation to account for the fact that
    GObject classes are not affected by the diamond problem:
    http://en.wikipedia.org/wiki/Diamond_problem

    Based on http://www.python.org/download/releases/2.3/mro/
    gi.repository.GObject\1_\2class_structMetaClassHelper._setup_constantsbases_of_subclassesget_fieldsfind_vfunc_info_in_interfaceGObjectMeta.__init__get_type_nameGObjectMeta.mrodo_%s_%s_GObjectMetaBase.__init__StructMeta.__doc__Cannot create a consistent method resolution order (MRO)constant_info_setup_class_methods_GObjectMetaBase._type_register<module gi.types>_setup_methodsget_constants_setup_native_vfuncs_install_metaclassget_vfuncsMetaClassHelper._setup_native_vfuncsfind_vfunc_conflict_in_basespy_vfuncskip_ambiguity_checkambiguous_basebase_infoMetaClassHelper._setup_class_methodssubclass_basesnot_headsnake_casehook_up_vfunc_implementation(.)([A-Z][a-z]+)field_infoMethod %s() on class %s.%s is ambiguous with methods in base classes %s.%s and %s.%sC:\msys64\mingw64\lib\python3.6\site-packages\gi\types.pyMetaClassHelper._setup_vfuncsMixin class %s is an old style class, please update this to derive from "object".GObjectMeta.__doc__MetaClassHelper._setup_methodsStructMeta.__init__get_container__gtype_name___setup_fieldsregister_interface_infoMetaclass for automatically registering GObject classes.get_class_structMeta class property which shows up on any class using this meta-class.MetaClassHelper._setup_fields_glob1Return an iterator which yields the paths matching a pathname pattern.

    The pattern may contain simple shell-style wildcards a la
    fnmatch. However, unlike fnmatch, filenames starting with a
    dot are special cases that are not matched by '*' and '?'
    patterns.

    If recursive is true, the pattern '**' will match any files and
    zero or more directories and subdirectories.
    ([*?[])Filename globbing utility.dironly_rlistdir[\1]_glob0Escape all special characters.
    _glob1.<locals>.<genexpr>glob_in_dirmagic_check_iterdir<module glob>_glob2Return a list of paths matching a pathname pattern.

    The pattern may contain simple shell-style wildcards a la
    fnmatch. However, unlike fnmatch, filenames starting with a
    dot are special cases that are not matched by '*' and '?'
    patterns.

    If recursive is true, the pattern '**' will match any files and
    zero or more directories and subdirectories.
    _iglob_isrecursivemagic_check_byteshas_magicC:\msys64\mingw64\lib\python3.6\glob.py_ishiddenGuarding.new_case_selectedguarding_locationsllqGuarding.__init__<module guarding>luqruqrlqmegalysC:\msys64\home\cbper\guarding.pynew_location
Guarding models the guarding balloons
case_wordsGuarding.get_active_locationset_active_locationGuarding.set_active_locationûznoneznonezhepatomegalyzhepatomegalyzsplenomegalyzsplenomegalyzenlarged_bladderzenlarged_bladderzappendixzrlqzcolonzllqzgallbladderzruqzugiznonez
ovary_leftzllqzovary_rightzrlqzpancreasznone0C:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\guiC:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\gui\__init__.pyQFont#[^\n]*indexIn_colorcreateTextFormat Syntax highlighting for Python.

Inspired/copied from by http://diotavelli.net/PyQtWiki/Python%20syntax%20highlighting
PythonHighlightergui.SyntaxHighlighting\{magentaQRegExpsetForegroundbrowncurrentBlockStatePythonHighlighter.match_multilinedefclasshighlightBlockPythonHighlighter.highlightBlockQTextCharFormatsetNamedColor\}display_formatin_multiline\b[+-]?0[xX][0-9A-Fa-f]+[lL]?\bsetCurrentBlockStatetri_double\bclass\b\s*(\w+)\bdef\b\s*(\w+)QColorDo highlighting of multi-line strings. ``delimiter`` should be a
        ``QRegExp`` for triple-single-quotes or triple-double-quotes, and
        ``in_state`` should be a unique integer to represent the corresponding
        state changes when inside those strings. Returns True if we're still
        inside a multi-line string when this function is finished.
        QSyntaxHighlighterdarkGray'[^'\\]*(\\.[^'\\]*)*'Return a QTextCharFormat with the given attributes.
    string2BoldApply syntax highlighting to the given block of text.
        \b%s\b\b[+-]?[0-9]+(?:\.[0-9]+)?(?:[eE][+-]?[0-9]+)?\bdarkGreensetFontItalic\b[+-]?[0-9]+[lL]?\b Syntax highlighter for the Python language.
    \bself\btri_singleitalicdarkMagentasetFormat"[^"\\]*(\\.[^"\\]*)*"matchedLengthSTYLESC:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\gui\SyntaxHighlighting.pyPythonHighlighter.__init__Û!   zandzassertzbreakzclasszcontinuezdefzdelzelifzelsezexceptzexeczfinallyzforzfromzglobalzifzimportzinziszlambdaznotzorzpasszprintzraisezreturnztryzwhilezwithzyieldzNonezTruezFalsepreviousBlockStateÛ   ú=z==z!=ú<z<=ú>z>=z\+ú-z\*ú/z//z\%z\*\*z\+=z-=z\*=z/=z\%=z\^z\|z\&z\~z>>z<<setFontWeight<module gui.SyntaxHighlighting>QDialogitem_pathsetWindowFlagsgetNodeFromPathNodeTreeModelItemNodeTreeModelItem.rowinternalPointerNode DetailheaderDataNodeTreeModelItem.columnCountItemIsSelectableNodeTreeModelItem._children.<locals>.<genexpr>textedit_sourceNodeTreeModelItem.__init__treeview_nodespyqtSignatureHorizontalloadSourceInspectNodeTreeDialogNodeTreeModel.parentonTreeviewNodesClickedmoveCursorDisplayRolegetItemFromSourceRefdialogsNodeTreeModel.getItemFromSourceRefNodeTreeModel.__init__InspectNodeTreeDialog.loadSource Module with functions to display a node tree.

Useful to getting an idea of what the internal representation of Nuitka is about a source
code.
NodeTreeModel.flagson_treeview_nodes_clicked(QModelIndex)InspectNodeTreeDialog.onTreeviewNodesClickedNodeTreeModelItem.childisValidroot_nodechildCountNode TypesetSelectionModeC:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\gui\TreeDisplay.pyNodeTreeModel.getNodeFromPathNodeTreeModel.dataonTexteditSourceCursorMovedexpandAllQtCoreQtGuisetModeltree_pathNodeTreeModelItem.parentroot_item<module gui.TreeDisplay>QAbstractItemModelSingleSelectionclicked_nodeInspectNodeTreeDialog.onTexteditSourceCursorMovedNodeTreeModelItem.appendChildInspectNodeTreeDialog.__init__ui_diron_textedit_source_cursorPositionChanged()NodeTreeModelItem.dataNodeTreeModel.headerDataQVariantItemIsEnabledui_filenameNodeTreeModel.columnCounttextCursorsetPlainTextNodeTreeModel.indexcreateIndexrowCountNodeTreeModelItem.childCountsetFocusNodeTreeModel.rowCountInspectNodeTreeDialog.setModelQApplicationInspectPythonTree.uiloadUiNodeTreeModel.getItemFromSourceRef.<locals>.checkparent_treeitem_PaddedFile.__init___GzipReader._add_read_dataNot a gzipped file (%r)wbitsGzipFile.peek_GzipReader.__init___GzipReader.read_write_gzip_headerGzipFile.writableFTEXTC:\msys64\mingw64\lib\python3.6\gzip.pyOpen a gzip-compressed file in binary or text mode.

    The filename argument can be an actual filename (a str or bytes object), or
    an existing file object to read from or write to.

    The mode argument can be "r", "rb", "w", "wb", "x", "xb", "a" or "ab" for
    binary mode, or "rt", "wt", "xt" or "at" for text mode. The default mode is
    "rb", and the default compresslevel is 9.

    For binary mode, this function is equivalent to the GzipFile constructor:
    GzipFile(filename, mode, compresslevel). In this case, the encoding, errors
    and newline arguments must not be provided.

    For text mode, a GzipFile object is created, and wrapped in an
    io.TextIOWrapper instance with the specified encoding, error handling
    behavior, and line ending(s).

    .gzgz_modewrite() on read-only GzipFile object_read_gzip_headerIncorrect length of data produced_init_readInvoke the underlying file object's fileno() method.

        This will raise AttributeError if the underlying file object
        doesn't support fileno().
        zlib_mode_read_exact_PaddedFile.prependGzipFile.close_GzipReader._init_readFHCRC_init_writeReturn the uncompressed stream file position indicator to the
        beginning of the fileZ_SYNC_FLUSHfilename doesn't end in .gz:Unknown compression methodGzipFile.flushuse the name attributeDecompress a gzip compressed string in one shot.
    Return the decompressed string.
    <module gzip>Last modification time read from stream, or NoneGzipFile.writeGzipFile.seekGzipFile.__init__filename must be a str or bytes object, or a fileGzipFile.read1<BBIxxMinimal read-only file object that prepends a string to the contents
    of an actual file. Shouldn't be used outside of gzip.py, as it lacks
    essential functionality.Constructor for the GzipFile class.

        At least one of fileobj and filename must be given a
        non-trivial value.

        The new class instance is based on fileobj, which can be a regular
        file, an io.BytesIO object, or any other object which simulates a file.
        It defaults to None, in which case filename is opened to provide
        a file object.

        When fileobj is not None, the filename argument is only used to be
        included in the gzip file header, which may include the original
        filename of the uncompressed file.  It defaults to the filename of
        fileobj, if discernible; otherwise, it defaults to the empty string,
        and in this case the original filename is not included in the header.

        The mode argument can be any of 'r', 'rb', 'a', 'ab', 'w', 'wb', 'x', or
        'xb' depending on whether the file will be read or written.  The default
        is the mode of fileobj if discernible; otherwise, the default is 'rb'.
        A mode of 'r' is equivalent to one of 'rb', and similarly for 'w' and
        'wb', 'a' and 'ab', and 'x' and 'xb'.

        The compresslevel argument is an integer from 0 to 9 controlling the
        level of compression; 1 is fastest and produces the least compression,
        and 9 is slowest and produces the most compression. 0 is no compression
        at all. The default is 9.

        The mtime argument is an optional numeric timestamp to be written
        to the last modification time field in the stream when compressing.
        If omitted or None, the current time is used.

        GzipFile.fileno<gzip isizemyfileobjFCOMMENTRead exactly *n* bytes from `self._fp`

        This method is required because self._fp may be unbuffered,
        i.e. return short reads.
        GzipFile.mtimeImplements BufferedIOBase.read1()

        Reads up to a buffer's worth of data is size is negative.GzipFile.readlineThe GzipFile class simulates most of the methods of a file object with
    the exception of the truncate() method.

    This class only supports opening files in binary mode. If you need to open a
    compressed file in text mode, use the gzip.open() function.

    writebufCRC check failed %s != %sextra_len_write_mtimeGzipFile.rewindFNAME_GzipReader._rewindpeek() on write-only GzipFile objectwrite() on closed GzipFile objectSeek from end not supportedGzipFile.readable_PaddedFile.seekFunctions that read and write gzipped files.

The user of the file doesn't have to worry about the compression,
but random access is not allowed._GzipReader._read_exact_GzipReader._read_eofread() on write-only GzipFile object_PaddedFile.read_PaddedFile.seekableGzipFile._write_gzip_headerCompress data in one shot and return the compressed string.
    Optional argument is the compression level, in range of 0-9.
    GzipFile.__repr___stream_sizewrite32u_GzipReader._read_gzip_headerGzipFile.closedGzipFile.seekable_last_mtimeGzipFile.filenameCan't rewind in write moderead1() on write-only GzipFile objectFEXTRAGzipFile._init_writeNegative seek in write modeSHA512SHA384sha384sha3_224__always_supportedSHA256sha256SHA224sha224__get_hash_sha256__hash_newpbkdf2_hmacsha3_512scryptblake2bblake2ssha3_256sha3_384shake_128shake_256new(name, data=b'') - Return a new hashing object using the named algorithm;
    optionally initialized with data (which must be bytes).
    __get_builtin_constructor__builtin_constructor_cache<module hashlib>code for hash %s was not found.algorithms_available_blake2hash_name_sha1_md5_sha3__py_newsaltSHA1hashlib module - A common interface to many hash functions.

new(name, data=b'', **kwargs) - returns a new hash object implementing the
                                given hash function; initializing the hash
                                using the given binary data.

Named constructor functions are also available, these are faster
than using new(name):

md5(), sha1(), sha224(), sha256(), sha384(), sha512(), blake2b(), blake2s(),
sha3_224, sha3_256, sha3_384, sha3_512, shake_128, and shake_256.

More algorithms may be available on your platform but the above are guaranteed
to exist.  See the algorithms_guaranteed and algorithms_available attributes
to find out what algorithm names can be passed to new().

NOTE: If you want the adler32 or crc32 hash functions they are available in
the zlib module.

Choose your hash function wisely.  Some have known collision weaknesses.
sha384 and sha512 will be slow on 32 bit platforms.

Hash objects have these methods:
 - update(arg): Update the hash object with the bytes in arg. Repeated calls
                are equivalent to a single call with the concatenation of all
                the arguments.
 - digest():    Return the digest of the bytes passed to the update() method
                so far.
 - hexdigest(): Like digest() except the digest is returned as a unicode
                object of double length, containing only hexadecimal digits.
 - copy():      Return a copy (clone) of the hash object. This can be used to
                efficiently compute the digests of strings that share a common
                initial substring.

For example, to obtain the digest of the string 'Nobody inspects the
spammish repetition':

    >>> import hashlib
    >>> m = hashlib.md5()
    >>> m.update(b"Nobody inspects")
    >>> m.update(b" the spammish repetition")
    >>> m.digest()
    b'\xbbd\x9c\x83\xdd\x1e\xa5\xc9\xd9\xde\xc9\xa1\x8d\xf0\xff\xe9'

More condensed:

    >>> hashlib.sha224(b"Nobody inspects the spammish repetition").hexdigest()
    'a4337bc45a8fc544c03f52dc550cd6e1e87021bc896588bd79e901e2'

unsupported hash type __get_openssl_constructor_trans_5Citerations__func_namedklenpbkdf2_hmac.<locals>.prfocpynew(name, data=b'', **kwargs) - Return a new hashing object using the
    named algorithm; optionally initialized with data (which must be bytes).
    C:\msys64\mingw64\lib\python3.6\hashlib.pyopenssl_md_meth_namesPassword based key derivation function 2 (PKCS #5 v2.0)

        This Python implementations based on the hmac module about as fast
        as OpenSSL's PKCS5_PBKDF2_HMAC for short passwords and much faster
        for long passwords.
        icpy_trans_36lasteltreturnitem_heapreplace_max_heapify_maxnsmallestheappushpopTransform list into a heap, in-place, in O(len(x)) time.parentpos_heappop_maxFast version of a heappush followed by a heappop.Maxheap variant of _siftupchildposMerge multiple sorted inputs into a single sorted output.

    Similar to sorted(itertools.chain(*iterables)) but returns a generator,
    does not pull the data into memory all at once, and assumes that each of
    the input streams is already sorted (smallest to largest).

    >>> list(merge([1,3,5,7], [0,2,4,8], [5,10,15,20], [], [25]))
    [0, 1, 2, 3, 4, 5, 5, 7, 8, 10, 15, 20, 25]

    If *key* is not None, applies a key function to each element to determine
    its sort order.

    >>> list(merge(['dog', 'horse'], ['cat', 'fish', 'kangaroo'], key=len))
    ['dog', 'cat', 'fish', 'horse', 'kangaroo']

    C:\msys64\mingw64\lib\python3.6\heapq.pykey_valueTransform list into a maxheap, in-place, in O(len(x)) time.__about__Heap queues

[explanation by FranÃ§ois Pinard]

Heaps are arrays for which a[k] <= a[2*k+1] and a[k] <= a[2*k+2] for
all k, counting elements from 0.  For the sake of comparison,
non-existing elements are considered to be infinite.  The interesting
property of a heap is that a[0] is always its smallest element.

The strange invariant above is meant to be an efficient memory
representation for a tournament.  The numbers below are `k', not a[k]:

                                   0

                  1                                 2

          3               4                5               6

      7       8       9       10      11      12      13      14

    15 16   17 18   19 20   21 22   23 24   25 26   27 28   29 30


In the tree above, each cell `k' is topping `2*k+1' and `2*k+2'.  In
a usual binary tournament we see in sports, each cell is the winner
over the two cells it tops, and we can trace the winner down the tree
to see all opponents s/he had.  However, in many computer applications
of such tournaments, we do not need to trace the history of a winner.
To be more memory efficient, when a winner is promoted, we try to
replace it by something else at a lower level, and the rule becomes
that a cell and the two cells it tops contain three different items,
but the top cell "wins" over the two topped cells.

If this heap invariant is protected at all time, index 0 is clearly
the overall winner.  The simplest algorithmic way to remove it and
find the "next" winner is to move some loser (let's say cell 30 in the
diagram above) into the 0 position, and then percolate this new 0 down
the tree, exchanging values, until the invariant is re-established.
This is clearly logarithmic on the total number of items in the tree.
By iterating over all items, you get an O(n ln n) sort.

A nice feature of this sort is that you can efficiently insert new
items while the sort is going on, provided that the inserted items are
not "better" than the last 0'th element you extracted.  This is
especially useful in simulation contexts, where the tree holds all
incoming events, and the "win" condition means the smallest scheduled
time.  When an event schedule other events for execution, they are
scheduled into the future, so they can easily go into the heap.  So, a
heap is a good structure for implementing schedulers (this is what I
used for my MIDI sequencer :-).

Various structures for implementing schedulers have been extensively
studied, and heaps are good for this, as they are reasonably speedy,
the speed is almost constant, and the worst case is not much different
than the average case.  However, there are other representations which
are more efficient overall, yet the worst cases might be terrible.

Heaps are also very useful in big disk sorts.  You most probably all
know that a big sort implies producing "runs" (which are pre-sorted
sequences, which size is usually related to the amount of CPU memory),
followed by a merging passes for these runs, which merging is often
very cleverly organised[1].  It is very important that the initial
sort produces the longest runs possible.  Tournaments are a good way
to that.  If, using all the memory available to hold a tournament, you
replace and percolate items that happen to fit the current run, you'll
produce runs which are twice the size of the memory for random input,
and much better for input fuzzily ordered.

Moreover, if you output the 0'th item on disk and get an input which
may not fit in the current tournament (because the value "wins" over
the last output value), it cannot fit in the heap, so the size of the
heap decreases.  The freed memory could be cleverly reused immediately
for progressively building a second heap, which grows at exactly the
same rate the first heap is melting.  When the first heap completely
vanishes, you switch heaps and start a new run.  Clever and quite
effective!

In a word, heaps are useful memory structures to know.  I use them in
a few applications, and I think it is good to keep a `heap' module
around. :-)

--------------------
[1] The disk balancing algorithms which are current, nowadays, are
more annoying than clever, and this is a consequence of the seeking
capabilities of the disks.  On devices which cannot seek, like big
tape drives, the story was quite different, and one had to be very
clever to ensure (far in advance) that each tape movement will be the
most effective possible (that is, will best participate at
"progressing" the merge).  Some tapes were even able to read
backwards, and this was also used to avoid the rewinding time.
Believe me, real good tape sorts were quite spectacular to watch!
From all times, sorting has always been a Great Art! :-)
h_appendPop the smallest item off the heap, maintaining the heap invariant.Maxheap variant of _siftdownPop and return the current smallest value, and add the new item.

    This is more efficient than heappop() followed by heappush(), and can be
    more appropriate when using a fixed-size heap.  Note that the value
    returned may be larger than item!  That constrains reasonable uses of
    this routine unless written as part of a conditional replacement:

        if item > heap[0]:
            item = heapreplace(heap, item)
    Find the n smallest elements in a dataset.

    Equivalent to:  sorted(iterable, key=key)[:n]
    _siftdown_max<module heapq>Maxheap version of a heappop followed by a heappush.Maxheap version of a heappop.Push item onto heap, maintaining the heap invariant._siftup_maxHeap queue algorithm (a.k.a. priority queue).

Heaps are arrays for which a[k] <= a[2*k+1] and a[k] <= a[2*k+2] for
all k, counting elements from 0.  For the sake of comparison,
non-existing elements are considered to be infinite.  The interesting
property of a heap is that a[0] is always its smallest element.

Usage:

heap = []            # creates an empty heap
heappush(heap, item) # pushes a new item on the heap
item = heappop(heap) # pops the smallest item from the heap
item = heap[0]       # smallest item on the heap without popping it
heapify(x)           # transforms list into a heap, in-place, in linear time
item = heapreplace(heap, item) # pops and returns smallest item, and adds
                               # new item; the heap size is unchanged

Our API differs from textbook heap algorithms as follows:

- We use 0-based indexing.  This makes the relationship between the
  index for a node and the indexes for its children slightly less
  obvious, but is more suitable since Python uses 0-based indexing.

- Our heappop() method returns the smallest item, not the largest.

These two make it possible to view the heap as a regular Python list
without surprises: heap[0] is the smallest item, and heap.sort()
maintains the heap invariant!
newitemrightposFind the n largest elements in a dataset.

    Equivalent to:  sorted(iterable, key=key, reverse=True)[:n]
    digestmodHMAC.digestblock_size of %d seems too small; using our default of %d._compare_digestkey: expected bytes or bytearray, but got %rHMAC.nameHMAC() without an explicit digestmod argument is deprecated.HMAC.hexdigestHMAC.__init__HMAC.updatehmac-<module hmac>Create a new hashing object and return it.

    key: The starting key for the hash.
    msg: if available, will immediately be hashed into the object's starting
    state.

    You can now feed arbitrary strings into the object using its update()
    method, and can ask for the hash value at any time by calling its digest()
    method.
    No block_size attribute on given digest object; Assuming %d.HMAC.copyReturn a separate copy of this hashing object.

        An update to this copy won't affect the original object.
        Return the hash value of this hashing object.

        This returns a string containing 8-bit data.  The object is
        not altered in any way by this function; you can continue
        updating the object after calling this function.
        Return a hash object for the current state.

        To be used only internally with digest() and hexdigest().
        HMAC (Keyed-Hashing for Message Authentication) Python module.

Implements the HMAC algorithm as described by RFC 2104.
C:\msys64\mingw64\lib\python3.6\hmac.pydigest_consHMAC.__init__.<locals>.<lambda>Like digest(), but returns a string of hexadecimal digits instead.
        RFC 2104 HMAC class.  Also complies with RFC 4231.

    This supports the API for Cryptographic Hash Functions (PEP 247).
    HMAC._currentUpdate this hashing object with the string msg.
        Create a new HMAC object.

        key:       key for the keyed hash object.
        msg:       Initial input for the hash, if provided.
        digestmod: A module supporting PEP 247.  *OR*
                   A hashlib constructor returning a new hash object. *OR*
                   A hash name suitable for hashlib.new().
                   Defaults to hashlib.md5.
                   Implicit default to hashlib.md5 is deprecated and will be
                   removed in Python 3.6.

        Note: key and msg must be a bytes or bytearray objects.
        C:\msys64\mingw64\lib\python3.6\html<module html>
General functions for HTML manipulation.
_invalid_codepoints_replace_charref&(#[0-9]+;?|#[xX][0-9a-fA-F]+;?|[^\t\n\f <&#;]{1,32};?)&#x27;
    Convert all named and numeric character references (e.g. &gt;, &#62;,
    &x3e;) in the string s to the corresponding unicode characters.
    This function uses the rules defined by the HTML 5 standard
    for both valid and invalid character references, and the list of
    HTML 5 named character references defined in html.entities.html5.
    ¼~   é   é   é   é   é   é   é   é   é   é   é   é   é   é   é   é   é   é   é   é   é   é   é   é   é   é   é   éÿÿ éÿÿ éþÿ	 éþÿ éÿÿ	 éþÿ é   é   é   é   é   é   é   é   é   é   é   é   é   é   é   é   é   é   é   é   é   é   é   é   é   é   é   é   é   é   é   é   é   éÿÿ éÿÿ
 éþÿ éþÿ
 éÿÿ éÿÿ éþÿ éÿÿ éÿÿ éþÿ éÿÿ éÿÿ éþÿ éÿÿ éÿÿ éÿÿ éþÿ éÐý  éÑý  éÒý  éÓý  éÔý  éÕý  éÖý  é×ý  éØý  éÙý  éÚý  éÛý  éÜý  éÝý  éÞý  éßý  éàý  éáý  éâý  éãý  éäý  éåý  éæý  éçý  éèý  ééý  éêý  éëý  éìý  éíý  éîý  éïý  éÿÿ éþÿ éþÿ éþÿ éþÿ éþÿ éÿÿ éþÿ éþÿ éþÿ  éÿÿ  ûé    u   ï¿½é   úé   u   â¬é   õ   Âé   u   âé   u   Æé   u   âé   u   â¦é   u   â é   u   â¡é   u   Ëé   u   â°é   u   Å é   u   â¹é   u   Åé   õ   Âé   u   Å½é   õ   Âé   õ   Âé   u   âé   u   âé   u   âé   u   âé   u   â¢é   u   âé   u   âé   u   Ëé   u   â¢é   u   Å¡é   u   âºé   u   Åé   õ   Âé   u   Å¾é   u   Å¸0_html5C:\msys64\mingw64\lib\python3.6\html\__init__.py_invalid_charrefs
    Replace special characters "&", "<" and ">" to HTML-safe sequences.
    If the optional flag quote is true (the default), the quotation mark
    characters, both double quote (") and single quote (') characters are also
    translated.
    C:\msys64\mingw64\lib\python3.6\html\entities.pyûzAacuteõ   Ãzaacuteõ   Ã¡zAacute;r   zaacute;r   zAbreve;u   Äzabreve;u   Äzac;u   â¾zacd;u   â¿zacE;u   â¾Ì³zAcircõ   Ãzacircõ   Ã¢zAcirc;r   zacirc;r   zacuteõ   Â´zacute;r   zAcy;u   Ðzacy;u   Ð°zAEligõ   Ãzaeligõ   Ã¦zAElig;r   zaelig;r   zaf;u   â¡zAfr;u   ðzafr;u   ðzAgraveõ   Ãzagraveõ   Ã zAgrave;r   zagrave;r	   zalefsym;u   âµzaleph;u   âµzAlpha;u   Îzalpha;u   Î±zAmacr;u   Äzamacr;u   Äzamalg;u   â¨¿zAMPú&zampr
   zAMP;r
   zamp;r
   zAnd;u   â©zand;u   â§zandand;u   â©zandd;u   â©z	andslope;u   â©zandv;u   â©zang;u   â zange;u   â¦¤zangle;u   â zangmsd;u   â¡z	angmsdaa;u   â¦¨z	angmsdab;u   â¦©z	angmsdac;u   â¦ªz	angmsdad;u   â¦«z	angmsdae;u   â¦¬z	angmsdaf;u   â¦­z	angmsdag;u   â¦®z	angmsdah;u   â¦¯zangrt;u   âzangrtvb;u   â¾z	angrtvbd;u   â¦zangsph;u   â¢zangst;õ   Ãzangzarr;u   â¼zAogon;u   Äzaogon;u   ÄzAopf;u   ð¸zaopf;u   ðzap;u   âzapacir;u   â©¯zapE;u   â©°zape;u   âzapid;u   âzapos;ú'zApplyFunction;u   â¡zapprox;u   âz	approxeq;u   âzAringr   zaringõ   Ã¥zAring;r   zaring;r   zAscr;u   ðzascr;u   ð¶zAssign;u   âzast;Ú*zasymp;u   âzasympeq;u   âzAtildeõ   Ãzatildeõ   Ã£zAtilde;r   zatilde;r   zAumlõ   Ãzaumlõ   Ã¤zAuml;r   zauml;r   z	awconint;u   â³zawint;u   â¨z	backcong;u   âzbackepsilon;u   Ï¶z
backprime;u   âµzbacksim;u   â½z
backsimeq;u   âz
Backslash;u   âzBarv;u   â«§zbarvee;u   â½zBarwed;u   âzbarwed;u   âz	barwedge;u   âzbbrk;u   âµz	bbrktbrk;u   â¶zbcong;u   âzBcy;u   Ðzbcy;u   Ð±zbdquo;u   âzbecaus;u   âµzBecause;u   âµzbecause;u   âµzbemptyv;u   â¦°zbepsi;u   Ï¶zbernou;u   â¬zBernoullis;u   â¬zBeta;u   Îzbeta;u   Î²zbeth;u   â¶zbetween;u   â¬zBfr;u   ðzbfr;u   ðzbigcap;u   âzbigcirc;u   â¯zbigcup;u   âzbigodot;u   â¨z	bigoplus;u   â¨z
bigotimes;u   â¨z	bigsqcup;u   â¨zbigstar;u   âzbigtriangledown;u   â½zbigtriangleup;u   â³z	biguplus;u   â¨zbigvee;u   âz	bigwedge;u   âzbkarow;u   â¤zblacklozenge;u   â§«zblacksquare;u   âªzblacktriangle;u   â´zblacktriangledown;u   â¾zblacktriangleleft;u   âzblacktriangleright;u   â¸zblank;u   â£zblk12;u   âzblk14;u   âzblk34;u   âzblock;u   âzbne;u   =â¥zbnequiv;u   â¡â¥zbNot;u   â«­zbnot;u   âzBopf;u   ð¹zbopf;u   ðzbot;u   â¥zbottom;u   â¥zbowtie;u   âzboxbox;u   â§zboxDL;u   âzboxDl;u   âzboxdL;u   âzboxdl;u   âzboxDR;u   âzboxDr;u   âzboxdR;u   âzboxdr;u   âzboxH;u   âzboxh;u   âzboxHD;u   â¦zboxHd;u   â¤zboxhD;u   â¥zboxhd;u   â¬zboxHU;u   â©zboxHu;u   â§zboxhU;u   â¨zboxhu;u   â´z	boxminus;u   âzboxplus;u   âz	boxtimes;u   â zboxUL;u   âzboxUl;u   âzboxuL;u   âzboxul;u   âzboxUR;u   âzboxUr;u   âzboxuR;u   âzboxur;u   âzboxV;u   âzboxv;u   âzboxVH;u   â¬zboxVh;u   â«zboxvH;u   âªzboxvh;u   â¼zboxVL;u   â£zboxVl;u   â¢zboxvL;u   â¡zboxvl;u   â¤zboxVR;u   â zboxVr;u   âzboxvR;u   âzboxvr;u   âzbprime;u   âµzBreve;u   Ëzbreve;u   Ëzbrvbarõ   Â¦zbrvbar;r   zBscr;u   â¬zbscr;u   ð·zbsemi;u   âzbsim;u   â½zbsime;u   âzbsol;ú\zbsolb;u   â§z	bsolhsub;u   âzbull;u   â¢zbullet;u   â¢zbump;u   âzbumpE;u   âª®zbumpe;u   âzBumpeq;u   âzbumpeq;u   âzCacute;u   Äzcacute;u   ÄzCap;u   âzcap;u   â©zcapand;u   â©z	capbrcup;u   â©zcapcap;u   â©zcapcup;u   â©zcapdot;u   â©zCapitalDifferentialD;u   âzcaps;u   â©ï¸zcaret;u   âzcaron;u   ËzCayleys;u   â­zccaps;u   â©zCcaron;u   Äzccaron;u   ÄzCcedilõ   Ãzccedilõ   Ã§zCcedil;r   zccedil;r   zCcirc;u   Äzccirc;u   ÄzCconint;u   â°zccups;u   â©zccupssm;u   â©zCdot;u   Äzcdot;u   Äzcedilõ   Â¸zcedil;r   zCedilla;r   zcemptyv;u   â¦²zcentõ   Â¢zcent;r   z
CenterDot;õ   Â·z
centerdot;r   zCfr;u   â­zcfr;u   ð zCHcy;u   Ð§zchcy;u   Ñzcheck;u   âz
checkmark;u   âzChi;u   Î§zchi;u   Ïzcir;u   âzcirc;u   Ëzcirceq;u   âzcirclearrowleft;u   âºzcirclearrowright;u   â»zcircledast;u   âzcircledcirc;u   âzcircleddash;u   âz
CircleDot;u   âz	circledR;õ   Â®z	circledS;u   âzCircleMinus;u   âzCirclePlus;u   âzCircleTimes;u   âzcirE;u   â§zcire;u   âz	cirfnint;u   â¨zcirmid;u   â«¯zcirscir;u   â§zClockwiseContourIntegral;u   â²zCloseCurlyDoubleQuote;u   âzCloseCurlyQuote;u   âzclubs;u   â£z	clubsuit;u   â£zColon;u   â·zcolon;ú:zColone;u   â©´zcolone;u   âzcoloneq;u   âzcomma;ú,zcommat;ú@zcomp;u   âzcompfn;u   âzcomplement;u   âz
complexes;u   âzcong;u   âzcongdot;u   â©­z
Congruent;u   â¡zConint;u   â¯zconint;u   â®zContourIntegral;u   â®zCopf;u   âzcopf;u   ðzcoprod;u   âz
Coproduct;u   âzCOPYõ   Â©zcopyr   zCOPY;r   zcopy;r   zcopysr;u   âz CounterClockwiseContourIntegral;u   â³zcrarr;u   âµzCross;u   â¨¯zcross;u   âzCscr;u   ðzcscr;u   ð¸zcsub;u   â«zcsube;u   â«zcsup;u   â«zcsupe;u   â«zctdot;u   â¯zcudarrl;u   â¤¸zcudarrr;u   â¤µzcuepr;u   âzcuesc;u   âzcularr;u   â¶zcularrp;u   â¤½zCup;u   âzcup;u   âªz	cupbrcap;u   â©zCupCap;u   âzcupcap;u   â©zcupcup;u   â©zcupdot;u   âzcupor;u   â©zcups;u   âªï¸zcurarr;u   â·zcurarrm;u   â¤¼zcurlyeqprec;u   âzcurlyeqsucc;u   âz	curlyvee;u   âzcurlywedge;u   âzcurrenõ   Â¤zcurren;r   zcurvearrowleft;u   â¶zcurvearrowright;u   â·zcuvee;u   âzcuwed;u   âz	cwconint;u   â²zcwint;u   â±zcylcty;u   â­zDagger;u   â¡zdagger;u   â zdaleth;u   â¸zDarr;u   â¡zdArr;u   âzdarr;u   âzdash;u   âzDashv;u   â«¤zdashv;u   â£zdbkarow;u   â¤zdblac;u   ËzDcaron;u   Äzdcaron;u   ÄzDcy;u   Ðzdcy;u   Ð´zDD;u   âzdd;u   âzddagger;u   â¡zddarr;u   âz	DDotrahd;u   â¤zddotseq;u   â©·zdegõ   Â°zdeg;r    zDel;u   âzDelta;u   Îzdelta;u   Î´zdemptyv;u   â¦±zdfisht;u   â¥¿zDfr;u   ðzdfr;u   ð¡zdHar;u   â¥¥zdharl;u   âzdharr;u   âzDiacriticalAcute;r   zDiacriticalDot;u   ËzDiacriticalDoubleAcute;u   ËzDiacriticalGrave;ú`zDiacriticalTilde;u   Ëzdiam;u   âzDiamond;u   âzdiamond;u   âzdiamondsuit;u   â¦zdiams;u   â¦zdie;õ   Â¨zDifferentialD;u   âzdigamma;u   Ïzdisin;u   â²zdiv;õ   Ã·zdivider#   zdivide;r#   zdivideontimes;u   âzdivonx;u   âzDJcy;u   Ðzdjcy;u   Ñzdlcorn;u   âzdlcrop;u   âzdollar;ú$zDopf;u   ð»zdopf;u   ðzDot;r"   zdot;u   ËzDotDot;u   âzdoteq;u   âz	doteqdot;u   âz	DotEqual;u   âz	dotminus;u   â¸zdotplus;u   âz
dotsquare;u   â¡zdoublebarwedge;u   âzDoubleContourIntegral;u   â¯z
DoubleDot;r"   zDoubleDownArrow;u   âzDoubleLeftArrow;u   âzDoubleLeftRightArrow;u   âzDoubleLeftTee;u   â«¤zDoubleLongLeftArrow;u   â¸zDoubleLongLeftRightArrow;u   âºzDoubleLongRightArrow;u   â¹zDoubleRightArrow;u   âzDoubleRightTee;u   â¨zDoubleUpArrow;u   âzDoubleUpDownArrow;u   âzDoubleVerticalBar;u   â¥z
DownArrow;u   âz
Downarrow;u   âz
downarrow;u   âzDownArrowBar;u   â¤zDownArrowUpArrow;u   âµz
DownBreve;u   Ìzdowndownarrows;u   âzdownharpoonleft;u   âzdownharpoonright;u   âzDownLeftRightVector;u   â¥zDownLeftTeeVector;u   â¥zDownLeftVector;u   â½zDownLeftVectorBar;u   â¥zDownRightTeeVector;u   â¥zDownRightVector;u   âzDownRightVectorBar;u   â¥zDownTee;u   â¤zDownTeeArrow;u   â§z	drbkarow;u   â¤zdrcorn;u   âzdrcrop;u   âzDscr;u   ðzdscr;u   ð¹zDScy;u   Ðzdscy;u   Ñzdsol;u   â§¶zDstrok;u   Äzdstrok;u   Äzdtdot;u   â±zdtri;u   â¿zdtrif;u   â¾zduarr;u   âµzduhar;u   â¥¯zdwangle;u   â¦¦zDZcy;u   Ðzdzcy;u   Ñz	dzigrarr;u   â¿zEacuteõ   Ãzeacuteõ   Ã©zEacute;r%   zeacute;r&   zeaster;u   â©®zEcaron;u   Äzecaron;u   Äzecir;u   âzEcircõ   Ãzecircõ   ÃªzEcirc;r'   zecirc;r(   zecolon;u   âzEcy;u   Ð­zecy;u   ÑzeDDot;u   â©·zEdot;u   ÄzeDot;u   âzedot;u   Äzee;u   âzefDot;u   âzEfr;u   ðzefr;u   ð¢zeg;u   âªzEgraveõ   Ãzegraveõ   Ã¨zEgrave;r)   zegrave;r*   zegs;u   âªzegsdot;u   âªzel;u   âªzElement;u   âz	elinters;u   â§zell;u   âzels;u   âªzelsdot;u   âªzEmacr;u   Äzemacr;u   Äzempty;u   âz	emptyset;u   âzEmptySmallSquare;u   â»zemptyv;u   âzEmptyVerySmallSquare;u   â«zemsp13;u   âzemsp14;u   âzemsp;u   âzENG;u   Åzeng;u   Åzensp;u   âzEogon;u   Äzeogon;u   ÄzEopf;u   ð¼zeopf;u   ðzepar;u   âzeparsl;u   â§£zeplus;u   â©±zepsi;u   ÎµzEpsilon;u   Îzepsilon;u   Îµzepsiv;u   Ïµzeqcirc;u   âzeqcolon;u   âzeqsim;u   âzeqslantgtr;u   âªzeqslantless;u   âªzEqual;u   â©µzequals;ú=zEqualTilde;u   âzequest;u   âzEquilibrium;u   âzequiv;u   â¡zequivDD;u   â©¸z	eqvparsl;u   â§¥zerarr;u   â¥±zerDot;u   âzEscr;u   â°zescr;u   â¯zesdot;u   âzEsim;u   â©³zesim;u   âzEta;u   Îzeta;u   Î·zETHõ   Ãzethõ   Ã°zETH;r,   zeth;r-   zEumlõ   Ãzeumlõ   Ã«zEuml;r.   zeuml;r/   zeuro;u   â¬zexcl;ú!zexist;u   âzExists;u   âzexpectation;u   â°zExponentialE;u   âzexponentiale;u   âzfallingdotseq;u   âzFcy;u   Ð¤zfcy;u   Ñzfemale;u   âzffilig;u   ï¬zfflig;u   ï¬zffllig;u   ï¬zFfr;u   ðzffr;u   ð£zfilig;u   ï¬zFilledSmallSquare;u   â¼zFilledVerySmallSquare;u   âªzfjlig;zfjzflat;u   â­zfllig;u   ï¬zfltns;u   â±zfnof;u   ÆzFopf;u   ð½zfopf;u   ðzForAll;u   âzforall;u   âzfork;u   âzforkv;u   â«zFouriertrf;u   â±z	fpartint;u   â¨zfrac12õ   Â½zfrac12;r1   zfrac13;u   âzfrac14õ   Â¼zfrac14;r2   zfrac15;u   âzfrac16;u   âzfrac18;u   âzfrac23;u   âzfrac25;u   âzfrac34õ   Â¾zfrac34;r3   zfrac35;u   âzfrac38;u   âzfrac45;u   âzfrac56;u   âzfrac58;u   âzfrac78;u   âzfrasl;u   âzfrown;u   â¢zFscr;u   â±zfscr;u   ð»zgacute;u   ÇµzGamma;u   Îzgamma;u   Î³zGammad;u   Ïzgammad;u   Ïzgap;u   âªzGbreve;u   Äzgbreve;u   ÄzGcedil;u   Ä¢zGcirc;u   Äzgcirc;u   ÄzGcy;u   Ðzgcy;u   Ð³zGdot;u   Ä zgdot;u   Ä¡zgE;u   â§zge;u   â¥zgEl;u   âªzgel;u   âzgeq;u   â¥zgeqq;u   â§z	geqslant;u   â©¾zges;u   â©¾zgescc;u   âª©zgesdot;u   âªzgesdoto;u   âªz	gesdotol;u   âªzgesl;u   âï¸zgesles;u   âªzGfr;u   ðzgfr;u   ð¤zGg;u   âzgg;u   â«zggg;u   âzgimel;u   â·zGJcy;u   Ðzgjcy;u   Ñzgl;u   â·zgla;u   âª¥zglE;u   âªzglj;u   âª¤zgnap;u   âªz	gnapprox;u   âªzgnE;u   â©zgne;u   âªzgneq;u   âªzgneqq;u   â©zgnsim;u   â§zGopf;u   ð¾zgopf;u   ðzgrave;r!   zGreaterEqual;u   â¥zGreaterEqualLess;u   âzGreaterFullEqual;u   â§zGreaterGreater;u   âª¢zGreaterLess;u   â·zGreaterSlantEqual;u   â©¾zGreaterTilde;u   â³zGscr;u   ð¢zgscr;u   âzgsim;u   â³zgsime;u   âªzgsiml;u   âªzGTú>zgtr4   zGT;r4   zGt;u   â«zgt;r4   zgtcc;u   âª§zgtcir;u   â©ºzgtdot;u   âzgtlPar;u   â¦zgtquest;u   â©¼z
gtrapprox;u   âªzgtrarr;u   â¥¸zgtrdot;u   âz
gtreqless;u   âzgtreqqless;u   âªzgtrless;u   â·zgtrsim;u   â³z
gvertneqq;u   â©ï¸zgvnE;u   â©ï¸zHacek;u   Ëzhairsp;u   âzhalf;r1   zhamilt;u   âzHARDcy;u   Ðªzhardcy;u   ÑzhArr;u   âzharr;u   âzharrcir;u   â¥zharrw;u   â­zHat;ú^zhbar;u   âzHcirc;u   Ä¤zhcirc;u   Ä¥zhearts;u   â¥z
heartsuit;u   â¥zhellip;u   â¦zhercon;u   â¹zHfr;u   âzhfr;u   ð¥zHilbertSpace;u   âz	hksearow;u   â¤¥z	hkswarow;u   â¤¦zhoarr;u   â¿zhomtht;u   â»zhookleftarrow;u   â©zhookrightarrow;u   âªzHopf;u   âzhopf;u   ðzhorbar;u   âzHorizontalLine;u   âzHscr;u   âzhscr;u   ð½zhslash;u   âzHstrok;u   Ä¦zhstrok;u   Ä§zHumpDownHump;u   âz
HumpEqual;u   âzhybull;u   âzhyphen;u   âzIacuteõ   Ãziacuteõ   Ã­zIacute;r6   ziacute;r7   zic;u   â£zIcircõ   Ãzicircõ   Ã®zIcirc;r8   zicirc;r9   zIcy;u   Ðzicy;u   Ð¸zIdot;u   Ä°zIEcy;u   Ðziecy;u   Ðµziexclõ   Â¡ziexcl;r:   ziff;u   âzIfr;u   âzifr;u   ð¦zIgraveõ   Ãzigraveõ   Ã¬zIgrave;r;   zigrave;r<   zii;u   âziiiint;u   â¨ziiint;u   â­ziinfin;u   â§ziiota;u   â©zIJlig;u   Ä²zijlig;u   Ä³zIm;u   âzImacr;u   Äªzimacr;u   Ä«zimage;u   âzImaginaryI;u   âz	imagline;u   âz	imagpart;u   âzimath;u   Ä±zimof;u   â·zimped;u   ÆµzImplies;u   âzin;u   âzincare;u   âzinfin;u   âz	infintie;u   â§zinodot;u   Ä±zInt;u   â¬zint;u   â«zintcal;u   âºz	integers;u   â¤z	Integral;u   â«z	intercal;u   âºzIntersection;u   âz	intlarhk;u   â¨zintprod;u   â¨¼zInvisibleComma;u   â£zInvisibleTimes;u   â¢zIOcy;u   Ðziocy;u   ÑzIogon;u   Ä®ziogon;u   Ä¯zIopf;u   ðziopf;u   ðzIota;u   Îziota;u   Î¹ziprod;u   â¨¼ziquestõ   Â¿ziquest;r=   zIscr;u   âziscr;u   ð¾zisin;u   âzisindot;u   âµzisinE;u   â¹zisins;u   â´zisinsv;u   â³zisinv;u   âzit;u   â¢zItilde;u   Ä¨zitilde;u   Ä©zIukcy;u   Ðziukcy;u   ÑzIumlõ   Ãziumlõ   Ã¯zIuml;r>   ziuml;r?   zJcirc;u   Ä´zjcirc;u   ÄµzJcy;u   Ðzjcy;u   Ð¹zJfr;u   ðzjfr;u   ð§zjmath;u   È·zJopf;u   ðzjopf;u   ðzJscr;u   ð¥zjscr;u   ð¿zJsercy;u   Ðzjsercy;u   ÑzJukcy;u   Ðzjukcy;u   ÑzKappa;u   Îzkappa;u   Îºzkappav;u   Ï°zKcedil;u   Ä¶zkcedil;u   Ä·zKcy;u   Ðzkcy;u   ÐºzKfr;u   ðzkfr;u   ð¨zkgreen;u   Ä¸zKHcy;u   Ð¥zkhcy;u   ÑzKJcy;u   Ðzkjcy;u   ÑzKopf;u   ðzkopf;u   ðzKscr;u   ð¦zkscr;u   ðzlAarr;u   âzLacute;u   Ä¹zlacute;u   Äºz	laemptyv;u   â¦´zlagran;u   âzLambda;u   Îzlambda;u   Î»zLang;u   âªzlang;u   â¨zlangd;u   â¦zlangle;u   â¨zlap;u   âªzLaplacetrf;u   âzlaquoõ   Â«zlaquo;r@   zLarr;u   âzlArr;u   âzlarr;u   âzlarrb;u   â¤zlarrbfs;u   â¤zlarrfs;u   â¤zlarrhk;u   â©zlarrlp;u   â«zlarrpl;u   â¤¹zlarrsim;u   â¥³zlarrtl;u   â¢zlat;u   âª«zlAtail;u   â¤zlatail;u   â¤zlate;u   âª­zlates;u   âª­ï¸zlBarr;u   â¤zlbarr;u   â¤zlbbrk;u   â²zlbrace;ú{zlbrack;ú[zlbrke;u   â¦zlbrksld;u   â¦zlbrkslu;u   â¦zLcaron;u   Ä½zlcaron;u   Ä¾zLcedil;u   Ä»zlcedil;u   Ä¼zlceil;u   âzlcub;rA   zLcy;u   Ðzlcy;u   Ð»zldca;u   â¤¶zldquo;u   âzldquor;u   âzldrdhar;u   â¥§z	ldrushar;u   â¥zldsh;u   â²zlE;u   â¦zle;u   â¤zLeftAngleBracket;u   â¨z
LeftArrow;u   âz
Leftarrow;u   âz
leftarrow;u   âzLeftArrowBar;u   â¤zLeftArrowRightArrow;u   âzleftarrowtail;u   â¢zLeftCeiling;u   âzLeftDoubleBracket;u   â¦zLeftDownTeeVector;u   â¥¡zLeftDownVector;u   âzLeftDownVectorBar;u   â¥z
LeftFloor;u   âzleftharpoondown;u   â½zleftharpoonup;u   â¼zleftleftarrows;u   âzLeftRightArrow;u   âzLeftrightarrow;u   âzleftrightarrow;u   âzleftrightarrows;u   âzleftrightharpoons;u   âzleftrightsquigarrow;u   â­zLeftRightVector;u   â¥zLeftTee;u   â£zLeftTeeArrow;u   â¤zLeftTeeVector;u   â¥zleftthreetimes;u   âzLeftTriangle;u   â²zLeftTriangleBar;u   â§zLeftTriangleEqual;u   â´zLeftUpDownVector;u   â¥zLeftUpTeeVector;u   â¥ zLeftUpVector;u   â¿zLeftUpVectorBar;u   â¥zLeftVector;u   â¼zLeftVectorBar;u   â¥zlEg;u   âªzleg;u   âzleq;u   â¤zleqq;u   â¦z	leqslant;u   â©½zles;u   â©½zlescc;u   âª¨zlesdot;u   â©¿zlesdoto;u   âªz	lesdotor;u   âªzlesg;u   âï¸zlesges;u   âªzlessapprox;u   âªzlessdot;u   âz
lesseqgtr;u   âzlesseqqgtr;u   âªzLessEqualGreater;u   âzLessFullEqual;u   â¦zLessGreater;u   â¶zlessgtr;u   â¶z	LessLess;u   âª¡zlesssim;u   â²zLessSlantEqual;u   â©½z
LessTilde;u   â²zlfisht;u   â¥¼zlfloor;u   âzLfr;u   ðzlfr;u   ð©zlg;u   â¶zlgE;u   âªzlHar;u   â¥¢zlhard;u   â½zlharu;u   â¼zlharul;u   â¥ªzlhblk;u   âzLJcy;u   Ðzljcy;u   ÑzLl;u   âzll;u   âªzllarr;u   âz	llcorner;u   âzLleftarrow;u   âzllhard;u   â¥«zlltri;u   âºzLmidot;u   Ä¿zlmidot;u   Åzlmoust;u   â°zlmoustache;u   â°zlnap;u   âªz	lnapprox;u   âªzlnE;u   â¨zlne;u   âªzlneq;u   âªzlneqq;u   â¨zlnsim;u   â¦zloang;u   â¬zloarr;u   â½zlobrk;u   â¦zLongLeftArrow;u   âµzLongleftarrow;u   â¸zlongleftarrow;u   âµzLongLeftRightArrow;u   â·zLongleftrightarrow;u   âºzlongleftrightarrow;u   â·zlongmapsto;u   â¼zLongRightArrow;u   â¶zLongrightarrow;u   â¹zlongrightarrow;u   â¶zlooparrowleft;u   â«zlooparrowright;u   â¬zlopar;u   â¦zLopf;u   ðzlopf;u   ðzloplus;u   â¨­zlotimes;u   â¨´zlowast;u   âzlowbar;Ú_zLowerLeftArrow;u   âzLowerRightArrow;u   âzloz;u   âzlozenge;u   âzlozf;u   â§«zlpar;ú(zlparlt;u   â¦zlrarr;u   âz	lrcorner;u   âzlrhar;u   âzlrhard;u   â¥­zlrm;u   âzlrtri;u   â¿zlsaquo;u   â¹zLscr;u   âzlscr;u   ðzLsh;u   â°zlsh;u   â°zlsim;u   â²zlsime;u   âªzlsimg;u   âªzlsqb;rB   zlsquo;u   âzlsquor;u   âzLstrok;u   Åzlstrok;u   ÅzLTú<zltrE   zLT;rE   zLt;u   âªzlt;rE   zltcc;u   âª¦zltcir;u   â©¹zltdot;u   âzlthree;u   âzltimes;u   âzltlarr;u   â¥¶zltquest;u   â©»zltri;u   âzltrie;u   â´zltrif;u   âzltrPar;u   â¦z	lurdshar;u   â¥zluruhar;u   â¥¦z
lvertneqq;u   â¨ï¸zlvnE;u   â¨ï¸zmacrõ   Â¯zmacr;rF   zmale;u   âzmalt;u   â zmaltese;u   â zMap;u   â¤zmap;u   â¦zmapsto;u   â¦zmapstodown;u   â§zmapstoleft;u   â¤z	mapstoup;u   â¥zmarker;u   â®zmcomma;u   â¨©zMcy;u   Ðzmcy;u   Ð¼zmdash;u   âzmDDot;u   âºzmeasuredangle;u   â¡zMediumSpace;u   âz
Mellintrf;u   â³zMfr;u   ðzmfr;u   ðªzmho;u   â§zmicroõ   Âµzmicro;rG   zmid;u   â£zmidast;r   zmidcir;u   â«°zmiddotr   zmiddot;r   zminus;u   âzminusb;u   âzminusd;u   â¸zminusdu;u   â¨ªz
MinusPlus;u   âzmlcp;u   â«zmldr;u   â¦zmnplus;u   âzmodels;u   â§zMopf;u   ðzmopf;u   ðzmp;u   âzMscr;u   â³zmscr;u   ðzmstpos;u   â¾zMu;u   Îzmu;u   Î¼z	multimap;u   â¸zmumap;u   â¸znabla;u   âzNacute;u   Åznacute;u   Åznang;u   â âznap;u   âznapE;u   â©°Ì¸znapid;u   âÌ¸znapos;u   Åznapprox;u   âznatur;u   â®znatural;u   â®z	naturals;u   âznbspõ   Â znbsp;rH   znbump;u   âÌ¸znbumpe;u   âÌ¸zncap;u   â©zNcaron;u   Åzncaron;u   ÅzNcedil;u   Åzncedil;u   Åzncong;u   âz	ncongdot;u   â©­Ì¸zncup;u   â©zNcy;u   Ðzncy;u   Ð½zndash;u   âzne;u   â znearhk;u   â¤¤zneArr;u   âznearr;u   âznearrow;u   âznedot;u   âÌ¸zNegativeMediumSpace;u   âzNegativeThickSpace;u   âzNegativeThinSpace;u   âzNegativeVeryThinSpace;u   âznequiv;u   â¢znesear;u   â¤¨znesim;u   âÌ¸zNestedGreaterGreater;u   â«zNestedLessLess;u   âªzNewLine;Ú
znexist;u   âznexists;u   âzNfr;u   ðznfr;u   ð«zngE;u   â§Ì¸znge;u   â±zngeq;u   â±zngeqq;u   â§Ì¸z
ngeqslant;u   â©¾Ì¸znges;u   â©¾Ì¸znGg;u   âÌ¸zngsim;u   âµznGt;u   â«âzngt;u   â¯zngtr;u   â¯znGtv;u   â«Ì¸znhArr;u   âznharr;u   â®znhpar;u   â«²zni;u   âznis;u   â¼znisd;u   âºzniv;u   âzNJcy;u   Ðznjcy;u   ÑznlArr;u   âznlarr;u   âznldr;u   â¥znlE;u   â¦Ì¸znle;u   â°znLeftarrow;u   âznleftarrow;u   âznLeftrightarrow;u   âznleftrightarrow;u   â®znleq;u   â°znleqq;u   â¦Ì¸z
nleqslant;u   â©½Ì¸znles;u   â©½Ì¸znless;u   â®znLl;u   âÌ¸znlsim;u   â´znLt;u   âªâznlt;u   â®znltri;u   âªznltrie;u   â¬znLtv;u   âªÌ¸znmid;u   â¤zNoBreak;u   â zNonBreakingSpace;rH   zNopf;u   âznopf;u   ðznotõ   Â¬zNot;u   â«¬znot;rJ   zNotCongruent;u   â¢z
NotCupCap;u   â­zNotDoubleVerticalBar;u   â¦zNotElement;u   âz	NotEqual;u   â zNotEqualTilde;u   âÌ¸z
NotExists;u   âzNotGreater;u   â¯zNotGreaterEqual;u   â±zNotGreaterFullEqual;u   â§Ì¸zNotGreaterGreater;u   â«Ì¸zNotGreaterLess;u   â¹zNotGreaterSlantEqual;u   â©¾Ì¸zNotGreaterTilde;u   âµzNotHumpDownHump;u   âÌ¸zNotHumpEqual;u   âÌ¸znotin;u   âz	notindot;u   âµÌ¸znotinE;u   â¹Ì¸znotinva;u   âznotinvb;u   â·znotinvc;u   â¶zNotLeftTriangle;u   âªzNotLeftTriangleBar;u   â§Ì¸zNotLeftTriangleEqual;u   â¬zNotLess;u   â®zNotLessEqual;u   â°zNotLessGreater;u   â¸zNotLessLess;u   âªÌ¸zNotLessSlantEqual;u   â©½Ì¸zNotLessTilde;u   â´zNotNestedGreaterGreater;u   âª¢Ì¸zNotNestedLessLess;u   âª¡Ì¸znotni;u   âznotniva;u   âznotnivb;u   â¾znotnivc;u   â½zNotPrecedes;u   âzNotPrecedesEqual;u   âª¯Ì¸zNotPrecedesSlantEqual;u   â zNotReverseElement;u   âzNotRightTriangle;u   â«zNotRightTriangleBar;u   â§Ì¸zNotRightTriangleEqual;u   â­zNotSquareSubset;u   âÌ¸zNotSquareSubsetEqual;u   â¢zNotSquareSuperset;u   âÌ¸zNotSquareSupersetEqual;u   â£z
NotSubset;u   ââzNotSubsetEqual;u   âzNotSucceeds;u   âzNotSucceedsEqual;u   âª°Ì¸zNotSucceedsSlantEqual;u   â¡zNotSucceedsTilde;u   â¿Ì¸zNotSuperset;u   ââzNotSupersetEqual;u   âz	NotTilde;u   âzNotTildeEqual;u   âzNotTildeFullEqual;u   âzNotTildeTilde;u   âzNotVerticalBar;u   â¤znpar;u   â¦z
nparallel;u   â¦znparsl;u   â«½â¥znpart;u   âÌ¸znpolint;u   â¨znpr;u   âznprcue;u   â znpre;u   âª¯Ì¸znprec;u   âznpreceq;u   âª¯Ì¸znrArr;u   âznrarr;u   âznrarrc;u   â¤³Ì¸znrarrw;u   âÌ¸znRightarrow;u   âznrightarrow;u   âznrtri;u   â«znrtrie;u   â­znsc;u   âznsccue;u   â¡znsce;u   âª°Ì¸zNscr;u   ð©znscr;u   ðz
nshortmid;u   â¤znshortparallel;u   â¦znsim;u   âznsime;u   âznsimeq;u   âznsmid;u   â¤znspar;u   â¦znsqsube;u   â¢znsqsupe;u   â£znsub;u   âznsubE;u   â«Ì¸znsube;u   âznsubset;u   ââz
nsubseteq;u   âznsubseteqq;u   â«Ì¸znsucc;u   âznsucceq;u   âª°Ì¸znsup;u   âznsupE;u   â«Ì¸znsupe;u   âznsupset;u   ââz
nsupseteq;u   âznsupseteqq;u   â«Ì¸zntgl;u   â¹zNtildeõ   Ãzntildeõ   Ã±zNtilde;rK   zntilde;rL   zntlg;u   â¸zntriangleleft;u   âªzntrianglelefteq;u   â¬zntriangleright;u   â«zntrianglerighteq;u   â­zNu;u   Îznu;u   Î½znum;ú#znumero;u   âznumsp;u   âznvap;u   ââznVDash;u   â¯znVdash;u   â®znvDash;u   â­znvdash;u   â¬znvge;u   â¥âznvgt;u   >âznvHarr;u   â¤znvinfin;u   â§znvlArr;u   â¤znvle;u   â¤âznvlt;u   <âznvltrie;u   â´âznvrArr;u   â¤znvrtrie;u   âµâznvsim;u   â¼âznwarhk;u   â¤£znwArr;u   âznwarr;u   âznwarrow;u   âznwnear;u   â¤§zOacuteõ   Ãzoacuteõ   Ã³zOacute;rN   zoacute;rO   zoast;u   âzocir;u   âzOcircõ   Ãzocircõ   Ã´zOcirc;rP   zocirc;rQ   zOcy;u   Ðzocy;u   Ð¾zodash;u   âzOdblac;u   Åzodblac;u   Åzodiv;u   â¨¸zodot;u   âzodsold;u   â¦¼zOElig;u   Åzoelig;u   Åzofcir;u   â¦¿zOfr;u   ðzofr;u   ð¬zogon;u   ËzOgraveõ   Ãzograveõ   Ã²zOgrave;rR   zograve;rS   zogt;u   â§zohbar;u   â¦µzohm;u   Î©zoint;u   â®zolarr;u   âºzolcir;u   â¦¾zolcross;u   â¦»zoline;u   â¾zolt;u   â§zOmacr;u   Åzomacr;u   ÅzOmega;u   Î©zomega;u   ÏzOmicron;u   Îzomicron;u   Î¿zomid;u   â¦¶zominus;u   âzOopf;u   ðzoopf;u   ð zopar;u   â¦·zOpenCurlyDoubleQuote;u   âzOpenCurlyQuote;u   âzoperp;u   â¦¹zoplus;u   âzOr;u   â©zor;u   â¨zorarr;u   â»zord;u   â©zorder;u   â´zorderof;u   â´zordfõ   Âªzordf;rT   zordmõ   Âºzordm;rU   zorigof;u   â¶zoror;u   â©zorslope;u   â©zorv;u   â©zoS;u   âzOscr;u   ðªzoscr;u   â´zOslashõ   Ãzoslashõ   Ã¸zOslash;rV   zoslash;rW   zosol;u   âzOtildeõ   Ãzotildeõ   ÃµzOtilde;rX   zotilde;rY   zOtimes;u   â¨·zotimes;u   âz	otimesas;u   â¨¶zOumlõ   Ãzoumlõ   Ã¶zOuml;rZ   zouml;r[   zovbar;u   â½zOverBar;u   â¾z
OverBrace;u   âzOverBracket;u   â´zOverParenthesis;u   âzpar;u   â¥zparaõ   Â¶zpara;r\   z	parallel;u   â¥zparsim;u   â«³zparsl;u   â«½zpart;u   âz	PartialD;u   âzPcy;u   Ðzpcy;u   Ð¿zpercnt;ú%zperiod;Ú.zpermil;u   â°zperp;u   â¥zpertenk;u   â±zPfr;u   ðzpfr;u   ð­zPhi;u   Î¦zphi;u   Ïzphiv;u   Ïzphmmat;u   â³zphone;u   âzPi;u   Î zpi;u   Ïz
pitchfork;u   âzpiv;u   Ïzplanck;u   âzplanckh;u   âzplankv;u   âzplus;ú+z	plusacir;u   â¨£zplusb;u   âzpluscir;u   â¨¢zplusdo;u   âzplusdu;u   â¨¥zpluse;u   â©²z
PlusMinus;õ   Â±zplusmnr`   zplusmn;r`   zplussim;u   â¨¦zplustwo;u   â¨§zpm;r`   zPoincareplane;u   âz	pointint;u   â¨zPopf;u   âzpopf;u   ð¡zpoundõ   Â£zpound;ra   zPr;u   âª»zpr;u   âºzprap;u   âª·zprcue;u   â¼zprE;u   âª³zpre;u   âª¯zprec;u   âºzprecapprox;u   âª·zpreccurlyeq;u   â¼z	Precedes;u   âºzPrecedesEqual;u   âª¯zPrecedesSlantEqual;u   â¼zPrecedesTilde;u   â¾zpreceq;u   âª¯zprecnapprox;u   âª¹z	precneqq;u   âªµz	precnsim;u   â¨zprecsim;u   â¾zPrime;u   â³zprime;u   â²zprimes;u   âzprnap;u   âª¹zprnE;u   âªµzprnsim;u   â¨zprod;u   âzProduct;u   âz	profalar;u   â®z	profline;u   âz	profsurf;u   âzprop;u   âzProportion;u   â·zProportional;u   âzpropto;u   âzprsim;u   â¾zprurel;u   â°zPscr;u   ð«zpscr;u   ðzPsi;u   Î¨zpsi;u   Ïzpuncsp;u   âzQfr;u   ðzqfr;u   ð®zqint;u   â¨zQopf;u   âzqopf;u   ð¢zqprime;u   âzQscr;u   ð¬zqscr;u   ðzquaternions;u   âzquatint;u   â¨zquest;ú?zquesteq;u   âzQUOTú"zquotrc   zQUOT;rc   zquot;rc   zrAarr;u   âzrace;u   â½Ì±zRacute;u   Åzracute;u   Åzradic;u   âz	raemptyv;u   â¦³zRang;u   â«zrang;u   â©zrangd;u   â¦zrange;u   â¦¥zrangle;u   â©zraquoõ   Â»zraquo;rd   zRarr;u   â zrArr;u   âzrarr;u   âzrarrap;u   â¥µzrarrb;u   â¥zrarrbfs;u   â¤ zrarrc;u   â¤³zrarrfs;u   â¤zrarrhk;u   âªzrarrlp;u   â¬zrarrpl;u   â¥zrarrsim;u   â¥´zRarrtl;u   â¤zrarrtl;u   â£zrarrw;u   âzrAtail;u   â¤zratail;u   â¤zratio;u   â¶z
rationals;u   âzRBarr;u   â¤zrBarr;u   â¤zrbarr;u   â¤zrbbrk;u   â³zrbrace;Ú}zrbrack;ú]zrbrke;u   â¦zrbrksld;u   â¦zrbrkslu;u   â¦zRcaron;u   Åzrcaron;u   ÅzRcedil;u   Åzrcedil;u   Åzrceil;u   âzrcub;re   zRcy;u   Ð zrcy;u   Ñzrdca;u   â¤·zrdldhar;u   â¥©zrdquo;u   âzrdquor;u   âzrdsh;u   â³zRe;u   âzreal;u   âzrealine;u   âz	realpart;u   âzreals;u   âzrect;u   â­zREGr   zregr   zREG;r   zreg;r   zReverseElement;u   âzReverseEquilibrium;u   âzReverseUpEquilibrium;u   â¥¯zrfisht;u   â¥½zrfloor;u   âzRfr;u   âzrfr;u   ð¯zrHar;u   â¥¤zrhard;u   âzrharu;u   âzrharul;u   â¥¬zRho;u   Î¡zrho;u   Ïzrhov;u   Ï±zRightAngleBracket;u   â©zRightArrow;u   âzRightarrow;u   âzrightarrow;u   âzRightArrowBar;u   â¥zRightArrowLeftArrow;u   âzrightarrowtail;u   â£zRightCeiling;u   âzRightDoubleBracket;u   â§zRightDownTeeVector;u   â¥zRightDownVector;u   âzRightDownVectorBar;u   â¥zRightFloor;u   âzrightharpoondown;u   âzrightharpoonup;u   âzrightleftarrows;u   âzrightleftharpoons;u   âzrightrightarrows;u   âzrightsquigarrow;u   âz	RightTee;u   â¢zRightTeeArrow;u   â¦zRightTeeVector;u   â¥zrightthreetimes;u   âzRightTriangle;u   â³zRightTriangleBar;u   â§zRightTriangleEqual;u   âµzRightUpDownVector;u   â¥zRightUpTeeVector;u   â¥zRightUpVector;u   â¾zRightUpVectorBar;u   â¥zRightVector;u   âzRightVectorBar;u   â¥zring;u   Ëzrisingdotseq;u   âzrlarr;u   âzrlhar;u   âzrlm;u   âzrmoust;u   â±zrmoustache;u   â±zrnmid;u   â«®zroang;u   â­zroarr;u   â¾zrobrk;u   â§zropar;u   â¦zRopf;u   âzropf;u   ð£zroplus;u   â¨®zrotimes;u   â¨µzRoundImplies;u   â¥°zrpar;ú)zrpargt;u   â¦z	rppolint;u   â¨zrrarr;u   âzRrightarrow;u   âzrsaquo;u   âºzRscr;u   âzrscr;u   ðzRsh;u   â±zrsh;u   â±zrsqb;rf   zrsquo;u   âzrsquor;u   âzrthree;u   âzrtimes;u   âzrtri;u   â¹zrtrie;u   âµzrtrif;u   â¸z	rtriltri;u   â§zRuleDelayed;u   â§´zruluhar;u   â¥¨zrx;u   âzSacute;u   Åzsacute;u   Åzsbquo;u   âzSc;u   âª¼zsc;u   â»zscap;u   âª¸zScaron;u   Å zscaron;u   Å¡zsccue;u   â½zscE;u   âª´zsce;u   âª°zScedil;u   Åzscedil;u   ÅzScirc;u   Åzscirc;u   Åzscnap;u   âªºzscnE;u   âª¶zscnsim;u   â©z	scpolint;u   â¨zscsim;u   â¿zScy;u   Ð¡zscy;u   Ñzsdot;u   âzsdotb;u   â¡zsdote;u   â©¦zsearhk;u   â¤¥zseArr;u   âzsearr;u   âzsearrow;u   âzsectõ   Â§zsect;rh   zsemi;ú;zseswar;u   â¤©z	setminus;u   âzsetmn;u   âzsext;u   â¶zSfr;u   ðzsfr;u   ð°zsfrown;u   â¢zsharp;u   â¯zSHCHcy;u   Ð©zshchcy;u   ÑzSHcy;u   Ð¨zshcy;u   ÑzShortDownArrow;u   âzShortLeftArrow;u   âz	shortmid;u   â£zshortparallel;u   â¥zShortRightArrow;u   âzShortUpArrow;u   âzshyõ   Â­zshy;rj   zSigma;u   Î£zsigma;u   Ïzsigmaf;u   Ïzsigmav;u   Ïzsim;u   â¼zsimdot;u   â©ªzsime;u   âzsimeq;u   âzsimg;u   âªzsimgE;u   âª zsiml;u   âªzsimlE;u   âªzsimne;u   âzsimplus;u   â¨¤zsimrarr;u   â¥²zslarr;u   âzSmallCircle;u   âzsmallsetminus;u   âzsmashp;u   â¨³z	smeparsl;u   â§¤zsmid;u   â£zsmile;u   â£zsmt;u   âªªzsmte;u   âª¬zsmtes;u   âª¬ï¸zSOFTcy;u   Ð¬zsoftcy;u   Ñzsol;ú/zsolb;u   â§zsolbar;u   â¿zSopf;u   ðzsopf;u   ð¤zspades;u   â z
spadesuit;u   â zspar;u   â¥zsqcap;u   âzsqcaps;u   âï¸zsqcup;u   âzsqcups;u   âï¸zSqrt;u   âzsqsub;u   âzsqsube;u   âz	sqsubset;u   âzsqsubseteq;u   âzsqsup;u   âzsqsupe;u   âz	sqsupset;u   âzsqsupseteq;u   âzsqu;u   â¡zSquare;u   â¡zsquare;u   â¡zSquareIntersection;u   âzSquareSubset;u   âzSquareSubsetEqual;u   âzSquareSuperset;u   âzSquareSupersetEqual;u   âzSquareUnion;u   âzsquarf;u   âªzsquf;u   âªzsrarr;u   âzSscr;u   ð®zsscr;u   ðzssetmn;u   âzssmile;u   â£zsstarf;u   âzStar;u   âzstar;u   âzstarf;u   âzstraightepsilon;u   Ïµzstraightphi;u   Ïzstrns;rF   zSub;u   âzsub;u   âzsubdot;u   âª½zsubE;u   â«zsube;u   âzsubedot;u   â«zsubmult;u   â«zsubnE;u   â«zsubne;u   âzsubplus;u   âª¿zsubrarr;u   â¥¹zSubset;u   âzsubset;u   âz	subseteq;u   âz
subseteqq;u   â«zSubsetEqual;u   âz
subsetneq;u   âzsubsetneqq;u   â«zsubsim;u   â«zsubsub;u   â«zsubsup;u   â«zsucc;u   â»zsuccapprox;u   âª¸zsucccurlyeq;u   â½z	Succeeds;u   â»zSucceedsEqual;u   âª°zSucceedsSlantEqual;u   â½zSucceedsTilde;u   â¿zsucceq;u   âª°zsuccnapprox;u   âªºz	succneqq;u   âª¶z	succnsim;u   â©zsuccsim;u   â¿z	SuchThat;u   âzSum;u   âzsum;u   âzsung;u   âªzsup1õ   Â¹zsup1;rl   zsup2õ   Â²zsup2;rm   zsup3õ   Â³zsup3;rn   zSup;u   âzsup;u   âzsupdot;u   âª¾zsupdsub;u   â«zsupE;u   â«zsupe;u   âzsupedot;u   â«z	Superset;u   âzSupersetEqual;u   âzsuphsol;u   âzsuphsub;u   â«zsuplarr;u   â¥»zsupmult;u   â«zsupnE;u   â«zsupne;u   âzsupplus;u   â«zSupset;u   âzsupset;u   âz	supseteq;u   âz
supseteqq;u   â«z
supsetneq;u   âzsupsetneqq;u   â«zsupsim;u   â«zsupsub;u   â«zsupsup;u   â«zswarhk;u   â¤¦zswArr;u   âzswarr;u   âzswarrow;u   âzswnwar;u   â¤ªzszligõ   Ãzszlig;ro   zTab;ú	ztarget;u   âzTau;u   Î¤ztau;u   Ïztbrk;u   â´zTcaron;u   Å¤ztcaron;u   Å¥zTcedil;u   Å¢ztcedil;u   Å£zTcy;u   Ð¢ztcy;u   Ñztdot;u   âztelrec;u   âzTfr;u   ðztfr;u   ð±zthere4;u   â´z
Therefore;u   â´z
therefore;u   â´zTheta;u   Îztheta;u   Î¸z	thetasym;u   Ïzthetav;u   Ïzthickapprox;u   âz	thicksim;u   â¼zThickSpace;u   ââzthinsp;u   âz
ThinSpace;u   âzthkap;u   âzthksim;u   â¼zTHORNõ   Ãzthornõ   Ã¾zTHORN;rq   zthorn;rr   zTilde;u   â¼ztilde;u   ËzTildeEqual;u   âzTildeFullEqual;u   âzTildeTilde;u   âztimesõ   Ãztimes;rs   ztimesb;u   â z	timesbar;u   â¨±ztimesd;u   â¨°ztint;u   â­ztoea;u   â¤¨ztop;u   â¤ztopbot;u   â¶ztopcir;u   â«±zTopf;u   ðztopf;u   ð¥ztopfork;u   â«ztosa;u   â¤©ztprime;u   â´zTRADE;u   â¢ztrade;u   â¢z	triangle;u   âµztriangledown;u   â¿ztriangleleft;u   âztrianglelefteq;u   â´z
triangleq;u   âztriangleright;u   â¹ztrianglerighteq;u   âµztridot;u   â¬ztrie;u   âz	triminus;u   â¨ºz
TripleDot;u   âztriplus;u   â¨¹ztrisb;u   â§ztritime;u   â¨»z	trpezium;u   â¢zTscr;u   ð¯ztscr;u   ðzTScy;u   Ð¦ztscy;u   ÑzTSHcy;u   Ðztshcy;u   ÑzTstrok;u   Å¦ztstrok;u   Å§ztwixt;u   â¬ztwoheadleftarrow;u   âztwoheadrightarrow;u   â zUacuteõ   Ãzuacuteõ   ÃºzUacute;rt   zuacute;ru   zUarr;u   âzuArr;u   âzuarr;u   âz	Uarrocir;u   â¥zUbrcy;u   Ðzubrcy;u   ÑzUbreve;u   Å¬zubreve;u   Å­zUcircõ   Ãzucircõ   Ã»zUcirc;rv   zucirc;rw   zUcy;u   Ð£zucy;u   Ñzudarr;u   âzUdblac;u   Å°zudblac;u   Å±zudhar;u   â¥®zufisht;u   â¥¾zUfr;u   ðzufr;u   ð²zUgraveõ   Ãzugraveõ   Ã¹zUgrave;rx   zugrave;ry   zuHar;u   â¥£zuharl;u   â¿zuharr;u   â¾zuhblk;u   âzulcorn;u   âz	ulcorner;u   âzulcrop;u   âzultri;u   â¸zUmacr;u   Åªzumacr;u   Å«zumlr"   zuml;r"   z	UnderBar;rC   zUnderBrace;u   âzUnderBracket;u   âµzUnderParenthesis;u   âzUnion;u   âz
UnionPlus;u   âzUogon;u   Å²zuogon;u   Å³zUopf;u   ðzuopf;u   ð¦zUpArrow;u   âzUparrow;u   âzuparrow;u   âzUpArrowBar;u   â¤zUpArrowDownArrow;u   âzUpDownArrow;u   âzUpdownarrow;u   âzupdownarrow;u   âzUpEquilibrium;u   â¥®zupharpoonleft;u   â¿zupharpoonright;u   â¾zuplus;u   âzUpperLeftArrow;u   âzUpperRightArrow;u   âzUpsi;u   Ïzupsi;u   Ïzupsih;u   ÏzUpsilon;u   Î¥zupsilon;u   ÏzUpTee;u   â¥zUpTeeArrow;u   â¥zupuparrows;u   âzurcorn;u   âz	urcorner;u   âzurcrop;u   âzUring;u   Å®zuring;u   Å¯zurtri;u   â¹zUscr;u   ð°zuscr;u   ðzutdot;u   â°zUtilde;u   Å¨zutilde;u   Å©zutri;u   âµzutrif;u   â´zuuarr;u   âzUumlõ   Ãzuumlõ   Ã¼zUuml;rz   zuuml;r{   zuwangle;u   â¦§zvangrt;u   â¦zvarepsilon;u   Ïµz	varkappa;u   Ï°zvarnothing;u   âzvarphi;u   Ïzvarpi;u   Ïz
varpropto;u   âzvArr;u   âzvarr;u   âzvarrho;u   Ï±z	varsigma;u   Ïzvarsubsetneq;u   âï¸zvarsubsetneqq;u   â«ï¸zvarsupsetneq;u   âï¸zvarsupsetneqq;u   â«ï¸z	vartheta;u   Ïzvartriangleleft;u   â²zvartriangleright;u   â³zVbar;u   â««zvBar;u   â«¨zvBarv;u   â«©zVcy;u   Ðzvcy;u   Ð²zVDash;u   â«zVdash;u   â©zvDash;u   â¨zvdash;u   â¢zVdashl;u   â«¦zVee;u   âzvee;u   â¨zveebar;u   â»zveeeq;u   âzvellip;u   â®zVerbar;u   âzverbar;ú|zVert;u   âzvert;r|   zVerticalBar;u   â£zVerticalLine;r|   zVerticalSeparator;u   âzVerticalTilde;u   âzVeryThinSpace;u   âzVfr;u   ðzvfr;u   ð³zvltri;u   â²zvnsub;u   ââzvnsup;u   ââzVopf;u   ðzvopf;u   ð§zvprop;u   âzvrtri;u   â³zVscr;u   ð±zvscr;u   ðzvsubnE;u   â«ï¸zvsubne;u   âï¸zvsupnE;u   â«ï¸zvsupne;u   âï¸zVvdash;u   âªzvzigzag;u   â¦zWcirc;u   Å´zwcirc;u   Åµzwedbar;u   â©zWedge;u   âzwedge;u   â§zwedgeq;u   âzweierp;u   âzWfr;u   ðzwfr;u   ð´zWopf;u   ðzwopf;u   ð¨zwp;u   âzwr;u   âzwreath;u   âzWscr;u   ð²zwscr;u   ðzxcap;u   âzxcirc;u   â¯zxcup;u   âzxdtri;u   â½zXfr;u   ðzxfr;u   ðµzxhArr;u   âºzxharr;u   â·zXi;u   Îzxi;u   Î¾zxlArr;u   â¸zxlarr;u   âµzxmap;u   â¼zxnis;u   â»zxodot;u   â¨zXopf;u   ðzxopf;u   ð©zxoplus;u   â¨zxotime;u   â¨zxrArr;u   â¹zxrarr;u   â¶zXscr;u   ð³zxscr;u   ðzxsqcup;u   â¨zxuplus;u   â¨zxutri;u   â³zxvee;u   âzxwedge;u   âzYacuteõ   Ãzyacuteõ   Ã½zYacute;r}   zyacute;r~   zYAcy;u   Ð¯zyacy;u   ÑzYcirc;u   Å¶zycirc;u   Å·zYcy;u   Ð«zycy;u   Ñzyenõ   Â¥zyen;r   zYfr;u   ðzyfr;u   ð¶zYIcy;u   Ðzyicy;u   ÑzYopf;u   ðzyopf;u   ðªzYscr;u   ð´zyscr;u   ðzYUcy;u   Ð®zyucy;u   Ñzyumlõ   Ã¿zYuml;u   Å¸zyuml;r   zZacute;u   Å¹zzacute;u   ÅºzZcaron;u   Å½zzcaron;u   Å¾zZcy;u   Ðzzcy;u   Ð·zZdot;u   Å»zzdot;u   Å¼zzeetrf;u   â¨zZeroWidthSpace;u   âzZeta;u   Îzzeta;u   Î¶zZfr;u   â¨zzfr;u   ð·zZHcy;u   Ðzzhcy;u   Ð¶zzigrarr;u   âzZopf;u   â¤zzopf;u   ð«zZscr;u   ðµzzscr;u   ðzzwj;u   âzzwnj;u   â0ûzAEligéÆ   zAacuteéÁ   zAcircéÂ   zAgraveéÀ   zAlphai  zAringéÅ   zAtildeéÃ   zAumléÄ   zBetai  zCcediléÇ   zChii§  zDaggeri!   zDeltai  zETHéÐ   zEacuteéÉ   zEcircéÊ   zEgraveéÈ   zEpsiloni  zEtai  zEumléË   zGammai  zIacuteéÍ   zIcircéÎ   zIgraveéÌ   zIotai  zIumléÏ   zKappai  zLambdai  zMui  zNtildeéÑ   zNui  zOEligiR  zOacuteéÓ   zOcircéÔ   zOgraveéÒ   zOmegai©  zOmicroni  zOslashéØ   zOtildeéÕ   zOumléÖ   zPhii¦  zPii   zPrimei3   zPsii¨  zRhoi¡  zScaroni`  zSigmai£  zTHORNéÞ   zTaui¤  zThetai  zUacuteéÚ   zUcircéÛ   zUgraveéÙ   zUpsiloni¥  zUumléÜ   zXii  zYacuteéÝ   zYumlix  zZetai  zaacuteéá   zacircéâ   zacuteé´   zaeligéæ   zagraveéà   zalefsymi5!  zalphai±  zampé&   zandi'"  zangi "  zaringéå   zasympiH"  zatildeéã   zaumléä   zbdquoi   zbetai²  zbrvbaré¦   zbulli"   zcapi)"  zccediléç   zcedilé¸   zcenté¢   zchiiÇ  zcirciÆ  zclubsic&  zcongiE"  zcopyé©   zcrarriµ!  zcupi*"  zcurrené¤   zdArriÓ!  zdaggeri    zdarri!  zdegé°   zdeltai´  zdiamsif&  zdivideé÷   zeacuteéé   zecircéê   zegraveéè   zemptyi"  zemspi   zenspi   zepsiloniµ  zequivia"  zetai·  zethéð   zeumléë   zeuroi¬   zexisti"  zfnofi  zforalli "  zfrac12é½   zfrac14é¼   zfrac34é¾   zfrasliD   zgammai³  zgeie"  zgté>   zhArriÔ!  zharri!  zheartsie&  zhellipi&   ziacuteéí   zicircéî   ziexclé¡   zigraveéì   zimagei!  zinfini"  zinti+"  ziotai¹  ziquesté¿   zisini"  ziumléï   zkappaiº  zlArriÐ!  zlambdai»  zlangi)#  zlaquoé«   zlarri!  zlceili#  zldquoi   zleid"  zlfloori
#  zlowasti"  zloziÊ%  zlrmi   zlsaquoi9   zlsquoi   zlté<   zmacré¯   zmdashi   zmicroéµ   zmiddoté·   zminusi"  zmui¼  znablai"  znbspé    zndashi   znei`"  znii"  znoté¬   znotini	"  znsubi"  zntildeéñ   znui½  zoacuteéó   zocircéô   zoeligiS  zograveéò   zolinei>   zomegaiÉ  zomicroni¿  zoplusi"  zori("  zordféª   zordméº   zoslashéø   zotildeéõ   zotimesi"  zoumléö   zparaé¶   zparti"  zpermili0   zperpi¥"  zphiiÆ  zpiiÀ  zpiviÖ  zplusmné±   zpoundé£   zprimei2   zprodi"  zpropi"  zpsiiÈ  zquoté"   zrArriÒ!  zradici"  zrangi*#  zraquoé»   zrarri!  zrceili	#  zrdquoi   zreali!  zregé®   zrfloori#  zrhoiÁ  zrlmi   zrsaquoi:   zrsquoi   zsbquoi   zscaronia  zsdotiÅ"  zsecté§   zshyé­   zsigmaiÃ  zsigmafiÂ  zsimi<"  zspadesi`&  zsubi"  zsubei"  zsumi"  zsupi"  zsup1é¹   zsup2é²   zsup3é³   zsupei"  zszligéß   ztauiÄ  zthere4i4"  zthetai¸  zthetasymiÑ  zthinspi	   zthornéþ   ztildeiÜ  ztimesé×   ztradei"!  zuArriÑ!  zuacuteéú   zuarri!  zucircéû   zugraveéù   zumlé¨   zupsihiÒ  zupsiloniÅ  zuumléü   zweierpi!  zxii¾  zyacuteéý   zyené¥   zyumléÿ   zzetai¶  zzwji   zzwnji   0name2codepointcodepoint2name<module html.entities>HTML character entity references.Request-URI Too LongURI is too longGateway TimeoutHTTPStatus.__new__MULTI_STATUSMULTIPLE_CHOICESCannot satisfy request rangePRECONDITION_REQUIREDThe server is unwilling to process the request because its header fields are too largeBad GatewayInvalid responses from another server/proxyRequest fulfilled, document followsUNSUPPORTED_MEDIA_TYPERequest TimeoutVariant Also NegotiatesEXPECTATION_FAILEDPartial ContentDocument created, URL followsNot AcceptableURI not available in preferred formatNETWORK_AUTHENTICATION_REQUIREDThe origin server requires the request to be conditionalObject moved temporarily -- see URI listMETHOD_NOT_ALLOWEDURI no longer exists and has been permanently removedNot ModifiedNon-Authoritative InformationNot FoundNothing matches the given URIALREADY_REPORTEDNOT_EXTENDED<module http>INTERNAL_SERVER_ERRORUnsupported Media TypeSWITCHING_PROTOCOLSExpectation FailedExpect condition could not be satisfiedTOO_MANY_REQUESTSPRECONDITION_FAILEDRequested Range Not SatisfiableFailed DependencySee OtherObject moved -- see Method and URL listInsufficient StorageLength RequiredClient must specify Content-LengthInternal Server ErrorNetwork Authentication RequiredUNPROCESSABLE_ENTITYReset ContentRequest fulfilled from cacheUnauthorizedNo permission -- see authorization schemesProcessingLOOP_DETECTEDRequest accepted, processing continues off-lineRequest forbidden -- authorization will not helpGATEWAY_TIMEOUTSEE_OTHEREntity body in unsupported formatMulti-StatusThe gateway server did not receive a timely responseGoneAlready ReportedSwitching to new protocol; obey Upgrade headerRequest fulfilled, nothing followsMethod Not AllowedSpecified method is invalid for this resourceLockedDocument has not changed since given timeSERVICE_UNAVAILABLEService UnavailableClear input form for further inputBad RequestBad request syntax or unsupported methodC:\msys64\mingw64\lib\python3.6\httpYou must use proxy specified in Location to access this resourceNo payment -- see charging schemesLOCKEDPartial content followsNOT_ACCEPTABLERequest Header Fields Too LargePrecondition RequiredUse ProxyConflictRequest conflictFAILED_DEPENDENCYBAD_GATEWAYREQUEST_ENTITY_TOO_LARGEREQUEST_TIMEOUTC:\msys64\mingw64\lib\python3.6\http\__init__.pyLENGTH_REQUIREDREQUESTED_RANGE_NOT_SATISFIABLEPrecondition FailedPrecondition in headers is falseThe user has sent too many requests in a given amount of time ("rate limiting")Request received, please continueAcceptedSwitching ProtocolsUNAUTHORIZEDPermanent RedirectEntity is too largeHTTP Version Not SupportedCannot fulfill requestNot ImplementedServer does not support this operationMultiple ChoicesObject has several resources -- see URI listPERMANENT_REDIRECTObject moved permanently -- see URI listHTTP status codes and reason phrases

    Status codes from the following RFCs are all observed:

        * RFC 7231: Hypertext Transfer Protocol (HTTP/1.1), obsoletes 2616
        * RFC 6585: Additional HTTP Status Codes
        * RFC 3229: Delta encoding in HTTP
        * RFC 4918: HTTP Extensions for WebDAV, obsoletes 2518
        * RFC 5842: Binding Extensions to WebDAV
        * RFC 7238: Permanent Redirect
        * RFC 2295: Transparent Content Negotiation in HTTP
        * RFC 2774: An HTTP Extension Framework
    You must authenticate with this proxy before proceedingUpgrade RequiredForbiddenNot ExtendedUPGRADE_REQUIREDToo Many RequestsIM UsedProxy Authentication RequiredIM_USEDUnprocessable EntityCONFLICTUSE_PROXYThe server cannot process the request due to a high loadFOUNDVARIANT_ALSO_NEGOTIATESRequest timed out; try again laterNON_AUTHORITATIVE_INFORMATIONPROXY_AUTHENTICATION_REQUIREDRequest Entity Too LargeServer got itself in troubleTemporary RedirectMoved PermanentlyINSUFFICIENT_STORAGELoop DetectedPAYMENT_REQUIREDPayment RequiredGONETEMPORARY_REDIRECTThe client needs to authenticate to gain network accessACCEPTEDPARTIAL_CONTENTCREATEDAdd a line of output to the current request buffer.

        Assumes that the line does *not* end with \r\n.
        HTTPSConnection.connectproxy-connectionHTTPConnection._tunnel_tunnel_headersRemote end closed connection without responsegot more than %d bytes when reading %sInvalidURLUnknownProtocol.__init__HTTPResponse.readintoRequest-startedHTTPConnection.set_tunnelHTTPResponse.closeReturn list of (header, value) tuples.pconn_check_closeGet the response from the server.

        If the HTTPConnection is in the correct state, returns an
        instance of HTTPResponse or of whatever object is returned by
        the response_class variable.

        If a request has not been sent or if a previous response has
        not be handled, ResponseNotReady is raised.  If the HTTP
        response indicates that the connection should be closed, then
        it will be closed before the response is returned.  When the
        connection is closed, the underlying socket is closed.
        total_bytesmvbtemp_mvbmessage_bodyHTTPConnection.connectHTTPResponse._safe_readRead up to len(b) bytes into bytearray b and return the number
        of bytes read.
        key_file, cert_file and check_hostname are deprecated, use a custom context instead.reply:NotConnectedTunnel connection failed: %d %shstringHTTPConnection.putheadersendIng a read()able_tunnel_portHTTPResponse._close_connauto_open_read_and_discard_trailerline_typechunk_left_MAXLINEheader_names_MAXHEADERSHTTPConnection._send_requestone_value_HTTPConnection__stateHTTPConnection._get_hostport\n(?![ \t])|\r(?![ \t\n])ImproperConnectionStateHTTPResponse._read_status_read_readableUNKNOWNZero length chunk ignoredHTTPResponse.peekwill_verifyRead with at most one underlying system call.  If at least one
        byte is buffered, return that instead.
        _UNKNOWNHTTPResponse.getcode_read1_chunkedHTTPResponse._get_chunk_leftReturn the HTTP status code that was sent with the response,
        or None if the URL is not an HTTP URL.

        host_enc_http_vsnSend a complete request to the server.Send the currently buffered request and clear the buffer.

        Appends an extra \r\n to the buffer.
        A message_body may be specified, to be appended to the request.
        HTTPResponse.begindatablockHTTPConnection._output0

HTTPResponse._read_next_chunk_size, %i more expected[^:\s][^:\r\n]*HTTPConnection._is_textIOIncompleteRead.__init__HTTPConnection.__init__%s(%i bytes read%s)UnknownTransferEncodingInvalid header value %rIncompleteRead.__str__skip_host
	HTTPConnection.putrequestHTTPMessage.getallmatchingheadersamtHTTPResponse.read1_METHODS_EXPECTING_BODYHTTPConnection.closeUnable to determine size of %rGet the content-length based on the body.

        If the body is None, we set Content-Length: 0 for methods that expect
        a body (RFC 7230, Section 3.3.2). We also set the Content-Length for
        any method if the body is a str or bytes-like object and not a file.
        HTTPResponse.__init__Returns an instance of the class mimetools.Message containing
        meta-information associated with the URL.

        When the method is HTTP, these headers are those returned by
        the server at the head of the retrieved HTML page (including
        Content-Length and Content-Type).

        When the method is FTP, a Content-Length header will be
        present if (as is now usual) the server passed back a file
        length in response to the FTP retrieval request. A
        Content-Type header will be present if the MIME type can be
        guessed.

        When the method is local-file, returned headers will include
        a Date representing the file's last-modified time, a
        Content-Length giving file size, and a Content-Type
        containing a guess at the file's type. See also the
        description of the mimetools module.

        HTTPResponse._peek_chunkedconnect_strconnect_bytesheader_strParses only RFC2822 headers from a file pointer.

    email Parser wants to see strings rather than bytes.
    But a TextIOWrapper around self.rfile would buffer too many bytes
    from the stream, bytes which we later need to read as bytes.
    So we read the correct bytes here, as bytes, for email Parser
    to parse.

    CannotSendRequestReturns the value of the header matching *name*.

        If there are multiple matching headers, the values are
        combined into a single string separated by commas and spaces.

        If no matching header is found, returns *default* or None if
        the *default* is not specified.

        If the headers are unknown, raises http.client.ResponseNotReady.

        _safe_readintoTest whether a file-like object is a text or a binary stream.
        trailer linechunk sizeHTTPConnection._send_outputnetloc_encHTTPConnection.set_debugleveldata should be a bytes-like object or an iterable, got %rtr_encRemoteDisconnected.__init__Same as _safe_read, but for reading into a buffer.HTTPResponse.isclosedThis class allows communication via SSL.status lineIndicate that the last header line has been sent to the server.

        This method sends the request to the server.  The optional message_body
        argument can be used to pass a message body associated with the
        request.
        UnimplementedFileModePATCH_HTTPConnection__responsecheck_hostname needs a SSL context with either CERT_OPTIONAL or CERT_REQUIREDBadStatusLine.__init__<module http.client>True if the connection is closed._readinto_chunkedHTTPResponse._readall_chunkedReturn the real URL of the page.

        In some cases, the HTTP server redirects a client to another
        URL. The urlopen() function handles this transparently, but in
        some cases the caller needs to know which URL the client was
        redirected to. The geturl() method can be used to get at this
        redirected URL.

        _is_illegal_header_valueencoding file using iso-8859-1Find all header lines matching a given header name.

        Look through the list of headers and find all lines matching a given
        header name (and their continuation lines).  A list of the lines is
        returned, without interpretation.  If the header does not occur, an
        empty list is returned.  If the header occurs multiple times, all
        occurrences are returned.  Case is not important in the header name.

        Connect to a host on a given (SSL) port.IncompleteRead.__repr__Invalid header name %rHTTPConnection.endheadersHTTPResponse._read_and_discard_trailerHTTP/1.1 client library

<intro stuff goes here>
<other stuff, too>

HTTPConnection goes through a number of "states", which define when a client
may legally make another request or fetch the response for a particular
request. This diagram details these state transitions:

    (null)
      |
      | HTTPConnection()
      v
    Idle
      |
      | putrequest()
      v
    Request-started
      |
      | ( putheader() )*  endheaders()
      v
    Request-sent
      |\_____________________________
      |                              | getresponse() raises
      | response = getresponse()     | ConnectionError
      v                              v
    Unread-response                Idle
    [Response-headers-read]
      |\____________________
      |                     |
      | response.read()     | putrequest()
      v                     v
    Idle                  Req-started-unread-response
                     ______/|
                   /        |
   response.read() |        | ( putheader() )*  endheaders()
                   v        v
       Request-started    Req-sent-unread-response
                            |
                            | response.read()
                            v
                          Request-sent

This diagram presents the following rules:
  -- a second request may not be started until {response-headers-read}
  -- a response [object] cannot be retrieved until {request-sent}
  -- there is no differentiation between an unread response body and a
     partially read response body

Note: this enforcement is applied by the HTTPConnection class. The
      HTTPResponse class does not enforce this state machine, which
      implies sophisticated clients may accelerate the request/response
      pipeline. Caution should be taken, though: accelerating the states
      beyond the above pattern may imply knowledge of the server's
      connection-close behavior for certain requests. For example, it
      is impossible to tell whether the server will close the connection
      UNTIL the response headers have been read; this means that further
      requests cannot be placed into the pipeline until it is known that
      the server will NOT be closing the connection.

Logical State                  __state            __response
-------------                  -------            ----------
Idle                           _CS_IDLE           None
Request-started                _CS_REQ_STARTED    None
Request-sent                   _CS_REQ_SENT       None
Unread-response                _CS_IDLE           <response_class>
Req-started-unread-response    _CS_REQ_STARTED    <response_class>
Req-sent-unread-response       _CS_REQ_SENT       <response_class>
will_closeC:\msys64\mingw64\lib\python3.6\http\client.pyCall data.encode("latin-1") but show a better error message.HTTPResponse.readablegot more than %d headersLineTooLong.__init__Set up host and port for HTTP CONNECT tunnelling.

        In a connection that uses HTTP CONNECT tunneling, the host passed to the
        constructor is used as a proxy server that relays all communication to
        the endpoint passed to `set_tunnel`. This done by sending an HTTP
        CONNECT request to the proxy server when the connection is established.

        This method must be called before the HTML connection has been
        established.

        The headers argument should be a mapping of extra HTTP headers to send
        with the CONNECT request.
        CannotSendHeaderHTTPResponse.infoHTTPResponse.filenoHTTPConnection.requestHTTPSConnection.__init__CONNECT %s:%d HTTP/1.0
_http_vsn_strRead the number of bytes requested, compensating for partial reads.

        Normally, we have a blocking socket, but a read() can be interrupted
        by a signal (resulting in a partial read).

        Note that we cannot distinguish between EOF and an interrupt when zero
        bytes have been read. IncompleteRead() will be raised in this
        situation.

        This function should be used when <amt> bytes "should" be present for
        reading. If the bytes are truly not available (due to EOF), then the
        IncompleteRead exception can be used to detect the problem.
        _create_connectionClose the connection to the HTTP server.HTTPResponse._safe_readintoHTTPResponse._readinto_chunkedSHUT_RDWRSend a request header line to the server.

        For example: h.putheader('Accept', 'text/html')
        HTTPResponse._read1_chunkedHTTPResponse.getheaderHTTPResponse.readlineCan't set up tunnel for established connectionHTTPResponse.getheadersHTTPResponse.geturl_is_legal_header_nameSend a request to the server.

        `method' specifies an HTTP request method, e.g. 'GET'.
        `url' specifies the object being requested, e.g. '/index.html'.
        `skip_host' if True does not add automatically a 'Host:' header
        `skip_accept_encoding' if True does not add automatically an
           'Accept-Encoding:' header
        Connect to the host and port specified in __init__.HTTPS_PORT%s (%.20r) is not valid Latin-1. Use %s.encode('utf-8') if you want to send it encoded in UTF-8.accept-encodingHTTPConnection.sendSend `data' to the server.
        ``data`` can be a string object, a bytes object, an array object, a
        file-like object that supports a .read() method, or an iterable object.
        MAXAMOUNTsend:HTTPConnection._read_readablemessage_body should be a bytes-like object or an iterable, got %rHTTPConnection._send_request.<locals>.<genexpr>Always returns TrueHTTPResponse.flushHTTPConnection.getresponseHTTPResponse._check_closeHTTPResponse.__iter__HTTPConnection._get_content_lengthMozillaCookieJar._really_loadDefaultCookiePolicy.return_ok_verifiabilityTIMEZONE_REDiscard all session cookies.

        Note that the .save() method won't save session cookies anyway, unless
        you ask otherwise by passing a true ignore_discard argument.

        commenturl   cookie with unspecified domain does not string-compare equal to request domain_normalized_cookie_tuplesLoadErrorHEADER_TOKEN_REHEADER_ESCAPE_REset_ok_port_specifieddomain_specifieddomain_initial_dotpath_specifiedexpirescomment_urlrfc2109FileCookieJar.save   cookie expiredCookieJar._cookies_for_domain   missing or invalid (non-numeric) value for max-age attributeCookieJar.add_cookie_header   illegal name (starts with '$'): '%s'is_blockedcut_port_rereq_portignore_expiresSet-Cookie3:_allowed_domainsCookie.__init__Return the sequence of blocked domains (as a tuple).CookieJar.make_cookiesSet a cookie, without checking whether or not it should be set.MONTHS_LOWEREscape any invalid characters in HTTP URL, and uppercase all escapes.cur_yr^[=\s;]*dots_rereturn_ok_versiondomain must be given to remove cookies by path_cookie_attrsnon_word_re^\s*=\s*\"([^\"\\]*(?:\\.[^\"\\]*)*)\"set_ok_versionunmatchedCookieJar.make_cookies.<locals>.no_matching_rfc2965non_junkCookieJar._cookies_from_attrs_setheader_valuesImplements the standard rules for accepting and returning cookies.split_header_words bug: '%s', '%s', %sCookieJar._cookie_from_cookie_tuplerfc2109_as_netscapereturn_ok_expiresrfc2109=%sSet-Cookie2req_hosterhntldundotted_domainembedded_dotshost_prefix   RFC 2965 cookies are switched offreturn_ok_portDomainLiberal   third-party RFC 2965 cookie during unverifiable transaction_cookies_lock
    The LWPCookieJar saves a sequence of "Set-Cookie3" lines.
    "Set-Cookie3" is the format used by the libwww-perl library, not known
    to be compatible with any browser, but which is easy to read and
    doesn't lose information about RFC 2965 cookies.

    Additional methods

    as_lwp_str(ignore_discard=True, ignore_expired=True)

    ^\s*([^=\s;,]+)LWPCookieJar.as_lwp_strrevertDefaultCookiePolicy.set_blocked_domainshas_nonstandard_attr_cookies_for_requestLoad cookies from a file.   missing value for domain attributeknown_attrs_str2timeeff_request_hostlwp_cookie_strvals_sorted_by_keyHEADER_JOIN_ESCAPE_RECookieJar.__str__ - checking cookie %s=%sSet the sequence of allowed domains, or None.^\w+$FileCookieJar.loadns_cookiestrict_ns_set_path setting cookie: %s\\(.)^(?:Sun|Mon|Tue|Wed|Thu|Fri|Sat)[a-z]*,?\s*ns_hdrsreturn_ok_domainClear some cookies.

        Invoking this method without arguments will clear all cookies.  If
        given a single argument, only cookies belonging to that domain will be
        removed.  If given two arguments, cookies belonging to the specified
        path within that domain are removed.  If given three arguments, then
        the cookie with the specified name, path and domain is removed.

        Raises KeyError if no matching cookie exists.

        
    As for http2time, but parses the ISO 8601 formats:

    1994-02-03 14:15:29 -0100    -- ISO 8601 format
    1994-02-03 14:15:29          -- zone is optional
    1994-02-03                   -- only date
    1994-02-03T14:15:29          -- Use T as separator
    19940203T141529Z             -- ISO 8601 compact format
    19940203                     -- only date

    domain and path must be given to remove a cookie by name^\.+Clear all cookies and reload cookies from a saved file.

        Raises LoadError (or OSError) if reversion is not successful; the
        object's state will not be altered if this happens.

        Return reach of host h, as defined by RFC 2965, section 1.

    The reach R of a host name H is defined as follows:

       *  If

          -  H is the host domain name of a host; and,

          -  H has the form A.B; and

          -  A has no embedded (that is, interior) dots; and

          -  B has at least one embedded dot, or B is the string "local".
             then the reach of H is .B.

       *  Otherwise, the reach of H is H.

    >>> reach("www.acme.com")
    '.acme.com'
    >>> reach("acme.com")
    'acme.com'
    >>> reach("acme.local")
    '.local'

    CookiePolicy.set_okns_headerset_allowed_domainsReturn a string representing time in seconds since epoch, t.

    If the function is called without an argument, it will use the current
    time.

    The format of the returned string is like "YYYY-MM-DD hh:mm:ssZ",
    representing Universal Time (UTC, aka GMT).  An example of this format is:

    1994-11-24 08:49:37Z

    strict_ns_unverifiable   request-host %s does not match Netscape cookie domain %sDiscard all expired cookies.

        You probably don't need to call this method: expired cookies are never
        sent back to the server (provided you're using DefaultCookiePolicy),
        this method is called by CookieJar itself every so often, and the
        .save() method won't save expired cookies anyway (unless you ask
        otherwise by passing a true ignore_expires argument).

        iso2timeis_HDNCookieJar.set_cookie_if_okParse header values into a list of lists containing key,value pairs.

    The function knows how to deal with ",", ";" and "=" as well as quoted
    values after "=".  A list of space separated tokens are parsed as if they
    were separated by ";".

    If the header_values passed as argument contains multiple values, then they
    are treated as if they were a single value separated by comma ",".

    This means that this function is useful for parsing header fields that
    follow this syntax (BNF as from the HTTP/1.1 specification, but we relax
    the requirement for tokens).

      headers           = #header
      header            = (token | parameter) *( [";"] (token | parameter))

      token             = 1*<any CHAR except CTLs or separators>
      separators        = "(" | ")" | "<" | ">" | "@"
                        | "," | ";" | ":" | "\" | <">
                        | "/" | "[" | "]" | "?" | "="
                        | "{" | "}" | SP | HT

      quoted-string     = ( <"> *(qdtext | quoted-pair ) <"> )
      qdtext            = <any TEXT except <">>
      quoted-pair       = "\" CHAR

      parameter         = attribute "=" value
      attribute         = token
      value             = token | quoted-string

    Each header is represented by a list of key/value pairs.  The value for a
    simple token (not part of a parameter) is None.  Syntactically incorrect
    headers will not necessarily be parsed as you would want.

    This is easier to describe with some examples:

    >>> split_header_words(['foo="bar"; port="80,81"; discard, bar=baz'])
    [[('foo', 'bar'), ('port', '80,81'), ('discard', None)], [('bar', 'baz')]]
    >>> split_header_words(['text/html; charset="iso-8859-1"'])
    [[('text/html', None), ('charset', 'iso-8859-1')]]
    >>> split_header_words([r'Basic realm="\"foo\bar\""'])
    [[('Basic', None), ('realm', '"foobar"')]]

       it's a match^\#LWP-Cookies-(\d+\.\d+)Extract cookies from response, where allowable given the request.$Version=%sHTTP cookie handling for web clients.

This module has (now fairly distant) origins in Gisle Aas' Perl module
HTTP::Cookies, from the libwww-perl library.

Docstrings, comments and debug strings in this code refer to the
attributes of the HTTP cookie system as cookie-attributes, to distinguish
them clearly from Python attributes.

Class diagram (note that BSDDBCookieJar and the MSIE* classes are not
distributed with the Python standard library, but are available from
http://wwwsearch.sf.net/):

                        CookieJar____
                        /     \      \
            FileCookieJar      \      \
             /    |   \         \      \
 MozillaCookieJar | LWPCookieJar \      \
                  |               |      \
                  |   ---MSIEBase |       \
                  |  /      |     |        \
                  | /   MSIEDBCookieJar BSDDBCookieJar
                  |/
               MSIECookieJar

rfc2965_hdrsdelayloadCookieJar._process_rfc2109_cookiesstrict_domainReturn true if (and only if) cookie should be returned to server.req_path   not returning cookieReturn True if domain A domain-matches domain B, according to RFC 2965.

    A and B may be host domain names or IP addresses.

    RFC 2965, section 1:

    Host names can be specified either as an IP address or a HDN string.
    Sometimes we compare one host name with another.  (Such comparisons SHALL
    be case-insensitive.)  Host A's name domain-matches host B's if

         *  their host name strings string-compare equal; or

         * A is a HDN string and has the form NB, where N is a non-empty
            name string, B has the form .B', and B' is a HDN string.  (So,
            x.y.com domain-matches .Y.com but not Y.com.)

    Note that domain-match is not a commutative operation: a.b.c.com
    domain-matches .c.com, but not the reverse.

    rfc2109_as_nsCookie.__repr__invalid Netscape format cookies file %r: %rReturn None, or the sequence of allowed domains (as a tuple).LOOSE_HTTP_DATE_RECookieJar.clearliberal_is_HDNDefaultCookiePolicy.set_ok_domaindomain_dotHEADER_VALUE_REC:\msys64\mingw64\lib\python3.6\http\cookiejar.pyset_ok_pathESCAPED_CHAR_REget_nonstandard_attrdeepvaluesCookie.is_expiredChecking %s for cookies to return

    RFC 2965, section 3.3.6:

        An unverifiable transaction is to a third-party host if its request-
        host U does not domain-match the reach R of the request-host O in the
        origin transaction.

    strict_domain_reReturn a list of cookie-attributes to be returned to server.

        like ['foo="bar"; $Path="/"', ...]

        The $Version attribute is also added when appropriate (currently only
        once per request).

           effective request-host name %s does not domain-match RFC 2965 cookie domain %sDefaultCookiePolicy.return_ok_securecookies_by_name\.?[^.]*Return a tuple (request-host, effective request-host name).

    As defined by RFC 2965, except both are lowercased.

    %04d-%02d-%02d %02d:%02d:%02dZ^([-+])?(\d\d?):?(\d\d)?$  %s does not path-match %stime2isozCookieJar.set_policyis_third_party©ÚselfÚtupÚrequestÚnameÚvalueÚstandardÚrestÚdomainÚpathÚportÚexpiresÚversionÚsecureÚdiscardÚcommentÚcomment_urlÚpath_specifiedÚiÚdomain_specifiedÚdomain_initial_dotÚreq_hostÚerhnÚport_specified^\s*=\s*([^\s;,]*)DEFAULT_HTTP_PORTReturn string representation of Cookie in the LWP cookie file format.

    Actually, the format is extended a bit -- see module docstring.

    $Path="%s"   Netscape cookies are switched off#LWP-Cookies-2.0
LWPCookieJar.save   request port (%s) not found in %sCookieJar.__repr__offset_from_tz_stringIterates over nested mapping, depth-first, in sorted order by key.Return True if text is a sort-of-like a host domain name.

    For accepting/blocking domains.

    ISO_DATE_REstrip_quotesstrict_rfc2965_unverifiable©zcozaczcomzeduzorgznetzgovzmilzintzaerozbizzcatzcoopzinfozjobszmobizmuseumznamezproztravelzeucookies_by_pathorig_textnr_junk_charsPath component of request-URI, as defined by RFC 2965.   domain %s is in user block-list   secure cookie with non-secure requestDefaultCookiePolicy.set_ok_pathLWPCookieJar._really_loadjoin_header_wordsReturn list of tuples containing normalised cookie information.

        attrs_set is the list of lists of key,value pairs extracted from
        the Set-Cookie or Set-Cookie2 headers.

        Tuples are name, value, standard, rest, where name and value are the
        cookie name and value, standard is a dictionary containing the standard
        cookie-attributes (discard, secure, version, expires or max-age,
        domain, path and port) and rest is a dictionary containing the rest of
        the cookie-attributes.

        invalid Set-Cookie3 format file %r: %rDefaultCookiePolicy.domain_return_okclear_session_cookiesFileCookieJar.__init__DomainStrictNonDomainextract_cookies: %sDefaultCookiePolicy.path_return_okCookieJar that can be loaded from and saved to a file.set_ok_nameAbsent   domain %s is not in user allow-listMozillaCookieJar.saveCookieJar.clear_session_cookies<module http.cookiejar>   request port %s does not match cookie port %sCookieJar.clear_expired_cookiesAdd correct Cookie: header to request (urllib.request.Request object).

        The Cookie2 header is also added unless policy.hide_cookie2 is true.

        
        If you override .set_ok(), be sure to call this method.  If it returns
        false, so should your subclass (assuming your subclass wants to be more
        strict about which cookies to accept).

        strict_ns_domain   path attribute %s is not a prefix of request path %s%r does not look like a Set-Cookie3 (LWP) format fileSave cookies to a file.©ÚselfÚfÚfilenameÚignore_discardÚignore_expiresÚmagicÚmsgÚnowÚheaderÚboolean_attrsÚvalue_attrsÚlineÚdataÚnameÚvalueÚstandardÚrestÚkÚvÚlcÚhÚexpiresÚdiscardÚdomainÚdomain_specifiedÚcSet the sequence of blocked domains.Do the inverse (almost) of the conversion done by split_header_words.

    Takes a list of lists of (key, value) pairs and produces a single header
    value.  Attribute values are quoted if needed.

    >>> join_header_words([[("text/plain", None), ("charset", "iso-8859-1")]])
    'text/plain; charset="iso-8859-1"'
    >>> join_header_words([[("text/plain", None)], [("charset", "iso-8859-1")]])
    'text/plain, charset="iso-8859-1"'

    Set-Cookie3: %sadictExpiring cookie, domain='%s', path='%s', name='%s'# Netscape HTTP Cookie File
# http://curl.haxx.se/rfc/cookie_spec.html
# This is a generated file!  Do not edit.

Return false if cookies should not be returned, given cookie domain.
        FileCookieJar.revertUTC_ZONES

    WARNING: you may want to backup your browser's cookies file if you use
    this class to save cookies.  I *think* it works, but there have been
    bugs in the past!

    This class differs from CookieJar only in the format it uses to save and
    load cookies to and from a file.  This class uses the Mozilla/Netscape
    `cookies.txt' format.  lynx uses this file format, too.

    Don't expect cookies saved while the browser is running to be noticed by
    the browser (in fact, Mozilla on unix will overwrite your saved cookies if
    you change them on disk while it's running; on Windows, you probably can't
    save at all while the browser is running).

    Note that the Mozilla/Netscape format will downgrade RFC2965 cookies to
    Netscape cookies on saving.

    In particular, the cookie version and port number information is lost,
    together with information about whether or not Path, Port and Discard were
    specified by the Set-Cookie2 (or Set-Cookie) header, and whether or not the
    domain as set in the HTTP header started with a dot (yes, I'm aware some
    domains in Netscape files start with a dot and some don't -- trust me, you
    really don't want to know any more about this).

    Note that though Mozilla and Netscape use the same format, they use
    slightly different headers.  The class saves cookies using the Netscape
    header by default (Mozilla can cope with that).

    %r does not look like a Netscape format cookies fileDefaultCookiePolicy.is_not_alloweduser_domain_matchrequest_path   effective request-host %s (even with added initial dot) does not end with %s%/;:@&=+$,!~*'()magic_re%%%squote_reWEEKDAY_REMISSING_FILENAME_TEXTFor blocking/accepting domains.

    A and B may be host domain names or IP addresses.

    fn_name   missing or invalid value for expires attribute: treating as session cookienamevalue   non-local domain %s contains no embedded dot([\"\\])Defines which cookies get accepted from and returned to server.

    May also modify cookies, though this is probably a bad idea.

    The subclass DefaultCookiePolicy defines the standard rules for Netscape
    and RFC 2965 cookies -- override that if you want a customized policy.

    request_portDefaultCookiePolicy.set_ok_verifiability_timegmDefaultCookiePolicy.set_allowed_domainsReturn unmatched part of re.Match object.Return a string representing time in seconds since epoch, t.

    If the function is called without an argument, it will use the current
    time.

    The format of the returned string is like this:

    Wed, DD-Mon-YYYY HH:MM:SS GMT

       third-party Netscape cookie during unverifiable transactionSet a cookie if policy says it's OK to do so.HTTP_PATH_SAFE#( Netscape)? HTTP Cookie File^[SMTWF][a-z][a-z], (\d\d) ([JFMASOND][a-z][a-z]) (\d\d\d\d) (\d\d):(\d\d):(\d\d) GMT$IPV4_REReturn cookies as a string of "\n"-separated "Set-Cookie3" headers.

        ignore_discard and ignore_expires: see docstring for FileCookieJar.save

        Cookie.get_nonstandard_attrDefaultCookiePolicy.return_ok_expiresCookie.__str__if port is None, port_specified must be false%([0-9a-fA-F][0-9a-fA-F])rest=%s^
    (\d\d?)            # day
       (?:\s+|[-\/])
    (\w+)              # month
        (?:\s+|[-\/])
    (\d+)              # year
    (?:
          (?:\s+|:)    # separator before clock
       (\d\d?):(\d\d)  # hour:min
       (?::(\d\d))?    # optional seconds
    )?                 # optional clock
       \s*
    ([-+]?\d{2,4}|(?![APap][Mm]\b)[A-Za-z]+)? # timezone
       \s*
    (?:\(\w+\))?       # ASCII representation of timezone in parens.
       \s*$strict_ns_set_initial_dollarCookie.set_nonstandard_attra filename was not supplied (nor was the CookieJar instance initialised with one)imon
        Cookies are NOT loaded from the named file until either the .load() or
        .revert() method is called.

        time2netscapeDefaultCookiePolicy.return_ok_version$PortCollection of HTTP cookies.

    You may not need to know about this class: try
    urllib.request.build_opener(HTTPCookieProcessor).open(url).
       host prefix %s for domain %s contains a dot_warn_unhandled_exception   Set-Cookie2 without version attribute (%s=%s)   missing value for %s attributeCookieJar._cookies_for_requestSTRICT_DATE_REmax_age_setbad_cookieCookieJar._cookie_attrs.<locals>.<lambda>http.cookiejar bug!
%sCookie.has_nonstandard_attrfilename must be string-likeuppercase_escaped_charescape_pathDefaultCookiePolicy.return_ok_port$Version="1"version_setDefaultCookiePolicy.blocked_domainsCookieJar._normalized_cookie_tuplesDefaultCookiePolicy.set_ok_nameReturn sequence of Cookie objects extracted from response object.DefaultCookiePolicy.is_blockedDefaultCookiePolicy.set_ok_port$Domain="%s"DomainStrictNoDotsparse_ns_headersReturn a list of cookies to be returned to server.Return false if cookies should not be returned, given cookie path.
        Return True if text is a host domain name.DomainRFC2965Match   effective request-host %s does not domain-match %s<%s[%s]>Ad-hoc parser for Netscape protocol cookie-attributes.

    The old Netscape cookie format for Set-Cookie can for instance contain
    an unquoted "," in the expires field, so we have to use this ad-hoc
    parser instead of split_header_words.

    XXX This may not make the best possible effort to parse all the crap
    that Netscape Cookie headers contain.  Ronald Tschalar's HTTPClient
    parser is probably better, so could do worse than following that if
    this ever gives any trouble.

    Currently, this is also used for parsing RFC 2109 cookies.

    Returns time in seconds since epoch of time represented by a string.

    Return value is an integer.

    None is returned if the format of str is unrecognized, the time is outside
    the representable range, or the timezone string is not recognized.  If the
    string contains no timezone, UTC is assumed.

    The timezone in the string may be numerical (like "-0800" or "+0100") or a
    string timezone (like "UTC", "GMT", "BST" or "EST").  Currently, only the
    timezone strings equivalent to UTC (zero offset) are known to the function.

    The function loosely parses the following formats:

    Wed, 09 Feb 1994 22:23:32 GMT       -- HTTP format
    Tuesday, 08-Feb-94 14:15:29 GMT     -- old rfc850 HTTP format
    Tuesday, 08-Feb-1994 14:15:29 GMT   -- broken rfc850 HTTP format
    09 Feb 1994 22:23:32 GMT            -- HTTP format (no weekday)
    08-Feb-94 14:15:29 GMT              -- rfc850 format (no weekday)
    08-Feb-1994 14:15:29 GMT            -- broken rfc850 format (no weekday)

    The parser ignores leading and trailing whitespace.  The time may be
    absent.

    If the year is given with only 2 digits, the function will select the
    century that makes the year closest to the current date.

    Constructor arguments should be passed as keyword arguments only.<Cookie %s for %s>Return true if (and only if) cookie should be accepted from server.

        Currently, pre-expired cookies never get this far -- the CookieJar
        class deletes such cookies itself.

        EPOCH_YEARHEADER_QUOTED_VALUE_RE%s, %02d-%s-%04d %02d:%02d:%02d GMT- checking cookie path=%s^
    (\d{4})              # year
       [-\/]?
    (\d\d?)              # numerical month
       [-\/]?
    (\d\d?)              # day
   (?:
         (?:\s+|[-:Tt])  # separator before clock
      (\d\d?):?(\d\d)    # hour:min
      (?::?(\d\d(?:\.\d*)?))?  # optional seconds (and fractional)
   )?                    # optional clock
      \s*
   ([-+]?\d\d?:?(:?\d\d)?
    |Z|z)?               # timezone  (Z is "zero meridian", i.e. GMT)
      \s*$DefaultCookiePolicy.set_ok_versionCookieJar.__len__   bad port %s (not numeric)HTTP Cookie.

    This class represents both Netscape and RFC 2965 cookies.

    This is deliberately a very simple class.  It just holds attributes.  It's
    possible to construct Cookie instances that don't comply with the cookie
    standards.  CookieJar.make_cookies is the factory function for Cookie
    objects -- it deals with cookie parsing, supplying defaults, and
    normalising to the representation used in this class.  CookiePolicy is
    responsible for checking them to see whether they should be accepted from
    and returned to the server.

    Note that the port may be present in the headers, but unspecified ("Port"
    rather than"Port=80", for example); if this is the case, port is None.

       country-code second level domain %sDefaultCookiePolicy.allowed_domainsDefaultCookiePolicy.return_ok_domainReturn number of contained cookies.DefaultCookiePolicy.__init__
        If you override .return_ok(), be sure to call this method.  If it
        returns false, so should your subclass (assuming your subclass wants to
        be more strict about which cookies to return).

        CookieJar.extract_cookiesCookieJar.__iter__SimpleHTTPRequestHandler.list_directory.<locals>.<lambda>Test whether argument path is a Python script.
Keyboard interrupt received, exiting.shortmsg
    Given a URL path, remove extra '/'s and '.' path elements and collapse
    any '..' references and returns a collapsed path.

    Implements something akin to RFC-2396 5.2 step 6 to parse relative paths.
    The utility of this function is limited to is_cgi method and helps
    preventing some security attacks.

    Returns: The reconstituted URL, which will always start with a '/'.

    Raises: IndexError if too many '..' occur within the path.

    HandlerClassVersion of send_head that support CGI scriptsHandle a single HTTP request.

        You normally don't need to override this method; see the class
        __doc__ string for information on how to handle specific HTTP
        commands such as GET and POST.

        	
 CONTENT_LENGTHraw_requestlinePATH_INFOclose_connectionQUERY_STRINGREMOTE_HOSTHTTP_USER_AGENTHTTP_COOKIEHTTP_REFERER<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
        "http://www.w3.org/TR/html4/strict.dtd">
<html>
    <head>
        <meta http-equiv="Content-Type" content="text/html;charset=utf-8">
        <title>Error response</title>
    </head>
    <body>
        <h1>Error response</h1>
        <p>Error code: %(code)d</p>
        <p>Message: %(message)s.</p>
        <p>Error code explanation: %(code)s - %(explain)s.</p>
    </body>
</html>
Translate a /-separated PATH to the local filename syntax.

        Components that mean special things to the local file system
        (e.g. drive or directory names) are ignored.  (XXX They should
        probably be diagnosed.)

        base_version_number<hr>
<ul>BaseHTTPRequestHandler.parse_requestsend_response_onlyBaseHTTPRequestHandler.log_messageBaseHTTPRequestHandler.send_headerInternal routine to get nobody's uidsend_errorhave_forkdir_sepHTTP_ACCEPTREMOTE_USERBaseHTTPRequestHandler.send_response/cgi-binCGI script is not a plain file (%r)error_message_formatUnsupported method (%r)ServerClassNo permission to list directory100-continue<meta http-equiv="Content-Type" content="text/html; charset=%s">BaseHTTPRequestHandler.log_date_time_stringSend and log an error reply.

        Arguments are
        * code:    an HTTP error code
                   3 digits
        * message: a simple optional 1 line reason phrase.
                   *( HTAB / SP / VCHAR / %x80-FF )
                   defaults to short entry matching the response code
        * explain: a detailed message defaults to the long entry
                   matching the response code.

        This sends an error response (so it must be called before any
        output has been generated), logs the error, and finally sends
        a piece of HTML explaining the error to the user.

        error_content_typeSimpleHTTP/<html>
<head>CGIHTTPRequestHandler.is_cgiLog an arbitrary message.

        This is used by all other logging functions.  Override
        it if you have specific logging wishes.

        The first argument, FORMAT, is a format string for the
        message to be logged.  If the format string contains
        any % escapes requiring parameters, they should be
        specified as subsequent arguments (it's just like
        printf!).

        The client ip and current date/time are prefixed to
        every message.

        Copy all data between two file objects.

        The SOURCE argument is a file object open for reading
        (or anything with a read() method) and the DESTINATION
        argument is a file object open for writing (or
        anything with a write() method).

        The only reason for overriding this would be to change
        the block size or perhaps to replace newlines by CRLF
        -- note however that this the default server uses this
        to copy binary data as well.

        Handle multiple requests if necessary.Log an accepted request.

        This is called by send_response().

        C:\msys64\mingw64\lib\python3.6\http\server.py_url_collapse_pathCGI script exited OKSend the response header only.<title>%s</title>
</head>HTTPServer.server_bind_headers_bufferw.exedo_HEADSimpleHTTPRequestHandler.do_HEAD©)ÚselfÚdirÚrestÚpathÚiÚnextdirÚnextrestÚ	scriptdirÚ_ÚqueryÚscriptÚ
scriptnameÚ
scriptfileÚispyÚenvÚuqrestÚauthorizationÚbase64ÚbinasciiÚlengthÚrefererÚacceptÚlineÚuaÚcoÚ
cookie_strÚkÚdecoded_queryÚargsÚnobodyÚpidÚstsÚ
subprocessÚcmdlineÚinterpÚnbytesÚpÚdataÚstdoutÚstderrÚstatuscgi_directoriesSimpleHTTPRequestHandler.guess_typehttpdhead_partsComplete HTTP server with GET, HEAD and POST commands.

    GET and HEAD also support running CGI scripts.

    The POST command is *only* implemented for CGI scripts.

    user-agentDecide what to do with an "Expect: 100-continue" header.

        If the client is expecting a 100 Continue response, we must
        respond with either a 100 Continue or a final response before
        waiting for the request body. The default is to always respond
        with a 100 Continue. You can behave differently (for example,
        reject unauthorized requests) by overriding this method.

        This method should either return True (possibly after sending
        a 100 Continue response) or send an error response and return
        False.

        /htbinBaseHTTPRequestHandler.handle_expect_100server_nameLog an error.

        This is called when a request cannot be fulfilled.  By
        default it passes the message on to log_message().

        Arguments are the same as for log_message().

        XXX This should go to the separate error log.

        %s - - [%s] %s
CGI/1.1BaseHTTPRequestHandler.log_errorCGI script is not executable (%r)Can only POST to CGI scriptsprotocol_versionSimpleHTTPRequestHandler.translate_pathReturn the server software version string.CGIHTTPRequestHandler.send_headSend a MIME header to the headers buffer.nobody_uiddefault_request_versionTest the HTTP request handler class.

    This runs an HTTP server on port 8000 (or the port argument).

    splitpathServe a POST request.

        This is only implemented for CGI scripts.

        PATH_TRANSLATEDcollapsed_pathserve_messagerun_cgiSERVER_PROTOCOLlog_requestREMOTE_ADDRSCRIPT_NAMEnew_partsBaseHTTPRequestHandler.version_stringDEFAULT_ERROR_CONTENT_TYPESend the blank line ending the MIME headers.CGI script exit status %#xBad request version (%r)application/octet-streamBaseHTTPRequestHandler.address_stringBaseHTTPRequestHandler.handle_one_requestBad request syntax (%r)mnameCommon code for GET and HEAD commands.

        This sends the response code and MIME headers.

        Return value is either a file object (which has to be copied
        to the outputfile by the caller unless the command was HEAD,
        and must be closed by the caller under all circumstances), or
        None, in which case the caller has nothing further to do.

        displaynameflush_headersHTTP request handler base class.

    The following explanation of HTTP serves to guide you through the
    code as well as to expose any misunderstandings I may have about
    HTTP (so you don't need to read the code to figure out I'm wrong
    :-).

    HTTP (HyperText Transfer Protocol) is an extensible protocol on
    top of a reliable stream transport (e.g. TCP/IP).  The protocol
    recognizes three parts to a request:

    1. One line identifying the request type and path
    2. An optional set of RFC-822-style headers
    3. An optional data part

    The headers and data are separated by a blank line.

    The first line of the request has the form

    <command> <path> <version>

    where <command> is a (case-sensitive) keyword such as GET or POST,
    <path> is a string containing path information for the request,
    and <version> should be the string "HTTP/1.0" or "HTTP/1.1".
    <path> is encoded using the URL encoding scheme (using %xx to signify
    the ASCII character with hex code xx).

    The specification specifies that lines are separated by CRLF but
    for compatibility with the widest range of clients recommends
    servers also handle LF.  Similarly, whitespace in the request line
    is treated sensibly (allowing multiple spaces between components
    and allowing trailing whitespace).

    Similarly, for output, lines ought to be separated by CRLF pairs
    but most clients grok LF characters just fine.

    If the first line of the request has the form

    <command> <path>

    (i.e. <version> is left out) then this is assumed to be an HTTP
    0.9 request; this form has no optional headers and data part and
    the reply consists of just the data.

    The reply form of the HTTP 1.x protocol again has three parts:

    1. One line giving the response code
    2. An optional set of RFC-822-style headers
    3. The data

    Again, the headers and data are separated by a blank line.

    The response code line has the form

    <version> <responsecode> <responsestring>

    where <version> is the protocol version ("HTTP/1.0" or "HTTP/1.1"),
    <responsecode> is a 3-digit response code indicating success or
    failure of the request, and <responsestring> is an optional
    human-readable string explaining what the response code means.

    This server parses the request and the headers, and then calls a
    function specific to the request type (<command>).  Specifically,
    a request SPAM will be handled by a method do_SPAM().  If no
    such method exists the server sends an error response to the
    client.  If it exists, it is called with no arguments:

    do_SPAM()

    Note that the request name is case sensitive (i.e. SPAM and spam
    are different requests).

    The various request details are stored in instance variables:

    - client_address is the client IP address in the form (host,
    port);

    - command, path and version are the broken-down request line;

    - headers is an instance of email.message.Message (or a derived
    class) containing the header information;

    - rfile is a file object open for reading positioned at the
    start of the optional input data part;

    - wfile is a file object open for writing.

    IT IS IMPORTANT TO ADHERE TO THE PROTOCOL FOR WRITING!

    The first thing to be written must be the response line.  Then
    follow 0 or more header lines, then a blank line, and then the
    actual data (if any).  The meaning of the header lines depends on
    the command executed by the server; in most cases, when data is
    returned, there should be at least one header line of the form

    Content-type: <type>/<subtype>

    where <type> and <subtype> should be registered MIME types,
    e.g. "text/html" or "text/plain".

    BaseHTTPRequestHandler.send_errorCGIHTTPRequestHandler.is_pythonconntypeLine too longdisplaypathSimpleHTTPRequestHandler.do_GETGuess the type of a file.

        Argument is a PATH (a filename).

        Return value is a string of the form type/subtype,
        usable for a MIME Content-type header.

        The default implementation looks the file's extension
        up in the table self.extensions_map, using application/octet-stream
        as a default; however it would be permissible (if
        slow) to look inside the data to make a better guess.

        <!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN" "http://www.w3.org/TR/html4/strict.dtd">%s %d %s
Directory listing for %sParse a request (internal).

        The request should be stored in self.raw_requestline; the results
        are in self.command, self.path, self.request_version and
        self.headers.

        Return True for success, False for failure; on failure, an
        error is sent back.

        longmsgnew_urlHTTP server classes.

Note: BaseHTTPRequestHandler doesn't implement any HTTP request; see
SimpleHTTPRequestHandler for simple implementations of GET, HEAD and POST,
and CGIHTTPRequestHandler for CGI scripts.

It does, however, optionally implement HTTP/1.1 persistent connections,
as of version 0.3.

Notes on CGIHTTPRequestHandler
------------------------------

This class implements GET and POST requests to cgi-bin scripts.

If the os.fork() function is not present (e.g. on Windows),
subprocess.Popen() is used as a fallback, with slightly altered semantics.

In all cases, the implementation is intentionally naive -- all
requests are executed synchronously.

SECURITY WARNING: DON'T USE THIS CODE UNLESS YOU ARE INSIDE A FIREWALL
-- it may execute arbitrary Python code or external programs.

Note that status code 200 is sent prior to execution of a CGI script, so
scripts cannot send other status codes such as 302 (redirect).

XXX To do:

- log requests even later (to capture byte count)
- log user-agent header and other interesting goodies
- send error log to separate file
BaseHTTPRequestHandler.send_response_onlyTest whether self.path corresponds to a CGI script.

        Returns True and updates the cgi_info attribute to the tuple
        (dir, rest) if self.path requires running a CGI script.
        Returns False otherwise.

        If any exception is raised, the caller should assume that
        self.path was rejected as invalid and act accordingly.

        The default implementation tests whether the normalized url
        path begins with one of the strings in self.cgi_directories
        (and the next character is a '/' or the end of the string).

        code %d, message %scommand: %sLast-ModifiedRequest timed out: %rAdd the response header to the headers buffer and log the
        response code.

        Also send two standard headers with the server software
        version and the current date.

        Execute a CGI script.SimpleHTTPRequestHandler.copyfiletrailing_slash</ul>
<hr>
</body>
</html>
SERVER_SOFTWAREweekdaynameOverride server_bind to store the server name.BaseHTTPRequestHandler.flush_headersdup2GATEWAY_INTERFACEis_executableServe a GET request.server_versionSERVER_PORT<module http.server>Serve a HEAD request.DEFAULT_ERROR_MESSAGEgetpwallTest for executable file."%s" %s %sdo_POST<body>
<h1>%s</h1>Test whether argument path is an executable file.CGIHTTPRequestHandler.run_cgiBaseHTTP/<li><a href="%s">%s</a></li>Return the current date and time formatted for a message header.CGIHTTPRequestHandler.is_executableBaseHTTPRequestHandler.log_requestCGIHTTPRequestHandler.do_POSTtail_partHelper to produce a directory listing (absent index.html).

        Return value is either a file object, or None (indicating an
        error).  In either case, the headers are sent, making the
        interface the same as for send_head().

        Too many headersSimple HTTP request handler with GET and HEAD commands.

    This serves files from the current directory and any of its
    subdirectories.  The MIME type for files is determined by
    calling the .guess_type() method.

    The GET and HEAD requests are identical except that the HEAD
    request omits the actual contents of the file.

    Invalid HTTP version (%s)Serving HTTP on {host} port {port} (http://{host}:{port}/) ...Return the current time formatted for logging.No such CGI script (%r)SERVER_NAMEScript output followsAUTH_TYPEnobody_uid.<locals>.<genexpr>setuidSimpleHTTPRequestHandler.send_headReturn the client address.Bad HTTP/0.9 request type (%r)BaseHTTPRequestHandler.end_headersFile not foundBaseHTTPRequestHandler.date_time_string%02d/%3s/%04d %02d:%02d:%02diso2win_langi18ntrans:330:Done.mo_re_str
MSGFMT subprocess failed (%s)i18ntrans:327:Print trying locale (%s)... Automaticno!!!!!!!i18ntrans:235:Detected Locale Preferences: *Automatictranslatorlibintlexpanded_loc_prefs_gen_locale_re.<locals>.named[a-z]{2,3}wencset_localelocale_tab_expand_iso_specwin2iso_langmenu_simNew locale override ({lbl}/{loc}) will take effect after restarting the program.locale_iso_countryi18ntrans:336:Check system locale is set_menu_localeÛ@   )zafzZAzUTF-8z	AfrikaanszSouth Africaz1252)zarzSAzUTF-8zArabiczSaudi Arabiaz1256)zbezBYzUTF-8z
BelarusianzBelarusz1251)zbgzBGzUTF-8z	BulgarianzBulgariaz1251)zbszBAzUTF-8NNN)zcazESzUTF-8zCatalanzSpainz1252)zcszCZzUTF-8zCzechzCzech Republicz1250)zdazDKzUTF-8zDanishzDenmarkz1252)zdezDEzUTF-8zdeNN)zelzGRzUTF-8zGreekzGreecez1253)zenzUSzUTF-8zEnglishzUnited Statesz1252)zeszESzUTF-8zSpanishzSpainz1252)zetzEEzUTF-8zEstonianzEstoniaz1257)zeuzESzUTF-8zBasquezSpainz1252)zfazIRzUTF-8zFarsizIranz1256)zfizFIzUTF-8zFinnishzFinlandz1252)zfrzBEzUTF-8zFrenchzFrancez1252)zfrzCAzUTF-8zFrenchzCanadaz1252)zfrzCHzUTF-8zFrenchzFrancez1252)zfrzFRzUTF-8NNN)zgaNzUTF-8NNN)zglzESzUTF-8zGalicianzSpainz1252)zguNzUTF-8zGujaratizIndiaÚ0)zhezILzutf8zHebrewzIsraelz1255)zhizINzUTF-8zHindiNz65001)zhrzHRzUTF-8zCroatianzCroatiaz1250)zhuNzUTF-8z	HungarianzHungaryz1250)zidzIDzUTF-8z
Indonesianz	indonesiaz1252)ziszISzUTF-8z	IcelandiczIcelandz1252)zitzITzUTF-8zItalianzItalyz1252)zjazJPzUTF-8zJapanesezJapanz932)zkazGEzUTF-8zGeorgianzGeorgiaz65001)zkmzKHzUTF-8zKhmerNz65001)zknzINzUTF-8zKannadaNz65001)zkozKRzUTF-8zKoreanzKoreaz949)zlatNzUTF-8zLatvianzLatviaz1257)zlozLAzUTF-8zLaozLaoszUTF-8)zltzLTzUTF-8z
Lithuanianz	Lithuaniaz1257)zmizNZzUTF-8zMaoriNz1252)zmlzINzUTF-8z	MalayalamzIndiaz
x-iscii-ma)zmnNzUTF-8zCyrillicz	Mongolianz1251)zmszMYzUTF-8zMalayzmalaysiaz1252)znlzNLzUTF-8zDutchzNetherlandsz1252)znnzNOzUTF-8zNorwegian-NynorskzNorwayz1252)znozNOzUTF-8znoNN)zphzPHzUTF-8zFilipinozPhilippinesz1252)zplNzUTF-8zPolishzPolandz1250)zptzBRzUTF-8z
PortuguesezBrazilz1252)zptzPTzUTF-8z
PortuguesezPortugalz1252)zrozROzUTF-8zRomanianzRomaniaz1250)zruzRUzUTF-8zRussianzRussiaz1251)zskzSKzUTF-8zSlovakzSlovakiaz1250)zslzSIzUTF-8z	SlovenianzSloveniaz1250)zsozSOzUTF-8NNN)zsqzALzUTF-8zAlbanianzAlbaniaz1250)zsrzCSzUTF-8NNN)zsvzSEzUTF-8zSwedishzSwedenz1252)zthzTHzUTF-8zThaizThailandz874)ztlNzUTF-8NNN)ztrzTRzUTF-8zTurkishzTurkeyz1254)zukzUAzUTF-8z	UkrainianzUkrainez1251)zvizVNzUTF-8z
VietnamesezViet Namz1258)zzhzCNzUTF-8zChinesezChinaz936)zzhzTWzUTF-8zChinesezTaiwanz950ab_simab_sim.mowlocmo_diri18ntrans:175:Parse Locale ISO: locale_win_countrylocale_tableCannot find 'msgfmt.py' executable in search path ( %s ).
wlang[A-Za-z_]*i18ntrans:339:LANG = %slocale_preferences(?:%s)??libintl-8.dlllocale_win_langiso2win_full\.po$i18ntrans:319:Unable to bind text domain for Glade UI.i18ntrans:335:Successfully set locale to i18ntrans:332:Locale %s failed..._list_po
    Handler for "Regenerate Locales" option.
    Attempts to use the Python library's gettext utilities to generate MO files from all Ab-Sim PO files.
    This requires the gettext scripts to be available and in the right place, which may be version and
    platform dependent.
    Reports result in a pop-up window.
    win2iso_locgettext_dirlocale_domainlocale_iso_langlocale_encodinglocale_re_strwin_locale_re_strpo_re_str[A-Z]{2,3}translator2win2iso_fullwindows_country_gen_locale_re.<locals>.optionalregenerate_locales_handler.<locals>.<genexpr>
    Uses introspection to generate the list of available locales for the "Locale" menu.
    Generates an option for each available MO file, plus the Automatic option
    (which turns off the override, reverting to automatic detection).
    i18ntrans:312:SETTING LOCALE DOMAIN FOR GTK/GLADE...
Generate a single internationalization translator for whole package.
iso2win_lociso2win_encwin2iso_enci18n_tools\.mo$_detect_windows_locale%s_%s.%sSetting locale toC:\msys64\home\cbper\i18ntrans2.pywindows_languagei18ntrans:17:LOCALE OVERRIDE: 
    List locale info for all PO translation source files in the i18n directory of the source tree.
    country_sloc_str. Results:

    List locale info for all MO translation binary files under the i18n directory of the source tree.
    i18ntrans:320:Some on-screen messages will not be translated.i18ntrans:316:('ab_sim'). Done.<module i18ntrans2>po_list
%s - Successful
    Attempt to detect the locale from Windows O/S.
    
    Generate utility regular expressions for parsing locale filenames (PO, MO, locale string).
    _list_moi18ntrans:21:GETTEXT DIR: 
    Parse an ISO locale specification into components.
    mo_listlanguage_s[A-Za-z ]*(?P<%s>%s)lo_reset_menu_locale_handler_parse_locale_iso_spec[A-Za-z0-9]*Available PO files: _new_loc_prefs**DEPRECATED**

    Null import object.

    Always returns None.**DEPRECATED**

    Given the path to a .py file, return the path to its .pyc file.

    The .py file does not need to exist; this simply returns the path to the
    .pyc file calculated as if the .py file were imported.

    If debug_override is not None, then it must be a boolean and is used in
    place of sys.flags.optimize.

    If sys.implementation.cache_tag is None then NotImplementedError is raised.

    load_packageopened_fileinit_pathlock_heldinit_frozenCompatibility support for implementing load_source()._HackedGetData.__init__load_compiledinvalid file open mode {!r}load_dynamic**DEPRECATED**

    Create a new module.

    The module is not entered into sys.modules.

    This module provides the components needed to build your own __import__
function.  Undocumented functions are obsolete.

In most cases it is preferred you consider using the importlib module's
functionality over this module.

file object required for import (type code {})**DEPRECATED**

    Load a module, given information returned by find_module().

    The module name must include the full package name, if any.

    'name' must be a str, not {}Compatibility support for implementing load_compiled().Compatibility support for 'file' arguments of various load_*()
    functions.SEARCH_ERRORempty pathname**DEPRECATED**

        Load an extension module.
        PY_CODERESOURCE_HackedGetData.get_dataC:\msys64\mingw64\lib\python3.6\imp.pyReturn the magic tag for .pyc files.{!r} is not a packagePY_FROZEN_LoadSourceCompatibility**DEPRECATED**

    Reload the module and return it.

    The module must have been successfully imported before.

    'path' must be None or a list, not {}<module imp>init_builtinNullImporter.__init__Don't know how to import {} (type code {})Gross hack to contort loader to deal w/ load_*()'s bad API.**DEPRECATED**

    Given the path to a .pyc. file, return the path to its .py file.

    The .pyc file does not need to exist; this simply returns the path to
    the .py file calculated to correspond to the .pyc file.  If path does
    not conform to PEP 3147 format, ValueError will be raised. If
    sys.implementation.cache_tag is None then NotImplementedError is raised.

    get_magic**DEPRECATED**

    Load and return a built-in module by name, or None is such module doesn't
    exist
    _LoadCompiledCompatibilityPY_RESOURCE**DEPRECATED**

    Return the magic number for .pyc files.
    NullImporter.find_moduleC_BUILTINIMP_HOOK**DEPRECATED**

    Search for a module.

    If path is omitted or None, search for a built-in, frozen or special
    module and continue search in sys.path. The module name cannot
    contain '.'; to search for a submodule of a package, pass the
    submodule name and the package's __path__.

    the imp module is deprecated in favour of importlib; see the module's documentation for alternative usesC:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\importingC:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\importing\__init__.pyC:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\importing\ImportCache.pyimported_modules<module importing.ImportCache>imported_by_name Import cache.

This is not about caching the search of modules in the file system, but about
maintaining a cache of module trees built.

It can happen that modules become unused, and then dropped from active modules,
and then later active again, via another import, and in this case, we should
not start anew, but reuse what we already found out about it.
%d package level uppackage_partpreloaded_pathWhitelisting<module importing.Importing> This is out own module finding low level implementation.

        Just the full module name and search path are given. This is then
        tasked to raise "ImportError" or return a path if it finds it, or
        None, if it is a built-in.
    win32comC:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\importing\Importing.py_findModuleInPath: Using search pathfindModule: Absolute imported module '%s' in as built-in':tried_nameslevel_desc%d package levels upforce_package Initialize the main script directory.

        We use this as part of the search path for modules.
    normalizePackageNamewin32comextparent_package_name%s: Module cannot be imported due to syntax errors._findModuleInPath2.<locals>.<genexpr>%s: Cannot find '%s' in package '%s' %s (tried %s).CandidatesPreloadedPackages_findModule: Cached result (see previous call).getPackageSearchPath.<locals>.getPackageDirCandidates Decide if a directory is a package.

        Before Python3.3 it's required to have a "__init__.py" file, but then
        it became impossible to decide, and for extra fun, there is also the
        extra packages provided via "*.pth" file tricks by "site.py" loading.
    getExtensionModuleSuffixesmin_priogetModuleFullNameFromPackageAndNamefindModule: Enter to search %r in package %r level %s.findModule: Relative imported module '%s' as '%s' in filename '%s':child_package_namecase_sensitivegetPackageNameFromFullName%s: Cannot find '%s' %s._findModule: Enter to search '%s'._findModule2findModule: Found absolute imported module '%s' in filename '%s':_debug_module_finding Find a module with given package name as parent.

        The package name can be None of course. Level is the same
        as with "__import__" built-in. Warnings are optional.

        Returns a triple of package name the module is in, filename of
        it, which can be a directory for packages, and the location
        method.
     Locating modules and package source on disk.

The actual import of a module would already execute code that changes
things. Imagine a module that does ``os.system()``, it would be done during
compilation. People often connect to databases, and these kind of things,
at import time.

Therefore CPython exhibits the interfaces in an ``imp`` module in standard
library, which one can use those to know ahead of time, what file import would
load. For us unfortunately there is nothing in CPython that is easily
accessible and gives us this functionality for packages and search paths
exactly like CPython does, so we implement here a multi step search process
that is compatible.

This approach is much safer of course and there is no loss. To determine if
it's from the standard library, one can abuse the attribute ``__file__`` of
the ``os`` module like it's done in ``isStandardLibraryPath`` of this module.

as absolute importas relative or absolute import_findModuleInPath: Entermodule_search_cachewarnAbout_findModuleInPath: _findModuleInPath2 gavepth_importspth_imported_packagesPython installation problem, cannot read file '%s'. This module abstracts what site.py is normally doing in .pth files.

This tries to extract "namespaces" packages that were manually created and
point to package directories, which need no "__init__.py" to count as a
package. Nuitka will pretend for those that there be one, but without content.
getPreloadedPackagePathspreloaded_packages Extract packages with no __file__, i.e. they got added manually.

        They are frequently created with "*.pth" files that then check for the
        "__init__.py" to exist, and when it doesn't, then they create during the
        loading of "site.py" an package with "__path__" set.
    <module importing.PreloadedPackages>C:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\importing\PreloadedPackages.pygetsitepackagesgetLoadedPackagesRequested to %srecurse to standard library.isSameModulePathCannot recurse to import module '%s' (%s) because of '%s'Requested to recurse to all non-standard library modules._recurseToconsiderFilenameplugin_infosub_pathsub_filenameModule %s instructed by user to recurse to.Checking top level plug-in path %s %sRequested to not recurse at all.Failed to include module from '%s'.Recursed to %s '%s' at '%s' twice.Checking detail plug-in path '%s' '%s':Shared library for inclusion.Checking plug-in pattern '%s':Package directory %sextra_recursionplugin_decisionany_caselogRecursionis exact match of %rRecurse to import '%s' from '%s'. (%s)matches pattern %rError, pattern cannot be a directory name.matchesModuleNameToPatternsis package content of match to pattern %rDefault behavior, not recursing without request.Didn't match any files against pattern '%s'.Shared library cannot be inspected. Recursion into other modules.

Module %s instructed by user to not recurse to.<module importing.Recursion>C:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\importing\Recursion.pyLives in plug-in directory.Cannot recurse to import module '%s' (%s) because code is too complex.Recursed to %s %s %sDuplicate '%s' of '%s' ignored .Failed to recurse to directory '%s'.is package content of %rstdlib_pathsorig_prefix_filenameos_filenameC:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\importing\StandardLibrary.py Access to standard library distinction.

For code to be in the standard library means that it's not written by the
user for sure. We treat code differently based on that information, by e.g.
including as byte code.

To determine if a module from the standard library, we can abuse the attribute
"__file__" of the "os" module like it's done in "isStandardLibraryPath" of this
module.
scripts/activatelib_partpython_link_filenameos_pathlib-tkbin/activate Check if a path is in the standard library.

    <module importing.StandardLibrary> Get the standard library paths.

     Whitelist modules that are not found, but probably that's acceptable.

<module importing.Whitelisting>white_listedC:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\importing\Whitelisting.pyYour CPython version has a built-in module '%s', that is not whitelisted
please report this to http://bugs.nuitka.net.¨;  zmaczntzos2zposixz	_emx_linkzriscoszcez
riscospathzriscosenvironzCarbon.Filezorg.python.corez_shaz_sha256zarrayz_sha512z_md5z_subprocesszmsvcrtzcPicklezmarshalzimpzsysz	itertoolsz	cStringIOztimezzlibzthreadzmathzerrnozoperatorzsignalzgcz
exceptionszwin32processzunicodedataz__builtin__zfcntlz_socketz_sslzpwdzspwdz_randomzgrpz_ioz_stringzselectz__main__z_winregz	_warningsz_srez
_functoolsz_hashlibz_collectionsz_localez_codecsz_weakrefz_structz_dummy_threadingzbinasciizdatetimez_astz	xxsubtypez_bytesiozcmathz_fileiozaetypeszaepackzMacOSzcdzclzgdbmzglzGLzaetoolsz_bisectz_heapqz	_symtablezsyslogz	_datetimez_elementtreez_picklez_posixsubprocessz_threadzatexitzpyexpatz_impz_sha1zfaulthandlerz_osx_supportz	sysconfigzcopyregz	ipaddresszreprlibz
win32eventz	win32filezPyQt4.uic.port_v3.string_iozPyQt4.uic.port_v3.load_pluginzPyQt4.uic.port_v3.ascii_upperzPyQt4.uic.port_v3.proxy_basezPyQt4.uic.port_v3.as_stringzbuiltinszUserDictzos.pathzStringIOz	_testcapizapplesinglez_testbufferz
bsddb.testzcollections.abcz__package__.modulez__mangled_modz__package__zctypes.testzdbm.dumbzdbm.ndbmzdistutils.testszdistutils.mwerkscompilerzxmlrpc.serverzemail.test.test_emailzemail.test.test_email_renamedzemail.test.test_email_codecsz
email.testzenumz_pyioz	__hello__z
__phello__z__phello__.spamz__phello__.foozfake test modulezhtmlzhtml.entitieszurllib.requestzhttpzimportlib.test.import_zpep3147.foozpep3147zRAnDoMzinfinite_reloadztest_trailing_slashznonexistent_xyzzyz_parent_foo.barz_parent_fooztest_unc_pathzhooktestmodulezhooktestpackagezhooktestpackage.subzreloadmodulezhooktestpackage.sub.subberzhooktestpackage.oldabszhooktestpackage.newrelz!hooktestpackage.sub.subber.subestzhooktestpackage.futrelzsubzhooktestpackage.newabszimportlib.test.__main__z	importlibzinspect_fodder3ztest.test_importzimgfilez
json.testszlib2to3.testszwin32evtlogzwin32evtlogutilz
pywintypeszlzmaz
macostoolszfoo.onezfoo.twozparent.child.onezparent.child.twozparent.child.threezbar.twoza_testzparent.childzparentzbarzSpamzossaudiodevzpathlibzgestaltzt1zt2zt2.subzt2.sub.subsubzt3.sub.subsubzt5zt6zt7zt7.subzt7.sub.subsubzt8zt3.subzt3zfoozfoo.barzfoo.bazz	zipimportzpkgz
pkg.subpkgzpkg.subpkg.czpkg.subpkg.dzurllib.parsezurllib.responsezgareallylongpackageandmodulenametotestreprtruncation.areallylongpackageandmodulenametotestreprtruncationz3areallylongpackageandmodulenametotestreprtruncationzurllib.errorzurllib.robotparserztest.script_helperzsecretsz	selectorsz
statisticsztest.test_dbmzjavazstropzsqlite3.testzdistutils.emxccompilerz
os2emxpathztkinterz
runtktestsztkinter.testztkinter.test.supportzanalyze_dxpztest_unparsezimportlib.machineryztest_bug737473ztracemalloczmockz	typing.ioz	typing.rezunittest.testztest.test_httpserverszxml.parsers.expat.errorszxmlrpc.clientztest_zipped_doctestzzip_pkgztest.test_cmd_line_scriptz_testconsolezcommandszdummy_threadz_dummy_threadzhttplibzQueuezsetszhttp.clientzqueuezwinregz
simplejsonzsetszsitecustomizezusercustomizezapport_python_hookz_frozen_importlibzcomtypes.server.inprocserverz_tkinterz_scproxyzEasyDialogszSOCKSz
rourl2pathz_winapizwin32apizwin32conz_gestaltz	java.langzvms_libziczreadlineztermiosz_sysconfigdatazalzALzsunaudiodevzSUNAUDIODEVz	Audio_macznisztest.test_MimeWriterzdosz	win32pipezCarbonzCarbon.Fileszsgizctypes.macholib.dyldzbsddb3z_pybsddbz
_xmlrpclibznetbiosz	win32wnetzemail.Parserzelementree.cElementTreezelementree.ElementTreez_gbdmzresourcezcryptzbz2zdbmzmmapzMailmanzstatprofzemail.Generatorzemail.Utilszwincertstorezsetuptools_svnz
pyfribidi2zmacfsz_psutil_windowsz	unittest2z
IronPythonzclrzcompiler.constsznewzpkg_resources.externzordereddictzcomzwin32comzgdkz	six.movesA pure Python implementation of import.spec for {} missing loaderthe 'package' argument is required to perform a relative import for {!r}_bootstrap.pyCall the invalidate_caches() method on all meta path finders stored in
    sys.meta_path (where implemented).module {} not in sys.modules_bootstrap_external.py{}.__loader__ is Nonenamespace packages do not have loadersC:\msys64\mingw64\lib\python3.6\importlib\__init__.pyreload() argument must be a module<module importlib>Import a module.

    The 'package' argument is required when performing a relative import. It
    specifies the package to use as the anchor point from which to resolve the
    relative import to an absolute import.

    Use importlib.util.find_spec() instead._RELOADING{}.__loader__ is not setReturn the loader for the specified module.

    This is a backward-compatible wrapper around find_spec().

    This function is deprecated in favor of importlib.util.find_spec().

    parent {!r} not in sys.modulesFrozenImporter.get_codeBuiltinImporter.is_packageFrozenImporter.get_source_requires_frozen_wrapperexceptions.ModuleNotFoundError does not take keyword arguments_DummyModuleLock.acquireAcquire the import lock.Item in _ModuleLock({!r}) at {}Install importlib as the implementation of import.ModuleSpec.parent_ImportLockContext.__enter___requires_builtin.<locals>._requires_builtin_wrapperVerify arguments are "sane"._installed_safely.__exit__<module {!r} from {!r}>FrozenImporter.module_repr_imp_module_ModuleLockManagerFind the built-in module.

        If 'path' is ever specified then the search is considered a failure.

        This method is deprecated.  Use find_spec() instead.

        _ModuleLock.__repr___ImportLockContext.__exit__loaders that define exec_module() must also define create_module()Return None as built-in modules do not have code objects.attempted relative import with no known parent package_new_module_DummyModuleLock.__repr__level must be >= 0<module {!r} ({!r})><module {!r} (built-in)>The name of the module's parent.attempted relative import beyond top-level package_ModuleLock.release_ModuleLock.__init___find_and_load_unlockeddeadlock detected by %r.__all__<module {!r} (frozen)>ModuleSpec.cached_ModuleLock.acquire_ERR_MSG_PREFIXmodule {!r} not in sys.modules_calc___package___DummyModuleLock.__init___ModuleLockManager.__init__Core implementation of import.

This module is NOT meant to be directly imported! It has been designed such
that it can be bootstrapped into Python as the implementation of import. As
such it requires the injection of specific modules and attributes in order to
work. One should use importlib as the public-facing version of this module.

Setup importlib by importing needed built-in modules and injecting them
    into the global namespace.

    As sys is needed for sys.modules access and _imp is needed to load built-in
    modules, those two modules must be explicitly passed in.

    <module importlib._bootstrap>BuiltinImporter.find_module_ModuleLockManager.__enter___get_module_lock.<locals>.cbA simple _ModuleLock equivalent for Python builds without
    multi-threading support.<module {!r} ({})>{!r} is not a frozen moduleA recursive lock implementation which is able to detect deadlocks
    (e.g. thread 1 trying to take locks A then B, and thread 2 trying to
    take locks B then A).
    _NEEDS_LOADINGModuleSpec.__repr__Acquires then releases the module lock for a given module name.

    This is used to ensure a module is completely initialized, in the
    event it is being imported by another thread.
    Import and return the module based on its name, the package the call is
    being made from, and the level adjustment.

    This function represents the greatest common denominator of functionality
    between import_module and __import__. This includes setting __package__ if
    the loader did not.

    Create a module based on the provided spec._DeadlockError_ModuleLockManager.__exit___initializingFrozenImporter.find_module_load_backward_compatibleThe specification for a module, used for loading.

    A module's spec is the source for information about the module.  For
    data associated with the module, including source, use the spec's
    loader.

    `name` is the absolute name of the module.  `loader` is the loader
    to use when loading the module.  `parent` is the name of the
    package the module is in.  The parent is derived from the name.

    `is_package` determines if the module is considered a package or
    not.  On modules this is reflected by the `__path__` attribute.

    `origin` is the specific location used by the loader from which to
    load the module, if that information is available.  When filename is
    set, origin will match.

    `has_location` indicates that a spec's "origin" reflects a location.
    When this is True, `__file__` attribute of the module is set.

    `cached` is the location of the cached bytecode file, if any.  It
    corresponds to the `__cached__` attribute.

    `submodule_search_locations` is the sequence of path entries to
    search when importing submodules.  If set, is_package should be
    True--and False otherwise.

    Packages are simply modules that (may) have submodules.  If a spec
    has a non-None value in `submodule_search_locations`, the import
    system will consider modules loaded from the spec as packages.

    Only finders (see importlib.abc.MetaPathFinder and
    importlib.abc.PathEntryFinder) should modify ModuleSpec instances.

    cut_offDecorator to verify the named module is frozen.Import a module.

    The 'globals' argument is used to infer where the import is occurring from
    to handle relative imports. The 'locals' argument is ignored. The
    'fromlist' argument specifies what should exist as attributes on the module
    being imported (e.g. ``from module import <fromlist>``).  The 'level'
    argument represents the package location to import from in a relative
    import (e.g. ``from ..pkg import mod`` would have a 'level' of 2).

    Get or create the module lock for a given module name.

    Acquire/release internally the global import lock to protect
    _module_locks.Return a new module object, loaded by the spec's loader.

    The module is not added to its parent.

    If a module is already in sys.modules, that existing module gets
    clobbered.

    _ORIGIN__package__ not set to a string{!r} is not a built-in module_lock_unlock_module_requires_frozen.<locals>._requires_frozen_wrapperBuiltinImporter.get_sourcecreate_builtinDecorator to verify the named module is built-in.Create a built-in moduleRelease the import lock regardless of any raised exceptions.Find a module's spec.import {!r} # {!r}_installed_safely.__init__Calculate what __package__ should be.

    __package__ is not guaranteed to be defined or could be set to None
    to represent that its proper value is unknown.

    _installed_safely.__exit__.<locals>.<genexpr>BuiltinImporter.module_reprsubmodule_search_locations={}sys.meta_path is emptyFrozenImporter.is_packageReturn the repr to use for the module.module name must be str, not {}Figure out what __import__ should return.

    The import_ parameter is a callable which takes the name of module to
    import. It is required to decouple the function from assuming importlib's
    import implementation is desired.

    remove_importlib_frames in import.c will always remove sequences
    of importlib frames that end with a call to this function

    Use it instead of a normal call in places where including the importlib
    frames introduces unwanted noise into the traceback (e.g. when executing
    module code)
    Return None as built-in modules do not have source code._spec_from_module_sanity_checkorigin={!r}BuiltinImporter.create_modulesys.meta_path is None, Python is likely shutting downContext manager for the import lock.Empty module name_module_reprno built-in module named Return False as built-in modules are never packages.Execute the spec's specified module in an existing module's namespace.FrozenImporter.load_module
        Acquire the module lock.  If a potential deadlock is detected,
        a _DeadlockError is raised.
        Otherwise, the lock is always acquired and True is returned.
        Exec a built-in moduleFrozenImporter.find_specBuiltinImporter.find_spec; {!r} is not a packageBuiltinImporter.get_codeReturn a module spec based on various loader methods.BuiltinImporter.exec_module<module {!r}>FrozenImporter.exec_moduleFind a frozen module.

        This method is deprecated.  Use find_spec() instead.

        C:\msys64\mingw64\lib\python3.6\importlib\_bootstrap.py_ModuleLock.has_deadlock_DummyModuleLock.release_module_repr_from_specMeta path import for frozen modules.

    All methods are either class or static methods to avoid the need to
    instantiate the class.

    loader={!r}can't resolve package from __spec__ or __package__, falling back on __name__ and __path__exec_builtinModuleSpec.__init__wakeupNo module named Meta path import for built-in modules.

    All methods are either class or static methods to avoid the need to
    instantiate the class.

    FrozenImporter.create_module_installed_safely.__enter__Return None as frozen modules do not have source code.Find and load the module._DummyModuleLock({!r}) at {}_handle_fromlistLoad the specified module into sys.modules and return it.

    This method is deprecated.  Use loader.exec_module instead.

    _find_spec_legacyReturn True if the frozen module is a package.Return the code object for the frozen module.Simple substitute for functools.update_wrapper.ModuleSpec.__eq____package__ != __spec__.parent (_init_module_attrs``from list''_blocking_onLoad a frozen module.

        This method is deprecated.  Use exec_module() instead.

        import of {} halted; None in sys.modulesPrint the message to stderr if -v/PYTHONVERBOSE is turned on.ModuleSpec.has_locationLoader which handles sourceless file imports.bytes_data_path_finderNon-code object in {!r}WindowsRegistryFinder.find_module_search_registryReturn None as an extension module cannot create a code object.Cache the module name and the path to the file found by the
        finder.SourceFileLoader._cache_bytecodeGiven the path to a .pyc. file, return the path to its .py file.

    The .pyc file does not need to exist; this simply returns the path to
    the .py file calculated to correspond to the .pyc file.  If path does
    not conform to PEP 3147/488 format, ValueError will be raised. If
    sys.implementation.cache_tag is None then NotImplementedError is raised.

    FileFinder._get_specCompile bytecode as returned by _validate_bytecode_header().WindowsRegistryFinder._open_registryExtensionFileLoader.get_codecpathnameloader_detailspath_hook_for_FileFinderextension_suffixesLoad a module from a file.

        This method is deprecated.  Use exec_module() instead.

        find the module on sys.path or 'path' based on sys.path_hooks and
        sys.path_importer_cache.

        This method is deprecated.  Use find_spec() instead.

        Stat the path.

    Made a separate function to make it easier to override in experiments
    (e.g. cache stat results).

    Convert a 32-bit integer to little-endian.ExtensionFileLoader.is_packageInitialize an extension moduleConcrete implementation of InspectLoader.get_source.parent_module_namepath_attr_namesource_mtimebytecode_pathRepresents a namespace package's path.  It uses the module name
    to find its parent module, and from there it looks up the parent's
    __path__.  When this changes, the module's own path is recomputed,
    using path_finder.  For top-level modules, the parent module's path
    is sys.path._NamespacePath._get_parent_pathPathFinder._get_specConcrete implementation of SourceLoader using the file system.winreg_moduleextension module {!r} executed from {!r}FileLoader.get_filenamePathFinder._path_hooksREGISTRY_KEYnamespace_pathExtensionFileLoader.create_moduleSourcelessFileLoader.get_sourceOptional method which writes data (bytes) to a file path (a str).

        Implementing this method allows for the writing of bytecode files.

        The source path is needed in order to correctly transfer permissions
        Invalidate the directory mtime.dot_countopt_levelPathFinder._legacy_get_specoptimization level {!r} is not an alphanumeric value_fix_up_modulePathFinder.find_spec_NamespacePath._find_parent_path_names_compile_bytecode_check_nameBase file loader class which implements the loader protocol methods that
    require file system usage.bytecode is stale for {!r}source not available through get_data()supported_loaderspossible namespace for {}SourcelessFileLoader.get_code_make_relax_case.<locals>._relax_case_LoaderBasics.is_packageCompile a code object into bytecode for writing out to a byte-compiled
    file.WindowsRegistryFinder.find_specMeta path finder for sys.path and package __path__ attributes.FileFinder.path_hook.<locals>.path_hook_for_FileFindersource_bytes_readlinenewline_decoder_CASE_INSENSITIVE_PLATFORMS_BYTES_KEYExtensionFileLoader.__hash__lower_suffix_contentsCore implementation of path-based import.

This module is NOT meant to be directly imported! It has been designed such
that it can be bootstrapped into Python as the implementation of import. As
such it requires the injection of specific modules and attributes in order to
work. One should use importlib as the public-facing version of this module.

loader for %s cannot handle %sFileFinder.find_loadernew_namepath_tmpConvert 4 bytes in little-endian to an integer._NamespacePath.__repr__extension module {!r} loaded from {!r}cache_moduleFileFinder({!r})PathFinder.find_moduleTry to find a loader for the specified module by delegating to
    self.find_loader().

    This method is deprecated in favor of finder.find_spec().

    registry_keyhkeyinit_filenameExecute the module.created {!r}_RAW_MAGIC_NUMBER_NamespacePath.append_NamespacePath.__iter___path_joincode object from {}PathFinder.invalidate_cachesloader_classWindowsRegistryFinder._search_registry_recalculate_NamespacePath._recalculate_NamespaceLoader.exec_module_setup.<locals>.<genexpr>FileLoader.get_dataFileFinder.__init__.<locals>.<genexpr>Base class of common code needed by both SourceLoader and
    SourcelessFileLoader.Decode bytes representing source code and return the string.

    Universal newline support is used in the decoding.
    os_detailsnamespace module loaded with path {!r}Decorator to verify that the module being requested matches the one the
    loader can handle.

    The first argument (self) must define _name which the second argument is
    compared against. If the comparison fails then ImportError is raised.

    _check_name.<locals>._check_name_wrapperFind the loader or namespace_path for this module/package name.only directories are supportedReturn True if the extension module is a package.Validate the header of the passed-in bytecode against source_stats (if
    given) and returning the bytecode that can be compiled by compile().

    All other arguments are used to enhance error reporting.

    ImportError is raised when the magic number is incorrect or the bytecode is
    found to be stale. EOFError is raised when the data is found to be
    truncated.

    ExtensionFileLoader.exec_modulereached EOF while reading timestamp in {!r}_check_name.<locals>._wrap_bootstrap_modulebuiltin_ospath_separatorsos_module_CASE_INSENSITIVE_PLATFORMS_STR_KEYExtensionFileLoader.__eq__Concrete implementation of InspectLoader.is_package by checking if
        the path returned by get_filename has a filename of '__init__.py'.could not create {!r}: {!r}opt-_NamespaceLoader.module_reprReplacement for os.path.join().{} matches {}Setup the path-based importers for importlib by importing needed
    built-in modules and injecting them into the global namespace.

    Other components are extracted from the core bootstrap module.

    source_size_NamespaceLoader.get_codeCall the invalidate_caches() method on all path entry finders
        stored in sys.path_importer_caches (where implemented).{!r} is not alphanumericSourceFileLoader.set_datacache_path_NamespacePath.__contains___fill_cacheExtensionFileLoader.__init__<bytecode>PathFinder._path_importer_cache_NamespaceLoader.get_sourceFileFinder._fill_cachebad magic number in {!r}: {!r}This module is deprecated.Try to find a spec for 'fullname' on sys.path or 'path'.

        The search is based on sys.path_hooks and sys.path_importer_cache.
        _path_splitdebug_override or optimization must be set to NoneFileFinder.invalidate_caches_NamespaceLoader.__init__trying {}filename_baseFileFinder.__repr__Find module named in the registry.

        This method is deprecated.  Use exec_module() instead.

        <module {!r} (namespace)>_path_cacheexpected only 2 or 3 dots in {!r}Fill the cache of potential modules and packages for this directory._path_isfile_get_supported_file_loadersTrue if filenames must be checked case-insensitively._LoaderBasics.exec_moduleReturns a list of file-based module loaders.

    Each item is a tuple (loader, suffixes).
    stat_infoNot importing directory {}: missing __init__raw_sizeTry to find a loader for the specified module, or the namespace
        package portions. Returns (loader, list-of-portions).

        This method is deprecated.  Use find_spec() instead.

        _path_isdirPYTHONCASEOKReturns a tuple of (parent-module-name, parent-path-attr-name)Given the path to a .py file, return the path to its .pyc file.

    The .py file does not need to exist; this simply returns the path to the
    .pyc file calculated as if the .py file were imported.

    The 'optimization' parameter controls the presumed optimization level of
    the bytecode file. If 'optimization' is not None, the string representation
    of the argument is taken and verified to be alphanumeric (else ValueError
    is raised).

    The debug_override parameter is deprecated. If debug_override is not None,
    a True value is the same as setting 'optimization' to the empty string
    while a False value is equivalent to setting 'optimization' to '1'.

    If sys.implementation.cache_tag is None then NotImplementedError is raised.

    {} not bottom-level directory in {!r}SourceFileLoader.path_statsInstall the path-based import components.reached EOF while reading size of source in {!r}_LoaderBasics.load_moduleLoader for extension modules.

    The constructor is designed to work with FileFinder.

    <module importlib._bootstrap_external>{}.{}{}spec missing loaderSearch sys.path_hooks for a finder for 'path'.Replacement for os.path.isfile.C:\msys64\mingw64\lib\python3.6\importlib\_bootstrap_external.py_NamespacePath.__init__int_bytesReturn None as there is no source code._NamespacePath({!r})Try to find a spec for the specified module.

        Returns the matching spec, or None if not found.
        tail_moduleCreate an unitialized extension moduleOptional method that returns the modification time (an int) for the
        specified path, where path is a str.

        Raises IOError when the path cannot be handled.
        Convert a bytecode file path to a source path (if possible).

    This function exists purely for backwards-compatibility for
    PyImport_ExecCodeModuleWithFilenames() in the C API.

    cannot load module {!r} when get_code() returns NoneOptional method which writes data (bytes) to a file path (a str).

        Implementing this method allows for the writing of bytecode files.
        SourceLoader.get_codeSourceLoader.get_sourceFile-based finder.

    Interactions with the file system are cached for performance, being
    refreshed when the directory the finder is handling has been modified.

    DEBUG_BUILDSourceLoader._cache_bytecode_get_sourcefileCalculate the mode permissions for a bytecode file.Software\Python\PythonCore\{sys_version}\Modules\{fullname}\DebugReturn the data from path as raw bytes.base_pathFileLoader.load_modulealmost_filename_LoaderBasics.create_moduleLoad a namespace module.

        This method is deprecated.  Use exec_module() instead.

        ExtensionFileLoader.get_source_NamespaceLoader.load_moduleConcrete implementation of InspectLoader.get_code.

        Reading of bytecode requires path_stats to be implemented. To write
        bytecode, set_data must also be implemented.

        Return the metadata for the path.Return the code object compiled from source.

        The 'data' argument can be any object type that compile() supports.
        Optional method returning a metadata dict for the specified path
        to by the path (str).
        Possible keys:
        - 'mtime' (mandatory) is the numeric timestamp of last source
          code modification;
        - 'size' (optional) is the size in bytes of the source code.

        Implementing this method allows the loader to read bytecode files.
        Raises IOError when the path cannot be handled.
        _path_mtimeExtensionFileLoader.is_package.<locals>.<genexpr>_PYCACHEsys.path_hooks is emptyoptimization portion of filename does not start with {!r}raw_timestampexec_dynamicTest whether the path is the specified mode type._NamespaceLoader.is_package_NamespacePath.__setitem__tail_nameExtensionFileLoader.get_filenameMeta path finder for modules declared in the Windows registry._relaxed_path_cachecode object from {!r}REGISTRY_KEY_DEBUGInitialize with the path to search on and a variable number of
        2-tuples containing the loader and the file suffixes the loader
        recognizes._path_statGet the finder for the path entry from sys.path_importer_cache.

        If the path entry is not in the cache, find the appropriate finder
        and cache it. If no finder is available, store None.

        wrote {!r}Return the path to the source file as found by the finder.Replacement for os.path.split()._NamespaceLoader.create_moduleReplacement for os.path.isdir.the debug_override parameter is deprecated; use 'optimization' instead_POPULATEBest-effort function to write data to a path atomically.
    Be prepared to handle a FileExistsError if concurrent writing of the
    temporary file is attempted.Path hook for importlib.machinery.FileFinder.A class method which returns a closure to use on sys.path_hook
        which will return an instance using the specified loaders and the path
        called on the closure.

        If the path called on the closure is not a directory, ImportError is
        raised.

        importlib requires posix or ntReturn None as extension modules have no source code._path_is_mode_type_last_parent_pathReturn a module spec based on a file location.

    To indicate that the module is a package, set
    submodule_search_locations to a list of directory paths.  An
    empty list is sufficient, though its not otherwise useful to the
    import system.

    The loader must take a spec as its only __init__() arg.

    SourceLoader.source_to_code_NamespacePath.__len__FileFinder.find_specWrite bytes data to a file.An optional method for clearing the finder's cache, if any.
        This method is used by PathFinder.invalidate_caches().
        Abstract base class for path entry finders used by PathFinder.Return (loader, namespace portion) for the path entry.

        The fullname is a str.  The namespace portion is a sequence of
        path entries contributing to part of a namespace package. The
        sequence may be empty.  If loader is not None, the portion will
        be ignored.

        The portion will be discarded if another path entry finder
        locates the module as a normal module or package.

        This method is deprecated in favor of finder.find_spec(). If find_spec()
        is provided than backwards-compatible functionality is provided.

        PathEntryFinder.find_loaderExecutionLoader.get_filenameAn abstract method that should find a module.
        The fullname is a str and the optional path is a str or None.
        Returns a Loader object or None.
        Legacy abstract base class for import finders.

    It may be subclassed for compatibility with legacy third party
    reimplementations of the import system.  Otherwise, finder
    implementations should derive from the more specific MetaPathFinder
    or PathEntryFinder ABCs.
    <module importlib.abc>Abstract method which when implemented should return the bytes for
        the specified path.  The path must be a str.MetaPathFinder.invalidate_cachesResourceLoader.get_dataWrite the bytes to the path (if possible).

        Accepts a str path and data as bytes.

        Any needed intermediary directories are to be created. If for some
        reason the file cannot be written because of permissions, fail
        silently.
        Return a module to initialize and into which to load.

        This method should raise ImportError if anything prevents it
        from creating a new module.  It may return None to indicate
        that the spec should create the new module.
        An optional method for clearing the finder's cache, if any.
        This method is used by importlib.invalidate_caches().
        Abstract base class for import loaders.InspectLoader.source_to_codeExecutionLoader.get_codeMetaPathFinder.find_moduleAbstract base class for loading source code (and optionally any
    corresponding bytecode).

    To support loading from source code, the abstractmethods inherited from
    ResourceLoader and ExecutionLoader need to be implemented. To also support
    loading from bytecode, the optional methods specified directly by this ABC
    is required.

    Inherited abstractmethods not implemented in this ABC:

        * ResourceLoader.get_data
        * ExecutionLoader.get_filename

    PathEntryFinder.invalidate_cachesAbstract base classes related to import.Abstract base class partially implementing the ResourceLoader and
    ExecutionLoader ABCs.Return the (int) modification time for the path (str).frozen_clsAbstract base class for import finders on sys.meta_path.Abstract base class for loaders which support inspection about the
    modules they can load.

    This ABC represents one of the optional protocols specified by PEP 302.

    Abstract method which should return the source code for the
        module.  The fullname is a str.  Returns a str.

        Raises ImportError if the module cannot be found.
        abstract_clsReturn a loader for the module.

        If no module is found, return None.  The fullname is a str and
        the path is a list of strings or None.

        This method is deprecated in favor of finder.find_spec(). If find_spec()
        exists then backwards-compatible functionality is provided for this
        method.

        Return the loaded module.

        The module must be added to sys.modules and have import-related
        attributes set properly.  The fullname is a str.

        ImportError is raised on failure.

        This method is deprecated in favor of loader.exec_module(). If
        exec_module() exists then it is used to provide a backwards-compatible
        functionality for this method.

        Method to return the code object for fullname.

        Should return None if not applicable (e.g. built-in module).
        Raise ImportError if the module cannot be found.
        Abstract base class for loaders that wish to support the execution of
    modules as scripts.

    This ABC represents one of the optional protocols specified in PEP 302.

    C:\msys64\mingw64\lib\python3.6\importlib\abc.pyCompile 'data' into a code object.

        The 'data' argument can be anything that compile() can handle. The'path'
        argument should be where the data was retrieved (when applicable).Abstract base class for loaders which can return data from their
    back-end storage.

    This ABC represents one of the optional protocols specified by PEP 302.

    Abstract method which should return the value that __file__ is to be
        set to.

        Raises ImportError if the module cannot be found.
        Optional method which when implemented should return whether the
        module is a package.  The fullname is a str.  Returns a bool.

        Raises ImportError if the module cannot be found.
        Return a metadata dict for the source pointed to by the path (str).
        Possible keys:
        - 'mtime' (mandatory) is the numeric timestamp of last source
          code modification;
        - 'size' (optional) is the size in bytes of the source code.
        Method which returns the code object for the module.

        The fullname is a str.  Returns a types.CodeType if possible, else
        returns None if a code object does not make sense
        (e.g. built-in module). Raises ImportError if the module cannot be
        found.
        Return a module's repr.

        Used by the module type when the method does not raise
        NotImplementedError.

        This method is deprecated.

        Returns a list of all recognized module suffixes for this process<module importlib.machinery>The machinery of importlib: finders, loaders, hooks, etc.C:\msys64\mingw64\lib\python3.6\importlib\machinery.pyLazyLoader.create_module{}.__spec__ is Noneset_packagemodule object for Trigger the load and then perform the deletion.Make the module load lazily.LazyLoader.factory_LazyModule.__delattr__set_loader substituted in sys.modules during a lazy loadConstruct a callable which returns the eager loader made lazy.loader must define exec_module()__check_eager_loaderLazyLoader.__check_eager_loaderset_package_wrapperA loader that creates a module which defers loading until attribute access._module_to_loadTrigger the load of the module and return the attribute.LazyLoader.__init__resolve_nameset_package.<locals>.set_package_wrapperattrs_updatedA subclass of the module type which triggers loading upon attribute access.Set __loader__ on the returned module.

    This function is deprecated.

    Return the spec for the specified module.

    First, sys.modules is checked to see if the module was already imported. If
    so, then sys.modules[name].__spec__ is returned. If that happens to be
    set to None, then ValueError is raised. If the module is not in
    sys.modules, then sys.meta_path is searched for a suitable spec with the
    value of 'path' given to the finders. None is returned if no spec could
    be found.

    Dotted names do not have their parent packages implicitly imported. You will
    most likely need to explicitly import all parent packages in the proper
    order for a submodule to get the correct spec.

    module_for_loaderThe import system now takes care of this automatically.module_for_loader_wrapper{}.__spec__ is not setoriginal_type_LazyLoader__check_eager_loaderReturn the spec for the specified module.

    First, sys.modules is checked to see if the module was already imported. If
    so, then sys.modules[name].__spec__ is returned. If that happens to be
    set to None, then ValueError is raised. If the module is not in
    sys.modules, then sys.meta_path is searched for a suitable spec with the
    value of 'path' given to the finders. None is returned if no spec could
    be found.

    If the name is for submodule (contains a dot), the parent module is
    automatically imported.

    The name and package arguments work the same as importlib.import_module().
    In other words, relative module names (with leading dots) work.

    Utility code for constructing importers, etc._LazyModule.__getattribute__ (required for relative module names)Decorator to handle selecting the proper module for loaders.

    The decorated function is passed the module to use instead of the module
    name. The module passed in to the function is either from sys.modules if
    it already exists or is a new module. If the module is new, then __name__
    is set the first argument to the method, __loader__ is set to self, and
    __package__ is set accordingly (if self.is_package() is defined) will be set
    before it is passed to the decorated function (if self.is_package() does
    not work for the module it will be set post-load).

    If an exception is raised and the decorator created the module it is
    subsequently removed from sys.modules.

    The decorator assumes that the decorated function takes the module name as
    the second argument.

    set_loader_wrapperLazyLoader.factory.<locals>.<lambda>module_for_loader.<locals>.module_for_loader_wrapper_find_spec_from_pathattrs_nowset_loader.<locals>.set_loader_wrapperno package specified for <module importlib.util>C:\msys64\mingw64\lib\python3.6\importlib\util.pyattrs_thenSet __package__ on the returned module.

    This function is deprecated.

    LazyLoader.exec_module_static_getmro_POSITIONAL_ONLY_is_typeSignature.__repr___MethodWrapperskip_bound_argReturn true if the object is a code object.

    Code objects provide these attributes:
        co_argcount         number of arguments (not including *, ** args
                            or keyword only arguments)
        co_code             string of raw compiled bytecode
        co_cellvars         tuple of names of cell variables
        co_consts           tuple of constants used in the bytecode
        co_filename         name of file in which this code object was created
        co_firstlineno      number of first line in Python source code
        co_flags            bitmap: 1=optimized | 2=newlocals | 4=*arg | 8=**arg
                            | 16=nested | 32=generator | 64=nofree | 128=coroutine
                            | 256=iterable_coroutine | 512=async_generator
        co_freevars         tuple of names of free variables
        co_kwonlyargcount   number of keyword only arguments (not including ** arg)
        co_lnotab           encoded mapping of line numbers to bytecode indices
        co_name             name with which this code object was defined
        co_names            tuple of names of local variables
        co_nlocals          number of local variables
        co_stacksize        virtual machine stack space required
        co_varnames         tuple of names of arguments and local variablesParameter.nameDisplay info about the module rather than its source codeisasyncgenfunctiongetrecursionlimitlast_positional_onlygetgeneratorstatereturn_annotationVAR_POSITIONALGEN_CREATEDformatannotationrelativetoname kind defining_class objectnew_paramimplicit{}framelistframeinfo©ÚclsÚfuncÚis_duck_functionÚ	ParameterÚ	func_codeÚ	pos_countÚ	arg_namesÚ
positionalÚkeyword_only_countÚkeyword_onlyÚannotationsÚdefaultsÚ
kwdefaultsÚpos_default_countÚ
parametersÚnon_default_countÚnameÚ
annotationÚoffsetÚdefaultÚindexConstructs Signature from the given list of Parameter
        objects and 'return_annotation'.  All arguments are optional.
        parameters_exBlockFinder.__init__klass_result_filesbymodnamefrom %d to %dExtract the block of code at the top of the given list of lines._signature_bound_methodGet the line number from a frame object, allowing for optimization.Signature.from_builtin<module inspect>getinnerframes_NonUserDefinedCallablesParameter.__reduce__mainobject_findclass_ParameterKindtext_sig©ÚargsÚvarargsÚvarkwÚdefaultsÚ
kwonlyargsÚkwonlydefaultsÚannotationsÚ	formatargÚformatvarargsÚformatvarkwÚformatvalueÚformatreturnsÚformatannotationÚformatargandannotationÚspecsÚfirstdefaultÚiÚargÚspecÚ	kwonlyargÚresultnew_argumentsGet a signature object for the passed callable.Return true if the object is a module.

    Module objects provide these attributes:
        __cached__      pathname to byte compiled file
        __doc__         documentation string
        __file__        filename (missing for built-in modules)Return the indent size, in spaces, at the start of a line of text.formatargspec.<locals>.formatargandannotationLoader: {}indentsize_too_manyfollow_wrappedgetmembers.<locals>.<lambda>Return the module name for a given file, or None.getgeneratorlocalsRecursive helper function for getclasstree().Result of `Signature.bind` call.  Holds the mapping of arguments
    to the function's parameters.

    Has the following public attributes:

    * arguments : OrderedDict
        An ordered mutable mapping of parameters' names to arguments' values.
        Does not contain arguments' default values.
    * signature : Signature
        The Signature object that created this instance.
    * args : tuple
        Tuple of positional arguments values.
    * kwargs : dict
        Dict of keyword arguments values.
    Signature.from_callableArgInfowrap_value{!r} is not a Python functionname is a required attribute for Parametergetlinenoinspect.Signature.from_builtin() is deprecated, use Signature.from_callable()partial_keywords_signature_fromstr.<locals>.pgetcallargsFormat an argument spec from the 4 values returned by getargvalues.

    The first four arguments are (args, varargs, varkw, locals).  The
    next four arguments are the corresponding optional formatting functions
    that are called to turn names and values into strings.  The ninth
    argument is an optional function to format the sequence of arguments.follow_wrapper_chainssigclswrapped_sigfirst_wrapped_paramsig_paramsAnnotations are not currently supportedReturn true if object can be passed to an ``await`` expression.args varargs keywords localsCreates a customized copy of the Parameter.at least %drecursion_limittoo many positional argumentsbuiltinobjectCORO_CLOSED Logic for inspecting an object given at command line getclosurevars--details: passsrowcolerowcolCreates a customized copy of the Signature.
        Pass 'parameters' and/or 'return_annotation' arguments
        to override them in the new copy.
        _missing_argumentsArgSpecargs varargs keywords defaultsReturn true if the object is a traceback.

    Traceback objects provide these attributes:
        tb_frame        frame object at this level
        tb_lasti        index of last attempted instruction in bytecode
        tb_lineno       current line number in Python source code
        tb_next         next inner traceback object (called by this level)Get a BoundArguments object, that maps the passed `args`
        and `kwargs` to the function's signature.  Raises `TypeError`
        if the passed arguments can not be bound.
        kwargs_startedparam_nameOrigin: {}token_streamkind_defaultsformatargvaluesWork out which source or compiled file an object was defined in.{!r} is not a module, class, method, function, traceback, frame, or code objectmultiple values for argument {arg!r}bind_partialinstance_resultdict_attrGet the names and default values of a function's parameters.

    A tuple of four things is returned: (args, varargs, keywords, defaults).
    'args' is a list of the argument names, including keyword-only argument names.
    'varargs' and 'keywords' are the names of the * and ** parameters or None.
    'defaults' is an n-tuple of the default values of the last n parameters.

    This function is deprecated, as it does not support annotations or
    keyword-only parameters and will raise ValueError if either is present
    on the supplied callable.

    For a more structured introspection API, use inspect.signature() instead.

    Alternatively, use getfullargspec() for an API with a similar namedtuple
    based interface, but full support for annotations and keyword-only
    parameters.
    Can't get info for builtin modules.duplicate parameter name: {!r}builtin_nsisgeneratorBoundArguments.__init__C:\msys64\mingw64\lib\python3.6\inspect.py%s() takes %s positional argument%s but %d%s %s givenReturn true if the object is a coroutine.Return true if the object is an abstract base class (ABC).Signature.__str___signature_get_partialReturn true if the object is a method descriptor.

    But not if ismethod() or isclass() or isfunction() are true.

    This is new in Python 2.2, and, for example, is true of int.__add__.
    An object passing this test has a __get__ attribute but not a __set__
    attribute, but beyond that the set of attributes varies.  __name__ is
    usually sensible, and __doc__ often is.

    Methods implemented via descriptors that also pass one of the other
    tests return false from the ismethoddescriptor() test, simply because
    the other tests promise more -- you can, e.g., count on having the
    __func__ attribute (etc) when an object passes ismethod()._parameter_clsdelayed_commaclean_signaturemodulesbyfile^(\s*def\s)|(\s*async\s+def\s)|(.*(?<!\w)lambda(:|\s))|^(\s*@)Marker object for Signature.empty and Parameter.empty.self_parameterskip_next_commacurrent_parameterunbound_namesGet information about arguments passed into a particular frame.

    A tuple of four things is returned: (args, varargs, varkw, locals).
    'args' is a list of the argument names.
    'varargs' and 'varkw' are the names of the * and ** arguments or None.
    'locals' is the locals dictionary of the given frame.tokeneaterBoundArguments.__getstate__could not get source codekwo_paramsFailed to import {} ({}: {})_formatannotationrender_kw_only_separatorneglenwrapper loop when unwrapping {!r}__kwdefaults__builtin_varsReturn true if the object is a getset descriptor.

        getset descriptors are specialized descriptors defined in extension
        modules.Return the module an object was defined in, or None if not found., {} and {}default_nodearg_vals©Úfunc_and_positionalÚnamedÚfuncÚ
positionalÚspecÚargsÚvarargsÚvarkwÚdefaultsÚ
kwonlyargsÚkwonlydefaultsÚannÚf_nameÚ	arg2valueÚnum_posÚnum_argsÚnum_defaultsÚnÚiÚpossible_kwargsÚkwÚvalueÚreqÚargÚmissingÚkwarg_signature_strip_non_python_syntaxSignature.replacedefcountReturn true if the object is an asynchronous generator function.

    Asynchronous generator functions are defined with "async def"
    syntax and have "yield" expressions in their body.
    Private helper to test if `obj` is a callable that might
    support Argument Clinic's __text_signature__ protocol.
    Private helper to test if `obj` is a duck type of FunctionType.
    A good example of such objects are functions compiled with
    Cython, which have all attributes that a pure Python function
    would have, but have their code statically compiled.
    Constructs Signature for the given builtin function.getcoroutinelocals__signature__{arg!r} parameter is positional only, but was passed as a keywordSignature.__reduce__Return the text of the source code for an object.

    The argument may be a module, class, method, function, traceback, frame,
    or code object.  The source code is returned as a single string.  An
    OSError is raised if the source code cannot be retrieved.kwargs_param{!r} is not a code objectBoundArguments.__eq__Get a list of records for a traceback's frame and all lower frames.

    Each record contains a frame object, filename, line number, function
    name, a list of lines of context, and index within the context.unwrap.<locals>._is_wrapperpartial_argsA private marker - used in Parameter & Signature.Signature._hash_basis{!r} is not a frame or traceback objectwalktreenkwargsGEN_RUNNINGCORO_RUNNINGReturn the entire source file and starting line number for an object.

    The argument may be a module, class, method, function, traceback, frame,
    or code object.  The source code is returned as a list of all the lines
    in the file and the line number indexes a line in that list.  An OSError
    is raised if the source code cannot be retrieved.{!r} is not a callable objectFormat an argument spec from the values returned by getfullargspec.

    The first seven arguments are (args, varargs, varkw, defaults,
    kwonlyargs, kwonlydefaults, annotations).  The other five arguments
    are the corresponding optional formatting functions that are called to
    turn names and values into strings.  The last argument is an optional
    function to format the sequence of arguments.getcoroutinestateall_bytecode_suffixeshas_attrsSignature._bindPrivate helper function to get signature for arbitrary
    callable objects.
    Yury Selivanov <yselivanov@sprymix.com>isawaitable
    Get the mapping of free variables to their current values.

    Returns a named tuple of dicts mapping the current nonlocal, global
    and builtin references as seen by the body of the function. A final
    set of unbound names that could not be resolved is also provided.
    _signature_fromstr.<locals>.wrap_valueParameter.__eq__Return true if the object is a class.

    Class objects provide these attributes:
        __doc__         documentation string
        __module__      name of module in which this class was defined_finddocConstructs Signature for the given python function.base_moduleinvalid value for 'Parameter.kind' attribute_signature_get_bound_param©ÚclsÚmroÚmetamroÚclass_basesÚ	all_basesÚnamesÚbaseÚkÚvÚresultÚ	processedÚnameÚhomeclsÚget_objÚdict_objÚexcÚlast_clsÚsrch_clsÚsrch_objÚobjÚkindSubmodule search path: {}BlockFinder.tokeneaterFunction has keyword-only parameters or annotations, use getfullargspec() API which can support them%s() got multiple values for argument %rParameter.__repr__missing a required argument: {arg!r}Parameter.replaceGet information about the arguments accepted by a code object.

    Three things are returned: (args, varargs, varkw), where
    'args' is the list of argument names. Keyword-only arguments are
    appended. 'varargs' and 'varkw' are the names of the * and **
    arguments or None.id_funcReturn true if the object is a frame object.

    Frame objects provide these attributes:
        f_back          next outer frame object (this frame's caller)
        f_builtins      built-in namespace seen by this frame
        f_code          code object being executed in this frame
        f_globals       global namespace seen by this frame
        f_lasti         index of last attempted instruction in bytecode
        f_lineno        current line number in Python source code
        f_locals        local namespace seen by this frame
        f_trace         tracing function for this frame, or NonePOSITIONAL_OR_KEYWORD__defaults__inspect.Signature.from_function() is deprecated, use Signature.from_callable()_check_class{!r} is not a valid parameter nameGet a BoundArguments object, that partially maps the
        passed `args` and `kwargs` to the function's signature.
        Raises `TypeError` if the passed arguments can not be bound.
        KEYWORD_ONLYSignature.__hash__filename lineno function code_context indexParameter.annotationGet the mapping of arguments to values.

    A dict is returned, with keys the function argument names (including the
    names of the * and ** arguments, if any), and values the respective bound
    values from 'positional' and 'named'._signature_is_builtinThe object to be analysed. It supports the 'module:qualname' syntaxgetouterframes_bound_arguments_clsmodule_dictsys_module_dictBoundArguments.__repr__©ÚclsÚobjÚsÚskip_bound_argÚ	ParameterÚclean_signatureÚself_parameterÚlast_positional_onlyÚprogramÚmoduleÚfÚ
parametersÚemptyÚinvalidÚmodule_dictÚmodule_nameÚsys_module_dictÚ
parse_nameÚ
wrap_valueÚRewriteSymbolicsÚpÚargsÚdefaultsÚiterÚkindÚiÚnameÚdefaultÚ_selfÚself_isboundÚself_ismodulecposGet the names and default values of a callable object's parameters.

    A tuple of seven things is returned:
    (args, varargs, varkw, defaults, kwonlyargs, kwonlydefaults, annotations).
    'args' is a list of the parameter names.
    'varargs' and 'varkw' are the names of the * and ** parameters or None.
    'defaults' is an n-tuple of the default values of the last n parameters.
    'kwonlyargs' is a list of keyword-only parameter names.
    'kwonlydefaults' is a dictionary mapping names from kwonlyargs to defaults.
    'annotations' is a dictionary mapping parameter names to annotations.

    Notable differences from inspect.signature():
      - the "self" parameter is always reported, even for bound methods
      - wrapper chains defined by __wrapped__ *not* unwrapped automatically
    invalid argument typename_nodeGEN_CLOSED__dict__ is special, don't want the proxypassline__closure__got an unexpected keyword argument {arg!r}render_pos_only_separatorargnamesReturn all members of an object as (name, value) pairs sorted by name.
    Optionally, only return members that satisfy a given predicate.Return the frame of the caller or None if this is not possible.($iscoroutinefunctiongetattr_staticProvide a tokeneater() method to detect the end of a code block.getsourcefile.<locals>.<genexpr>Private helper function to get signature for
    builtin callables.
    _VAR_POSITIONALReturn true if the object is a generator.

    Generator objects provide these attributes:
        __iter__        defined to support iteration over container
        close           raises a new GeneratorExit exception inside the
                        generator to terminate the iteration
        gi_code         code object
        gi_frame        frame object or possibly None once the generator has
                        been exhausted
        gi_running      set to 1 when generator is executing, 0 otherwise
        next            return the next item from the container
        send            resumes the generator and "sends" a value that becomes
                        the result of the current yield-expression
        throw           used to raise an exception inside the generatorArrange the given list of classes into a hierarchy of nested lists.

    Where a nested list appears, it contains classes derived from the class
    whose entry immediately precedes the list.  Each entry is a 2-tuple
    containing a class and a tuple of its base classes.  If the 'unique'
    argument is true, exactly one entry appears in the returned structure
    for each class in the given list.  Otherwise, classes using multiple
    inheritance and their descendants will appear multiple times.indecoratorPrivate helper to calculate how 'wrapped_sig' signature will
    look like after applying a 'functools.partial' object (or alike)
    on it.
    Get information about the arguments accepted by a code object.

    Four things are returned: (args, varargs, kwonlyargs, varkw), where
    'args' and 'kwonlyargs' are lists of argument names, and 'varargs'
    and 'varkw' are the names of the * and ** arguments or None.%s() got an unexpected keyword argument %r_signature_fromstr.<locals>.parse_nameislambda<{} ({})>non-default argument follows default argumentold_paramstransform_to_kwonlykwonly_sigTarget: {}GEN_SUSPENDEDno signature found for {!r}getframeinfoReturn an absolute path to the source or compiled file for an object.

    The idea is for each object to have a unique origin, so this routine
    normalizes the result as much as possible.Return true if the object is any kind of function or method.Represents a parameter in a function signature.

    Has the following public attributes:

    * name : str
        The name of the parameter as a string.
    * default : object
        The default value for the parameter if specified.  If the
        parameter has no default value, this attribute is set to
        `Parameter.empty`.
    * annotation
        The annotation for the parameter if specified.  If the
        parameter has no annotation, this attribute is set to
        `Parameter.empty`.
    * kind : str
        Describes how argument values are bound to the parameter.
        Possible values: `Parameter.POSITIONAL_ONLY`,
        `Parameter.POSITIONAL_OR_KEYWORD`, `Parameter.VAR_POSITIONAL`,
        `Parameter.KEYWORD_ONLY`, `Parameter.VAR_KEYWORD`.
    apply_defaultsReturn true if the object is a user-defined generator function.

    Generator function objects provide the same attributes as functions.
    See help(isfunction) for a list of attributes.Retrieve attributes without triggering dynamic lookup via the
       descriptor protocol,  __getattr__ or __getattribute__.

       Note: this function may not be able to retrieve all attributes
       that getattr can fetch (like dynamically created attributes)
       and may find attributes that getattr can't (like descriptors
       that raise AttributeError). It can also return descriptor objects
       instead of instance members in some cases. See the
       documentation for details.
    Return true if the object is an instance method.

    Instance method objects provide these attributes:
        __doc__         documentation string
        __name__        name with which this method was defined
        __func__        function object containing implementation of method
        __self__        instance to which this method is bound{!r} is a built-in moduleSignature.__eq__unsupported callableReturn true if the object is a coroutine function.

    Coroutine functions are defined with "async def" syntax.
    {!r} builtin has invalid signatureatleastkwonly_given_WrapperDescriptor_signature_fromstr.<locals>.RewriteSymbolics.visit_NameSignature._hash_basis.<locals>.<genexpr>Constructs Signature for the given callable object.
    Get the mapping of generator local variables to their current values.

    A dict is returned, with the keys the local variable names and values the
    bound values.no signature found for builtin function {!r}blockfinder_return_annotation{!r} is a built-in classBoundArguments.__setstate__Private method. Don't use directly.cell_contents_signature_from_builtinsource code not availableGet a list of records for a frame and all higher (calling) frames.

    Each record contains a frame object, filename, line number, function
    name, a list of lines of context, and index within the context.Return true if the object is an asynchronous generator.CORO_SUSPENDEDReturn a list of source lines and starting line number for an object.

    The argument may be a module, class, method, function, traceback, frame,
    or code object.  The source code is returned as a list of the lines
    corresponding to the object and the line number indicates where in the
    original source file the first line of code was found.  An OSError is
    raised if the source code cannot be retrieved.{} parameters cannot have default values_POSITIONAL_OR_KEYWORDunexpected object {!r} in __signature__ attribute_shadowed_dictSignature.__setstate___signature_fromstr.<locals>.RewriteSymbolics.visit_AttributeReturn true if the object is a built-in function or method.

    Built-in functions and methods provide these attributes:
        __doc__         documentation string
        __name__        original name of this function or method
        __self__        instance to which a method is bound, or NoneParameter.__setstate__Private helper. Checks if ``cls`` has an attribute
    named ``method_name`` and returns it only if it is a
    pure python function.
    getargspec_KEYWORD_ONLY
    Get the mapping of coroutine local variables to their current values.

    A dict is returned, with the keys the local variable names and values the
    bound values.'{!r}' is not a Python functionEndOfBlockCached: {}Signature.bind_partial_getfullargsno signature found for builtin {!r}_ClassMethodWrapperPrivate helper to parse content of '__text_signature__'
    and return a Signature based on it.
    Get useful information from live Python objects.

This module encapsulates the interface provided by the internal special
attributes (co_*, im_*, tb_*, etc.) in a friendlier fashion.
It also provides some help for examining source code and class layout.

Here are some of the useful functions provided by this module:

    ismodule(), isclass(), ismethod(), isfunction(), isgeneratorfunction(),
        isgenerator(), istraceback(), isframe(), iscode(), isbuiltin(),
        isroutine() - check object types
    getmembers() - get members of an object that satisfy a given condition

    getfile(), getsourcefile(), getsource() - find an object's source code
    getdoc(), getcomments() - get documentation on an object
    getmodule() - determine the module that an object came from
    getclasstree() - arrange classes so as to represent their hierarchy

    getargvalues(), getcallargs() - get info about function arguments
    getfullargspec() - same, with support for Python 3 features
    formatargspec(), formatargvalues() - format an argument spec
    getouterframes(), getinnerframes() - get info about frames
    currentframe() - get the current stack frame
    stack(), trace() - get info about frames on the stack or in a traceback

    signature() - get a Signature object for the callable
Clean up indentation from docstrings.

    Any whitespace that can be uniformly removed from the second line
    onwards is removed.BoundArguments.apply_defaultsSet default values for missing arguments.

        For variable-positional arguments (*args) the default is an
        empty tuple.

        For variable-keyword arguments (**kwargs) the default is an
        empty dict.
        mod_dictReturn a list of records for the stack below the current exception.Signature.return_annotationdef fooGet the documentation string for an object.

    All tabs are expanded to spaces.  To clean up docstrings that are
    indented to line up with blocks of code, any whitespace than can be
    uniformly removed from the second line onwards is removed.__validate_parameters__FullArgSpecwrong parameter order: {!r} before {!r} positional argument%s (and %d keyword-only argument%s)<{} "{}">callable {!r} is not supported by signatureParameter.defaultA Signature object represents the overall signature of a function.
    It stores a Parameter object for each parameter accepted by the
    function, as well as information specific to the function itself.

    A Signature object has the following public attributes and methods:

    * parameters : OrderedDict
        An ordered mapping of parameters' names to the corresponding
        Parameter objects (keyword-only arguments are in the same order
        as listed in `code.co_varnames`).
    * return_annotation : object
        The annotation for the return type of the function if specified.
        If the function has no annotation for its return type, this
        attribute is set to `Signature.empty`.
    * bind(*args, **kwargs) -> BoundArguments
        Creates a mapping from positional and keyword arguments to
        parameters.
    * bind_partial(*args, **kwargs) -> BoundArguments
        Creates a partial mapping from positional and keyword arguments
        to parameters (simulating 'functools.partial' behavior.)
    ClosureVarsReturn tuple of base classes (including cls) in method resolution order.'{!r}' is not a Python generatorpartial object {!r} has incorrect argumentsexpline_check_instanceReturn true if the object is a member descriptor.

        Member descriptors are specialized descriptors defined in extension
        modules.top_kindReturn true if the object is a data descriptor.

    Data descriptors have both a __get__ and a __set__ attribute.  Examples are
    properties (defined in Python) and getsets and members (defined in C).
    Typically, data descriptors will also have __name__ and __doc__ attributes
    (properties, getsets, and members have both of these attributes), but this
    is not guaranteed.TPFLAGS_IS_ABSTRACT^(\s*)class\s*no signature found for builtin type {!r}could not find function definitionLine: {}Parameter.__str__Get information about a frame or traceback object.

    A tuple of five things is returned: the filename, the line number of
    the current line, the function name, a list of lines of context from
    the source code, and the index of the current line within that list.
    The optional second argument specifies the number of lines of context
    to return, which are centered around the current line.<{} {}>BoundArguments.signatureSignature.__init__.<locals>.<genexpr>_signature_get_user_defined_methodinspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()decoratorhasargs_VAR_KEYWORDcould not find class definitionnonlocals globals builtins unboundPrivate helper to transform signatures for unbound
    functions to bound methods.
    Private helper: constructs Signature for the given python function.Get current state of a coroutine object.

    Possible states are:
      CORO_CREATED: Waiting to start execution.
      CORO_RUNNING: Currently being executed by the interpreter.
      CORO_SUSPENDED: Currently suspended at an await expression.
      CORO_CLOSED: Execution has completed.
    implicit arguments must be passed in as {}_signature_is_functionlikeReturn true if the object is a user-defined function.

    Function objects provide these attributes:
        __doc__         documentation string
        __name__        name with which this function was defined
        __code__        code object containing compiled function bytecode
        __defaults__    tuple of any default values for arguments
        __globals__     global namespace in which this function was defined
        __annotations__ dict of parameter annotations
        __kwdefaults__  dict of keyword only parameters with defaultsCO_ITERABLE_COROUTINE -> {}_signature_from_callable.<locals>.<lambda>instance_dict_signature_from_functionParameter.__hash__invalid method signatureBoundArguments.kwargsformatargvalues.<locals>.convert
    Private helper function. Takes a signature in Argument Clinic's
    extended signature format.

    Returns a tuple of three things:
      * that signature re-rendered in standard Python syntax,
      * the index of the "self" parameter (generally 0), or None if
        the function does not have a "self" parameter, and
      * the index of the last "positional only" parameter,
        or None if the signature has no positional-only parameters.
    global_varscould not find code objectname must be a str, not a {!r}Parameter.__init__ Private helper to get first parameter name from a
    __text_signature__ of a builtin method, which should
    be in the following format: '($param1, ...)'.
    Assumptions are that the first argument won't have
    a default value or an annotation.
    _ParameterKind.__str__formatannotationrelativeto.<locals>._formatannotationGet lines of comments immediately preceding an object's source code.

    Returns None when source can't be found.
    Return list of attribute-descriptor tuples.

    For each name in dir(cls), the return list contains a 4-tuple
    with these elements:

        0. The name (a string).

        1. The kind of attribute this is, one of these strings:
               'class method'    created via classmethod()
               'static method'   created via staticmethod()
               'property'        created via property()
               'method'          any other flavor of method or descriptor
               'data'            not a method

        2. The class which defined this attribute (a class).

        3. The object as obtained by calling getattr; if this fails, or if the
           resulting object does not live anywhere in the class' mro (including
           metaclasses) then the object is looked up in the defining class's
           dict (found by walking the mro).

    If one of the items in dir(cls) is stored in the metaclass it will now
    be discovered and not have None be listed as the class in which it was
    defined.  Any items whose home class cannot be discovered are skipped.
    {!r} is not a Python builtin functionReturn the filename that can be used to locate an object's source.
    Return None if no way can be identified to get the source.
    Signature.parametersFrameInfoGet the object wrapped by *func*.

   Follows the chain of :attr:`__wrapped__` attributes returning the last
   object in the chain.

   *stop* is an optional callback accepting an object in the wrapper chain
   as its sole argument that allows the unwrapping to be terminated early if
   the callback returns a true value. If the callback never returns a true
   value, the last object in the chain is returned as usual. For example,
   :func:`signature` uses this to stop unwrapping if any object in the
   chain has a ``__signature__`` attribute defined.

   :exc:`ValueError` is raised if a cycle is encountered.

    BoundArguments.args%s() missing %i required %s argument%s: %sReturn a list of records for the stack above the caller's frame.nonlocal_varsGet current state of a generator-iterator.

    Possible states are:
      GEN_CREATED: Waiting to start execution.
      GEN_RUNNING: Currently being executed by the interpreter.
      GEN_SUSPENDED: Currently suspended at a yield expression.
      GEN_CLOSED: Execution has completed.
    _TextIOBaseBufferedRandom_IOBase_WindowsConsoleIOC:\msys64\mingw64\lib\python3.6\io.py_RawIOBase_BufferedIOBaseOpenWrapperBlockingIOErrorThe io module provides the Python interfaces to stream handling. The
builtin open function is defined in this module.

At the top of the I/O hierarchy is the abstract base class IOBase. It
defines the basic interface to a stream. Note, however, that there is no
separation between reading and writing to streams; implementations are
allowed to raise an OSError if they do not support a given operation.

Extending IOBase is RawIOBase which deals simply with the reading and
writing of raw bytes to a stream. FileIO subclasses RawIOBase to provide
an interface to OS files.

BufferedIOBase deals with buffering on a raw byte stream (RawIOBase). Its
subclasses, BufferedWriter, BufferedReader, and BufferedRWPair buffer
streams that are readable, writable, and both respectively.
BufferedRandom provides a buffered interface to random access
streams. BytesIO is a simple stream of in-memory bytes.

Another IOBase subclass, TextIOBase, deals with the encoding and decoding
of streams into text. TextIOWrapper, which extends it, is a buffered text
interface to a buffered raw stream (`BufferedIOBase`). Finally, StringIO
is an in-memory stream for text.

Argument names are not part of the specification, and only the arguments
of open() are intended to be used as keyword arguments.

data:

DEFAULT_BUFFER_SIZE

   An int containing the default buffer size used by the module's buffered
   I/O classes. open() uses the file's blksize (as obtained by os.stat) if
   possible.
<module io>Guido van Rossum <guido@python.org>, Mike Verdone <mike.verdone@gmail.com>, Mark Russell <mark.russell@zen.co.uk>, Antoine Pitrou <solipsis@pitrou.net>, Amaury Forgeot d'Arc <amauryfa@gmail.com>, Benjamin Peterson <benjamin@python.org>packedTest if the address is unspecified.

        Returns:
            A boolean, True if this is the unspecified address as defined in
            RFC 5735 3.

        Return the reverse DNS pointer name for the IPv4 address.

        This implements the method described in RFC1035 3.5.

        IPv4Network.__init__Address cannot be empty_BaseAddressoverlapsTest if the address is a loopback address.

        Returns:
            A boolean, True if the address is a loopback address as defined in
            RFC 2373 2.5.3.

        _IPv6Constants_BaseNetwork.is_multicastEmpty octet not permittedAddressValueError10.0.0.0/8_BaseV6.version255.255.255.255/32192.168.0.0/16ip_strhextets_BaseNetwork.is_link_localOnly one '/' permitted in %rprefix length diff must be > 0169.254.0.0/16byteslen_BaseNetwork.__init__192.0.2.0/24The subnets which join to make the current subnet.

        In the case that self contains only one IP
        (self._prefixlen == 32 for IPv4 or self._prefixlen == 128
        for IPv6), yield an iterator with just ourself.

        Args:
            prefixlen_diff: An integer, the amount the prefix length
              should be increased by. This should not be set if
              new_prefix is also set.
            new_prefix: The desired new prefix length. This must be a
              larger number (smaller prefix) than the existing prefix.
              This should not be set if prefixlen_diff is also set.

        Returns:
            An iterator of IPv(4|6) objects.

        Raises:
            ValueError: The prefixlen_diff is too small or too large.
                OR
            prefixlen_diff and new_prefix are both set or new_prefix
              is a smaller number than the current prefix (smaller
              number means a larger network)

        Test if the address is reserved for link-local.

        Returns:
            A boolean, True if the address is link-local per RFC 3927.

        reverse_octetsnew_prefixlen_BaseAddress.__repr__Return the shorthand version of the IP address as a string.4000::/3_ip_int_from_stringaddress_equalIPv4Address.is_private.<locals>.<genexpr>100.64.0.0/10F000::/5IPv6Interface.__lt__%s and %s are not of the same version_address_classAt least %d parts expected in %r200::/7Exactly %d parts expected without '::' in %ripv4_intnetmask_BaseV6._string_from_ip_intE000::/4224.0.0.0/4
        Args:
            address: A string or integer representing the IP

              Additionally, an integer can be passed, so
              IPv4Address('192.0.2.1') == IPv4Address(3221225985).
              or, more generally
              IPv4Address(int(IPv4Address('192.0.2.1'))) ==
                IPv4Address('192.0.2.1')

        Raises:
            AddressValueError: If ipaddress isn't a valid IPv4 address.

        _BaseV4._ip_int_from_stringTest if the address is reserved for multicast use.

        Returns:
            A boolean, True if the address is multicast.
            See RFC 3171 for details.

        Represent and manipulate single IPv6 Addresses.A generic IP object.

    This IP class contains the version independent methods which are
    used by single IP addresses.
    IPv6Network.__init___HEXTET_COUNTTrailing ':' only permitted as part of '::' in %r_min_parts_max_partsskip_indexparts_hiparts_loparts_skippedAt most %d colons permitted in %r_IPAddressBase.compressed%r does not appear to be an IPv4 or IPv6 address_BaseV4._string_from_ip_int_BaseAddress.__add__Instantiate a new IPv6 address object.

        Args:
            address: A string or integer representing the IP

              Additionally, an integer can be passed, so
              IPv6Address('2001:db8::') ==
                IPv6Address(42540766411282592856903984951653826560)
              or, more generally
              IPv6Address(int(IPv6Address('2001:db8::'))) ==
                IPv6Address('2001:db8::')

        Raises:
            AddressValueError: If address isn't a valid IPv6 address.

        _BaseNetwork.broadcast_address_IPAddressBase.__reduce__At most 4 characters permitted in %r_BaseNetwork.prefixlenIPv4Interface.with_prefixlenfc00::/7Test if the address is reserved for multicast use.

        Returns:
            A boolean, True if the address is a multicast address.
            See RFC 2373 2.7 for details.

        IPv4Address.is_multicastTest if the address is a loopback address.

        Returns:
            A boolean, True if the address is a loopback per RFC 3330.

        ::ffff:0:0/96trailing_zeroesThis class represents and manipulates 32-bit IPv4 network + addresses..

    Attributes: [examples for IPv4Network('192.0.2.0/27')]
        .network_address: IPv4Address('192.0.2.0')
        .hostmask: IPv4Address('0.0.0.31')
        .broadcast_address: IPv4Address('192.0.2.32')
        .netmask: IPv4Address('255.255.255.224')
        .prefixlen: 27

    ipv4_mapped%s not contained in %sTest if this address is allocated for private networks.

        Returns:
            A boolean, True if the address is reserved per
            iana-ipv4-special-registry or iana-ipv6-special-registry.

        octet_stroctet_inthex_strNetmaskValueError_BaseNetwork.num_addresses2001:10::/28_BaseNetwork.is_reservedbest_doublecolon_lenfirst and last must be IP addresses, not networks_loopback_network2001:2::/48_linklocal_networkaddress_exclude_BaseV4._reverse_pointeraddress out of range%r (len %d != %d) is not permitted as an IPv%d addressIPv6Address.is_site_localprefix length diff %d is invalid for netblock %sOnly hex digits permitted in %rIPv6Address.is_globalprefixlen_str172.16.0.0/12_BaseNetwork.__contains__IPv6Interface.with_hostmaskIPv6Interface.ip%r does not appear to be an IPv4 or IPv6 networkConvert a decimal octet into an integer.

        Args:
            octet_str: A string, the number to parse.

        Returns:
            The octet as an integer.

        Raises:
            ValueError: if the octet isn't strictly a decimal from [0..255].

        IPv4Interface.__lt__192.0.0.0/29240.0.0.0/4new prefix must be longer::/8_BaseV4.max_prefixlenv4_int_to_packedTest if this address is allocated for public networks.

        Returns:
            A boolean, true if the address is not reserved per
            iana-ipv6-special-registry.

        _check_int_address_BaseAddress.__str__IPv4Interface.ipnew prefix must be shorterlast_intlast IP address must be greater than first%r does not appear to be an IPv4 or IPv6 interfaceTest if this address is allocated for private networks.

        Returns:
            A boolean, True if the address is reserved per
            iana-ipv6-special-registry.

        unknown IP version127.0.0.0/8best_doublecolon_endC000::/3Network-only key function.

        Returns an object that identifies this address' network and
        netmask. This function is a suitable "key" argument for sorted()
        and list.sort().

        Loops through the addresses, collapsing concurrent netblocks.

    Example:

        ip1 = IPv4Network('192.0.2.0/26')
        ip2 = IPv4Network('192.0.2.64/26')
        ip3 = IPv4Network('192.0.2.128/26')
        ip4 = IPv4Network('192.0.2.192/26')

        _collapse_addresses_internal([ip1, ip2, ip3, ip4]) ->
          [IPv4Network('192.0.2.0/24')]

        This shouldn't be called directly; it is called via
          collapse_addresses([]).

    Args:
        addresses: A list of IPv4Network's or IPv6Network's

    Returns:
        A list of IPv4Network's or IPv6Network's depending on what we were
        passed.

    _IPAddressBase._ip_int_from_prefixfirst_int800::/5_make_netmaskIPv6Interface.with_prefixlen%200s has no version specified_BaseNetwork.is_loopback_sitelocal_networkReturn the longhand version of the IP address as a string._get_networks_keyIPv6Address.is_private.<locals>.<genexpr>is_unspecified%200s has no associated address classnew_addr_BaseV4._make_netmaskBase IPv6 object.

    The following methods are used by IPv6 objects in both single IP
    addresses and networks.

    IPv6Interface.is_loopbackReturn the reverse DNS pointer name for the IPv6 address.

        This implements the method described in RFC3596 2.5.

        leading_onesall_ones_BaseV4._parse_octet_netmask_cache_prefix_from_ip_int_HEX_DIGITSaddr_strAddress negative or too large for IPv6_count_righthand_zero_bitsdoublecolon_start198.51.100.0/24_BaseV6._parse_hextet_BaseAddress._get_address_keyreverse_charsAt most 3 characters permitted in %rBase IPv4 object.

    The following methods are used by IPv4 objects in both single IP
    addresses and networks.

    IPv4Address.is_globalIPv6Interface.with_netmask2001:db8::/32F800::/6A Value Error related to the netmask.IPv6Address.is_loopbackHelper to split the netmask and raise AddressValueError if needed_BaseNetwork.with_netmaskTurn an IPv6 ip_str into an integer.

        Args:
            ip_str: A string, the IPv6 ip_str.

        Returns:
            An int, the IPv6 address

        Raises:
            AddressValueError: if ip_str isn't a valid IPv6 Address.

        _BaseNetwork.__hash__expected_len_find_address_range203.0.113.0/24Return prefix length from the bitwise netmask.

        Args:
            ip_int: An integer, the netmask in expanded bitwise format

        Returns:
            An integer, the prefix length.

        Raises:
            ValueError: If the input intermingles zeroes & ones
        fe80::/10_public_networkcurrent prefixlen is %d, cannot have a prefixlen_diff of %dIPv4Address.packedRemove an address from a larger block.

        For example:

            addr1 = ip_network('192.0.2.0/28')
            addr2 = ip_network('192.0.2.1/32')
            list(addr1.address_exclude(addr2)) =
                [IPv4Network('192.0.2.0/32'), IPv4Network('192.0.2.2/31'),
                 IPv4Network('192.0.2.4/30'), IPv4Network('192.0.2.8/29')]

        or IPv6:

            addr1 = ip_network('2001:db8::1/32')
            addr2 = ip_network('2001:db8::1/128')
            list(addr1.address_exclude(addr2)) =
                [ip_network('2001:db8::1/128'),
                 ip_network('2001:db8::2/127'),
                 ip_network('2001:db8::4/126'),
                 ip_network('2001:db8::8/125'),
                 ...
                 ip_network('2001:db8:8000::/33')]

        Args:
            other: An IPv4Network or IPv6Network object of the same type.

        Returns:
            An iterator of the IPv(4|6)Network objects which is self
            minus other.

        Raises:
            TypeError: If self and other are of differing address
              versions, or if other is not a network object.
            ValueError: If other is not completely contained by self.

        netmask_strExpand a shortened IPv6 address.

        Args:
            ip_str: A string, the IPv6 address.

        Returns:
            A string, the expanded IPv6 address.

        Only decimal digits permitted in %raddress_len_reserved_networkIPv4Interface.__str__Instantiate a new IPv6 Network object.

        Args:
            address: A string or integer representing the IPv6 network or the
              IP and prefix/netmask.
              '2001:db8::/128'
              '2001:db8:0000:0000:0000:0000:0000:0000/128'
              '2001:db8::'
              are all functionally the same in IPv6.  That is to say,
              failing to provide a subnetmask will create an object with
              a mask of /128.

              Additionally, an integer can be passed, so
              IPv6Network('2001:db8::') ==
                IPv6Network(42540766411282592856903984951653826560)
              or, more generally
              IPv6Network(int(IPv6Network('2001:db8::'))) ==
                IPv6Network('2001:db8::')

            strict: A boolean. If true, ensure that we have been passed
              A true network address, eg, 2001:db8::1000/124 and not an
              IP address on a network, eg, 2001:db8::1/124.

        Raises:
            AddressValueError: If address isn't a valid IPv6 address.
            NetmaskValueError: If the netmask isn't valid for
              an IPv6 address.
            ValueError: If strict was True and a network address was not
              supplied.

        100::/64Take an IP string/int and return an object of the correct type.

    Args:
        address: A string or integer, the IP address.  Either IPv4 or
          IPv6 addresses may be supplied; integers less than 2**32 will
          be considered to be IPv4 by default.

    Returns:
        An IPv4Address or IPv6Address object.

    Raises:
        ValueError: if the *address* passed isn't either a v4 or a v6
          address

    Error performing exclusion: s1: %s s2: %s other: %s_BaseV6.max_prefixlen_BaseNetwork.__repr__Ambiguous (octal/decimal) value in %r not permittedTake an IP string/int and return an object of the correct type.

    Args:
        address: A string or integer, the IP address.  Either IPv4 or
          IPv6 addresses may be supplied; integers less than 2**32 will
          be considered to be IPv4 by default.

    Returns:
        An IPv4Interface or IPv6Interface object.

    Raises:
        ValueError: if the string passed isn't either a v4 or a v6
          address.

    Notes:
        The IPv?Interface classes describe an Address on a particular
        Network, so they're basically a combination of both the Address
        and Network classes.

    Count the number of zero bits on the right hand side.

    Args:
        number: an integer.
        bits: maximum number of bits to count.

    Returns:
        The number of zero bits on the right hand side of the number.

    Instantiate a new IPv4 network object.

        Args:
            address: A string or integer representing the IP [& network].
              '192.0.2.0/24'
              '192.0.2.0/255.255.255.0'
              '192.0.0.2/0.0.0.255'
              are all functionally the same in IPv4. Similarly,
              '192.0.2.1'
              '192.0.2.1/255.255.255.255'
              '192.0.2.1/32'
              are also functionally equivalent. That is to say, failing to
              provide a subnetmask will create an object with a mask of /32.

              If the mask (portion after the / in the argument) is given in
              dotted quad form, it is treated as a netmask if it starts with a
              non-zero field (e.g. /255.0.0.0 == /8) and as a hostmask if it
              starts with a zero field (e.g. 0.255.255.255 == /8), with the
              single exception of an all-zero mask which is treated as a
              netmask == /0. If no mask is given, a default of /32 is used.

              Additionally, an integer can be passed, so
              IPv4Network('192.0.2.1') == IPv4Network(3221225985)
              or, more generally
              IPv4Interface(int(IPv4Interface('192.0.2.1'))) ==
                IPv4Interface('192.0.2.1')

        Raises:
            AddressValueError: If ipaddress isn't a valid IPv4 address.
            NetmaskValueError: If the netmask isn't valid for
              an IPv4 address.
            ValueError: If strict is True and a network address is not
              supplied.

        %s and %s are not of the same type_prefix_from_prefix_string_prefix_from_ip_string_BaseNetwork.hosts_IPAddressBase._check_int_addressIPv6Address.ipv4_mapped_private_networks_IPAddressBase.reverse_pointerIPv6Address.is_unspecifiedA generic IP network object.

    This IP class contains the version independent methods which are
    used by networks.

    best_doublecolon_start%032x%s/%d_reserved_networksTest if the address is reserved for link-local.

        Returns:
            A boolean, True if the address is reserved per RFC 4291.

        Leading ':' only permitted as part of '::' in %rIPv4Network.is_global_BaseNetwork.supernet%s has host bits setRepresent and manipulate single IPv4 Addresses._unspecified_addressTest if this address is allocated for public networks.

        Returns:
            A boolean, True if the address is not reserved per
            iana-ipv4-special-registry.

        _ALL_ONESTest if the address is unspecified.

        Returns:
            A boolean, True if this is the unspecified address as defined in
            RFC 2373 2.5.2.

        _BaseV4.version_IPAddressBase._prefix_from_prefix_stringsixtofour_compress_hextetsAddress negative or too large for IPv4IPv4Address.is_unspecified400::/6cannot set prefixlen_diff and new_prefix_BaseAddress.__sub___multicast_networkTest if the address is otherwise IETF reserved.

         Returns:
             A boolean, True if the address is within the
             reserved IPv4 Network range.

        IPv4Address.is_loopbackExpected at most %d other parts with '::' in %rSummarize a network range given the first and last IP addresses.

    Example:
        >>> list(summarize_address_range(IPv4Address('192.0.2.0'),
        ...                              IPv4Address('192.0.2.130')))
        ...                                #doctest: +NORMALIZE_WHITESPACE
        [IPv4Network('192.0.2.0/25'), IPv4Network('192.0.2.128/31'),
         IPv4Network('192.0.2.130/32')]

    Args:
        first: the first IPv4Address or IPv6Address in the range.
        last: the last IPv4Address or IPv6Address in the range.

    Returns:
        An iterator of the summarized IPv(4|6) network objects.

    Raise:
        TypeError:
            If the first and last objects are not IP addresses.
            If the first and last objects are not the same version.
        ValueError:
            If the last object is not greater than the first.
            If the version of the first address is not 4 or 6.

    _is_valid_netmaskTest if this address is allocated for private networks.

        Returns:
            A boolean, True if the address is reserved per
            iana-ipv4-special-registry.

        Turn a netmask/hostmask string into a prefix length

        Args:
            ip_str: The netmask/hostmask to be converted

        Returns:
            An integer, the prefix length.

        Raises:
            NetmaskValueError: If the input is not a valid netmask/hostmask
        192.0.0.170/31_BaseNetwork.is_privatecompare_networks_report_invalid_netmaskFE00::/9address_less_BaseNetwork.with_prefixlen_BaseV4._is_valid_netmask%r is not a valid netmaskIPv4Interface.with_netmaskIPv4Address.is_link_localA Value Error related to the address.hextet_str_BaseV6._ip_int_from_stringC:\msys64\mingw64\lib\python3.6\ipaddress.pyto_mergeIPv6Network.hostsExpected 4 octets in %rTurn the prefix length into a bitwise netmask

        Args:
            prefixlen: An integer, the prefix length.

        Returns:
            An integer.

        _BaseNetwork.__lt__IPv4Address.__init__.ip6.arpa_is_hostmask_IPAddressBase.version_IPv4Constants_BaseNetwork.__iter__ip_bitsexploded_BaseV4._is_hostmaskA000::/3Generate Iterator over usable hosts in a network.

        This is like __iter__ except it doesn't return the network
        or broadcast addresses.

        Unexpected '/' in %r1000::/4_BaseNetwork.with_hostmask_BaseAddress.__hash__Turns a 32-bit integer into dotted decimal notation.

        Args:
            ip_int: An integer, the IP address.

        Returns:
            The IP address as a string in dotted decimal notation.

        _BaseNetwork.address_exclude_BaseNetwork._get_networks_keyIPv6Address.sixtofourIPV6LENGTHIPv6Interface.__str___BaseNetwork.is_globalIPV4LENGTHIPv6Interface.is_unspecifiedNumber of hosts in the current subnet._BaseNetwork.overlapsTell if self is partly contained in other.IPv6Network.is_site_local%s is not a network object_BaseAddress.__int__ff00::/8IPv6Interface.__init__Represent an address as 16 packed bytes in network (big-endian) order.

    Args:
        address: An integer representation of an IPv6 IP address.

    Returns:
        The integer address packed as 16 bytes in network (big-endian) order.

    _BaseNetwork.subnets_max_prefixlenTurn the given IP string into an integer for comparison.

        Args:
            ip_str: A string, the IP ip_str.

        Returns:
            The IP ip_str as an integer.

        Raises:
            AddressValueError: if ip_str isn't a valid IPv4 Address.

        IPv4Interface.__init___BaseV4._explode_shorthand_ip_stringMake a (netmask, prefix_len) tuple from the given argument.

        Argument can be:
        - an integer (the prefix length)
        - a string representing the prefix length (e.g. "24")
        - a string representing the prefix netmask (e.g. "255.255.255.0")
        IPv4Interface.__hash__Take an IP string/int and return an object of the correct type.

    Args:
        address: A string or integer, the IP network.  Either IPv4 or
          IPv6 networks may be supplied; integers less than 2**32 will
          be considered to be IPv4 by default.

    Returns:
        An IPv4Network or IPv6Network object.

    Raises:
        ValueError: if the string passed isn't either a v4 or a v6
          address. Or if the network has host bits set.

    Verify that the netmask is valid.

        Args:
            netmask: A string, either a prefix or dotted decimal
              netmask.

        Returns:
            A boolean, True if the prefix represents a valid IPv4
            netmask.

        The binary representation of this address._BaseV6._make_netmask6000::/3Return the IPv4 6to4 embedded address.

        Returns:
            The IPv4 6to4-embedded address if present or None if the
            address doesn't appear to contain a 6to4 embedded address.

        _IPAddressBase.explodedTest if this address is allocated for public networks.

        Returns:
            A boolean, True if the address is not reserved per
            iana-ipv4-special-registry or iana-ipv6-special-registry.

        IPv6Address.packedConvert an IPv6 hextet string into an integer.

        Args:
            hextet_str: A string, the number to parse.

        Returns:
            The hextet as an integer.

        Raises:
            ValueError: if the input isn't strictly a hex number from
              [0..FFFF].

        100::/8198.18.0.0/15teredoGenerate Iterator over usable hosts in a network.

          This is like __iter__ except it doesn't return the
          Subnet-Router anycast address.

        Collapse a list of IP objects.

    Example:
        collapse_addresses([IPv4Network('192.0.2.0/25'),
                            IPv4Network('192.0.2.128/25')]) ->
                           [IPv4Network('192.0.2.0/24')]

    Args:
        addresses: An iterator of IPv4Network or IPv6Network objects.

    Returns:
        An iterator of the collapsed IPv(4|6)Network objects.

    Raises:
        TypeError: If passed a list of mixed version objects.

    At most one '::' permitted in %r_valid_mask_octets_BaseNetwork.__eq___BaseNetwork.__str__The supernet containing the current network.

        Args:
            prefixlen_diff: An integer, the amount the prefix length of
              the network should be decreased by.  For example, given a
              /24 network and a prefixlen_diff of 3, a supernet with a
              /21 netmask is returned.

        Returns:
            An IPv4 network object.

        Raises:
            ValueError: If self.prefixlen - prefixlen_diff < 0. I.e., you have
              a negative prefix length.
                OR
            If prefixlen_diff and new_prefix are both set or new_prefix is a
              larger number than the current prefix (larger number means a
              smaller network)

        Return a key suitable for sorting between networks and addresses.

    Address and Network objects are not sortable by default; they're
    fundamentally different so the expression

        IPv4Address('192.0.2.0') <= IPv4Network('192.0.2.0/24')

    doesn't make any sense.  There are some times however, where you may wish
    to have ipaddress sort these for you anyway. If you need to do this, you
    can use this function as the key= argument to sorted().

    Args:
      obj: either a Network or Address object.
    Returns:
      appropriate key.

    2001::/23_BaseNetwork.hostmask%d (>= 2**%d) is not permitted as an IPv%d addressIPv6 address is too largeCompare two IP objects.

        This is only concerned about the comparison of the integer
        representation of the network addresses.  This means that the
        host bits aren't considered at all in this method.  If you want
        to compare host bits, you can easily enough do a
        'HostA._ip < HostB._ip'

        Args:
            other: An IP object.

        Returns:
            If the IP versions of self and other are the same, returns:

            -1 if self < other:
              eg: IPv4Network('192.0.2.0/25') < IPv4Network('192.0.2.128/25')
              IPv6Network('2001:db8::1000/124') <
                  IPv6Network('2001:db8::2000/124')
            0 if self == other
              eg: IPv4Network('192.0.2.0/24') == IPv4Network('192.0.2.0/24')
              IPv6Network('2001:db8::1000/124') ==
                  IPv6Network('2001:db8::1000/124')
            1 if self > other
              eg: IPv4Network('192.0.2.128/25') > IPv4Network('192.0.2.0/25')
                  IPv6Network('2001:db8::2000/124') >
                      IPv6Network('2001:db8::1000/124')

          Raises:
              TypeError if the IP versions are different.

        %s in %rThe mother class._check_packed_addressfec0::/10_BaseNetwork.is_unspecified_BaseV6._explode_shorthand_ip_stringRepresent an address as 4 packed bytes in network (big-endian) order.

    Args:
        address: An integer representation of an IPv4 IP address.

    Returns:
        The integer address packed as 4 bytes in network (big-endian) order.

    Raises:
        ValueError: If the integer is negative or too large to be an
          IPv4 IP address.

    _BaseV6._compress_hextets_IPAddressBase._report_invalid_netmaskTest if the IP string is a hostmask (rather than a netmask).

        Args:
            ip_str: A string, the potential hostmask.

        Returns:
            A boolean, True if the IP string is a hostmask.

        _BaseNetwork._address_classCompresses a list of hextets.

        Compresses a list of strings, replacing the longest continuous
        sequence of "0" in the list with "" and adding empty strings at
        the beginning or at the end of the string such that subsequently
        calling ":".join(hextets) will produce the compressed version of
        the IPv6 address.

        Args:
            hextets: A list of strings, the hextets to compress.

        Returns:
            A list of strings.

        _BaseAddress.__lt__IPv6Interface.__hash__The name of the reverse DNS pointer for the IP address, e.g.:
            >>> ipaddress.ip_address("127.0.0.1").reverse_pointer
            '1.0.0.127.in-addr.arpa'
            >>> ipaddress.ip_address("2001:db8::1").reverse_pointer
            '1.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.8.b.d.0.1.0.0.2.ip6.arpa'

        _BaseV6._reverse_pointer_IPAddressBase._check_packed_addressThis class represents and manipulates 128-bit IPv6 networks.

    Attributes: [examples for IPv6('2001:db8::1000/124')]
        .network_address: IPv6Address('2001:db8::1000')
        .hostmask: IPv6Address('::f')
        .broadcast_address: IPv6Address('2001:db8::100f')
        .netmask: IPv6Address('ffff:ffff:ffff:ffff:ffff:ffff:ffff:fff0')
        .prefixlen: 124

    %d (< 0) is not permitted as an IPv%d addressTuple of embedded teredo IPs.

        Returns:
            Tuple of the (server, client) IPs or None if the address
            doesn't appear to be a teredo address (doesn't start with
            2001::/32)

        IPv6Address.__init__IPv6Address.is_reserved.<locals>.<genexpr>IPv4Interface.with_hostmaskFind a sequence of sorted deduplicated IPv#Address.

    Args:
        addresses: a list of IPv#Address objects.

    Yields:
        A tuple containing the first and last IP addresses in the sequence.

    _BaseNetwork.compare_networksv6_int_to_packedA fast, lightweight IPv4/IPv6 manipulation library in Python.

This library is used to create/poke/manipulate IPv4 and IPv6 addresses
and networks.

IPv6Address.is_multicastReturn the IPv4 mapped address.

        Returns:
            If the IPv6 address is a v4 mapped address, return the
            IPv4 mapped address. Return None otherwise.

        Test if the address is reserved for site-local.

        Note that the site-local address space has been deprecated by RFC 3879.
        Use is_private to test if this address is in the space of unique local
        addresses as defined by RFC 4193.

        Returns:
            A boolean, True if the address is reserved per RFC 3513 2.5.6.

        get_mixed_type_key_BaseAddress.__eq__<module ipaddress>IPv4Address.is_reservedOctet %d (> 255) not permittedIPv6Address.is_link_localTurns a 128-bit integer into hexadecimal notation.

        Args:
            ip_int: An integer, the IP address.

        Returns:
            A string, the hexadecimal representation of the address.

        Raises:
            ValueError: The address is bigger than 128 bits of all ones.

        IPv6Interface.__eq___IPAddressBase._prefix_from_ip_string_DECIMAL_DIGITSReturn prefix length from a numeric string

        Args:
            prefixlen_str: The string to be converted

        Returns:
            An integer, the prefix length.

        Raises:
            NetmaskValueError: If the input is not a valid netmask
        ip_interfaceTest if the address is otherwise IETF reserved.

        Returns:
            A boolean, True if the address is within one of the
            reserved IPv6 Network ranges.

        _IPAddressBase._prefix_from_ip_int_BaseAddress.__reduce__IPv4Interface.__eq__Netmask pattern %r mixes zeroes & ones_split_optional_netmaskIPv6Address.teredo_BaseNetwork.__getitem___iso_countrycodeC:\msys64\home\cbper\iso3166.pyget_state_nameûzAD)zAndorrazANDz020zAE)zUnited Arab EmirateszAREz784zAF)zAfghanistanzAFGz004zAG)zAntigua and BarbudazATGz028zAI)zAnguillazAIAz660zAL)zAlbaniazALBz008zAM)zArmeniazARMz051zAN)zNetherlands AntilleszANTz530zAO)zAngolazAGOz024zAQ)z
AntarcticazATAz010zAR)z	ArgentinazARGz032zAS)zAmerican SamoazASMz016zAT)zAustriazAUTz040zAU)z	AustraliazAUSz036zAW)zArubazABWz533zAZ)z
AzerbaijanzAZEz031zBA)zBosnia and HerzegowinazBIHz070zBB)zBarbadoszBRBz052zBD)z
BangladeshzBGDz050zBE)zBelgiumzBELz056zBF)zBurkina FasozBFAz854zBG)zBulgariazBGRz100zBH)zBahrainzBHRz048zBI)zBurundizBDIz108zBJ)zBeninzBENz204zBM)zBermudazBMUz060zBN)zBrunei DarussalamzBRNz096zBO)zBoliviazBOLz068zBR)zBrazilzBRAz076zBS)zBahamaszBHSz044zBT)zBhutanzBTNz064zBV)zBouvet IslandzBVTz074zBW)zBotswanazBWAz072zBY)zBelaruszBLRz112zBZ)zBelizezBLZz084zCA)zCanadazCANz124zCC)zCocos (keeling) IslandszCCKz166zCF)zCentral African RepubliczCAFz140zCG)zCongozCOGz178zCH)zSwitzerlandzCHEz756zCI)zCote D'ivoirezCIVz384zCK)zCook IslandszCOKz184zCL)zChilezCHLz152zCM)zCameroonzCMRz120zCN)zChinazCHNz156zCO)zColombiazCOLz170zCR)z
Costa RicazCRIz188zCU)zCubazCUBz192zCV)z
Cape VerdezCPVz132zCX)zChristmas IslandzCXRz162zCY)zCypruszCYPz196zCZ)zCzech RepubliczCZEz203zDE)zGermanyzDEUz276zDJ)zDjiboutizDJIz262zDK)zDenmarkzDNKz208zDM)zDominicazDMAz212zDO)zDominican RepubliczDOMz214zDZ)zAlgeriazDZAz012zEC)zEcuadorzECUz218zEE)zEstoniazESTz233zEG)zEgyptzEGYz818zEH)zWestern SaharazESHz732zER)zEritreazERIz232zES)zSpainzESPz724zET)zEthiopiazETHz231zFI)zFinlandzFINz246zFJ)zFijizFJIz242zFK)zFalkland Islands (malvinas)zFLKz238zFM)zMicronesia, Federated States ofzFSMz583zFO)zFaroe IslandszFROz234zFR)zFrancezFRAz250zFX)zFrance, MetropolitanzFXXz249zGA)zGabonzGABz266zGB)zUnited KingdomzGBRz826zGD)zGrenadazGRDz308zGE)zGeorgiazGEOz268zGF)zFrench GuianazGUFz254zGH)zGhanazGHAz288zGI)z	GibraltarzGIBz292zGL)z	GreenlandzGRLz304zGM)zGambiazGMBz270zGN)zGuineazGINz324zGP)z
GuadeloupezGLPz312zGQ)zEquatorial GuineazGNQz226zGR)zGreecezGRCz300zGS)z,South Georgia and the South Sandwich IslandszSGSz239zGT)z	GuatemalazGTMz320zGU)zGuamzGUMz316zGW)zGuinea-bissauzGNBz624zGY)zGuyanazGUYz328zHK)z	Hong KongzHKGz344zHM)zHeard and McDonald IslandszHMDz334zHN)zHonduraszHNDz340zHR)zCroatia (local name: Hrvatska)zHRVz191zHT)zHaitizHTIz332zHU)zHungaryzHUNz348zID)z	IndonesiazIDNz360zIE)zIrelandzIRLz372zIL)zIsraelzISRz376zIN)zIndiazINDz356zIO)zBritish Indian Ocean TerritoryzIOTz086zIQ)zIraqzIRQz368zIR)zIran (Islamic Republic of)zIRNz364zIS)zIcelandzISLz352zIT)zItalyzITAz380zJM)zJamaicazJAMz388zJO)zJordanzJORz400zJP)zJapanzJPNz392zKE)zKenyazKENz404zKG)z
KyrgyzstanzKGZz417zKH)zCambodiazKHMz116zKI)zKiribatizKIRz296zKM)zComoroszCOMz174zKN)zSaint Kitts and NeviszKNAz659zKP)z&Korea, Democratic People's Republic ofzPRKz408zKR)zKorea, Republic ofzKORz410zKW)zKuwaitzKWTz414zKY)zCayman IslandszCYMz136zKZ)z
KazakhstanzKAZz398zLA)z Lao People's Democratic RepubliczLAOz418zLB)zLebanonzLBNz422zLC)zSaint LuciazLCAz662zLI)zLiechtensteinzLIEz438zLK)z	Sri LankazLKAz144zLR)zLiberiazLBRz430zLS)zLesothozLSOz426zLT)z	LithuaniazLTUz440zLU)z
LuxembourgzLUXz442zLV)zLatviazLVAz428zLY)zLibyan Arab JamahiriyazLBYz434zMA)zMoroccozMARz504zMC)zMonacozMCOz492zMD)zMoldova, Republic ofzMDAz498zMG)z
MadagascarzMDGz450zMH)zMarshall IslandszMHLz584zMK)z*Macedonia, The Former Yugoslav Republic ofzMKDz807zML)zMalizMLIz466zMM)zMyanmarzMMRz104zMN)zMongoliazMNGz496zMO)zMacauzMACz446zMP)zNorthern Mariana IslandszMNPz580zMQ)z
MartiniquezMTQz474zMR)z
MauritaniazMRTz478zMS)z
MontserratzMSRz500zMT)zMaltazMLTz470zMU)z	MauritiuszMUSz480zMV)zMaldiveszMDVz462zMW)zMalawizMWIz454zMX)zMexicozMEXz484zMY)zMalaysiazMYSz458zMZ)z
MozambiquezMOZz508zNA)zNamibiazNAMz516zNC)zNew CaledoniazNCLz540zNE)zNigerzNERz562zNF)zNorfolk IslandzNFKz574zNG)zNigeriazNGAz566zNI)z	NicaraguazNICz558zNL)zNetherlandszNLDz528zNO)zNorwayzNORz578zNP)zNepalzNPLz524zNR)zNauruzNRUz520zNU)zNiuezNIUz570zNZ)zNew ZealandzNZLz554zOM)zOmanzOMNz512zPA)zPanamazPANz591zPE)zPeruzPERz604zPF)zFrench PolynesiazPYFz258zPG)zPapua New GuineazPNGz598zPH)zPhilippineszPHLz608zPK)zPakistanzPAKz586zPL)zPolandzPOLz616zPM)zSt. Pierre and MiquelonzSPMz666zPN)zPitcairnzPCNz612zPR)zPuerto RicozPRIz630zPT)zPortugalzPRTz620zPW)zPalauzPLWz585zPY)zParaguayzPRYz600zQA)zQatarzQATz634zRE)zReunionzREUz638zRO)zRomaniazROMz642zRU)zRussian FederationzRUSz643zRW)zRwandazRWAz646zSA)zSaudi ArabiazSAUz682zSB)zSolomon IslandszSLBz090zSC)z
SeychelleszSYCz690zSD)zSudanzSDNz736zSE)zSwedenzSWEz752zSG)z	SingaporezSGPz702zSH)z
St. HelenazSHNz654zSI)zSloveniazSVNz705zSJ)zSvalbard and Jan Mayen IslandszSJMz744zSK)zSlovakia (slovak Republic)zSVKz703zSL)zSierra LeonezSLEz694zSM)z
San MarinozSMRz674zSN)zSenegalzSENz686zSO)zSomaliazSOMz706zSR)zSurinamezSURz740zST)zSao Tome and PrincipezSTPz678zSV)zEl SalvadorzSLVz222zSY)zSyrian Arab RepubliczSYRz760zSZ)z	SwazilandzSWZz748zTC)zTurks and Caicos IslandszTCAz796zTD)zChadzTCDz148zTF)zFrench Southern TerritorieszATFz260zTG)zTogozTGOz768zTH)zThailandzTHAz764zTJ)z
TajikistanzTJKz762zTK)zTokelauzTKLz772zTM)zTurkmenistanzTKMz795zTN)zTunisiazTUNz788zTO)zTongazTONz776zTP)z
East TimorzTMPz626zTR)zTurkeyzTURz792zTT)zTrinidad and TobagozTTOz780zTV)zTuvaluzTUVz798zTW)zTaiwan, Province of ChinazTWNz158zTZ)zTanzania, United Republic ofzTZAz834zUA)zUkrainezUKRz804zUG)zUgandazUGAz800zUM)z$United States Minor Outlying IslandszUMIz581zUS)zUnited StateszUSAz840zUY)zUruguayzURYz858zUZ)z
UzbekistanzUZBz860zVA)zVatican City State (Holy See)zVATz336zVC)z Saint Vincent and the GrenadineszVCTz670zVE)z	VenezuelazVENz862zVG)zVirgin Islands (british)zVGBz092zVI)zVirgin Islands (u.s.)zVIRz850zVN)zViet NamzVNMz704zVU)zVanuatuzVUTz548zWF)zWallis and Futuna IslandszWLFz876zWS)zSamoazWSMz882zYE)zYemenzYEMz887zYT)zMayottezMYTz175zYU)z
YugoslaviazYUGz891zZA)zSouth AfricazZAFz710zZM)zZambiazZMBz894zZR)zZairezZARz180zZW)zZimbabwezZWEz7160ûzALzAlabamazAKzAlaskazAZzArizonazARzArkansaszCAz
CaliforniazCOzColoradozCTzConnecticutzDEzDelawarezDCzD.C.zFLzFloridazGAzGeorgiazHIzHawaiizIDzIdahozILzIllinoiszINzIndianazIAzIowazKSzKansaszKYzKentuckyzLAz	LouisianazMEzMainezMDzMarylandzMAzMassachusettszMIzMichiganzMNz	MinnesotazMSzMississippizMOzMissourizMTzMontanazNEzNebraskazNVzNevadazNHzNew HampshirezNJz
New JerseyzNMz
New MexicozNYzNew YorkzNCzNorth CarolinazNDzNorth DakotazOHzOhiozOKzOklahomazORzOregonzPAzPennsylvaniazPRzPuerto RicozRIzRhode IslandzSCzSouth CarolinazSDzSouth DakotazTNzTenneseezTXzTexaszUTzUtahzVTzVermontzVAzVirginiazWAz
WashingtonzWVzWest VirginiazWIz	WisconsinzWYzWyoming0_us_statecodeiso639_to_nameiso639fiso639_1iso639_1_codesiso639_1_to_namename_to_iso639_1iso639_2iso639_2_codesiso639_2_to_namename_to_iso639_2iso639_3iso639_3_codesiso639_3_to_namename_to_iso639_3ISO 639-1 not 1:1... bug?common_languagesISO 639-3 not 1:1... bug?ISO 639-2 not 1:1... bug?get_common_languages<module iso639>Û   zenzfrzeszptzarzruzzhzdezitzsvzroznlzdazetzbgzlazhuznozltzcazfizmtzlvzgazcszskzpl
ISO 639 language code services

Validate ISO 639 language codes, translate to language names,
and provide selection lists.
get_language_codeiso639_to_name_reducediso-639-3_20070205.tabC:\msys64\home\cbper\iso639.py_extract_language_tablesthe JSON object must be str, bytes or bytearray, not {!r}ï»¿utf-32-bebstartswithutf-32-leUnexpected UTF-8 BOM (decode using utf-8-sig)Serialize ``obj`` to a JSON formatted ``str``.

    If ``skipkeys`` is true then ``dict`` keys that are not basic types
    (``str``, ``int``, ``float``, ``bool``, ``None``) will be skipped
    instead of raising a ``TypeError``.

    If ``ensure_ascii`` is false, then the return value can contain non-ASCII
    characters if they appear in strings contained in ``obj``. Otherwise, all
    such characters are escaped in JSON strings.

    If ``check_circular`` is false, then the circular reference check
    for container types will be skipped and a circular reference will
    result in an ``OverflowError`` (or worse).

    If ``allow_nan`` is false, then it will be a ``ValueError`` to
    serialize out of range ``float`` values (``nan``, ``inf``, ``-inf``) in
    strict compliance of the JSON specification, instead of using the
    JavaScript equivalents (``NaN``, ``Infinity``, ``-Infinity``).

    If ``indent`` is a non-negative integer, then JSON array elements and
    object members will be pretty-printed with that indent level. An indent
    level of 0 will only insert newlines. ``None`` is the most compact
    representation.

    If specified, ``separators`` should be an ``(item_separator, key_separator)``
    tuple.  The default is ``(', ', ': ')`` if *indent* is ``None`` and
    ``(',', ': ')`` otherwise.  To get the most compact JSON representation,
    you should specify ``(',', ':')`` to eliminate whitespace.

    ``default(obj)`` is a function that should return a serializable version
    of obj or raise TypeError. The default simply raises TypeError.

    If *sort_keys* is true (default: ``False``), then the output of
    dictionaries will be sorted by key.

    To use a custom ``JSONEncoder`` subclass (e.g. one that overrides the
    ``.default()`` method to serialize additional types), specify it with
    the ``cls`` kwarg; otherwise ``JSONEncoder`` is used.

    C:\msys64\mingw64\lib\python3.6\json\__init__.py_default_encoderJSON (JavaScript Object Notation) <http://json.org> is a subset of
JavaScript syntax (ECMA-262 3rd edition) used as a lightweight data
interchange format.

:mod:`json` exposes an API familiar to users of the standard library
:mod:`marshal` and :mod:`pickle` modules.  It is derived from a
version of the externally maintained simplejson library.

Encoding basic Python object hierarchies::

    >>> import json
    >>> json.dumps(['foo', {'bar': ('baz', None, 1.0, 2)}])
    '["foo", {"bar": ["baz", null, 1.0, 2]}]'
    >>> print(json.dumps("\"foo\bar"))
    "\"foo\bar"
    >>> print(json.dumps('\u1234'))
    "\u1234"
    >>> print(json.dumps('\\'))
    "\\"
    >>> print(json.dumps({"c": 0, "b": 0, "a": 0}, sort_keys=True))
    {"a": 0, "b": 0, "c": 0}
    >>> from io import StringIO
    >>> io = StringIO()
    >>> json.dump(['streaming API'], io)
    >>> io.getvalue()
    '["streaming API"]'

Compact encoding::

    >>> import json
    >>> from collections import OrderedDict
    >>> mydict = OrderedDict([('4', 5), ('6', 7)])
    >>> json.dumps([1,2,3,mydict], separators=(',', ':'))
    '[1,2,3,{"4":5,"6":7}]'

Pretty printing::

    >>> import json
    >>> print(json.dumps({'4': 5, '6': 7}, sort_keys=True, indent=4))
    {
        "4": 5,
        "6": 7
    }

Decoding JSON::

    >>> import json
    >>> obj = ['foo', {'bar': ['baz', None, 1.0, 2]}]
    >>> json.loads('["foo", {"bar":["baz", null, 1.0, 2]}]') == obj
    True
    >>> json.loads('"\\"foo\\bar"') == '"foo\x08ar'
    True
    >>> from io import StringIO
    >>> io = StringIO('["streaming API"]')
    >>> json.load(io)[0] == 'streaming API'
    True

Specializing JSON object decoding::

    >>> import json
    >>> def as_complex(dct):
    ...     if '__complex__' in dct:
    ...         return complex(dct['real'], dct['imag'])
    ...     return dct
    ...
    >>> json.loads('{"__complex__": true, "real": 1, "imag": 2}',
    ...     object_hook=as_complex)
    (1+2j)
    >>> from decimal import Decimal
    >>> json.loads('1.1', parse_float=Decimal) == Decimal('1.1')
    True

Specializing JSON object encoding::

    >>> import json
    >>> def encode_complex(obj):
    ...     if isinstance(obj, complex):
    ...         return [obj.real, obj.imag]
    ...     raise TypeError(repr(obj) + " is not JSON serializable")
    ...
    >>> json.dumps(2 + 1j, default=encode_complex)
    '[2.0, 1.0]'
    >>> json.JSONEncoder(default=encode_complex).encode(2 + 1j)
    '[2.0, 1.0]'
    >>> ''.join(json.JSONEncoder(default=encode_complex).iterencode(2 + 1j))
    '[2.0, 1.0]'


Using json.tool from the shell to validate and pretty-print::

    $ echo '{"json":"obj"}' | python -m json.tool
    {
        "json": "obj"
    }
    $ echo '{ 1.2:3.4}' | python -m json.tool
    Expecting property name enclosed in double quotes: line 1 column 3 (char 2)
Bob Ippolito <bob@redivi.com>Deserialize ``fp`` (a ``.read()``-supporting file-like object containing
    a JSON document) to a Python object.

    ``object_hook`` is an optional function that will be called with the
    result of any object literal decode (a ``dict``). The return value of
    ``object_hook`` will be used instead of the ``dict``. This feature
    can be used to implement custom decoders (e.g. JSON-RPC class hinting).

    ``object_pairs_hook`` is an optional function that will be called with the
    result of any object literal decoded with an ordered list of pairs.  The
    return value of ``object_pairs_hook`` will be used instead of the ``dict``.
    This feature can be used to implement custom decoders that rely on the
    order that the key and value pairs are decoded (for example,
    collections.OrderedDict will remember the order of insertion). If
    ``object_hook`` is also defined, the ``object_pairs_hook`` takes priority.

    To use a custom ``JSONDecoder`` subclass, specify it with the ``cls``
    kwarg; otherwise ``JSONDecoder`` is used.

    Deserialize ``s`` (a ``str``, ``bytes`` or ``bytearray`` instance
    containing a JSON document) to a Python object.

    ``object_hook`` is an optional function that will be called with the
    result of any object literal decode (a ``dict``). The return value of
    ``object_hook`` will be used instead of the ``dict``. This feature
    can be used to implement custom decoders (e.g. JSON-RPC class hinting).

    ``object_pairs_hook`` is an optional function that will be called with the
    result of any object literal decoded with an ordered list of pairs.  The
    return value of ``object_pairs_hook`` will be used instead of the ``dict``.
    This feature can be used to implement custom decoders that rely on the
    order that the key and value pairs are decoded (for example,
    collections.OrderedDict will remember the order of insertion). If
    ``object_hook`` is also defined, the ``object_pairs_hook`` takes priority.

    ``parse_float``, if specified, will be called with the string
    of every JSON float to be decoded. By default this is equivalent to
    float(num_str). This can be used to use another datatype or parser
    for JSON floats (e.g. decimal.Decimal).

    ``parse_int``, if specified, will be called with the string
    of every JSON int to be decoded. By default this is equivalent to
    int(num_str). This can be used to use another datatype or parser
    for JSON integers (e.g. float).

    ``parse_constant``, if specified, will be called with one of the
    following strings: -Infinity, Infinity, NaN.
    This can be used to raise an exception if invalid JSON numbers
    are encountered.

    To use a custom ``JSONDecoder`` subclass, specify it with the ``cls``
    kwarg; otherwise ``JSONDecoder`` is used.

    The ``encoding`` argument is ignored and deprecated.

    <module json>utf-16_default_decoderSerialize ``obj`` as a JSON formatted stream to ``fp`` (a
    ``.write()``-supporting file-like object).

    If ``skipkeys`` is true then ``dict`` keys that are not basic types
    (``str``, ``int``, ``float``, ``bool``, ``None``) will be skipped
    instead of raising a ``TypeError``.

    If ``ensure_ascii`` is false, then the strings written to ``fp`` can
    contain non-ASCII characters if they appear in strings contained in
    ``obj``. Otherwise, all such characters are escaped in JSON strings.

    If ``check_circular`` is false, then the circular reference check
    for container types will be skipped and a circular reference will
    result in an ``OverflowError`` (or worse).

    If ``allow_nan`` is false, then it will be a ``ValueError`` to
    serialize out of range ``float`` values (``nan``, ``inf``, ``-inf``)
    in strict compliance of the JSON specification, instead of using the
    JavaScript equivalents (``NaN``, ``Infinity``, ``-Infinity``).

    If ``indent`` is a non-negative integer, then JSON array elements and
    object members will be pretty-printed with that indent level. An indent
    level of 0 will only insert newlines. ``None`` is the most compact
    representation.

    If specified, ``separators`` should be an ``(item_separator, key_separator)``
    tuple.  The default is ``(', ', ': ')`` if *indent* is ``None`` and
    ``(',', ': ')`` otherwise.  To get the most compact JSON representation,
    you should specify ``(',', ':')`` to eliminate whitespace.

    ``default(obj)`` is a function that should return a serializable version
    of obj or raise TypeError. The default simply raises TypeError.

    If *sort_keys* is true (default: ``False``), then the output of
    dictionaries will be sorted by key.

    To use a custom ``JSONEncoder`` subclass (e.g. one that overrides the
    ``.default()`` method to serialize additional types), specify it with
    the ``cls`` kwarg; otherwise ``JSONEncoder`` is used.

    2.0.9raw_decodeJSONDecodeError.__init__JSONObjectSubclass of ValueError with the following additional properties:

    msg: The unformatted error message
    doc: The JSON document being parsed
    pos: The start index of doc where parsing failed
    lineno: The line corresponding to pos
    colno: The column corresponding to pos

    <module json.decoder>PosInfC:\msys64\mingw64\lib\python3.6\json\decoder.pyReturn the Python representation of ``s`` (a ``str`` instance
        containing a JSON document).

        NegInfExpecting ',' delimiter%s: line %d column %d (char %d)_CONSTANTSBACKSLASHScan the string s for a JSON string. End is the index of the
    character in s after the quote that started the JSON string.
    Unescapes all valid JSON string escape sequences and raises ValueError
    on attempt to decode an invalid string. If strict is False then literal
    control characters are allowed in the string.

    Returns a tuple of the decoded string and the index of the character in s
    after the end quote.Unterminated string starting at      ðÿpy_scanstringuni2JSONDecoder.decodeExpecting valueSimple JSON <http://json.org> decoder

    Performs the following translations in decoding by default:

    +---------------+-------------------+
    | JSON          | Python            |
    +===============+===================+
    | object        | dict              |
    +---------------+-------------------+
    | array         | list              |
    +---------------+-------------------+
    | string        | str               |
    +---------------+-------------------+
    | number (int)  | int               |
    +---------------+-------------------+
    | number (real) | float             |
    +---------------+-------------------+
    | true          | True              |
    +---------------+-------------------+
    | false         | False             |
    +---------------+-------------------+
    | null          | None              |
    +---------------+-------------------+

    It also understands ``NaN``, ``Infinity``, and ``-Infinity`` as
    their corresponding ``float`` values, which is outside the JSON spec.

    s_and_endpairs_appendmemo_getInvalid control character {0!r} atImplementation of JSONDecoder
      ø(.*?)(["\\\x00-\x1f])STRINGCHUNKExtra dataJSONDecoder.__init___decode_uXXXX[ \t\n\r]*JSONDecoder.raw_decodeWHITESPACE_STRJSONArrayc_scanstringDecode a JSON document from ``s`` (a ``str`` beginning with
        a JSON document) and return a 2-tuple of the Python
        representation and the index in ``s`` where the document ended.

        This can be used to decode a JSON document from a string that may
        have extraneous data at the end.

        Invalid \uXXXX escapeInvalid \escape: {0!r}``object_hook``, if specified, will be called with the result
        of every JSON object decoded and its return value will be used in
        place of the given ``dict``.  This can be used to provide custom
        deserializations (e.g. to support JSON-RPC class hinting).

        ``object_pairs_hook``, if specified will be called with the result of
        every JSON object decoded with an ordered list of pairs.  The return
        value of ``object_pairs_hook`` will be used instead of the ``dict``.
        This feature can be used to implement custom decoders that rely on the
        order that the key and value pairs are decoded (for example,
        collections.OrderedDict will remember the order of insertion). If
        ``object_hook`` is also defined, the ``object_pairs_hook`` takes
        priority.

        ``parse_float``, if specified, will be called with the string
        of every JSON float to be decoded. By default this is equivalent to
        float(num_str). This can be used to use another datatype or parser
        for JSON floats (e.g. decimal.Decimal).

        ``parse_int``, if specified, will be called with the string
        of every JSON int to be decoded. By default this is equivalent to
        int(num_str). This can be used to use another datatype or parser
        for JSON integers (e.g. float).

        ``parse_constant``, if specified, will be called with one of the
        following strings: -Infinity, Infinity, NaN.
        This can be used to raise an exception if invalid JSON numbers
        are encountered.

        If ``strict`` is false (true is the default), then control
        characters will be allowed inside strings.  Control characters in
        this context are those with character codes in the 0-31 range,
        including ``'\t'`` (tab), ``'\n'``, ``'\r'`` and ``'\0'``.

        Expecting ':' delimiterJSONDecodeError.__reduce__©ÚoÚ_current_indent_levelÚmarkeridÚ
isinstanceÚstrÚ_encoderÚintÚ_intstrÚfloatÚ	_floatstrÚlistÚtupleÚ_iterencode_listÚdictÚ_iterencode_dictÚmarkersÚidÚ
ValueErrorÚ_defaultÚ_iterencodeEncode the given object and yield each string
        representation as available.

        For example::

            for chunk in JSONEncoder().iterencode(bigobject):
                mysocket.write(chunk)

        JSONEncoder.__init__ESCAPE_ASCIIJSONEncoder.defaultJSONEncoder.encode\u{0:04x}_neginfencode_basestring[\x00-\x1f\\"\b\f\n\r\t]©ÚdctÚ_current_indent_levelÚmarkeridÚnewline_indentÚitem_separatorÚfirstÚitemsÚkeyÚvalueÚchunksÚmarkersÚidÚ
ValueErrorÚ_indentÚ_item_separatorÚ
_sort_keysÚ
isinstanceÚstrÚfloatÚ	_floatstrÚintÚ_intstrÚ	_skipkeysÚ_encoderÚ_key_separatorÚlistÚtupleÚ_iterencode_listÚdictÚ_iterencode_dictÚ_iterencodec_encode_basestring_ascii([\\"]|[^\ -~])Return a JSON representation of a Python string

    C:\msys64\mingw64\lib\python3.6\json\encoder.pyReturn an ASCII-only JSON representation of a Python string

    \u{0:04x}\u{1:04x}make_encoderCircular reference detectedExtensible JSON <http://json.org> encoder for Python data structures.

    Supports the following objects and types by default:

    +-------------------+---------------+
    | Python            | JSON          |
    +===================+===============+
    | dict              | object        |
    +-------------------+---------------+
    | list, tuple       | array         |
    +-------------------+---------------+
    | str               | string        |
    +-------------------+---------------+
    | int, float        | number        |
    +-------------------+---------------+
    | True              | true          |
    +-------------------+---------------+
    | False             | false         |
    +-------------------+---------------+
    | None              | null          |
    +-------------------+---------------+

    To extend this to recognize other objects, subclass and implement a
    ``.default()`` method with another method that returns a serializable
    object for ``o`` if possible, otherwise it should call the superclass
    implementation (to raise ``TypeError``).

    Constructor for JSONEncoder, with sensible defaults.

        If skipkeys is false, then it is a TypeError to attempt
        encoding of keys that are not str, int, float or None.  If
        skipkeys is True, such items are simply skipped.

        If ensure_ascii is true, the output is guaranteed to be str
        objects with all incoming non-ASCII characters escaped.  If
        ensure_ascii is false, the output can contain non-ASCII characters.

        If check_circular is true, then lists, dicts, and custom encoded
        objects will be checked for circular references during encoding to
        prevent an infinite recursion (which would cause an OverflowError).
        Otherwise, no such check takes place.

        If allow_nan is true, then NaN, Infinity, and -Infinity will be
        encoded as such.  This behavior is not JSON specification compliant,
        but is consistent with most JavaScript based encoders and decoders.
        Otherwise, it will be a ValueError to encode such floats.

        If sort_keys is true, then the output of dictionaries will be
        sorted by key; this is useful for regression tests to ensure
        that JSON serializations can be compared on a day-to-day basis.

        If indent is a non-negative integer, then JSON array
        elements and object members will be pretty-printed with that
        indent level.  An indent level of 0 will only insert newlines.
        None is the most compact representation.

        If specified, separators should be an (item_separator, key_separator)
        tuple.  The default is (', ', ': ') if *indent* is ``None`` and
        (',', ': ') otherwise.  To get the most compact JSON representation,
        you should specify (',', ':') to eliminate whitespace.

        If specified, default is a function that gets called for objects
        that can't otherwise be serialized.  It should return a JSON encodable
        version of the object or raise a ``TypeError``.

        c_make_encoderpy_encode_basestring_ascii[-ÿ]json.encoderOut of range float values are not JSON compliant: INFINITY<module json.encoder>©ÚlstÚ_current_indent_levelÚmarkeridÚbufÚnewline_indentÚ	separatorÚfirstÚvalueÚchunksÚmarkersÚidÚ
ValueErrorÚ_indentÚ_item_separatorÚ
isinstanceÚstrÚ_encoderÚintÚ_intstrÚfloatÚ	_floatstrÚlistÚtupleÚ_iterencode_listÚdictÚ_iterencode_dictÚ_iterencodepy_encode_basestring.<locals>.replace©ÚmarkersÚ_defaultÚ_encoderÚ_indentÚ	_floatstrÚ_key_separatorÚ_item_separatorÚ
_sort_keysÚ	_skipkeysÚ	_one_shotÚ
ValueErrorÚdictÚfloatÚidÚintÚ
isinstanceÚlistÚstrÚtupleÚ_intstrÚ_iterencode_listÚ_iterencode_dictÚ_iterencodeImplement this method in a subclass such that it returns
        a serializable object for ``o``, or calls the base implementation
        (to raise a ``TypeError``).

        For example, to support arbitrary iterators, you could
        implement default like this::

            def default(self, o):
                try:
                    iterable = iter(o)
                except TypeError:
                    pass
                else:
                    return list(iterable)
                # Let the base class default method raise the TypeError
                return JSONEncoder.default(self, o)

        ESCAPE_DCT_make_iterencodepy_encode_basestring_ascii.<locals>.replace_make_iterencode.<locals>._iterencode_list_make_iterencode.<locals>._iterencode_dict.<locals>.<lambda>Implementation of JSONEncoder
Return a JSON string representation of a Python data structure.

        >>> from json.encoder import JSONEncoder
        >>> JSONEncoder().encode({"foo": ["bar", "baz"]})
        '{"foo": ["bar", "baz"]}'

        HAS_UTF8Object of type '%s' is not JSON serializableJSONEncoder.iterencodeJSONEncoder.iterencode.<locals>.floatstr is not a stringpy_make_scanner_scan_oncejson.scanner©ÚstringÚidxÚnextcharÚmÚintegerÚfracÚexpÚresÚparse_stringÚstrictÚparse_objectÚ
_scan_onceÚobject_hookÚobject_pairs_hookÚmemoÚparse_arrayÚmatch_numberÚparse_floatÚ	parse_intÚparse_constantC:\msys64\mingw64\lib\python3.6\json\scanner.py(-?(?:0|[1-9]\d*))(\.\d+)?([eE][-+]?\d+)?py_make_scanner.<locals>._scan_onceNUMBER_RE<module json.scanner>JSON token scanner
c_make_scannerpy_make_scanner.<locals>.scan_once{1, ""([^"]+)"Û!   zFalsezNonezTruezandzaszassertzbreakzclasszcontinuezdefzdelzelifzelsezexceptzfinallyzforzfromzglobalzifzimportzinziszlambdaznonlocalznotzorzpasszraisezreturnztryzwhilezwithzyield#--start keywords--strprogKeywords (from "graminit.c")

This file is automatically generated; please don't muck it up!

To update the symbols in this file, 'cd' to the top directory of
the python source tree after building the interpreter and run:

    ./python Lib/keyword.py
Python/graminit.ctarget does not contain format markers
<module keyword>optfileC:\msys64\mingw64\lib\python3.6\keyword.py#--end keywords--updatecacheClear the cache entirely.Update a cache entry and return its list of lines.
    If something's wrong, print a message, discard the cache entry,
    and return an empty list.C:\msys64\mingw64\lib\python3.6\linecache.pyCache lines from Python source files.

This is intended to read lines from modules imported -- hence if a filename
is not found, it will look down the module search path for a file by
that name.
Seed the cache for filename with module_globals.

    The module loader will be asked for the source only when getlines is
    called, not immediately.

    If there is an entry in the cache already, it is not altered.

    :return: True if a lazy load is registered in the cache,
        otherwise False. To register such a load a module loader with a
        get_source method must be found, the filename must be a cachable
        filename, and the filename must not be already cached.
    clearcacheDiscard cache entries that are out of date.
    (This is not checked upon each call!)<module linecache>Get the lines for a Python source file from the cache.
    Update the cache if it doesn't contain an entry for this file already.LiveView.draw_ailmentLiveView.change_ailmentLiveView.draw_filehtml/guarding_html/dummy_imitation_show_all.svgdraw_pushbackLiveView.draw_guardingbg_crLiveView.draw_backgroundC:\msys64\home\cbper\liveview.pyLiveView.draw_pushbackbgfilenamenew_allocationget_scale_factorLiveView.__init__LiveView.exposehtml/dummy_imitation.svgLiveView.get_scale_factorLiveView.draw_abdomen_backgroundset_bgfilenameLiveView.draw_palpation_locationLiveView.set_bgfilenameparent_window_pushback.svgLiveView.OnStateChange<module liveview>_parse_localenameresetlocalestarcountLocale support module.

The module provides low-level access to the C lib's locale APIs and adds high
level number formatting APIs as well as a locale aliasing engine to complement
these.

The aliasing engine includes support for many commonly used locale names and
maps them to values suitable for passing to the C lib's setlocale() function. It
also includes default encodings for all supported locale names.

category LC_ALL is not supported_strxfrmLocale settings on startup:smb%(?:\((?P<key>.*?)\))?(?P<modifiers>[-#0-9 +*.hlL]*?)[eEfFgGdiouxXcrs%]Converts a string to an integer according to the locale settings.ISO8859-1format() must be given exactly one %%char format specifier, %s not validcurrencysign_posLocale settings after calling setlocale(LC_ALL, ""):_replace_encodinggiven in the OS environment variables._strcolln_sign_posnp_cs_precedeslookup_name<module locale>_strip_paddingcategories Sets the locale for category to the default setting.

        The default setting is determined by calling
        getdefaultlocale(). category defaults to LC_ALL.

    delocalize_setlocale_override_localeconvC:\msys64\mingw64\lib\python3.6\locale.pyenvvarsParses a string as a float according to the locale settings.monetary------------------------------------------------------------------------_locale emulation only supports "C" localelocaletuple Returns a normalized locale code for the given locale
        name.

        The returned locale code is formatted for use with
        setlocale().

        If normalization fails, the original name is returned
        unchanged.

        If the given encoding is not known, the function defaults to
        the default encoding for the locale code just like setlocale()
        does.

    lang_enc%.12gright_spaces strxfrm(string) -> string.
        Returns a string that behaves for cmp locale-aware.
    Return the charset that the user is likely using,
            by looking at environment variables.ISO8859-15   Language: mon_groupingn_cs_precedeslangnameinvalid grouping Parses the locale code for localename and returns the
        result as tuple (language code, encoding).

        The localename is normalized and passed through the locale
        alias engine. A ValueError is raised in case the locale name
        cannot be parsed.

        The language code corresponds to RFC 1766.  code and encoding
        can be None in case the values cannot be determined or are
        unknown to this implementation.

    int_frac_digitsëQ¸	@_grouping_intervalsûz437ÚCÚcr   zenz	ISO8859-1zjiszJIS7zjis7zJIS7zajeczeucJPzkoi8czKOI8-Czmicrosoftcp1251zCP1251zmicrosoftcp1255zCP1255zmicrosoftcp1256zCP1256z88591z	ISO8859-1z88592z	ISO8859-2z88595z	ISO8859-5z885915z
ISO8859-15zasciiz	ISO8859-1zlatin_1z	ISO8859-1z	iso8859_1z	ISO8859-1z
iso8859_10z
ISO8859-10z
iso8859_11z
ISO8859-11z
iso8859_13z
ISO8859-13z
iso8859_14z
ISO8859-14z
iso8859_15z
ISO8859-15z
iso8859_16z
ISO8859-16z	iso8859_2z	ISO8859-2z	iso8859_3z	ISO8859-3z	iso8859_4z	ISO8859-4z	iso8859_5z	ISO8859-5z	iso8859_6z	ISO8859-6z	iso8859_7z	ISO8859-7z	iso8859_8z	ISO8859-8z	iso8859_9z	ISO8859-9z
iso2022_jpzJIS7z	shift_jiszSJISztactiszTACTISzeuc_jpzeucJPzeuc_krzeucKRzutf_8zUTF-8zkoi8_rzKOI8-Rzkoi8_tzKOI8-Tzkoi8_uzKOI8-Uzkz1048zRK1048zcp1251zCP1251zcp1255zCP1255zcp1256zCP12560 localeconv() -> dict.
            Returns numeric and monetary locale-specific parameters.
        defmod_build_localename_init_categoriesLocale defaults as determined by getdefaultlocale():mon_thousands_sepmon_decimal_pointleft_spacessetlocale(LC_ALL, "") does not support the default locale Tries to determine the default locale settings and returns
        them as tuple (language code, encoding).

        According to POSIX, a program which has not called
        setlocale(LC_ALL, "") runs using the portable 'C' locale.
        Calling setlocale(LC_ALL, "") lets it use the default locale as
        defined by the LANG variable. Since we don't want to interfere
        with the current locale setting we thus emulate the behavior
        in the way described above.

        To maintain compatibility with other platforms, not only the
        LANG variable is tested, but a list of variables given as
        envvars parameter. The first found to be defined will be
        used. envvars defaults to the search path used in GNU gettext;
        it must always contain the variable name 'LANG'.

        Except for the code 'C', the language code corresponds to RFC
        1766.  code and encoding can be None in case the values cannot
        be determined.

    Currency formatting is not possible using the 'C' locale.Formats a string in the same way that the % formatting would use,
    but takes the current locale into account.
    Grouping is applied if the third parameter is true.Return the charset that the user is likely using.atoiLocale must be None, a string, or an iterable of two strings -- language code, encoding.Locale settings after calling resetlocale():p_sep_by_spacelast_interval Builds a locale code from the given tuple (language code,
        encoding).

        No aliasing or normalizing takes place.

    currency_symbol_print_localepositive_signp_sign_posnLC_MONETARYÛ   z	getlocalezgetdefaultlocalezgetpreferredencodingzErrorz	setlocalezresetlocalez
localeconvzstrcollzstrxfrmzstrzatofzatoizformatzformat_stringzcurrencyz	normalizezLC_CTYPEz
LC_COLLATEzLC_TIMEzLC_MONETARYz
LC_NUMERICzLC_ALLzCHAR_MAXint_curr_symbolReturns the locale-aware substitution of a %? specifier
    (percent).

    additional is for format strings which contain one or more
    '*' modifiers.ûi6  zaf_ZAi  zsq_ALi  zgsw_FRi^  zam_ETi  zar_SAi  zar_IQi  zar_EGi  zar_LYi  zar_DZi  zar_MAi  zar_TNi   zar_OMi$  zar_YEi(  zar_SYi,  zar_JOi0  zar_LBi4  zar_KWi8  zar_AEi<  zar_BHi@  zar_QAi+  zhy_AMiM  zas_INi,  zaz_AZi,  zaz_AZim  zba_RUi-  zeu_ESi#  zbe_BYiE  zbn_INi   zbs_BAi  zbs_BAi~  zbr_FRi  zbg_BGi  zca_ESé   zzh_CHSi  zzh_TWi  zzh_CNi  zzh_HKi  zzh_SGi  zzh_MOi|  zzh_CHTi  zco_FRi  zhr_HRi  zhr_BAi  zcs_CZi  zda_DKi  zgbz_AFie  zdiv_MVi  znl_NLi  znl_BEi	  zen_USi	  zen_GBi	  zen_AUi	  zen_CAi	  zen_NZi	  zen_IEi	  zen_ZAi	   zen_JAi	$  zen_CBi	(  zen_BZi	,  zen_TTi	0  zen_ZWi	4  zen_PHi	@  zen_INi	D  zen_MYi	H  zen_INi%  zet_EEi8  zfo_FOid  zfil_PHi  zfi_FIi  zfr_FRi  zfr_BEi  zfr_CAi  zfr_CHi  zfr_LUi  zfr_MCib  zfy_NLiV  zgl_ESi7  zka_GEi  zde_DEi  zde_CHi  zde_ATi  zde_LUi  zde_LIi  zel_GRio  zkl_GLiG  zgu_INih  zha_NGi  zhe_ILi9  zhi_INi  zhu_HUi  zis_ISi!  zid_IDi]  ziu_CAi]  ziu_CAi<  zga_IEi  zit_ITi  zit_CHi  zja_JPiK  zkn_INi?  zkk_KZiS  zkh_KHi  zqut_GTi  zrw_RWiW  zkok_INi  zko_KRi@  zky_KGiT  zlo_LAi&  zlv_LVi'  zlt_LTi.  zdsb_DEin  zlb_LUi/  zmk_MKi>  zms_MYi>  zms_BNiL  zml_INi:  zmt_MTi  zmi_NZiz  zarn_CLiN  zmr_INi|  zmoh_CAiP  zmn_MNiP  zmn_CNia  zne_NPi  znb_NOi  znn_NOi  zoc_FRiH  zor_INic  zps_AFi)  zfa_IRi  zpl_PLi  zpt_BRi  zpt_PTiF  zpa_INik  zquz_BOik  zquz_ECik  zquz_PEi  zro_ROi  zrm_CHi  zru_RUi;$  zsmn_FIi;  zsmj_NOi;  zsmj_SEi;  zse_NOi;  zse_SEi;  zse_FIi;   zsms_FIi;  zsma_NOi;  zsma_SEiO  zsa_INi  zsr_SPi  zsr_BAi  zsr_SPi  zsr_BAi[  zsi_LKil  zns_ZAi2  ztn_ZAi  zsk_SKi$  zsl_SIi
  zes_ESi
  zes_MXi
  zes_ESi
  zes_GTi
  zes_CRi
  zes_PAi
  zes_DOi
   zes_VEi
$  zes_COi
(  zes_PEi
,  zes_ARi
0  zes_ECi
4  zes_CLi
8  zes_URi
<  zes_PYi
@  zes_BOi
D  zes_SVi
H  zes_HNi
L  zes_NIi
P  zes_PRi
T  zes_USiA  zsw_KEi  zsv_SEi  zsv_FIiZ  zsyr_SYi(  ztg_TJi_  ztmz_DZiI  zta_INiD  ztt_RUiJ  zte_INi  zth_THiQ  zbo_BTiQ  zbo_CNi  ztr_TRiB  ztk_TMi  zug_CNi"  zuk_UAi.  zwen_DEi   zur_PKi   zur_INiC  zuz_UZiC  zuz_UZi*  zvi_VNiR  zcy_GBi  zwo_SNi4  zxh_ZAi  zsah_RUix  zii_CNij  zyo_NGi5  zzu_ZA0_append_modifiern_sep_by_spaceReturn the charset that the user is likely using,
            according to the system configuration.Formats val according to the currency settings
    in the current locale.locale_alias_builtin_strûza3zaz_AZ.KOI8-Cza3_azzaz_AZ.KOI8-Cz
a3_az.koiczaz_AZ.KOI8-Czaa_djzaa_DJ.ISO8859-1zaa_erzaa_ER.UTF-8zaa_etzaa_ET.UTF-8zafzaf_ZA.ISO8859-1zaf_zazaf_ZA.ISO8859-1zamzam_ET.UTF-8zam_etzam_ET.UTF-8zamericanzen_US.ISO8859-1zan_eszan_ES.ISO8859-15zarzar_AA.ISO8859-6zar_aazar_AA.ISO8859-6zar_aezar_AE.ISO8859-6zar_bhzar_BH.ISO8859-6zar_dzzar_DZ.ISO8859-6zar_egzar_EG.ISO8859-6zar_inzar_IN.UTF-8zar_iqzar_IQ.ISO8859-6zar_jozar_JO.ISO8859-6zar_kwzar_KW.ISO8859-6zar_lbzar_LB.ISO8859-6zar_lyzar_LY.ISO8859-6zar_mazar_MA.ISO8859-6zar_omzar_OM.ISO8859-6zar_qazar_QA.ISO8859-6zar_sazar_SA.ISO8859-6zar_sdzar_SD.ISO8859-6zar_syzar_SY.ISO8859-6zar_tnzar_TN.ISO8859-6zar_yezar_YE.ISO8859-6zarabiczar_AA.ISO8859-6zaszas_IN.UTF-8zas_inzas_IN.UTF-8zast_eszast_ES.ISO8859-15zayc_pezayc_PE.UTF-8zazzaz_AZ.ISO8859-9Ezaz_azzaz_AZ.ISO8859-9Ezaz_az.iso88599ezaz_AZ.ISO8859-9Ezbezbe_BY.CP1251zbe@latinzbe_BY.UTF-8@latinz
be_bg.utf8zbg_BG.UTF-8zbe_byzbe_BY.CP1251zbe_by@latinzbe_BY.UTF-8@latinzbem_zmzbem_ZM.UTF-8zber_dzzber_DZ.UTF-8zber_mazber_MA.UTF-8zbgzbg_BG.CP1251zbg_bgzbg_BG.CP1251zbho_inzbho_IN.UTF-8zbn_bdzbn_BD.UTF-8zbn_inzbn_IN.UTF-8zbo_cnzbo_CN.UTF-8zbo_inzbo_IN.UTF-8zbokmalznb_NO.ISO8859-1u   bokmÃ¥lznb_NO.ISO8859-1zbrzbr_FR.ISO8859-1zbr_frzbr_FR.ISO8859-1zbrx_inzbrx_IN.UTF-8zbszbs_BA.ISO8859-2zbs_bazbs_BA.ISO8859-2z	bulgarianzbg_BG.CP1251zbyn_erzbyn_ER.UTF-8ÚcÚCzc-frenchzfr_CA.ISO8859-1zc.asciir   zc.enr   z
c.iso88591zen_US.ISO8859-1zc.utf8zen_US.UTF-8zc_cr   zc_c.cr   zcazca_ES.ISO8859-1zca_adzca_AD.ISO8859-1zca_eszca_ES.ISO8859-1zca_es@valenciazca_ES.ISO8859-15@valenciazca_frzca_FR.ISO8859-1zca_itzca_IT.ISO8859-1zcatalanzca_ES.ISO8859-1zcextendzen_US.ISO8859-1z	chinese-szzh_CN.eucCNz	chinese-tzzh_TW.eucTWzcrh_uazcrh_UA.UTF-8zcroatianzhr_HR.ISO8859-2zcszcs_CZ.ISO8859-2zcs_cszcs_CZ.ISO8859-2zcs_czzcs_CZ.ISO8859-2zcsb_plzcsb_PL.UTF-8zcv_ruzcv_RU.UTF-8zcyzcy_GB.ISO8859-1zcy_gbzcy_GB.ISO8859-1zczzcs_CZ.ISO8859-2zcz_czzcs_CZ.ISO8859-2zczechzcs_CZ.ISO8859-2zdazda_DK.ISO8859-1zda_dkzda_DK.ISO8859-1zdanishzda_DK.ISO8859-1zdanskzda_DK.ISO8859-1zdezde_DE.ISO8859-1zde_atzde_AT.ISO8859-1zde_bezde_BE.ISO8859-1zde_chzde_CH.ISO8859-1zde_dezde_DE.ISO8859-1z
de_li.utf8zde_LI.UTF-8zde_luzde_LU.ISO8859-1zdeutschzde_DE.ISO8859-1zdoi_inzdoi_IN.UTF-8zdutchznl_NL.ISO8859-1zdutch.iso88591znl_BE.ISO8859-1zdv_mvzdv_MV.UTF-8zdz_btzdz_BT.UTF-8zeezee_EE.ISO8859-4zee_eezee_EE.ISO8859-4zeestizet_EE.ISO8859-1zelzel_GR.ISO8859-7zel_cyzel_CY.ISO8859-7zel_grzel_GR.ISO8859-7z
el_gr@eurozel_GR.ISO8859-15zenzen_US.ISO8859-1zen_agzen_AG.UTF-8zen_auzen_AU.ISO8859-1zen_bezen_BE.ISO8859-1zen_bwzen_BW.ISO8859-1zen_cazen_CA.ISO8859-1zen_dkzen_DK.ISO8859-1z
en_dl.utf8zen_DL.UTF-8zen_gbzen_GB.ISO8859-1zen_hkzen_HK.ISO8859-1zen_iezen_IE.ISO8859-1zen_inzen_IN.ISO8859-1zen_ngzen_NG.UTF-8zen_nzzen_NZ.ISO8859-1zen_phzen_PH.ISO8859-1zen_sgzen_SG.ISO8859-1zen_ukzen_GB.ISO8859-1zen_uszen_US.ISO8859-1zen_us@euro@eurozen_US.ISO8859-15zen_zazen_ZA.ISO8859-1zen_zmzen_ZM.UTF-8zen_zwzen_ZW.ISO8859-1z
en_zw.utf8zen_ZS.UTF-8zeng_gbzen_GB.ISO8859-1zenglishzen_EN.ISO8859-1z
english_ukzen_GB.ISO8859-1zenglish_united-stateszen_US.ISO8859-1zenglish_united-states.437r   z
english_uszen_US.ISO8859-1zeozeo_XX.ISO8859-3zeo.utf8zeo.UTF-8zeo_eozeo_EO.ISO8859-3z
eo_us.utf8zeo_US.UTF-8zeo_xxzeo_XX.ISO8859-3zeszes_ES.ISO8859-1zes_arzes_AR.ISO8859-1zes_bozes_BO.ISO8859-1zes_clzes_CL.ISO8859-1zes_cozes_CO.ISO8859-1zes_crzes_CR.ISO8859-1zes_cuzes_CU.UTF-8zes_dozes_DO.ISO8859-1zes_eczes_EC.ISO8859-1zes_eszes_ES.ISO8859-1zes_gtzes_GT.ISO8859-1zes_hnzes_HN.ISO8859-1zes_mxzes_MX.ISO8859-1zes_nizes_NI.ISO8859-1zes_pazes_PA.ISO8859-1zes_pezes_PE.ISO8859-1zes_przes_PR.ISO8859-1zes_pyzes_PY.ISO8859-1zes_svzes_SV.ISO8859-1zes_uszes_US.ISO8859-1zes_uyzes_UY.ISO8859-1zes_vezes_VE.ISO8859-1zestonianzet_EE.ISO8859-1zetzet_EE.ISO8859-15zet_eezet_EE.ISO8859-15zeuzeu_ES.ISO8859-1zeu_eszeu_ES.ISO8859-1zeu_frzeu_FR.ISO8859-1zfazfa_IR.UTF-8zfa_irzfa_IR.UTF-8zfa_ir.isiri3342zfa_IR.ISIRI-3342zff_snzff_SN.UTF-8zfizfi_FI.ISO8859-15zfi_fizfi_FI.ISO8859-15zfil_phzfil_PH.UTF-8zfinnishzfi_FI.ISO8859-1zfozfo_FO.ISO8859-1zfo_fozfo_FO.ISO8859-1zfrzfr_FR.ISO8859-1zfr_bezfr_BE.ISO8859-1zfr_cazfr_CA.ISO8859-1zfr_chzfr_CH.ISO8859-1zfr_frzfr_FR.ISO8859-1zfr_luzfr_LU.ISO8859-1u	   franÃ§aiszfr_FR.ISO8859-1zfre_frzfr_FR.ISO8859-1zfrenchzfr_FR.ISO8859-1zfrench.iso88591zfr_CH.ISO8859-1zfrench_francezfr_FR.ISO8859-1zfur_itzfur_IT.UTF-8zfy_dezfy_DE.UTF-8zfy_nlzfy_NL.UTF-8zgazga_IE.ISO8859-1zga_iezga_IE.ISO8859-1zgalegozgl_ES.ISO8859-1zgalicianzgl_ES.ISO8859-1zgdzgd_GB.ISO8859-1zgd_gbzgd_GB.ISO8859-1zger_dezde_DE.ISO8859-1zgermanzde_DE.ISO8859-1zgerman.iso88591zde_CH.ISO8859-1zgerman_germanyzde_DE.ISO8859-1zgez_erzgez_ER.UTF-8zgez_etzgez_ET.UTF-8zglzgl_ES.ISO8859-1zgl_eszgl_ES.ISO8859-1zgreekzel_GR.ISO8859-7zgu_inzgu_IN.UTF-8zgvzgv_GB.ISO8859-1zgv_gbzgv_GB.ISO8859-1zha_ngzha_NG.UTF-8zhezhe_IL.ISO8859-8zhe_ilzhe_IL.ISO8859-8zhebrewzhe_IL.ISO8859-8zhizhi_IN.ISCII-DEVzhi_inzhi_IN.ISCII-DEVzhi_in.isciidevzhi_IN.ISCII-DEVzhnezhne_IN.UTF-8zhne_inzhne_IN.UTF-8zhrzhr_HR.ISO8859-2zhr_hrzhr_HR.ISO8859-2zhrvatskizhr_HR.ISO8859-2zhsb_dezhsb_DE.ISO8859-2zht_htzht_HT.UTF-8zhuzhu_HU.ISO8859-2zhu_huzhu_HU.ISO8859-2z	hungarianzhu_HU.ISO8859-2zhy_amzhy_AM.UTF-8zhy_am.armscii8zhy_AM.ARMSCII_8ziazia.UTF-8zia_frzia_FR.UTF-8z	icelandiczis_IS.ISO8859-1zidzid_ID.ISO8859-1zid_idzid_ID.ISO8859-1zig_ngzig_NG.UTF-8zik_cazik_CA.UTF-8zinzid_ID.ISO8859-1zin_idzid_ID.ISO8859-1ziszis_IS.ISO8859-1zis_iszis_IS.ISO8859-1z
iso-8859-1zen_US.ISO8859-1ziso-8859-15zen_US.ISO8859-15z	iso8859-1zen_US.ISO8859-1z
iso8859-15zen_US.ISO8859-15z
iso_8859_1zen_US.ISO8859-1ziso_8859_15zen_US.ISO8859-15zitzit_IT.ISO8859-1zit_chzit_CH.ISO8859-1zit_itzit_IT.ISO8859-1zitalianzit_IT.ISO8859-1ziuziu_CA.NUNACOM-8ziu_caziu_CA.NUNACOM-8ziu_ca.nunacom8ziu_CA.NUNACOM-8ziwzhe_IL.ISO8859-8ziw_ilzhe_IL.ISO8859-8z
iw_il.utf8ziw_IL.UTF-8zjazja_JP.eucJPzja_jpzja_JP.eucJPz	ja_jp.euczja_JP.eucJPzja_jp.mscodez
ja_JP.SJISz	ja_jp.pckz
ja_JP.SJISzjapanzja_JP.eucJPzjapanesezja_JP.eucJPzjapanese-euczja_JP.eucJPzjapanese.euczja_JP.eucJPzjp_jpzja_JP.eucJPzkazka_GE.GEORGIAN-ACADEMYzka_gezka_GE.GEORGIAN-ACADEMYzka_ge.georgianacademyzka_GE.GEORGIAN-ACADEMYzka_ge.georgianpszka_GE.GEORGIAN-PSzka_ge.georgianrszka_GE.GEORGIAN-ACADEMYzkk_kzzkk_KZ.RK1048zklzkl_GL.ISO8859-1zkl_glzkl_GL.ISO8859-1zkm_khzkm_KH.UTF-8zknzkn_IN.UTF-8zkn_inzkn_IN.UTF-8zkozko_KR.eucKRzko_krzko_KR.eucKRz	ko_kr.euczko_KR.eucKRzkok_inzkok_IN.UTF-8zkoreanzko_KR.eucKRz
korean.euczko_KR.eucKRzkszks_IN.UTF-8zks_inzks_IN.UTF-8zks_in@devanagari.utf8zks_IN.UTF-8@devanagarizku_trzku_TR.ISO8859-9zkwzkw_GB.ISO8859-1zkw_gbzkw_GB.ISO8859-1zkyzky_KG.UTF-8zky_kgzky_KG.UTF-8zlb_luzlb_LU.UTF-8zlg_ugzlg_UG.ISO8859-10zli_bezli_BE.UTF-8zli_nlzli_NL.UTF-8zlij_itzlij_IT.UTF-8z
lithuanianzlt_LT.ISO8859-13zlozlo_LA.MULELAO-1zlo_lazlo_LA.MULELAO-1zlo_la.cp1133zlo_LA.IBM-CP1133zlo_la.ibmcp1133zlo_LA.IBM-CP1133zlo_la.mulelao1zlo_LA.MULELAO-1zltzlt_LT.ISO8859-13zlt_ltzlt_LT.ISO8859-13zlvzlv_LV.ISO8859-13zlv_lvzlv_LV.ISO8859-13zmag_inzmag_IN.UTF-8zmaizmai_IN.UTF-8zmai_inzmai_IN.UTF-8zmg_mgzmg_MG.ISO8859-15zmhr_ruzmhr_RU.UTF-8zmizmi_NZ.ISO8859-1zmi_nzzmi_NZ.ISO8859-1zmkzmk_MK.ISO8859-5zmk_mkzmk_MK.ISO8859-5zmlzml_IN.UTF-8zml_inzml_IN.UTF-8zmn_mnzmn_MN.UTF-8zmni_inzmni_IN.UTF-8zmrzmr_IN.UTF-8zmr_inzmr_IN.UTF-8zmszms_MY.ISO8859-1zms_myzms_MY.ISO8859-1zmtzmt_MT.ISO8859-3zmt_mtzmt_MT.ISO8859-3zmy_mmzmy_MM.UTF-8znan_tw@latinznan_TW.UTF-8@latinznbznb_NO.ISO8859-1znb_noznb_NO.ISO8859-1znds_deznds_DE.UTF-8znds_nlznds_NL.UTF-8zne_npzne_NP.UTF-8znhn_mxznhn_MX.UTF-8zniu_nuzniu_NU.UTF-8zniu_nzzniu_NZ.UTF-8znlznl_NL.ISO8859-1znl_awznl_AW.UTF-8znl_beznl_BE.ISO8859-1znl_nlznl_NL.ISO8859-1znnznn_NO.ISO8859-1znn_noznn_NO.ISO8859-1znozno_NO.ISO8859-1z
no@nynorskzny_NO.ISO8859-1zno_nozno_NO.ISO8859-1zno_no.iso88591@bokmalzno_NO.ISO8859-1zno_no.iso88591@nynorskzno_NO.ISO8859-1z	norwegianzno_NO.ISO8859-1znrznr_ZA.ISO8859-1znr_zaznr_ZA.ISO8859-1znsoznso_ZA.ISO8859-15znso_zaznso_ZA.ISO8859-15znyzny_NO.ISO8859-1zny_nozny_NO.ISO8859-1znynorskznn_NO.ISO8859-1zoczoc_FR.ISO8859-1zoc_frzoc_FR.ISO8859-1zom_etzom_ET.UTF-8zom_kezom_KE.ISO8859-1zorzor_IN.UTF-8zor_inzor_IN.UTF-8zos_ruzos_RU.UTF-8zpazpa_IN.UTF-8zpa_inzpa_IN.UTF-8zpa_pkzpa_PK.UTF-8zpap_anzpap_AN.UTF-8zpdzpd_US.ISO8859-1zpd_dezpd_DE.ISO8859-1zpd_uszpd_US.ISO8859-1zphzph_PH.ISO8859-1zph_phzph_PH.ISO8859-1zplzpl_PL.ISO8859-2zpl_plzpl_PL.ISO8859-2zpolishzpl_PL.ISO8859-2z
portuguesezpt_PT.ISO8859-1zportuguese_brazilzpt_BR.ISO8859-1zposixr   z
posix-utf2r   zppzpp_AN.ISO8859-1zpp_anzpp_AN.ISO8859-1zps_afzps_AF.UTF-8zptzpt_PT.ISO8859-1zpt_brzpt_BR.ISO8859-1zpt_ptzpt_PT.ISO8859-1zrozro_RO.ISO8859-2zro_rozro_RO.ISO8859-2zromanianzro_RO.ISO8859-2zruzru_RU.UTF-8zru_ruzru_RU.UTF-8zru_uazru_UA.KOI8-Uzrumanianzro_RO.ISO8859-2zrussianzru_RU.ISO8859-5zrwzrw_RW.ISO8859-1zrw_rwzrw_RW.ISO8859-1zsa_inzsa_IN.UTF-8zsat_inzsat_IN.UTF-8zsc_itzsc_IT.UTF-8zsdzsd_IN.UTF-8zsd_inzsd_IN.UTF-8zsd_in@devanagari.utf8zsd_IN.UTF-8@devanagarizsd_pkzsd_PK.UTF-8zse_nozse_NO.UTF-8zserbocroatianzsr_RS.UTF-8@latinzshzsr_RS.UTF-8@latinzsh_ba.iso88592@bosniazsr_CS.ISO8859-2zsh_hrzsh_HR.ISO8859-2zsh_hr.iso88592zhr_HR.ISO8859-2zsh_spzsr_CS.ISO8859-2zsh_yuzsr_RS.UTF-8@latinzshs_cazshs_CA.UTF-8zsizsi_LK.UTF-8zsi_lkzsi_LK.UTF-8zsid_etzsid_ET.UTF-8zsinhalazsi_LK.UTF-8zskzsk_SK.ISO8859-2zsk_skzsk_SK.ISO8859-2zslzsl_SI.ISO8859-2zsl_cszsl_CS.ISO8859-2zsl_sizsl_SI.ISO8859-2zslovakzsk_SK.ISO8859-2zslovenezsl_SI.ISO8859-2z	slovenianzsl_SI.ISO8859-2zso_djzso_DJ.ISO8859-1zso_etzso_ET.UTF-8zso_kezso_KE.ISO8859-1zso_sozso_SO.ISO8859-1zspzsr_CS.ISO8859-5zsp_yuzsr_CS.ISO8859-5zspanishzes_ES.ISO8859-1zspanish_spainzes_ES.ISO8859-1zsqzsq_AL.ISO8859-2zsq_alzsq_AL.ISO8859-2zsq_mkzsq_MK.UTF-8zsrzsr_RS.UTF-8zsr@cyrilliczsr_RS.UTF-8zsr@latnzsr_CS.UTF-8@latinzsr_cszsr_CS.UTF-8zsr_cs.iso88592@latnzsr_CS.ISO8859-2z
sr_cs@latnzsr_CS.UTF-8@latinzsr_mezsr_ME.UTF-8zsr_rszsr_RS.UTF-8z
sr_rs@latnzsr_RS.UTF-8@latinzsr_spzsr_CS.ISO8859-2zsr_yuzsr_RS.UTF-8@latinzsr_yu.cp1251@cyrilliczsr_CS.CP1251zsr_yu.iso88592zsr_CS.ISO8859-2zsr_yu.iso88595zsr_CS.ISO8859-5zsr_yu.iso88595@cyrilliczsr_CS.ISO8859-5zsr_yu.microsoftcp1251@cyrilliczsr_CS.CP1251z
sr_yu.utf8zsr_RS.UTF-8zsr_yu.utf8@cyrilliczsr_RS.UTF-8zsr_yu@cyrilliczsr_RS.UTF-8zsszss_ZA.ISO8859-1zss_zazss_ZA.ISO8859-1zstzst_ZA.ISO8859-1zst_zazst_ZA.ISO8859-1zsvzsv_SE.ISO8859-1zsv_fizsv_FI.ISO8859-1zsv_sezsv_SE.ISO8859-1zsw_kezsw_KE.UTF-8zsw_tzzsw_TZ.UTF-8zswedishzsv_SE.ISO8859-1zszl_plzszl_PL.UTF-8ztazta_IN.TSCII-0zta_inzta_IN.TSCII-0zta_in.tsciizta_IN.TSCII-0zta_in.tscii0zta_IN.TSCII-0zta_lkzta_LK.UTF-8ztezte_IN.UTF-8zte_inzte_IN.UTF-8ztgztg_TJ.KOI8-Cztg_tjztg_TJ.KOI8-Czthzth_TH.ISO8859-11zth_thzth_TH.ISO8859-11zth_th.tactiszth_TH.TIS620zth_th.tis620zth_TH.TIS620zthaizth_TH.ISO8859-11zti_erzti_ER.UTF-8zti_etzti_ET.UTF-8ztig_erztig_ER.UTF-8ztk_tmztk_TM.UTF-8ztlztl_PH.ISO8859-1ztl_phztl_PH.ISO8859-1ztnztn_ZA.ISO8859-15ztn_zaztn_ZA.ISO8859-15ztrztr_TR.ISO8859-9ztr_cyztr_CY.ISO8859-9ztr_trztr_TR.ISO8859-9ztszts_ZA.ISO8859-1zts_zazts_ZA.ISO8859-1zttztt_RU.TATAR-CYRztt_ruztt_RU.TATAR-CYRztt_ru.tatarcyrztt_RU.TATAR-CYRztt_ru@iqtelifztt_RU.UTF-8@iqtelifzturkishztr_TR.ISO8859-9zug_cnzug_CN.UTF-8zukzuk_UA.KOI8-Uzuk_uazuk_UA.KOI8-Uzunivz	en_US.utfz	universalz	en_US.utfzuniversal.utf8@ucs4zen_US.UTF-8zunm_uszunm_US.UTF-8zurzur_PK.CP1256zur_inzur_IN.UTF-8zur_pkzur_PK.CP1256zuzzuz_UZ.UTF-8zuz_uzzuz_UZ.UTF-8zuz_uz@cyrilliczuz_UZ.UTF-8zvezve_ZA.UTF-8zve_zazve_ZA.UTF-8zviz
vi_VN.TCVNzvi_vnz
vi_VN.TCVNz
vi_vn.tcvnz
vi_VN.TCVNzvi_vn.tcvn5712z
vi_VN.TCVNzvi_vn.visciizvi_VN.VISCIIzvi_vn.viscii111zvi_VN.VISCIIzwazwa_BE.ISO8859-1zwa_bezwa_BE.ISO8859-1zwae_chzwae_CH.UTF-8zwal_etzwal_ET.UTF-8zwo_snzwo_SN.UTF-8zxhzxh_ZA.ISO8859-1zxh_zazxh_ZA.ISO8859-1zyizyi_US.CP1255zyi_uszyi_US.CP1255zyo_ngzyo_NG.UTF-8zyue_hkzyue_HK.UTF-8zzhzzh_CN.eucCNzzh_cnzzh_CN.gb2312z
zh_cn.big5z
zh_TW.big5z	zh_cn.euczzh_CN.eucCNzzh_hkzzh_HK.big5hkscszzh_hk.big5hkzzh_HK.big5hkscszzh_sgzzh_SG.GB2312z	zh_sg.gbkz	zh_SG.GBKzzh_twz
zh_TW.big5z	zh_tw.euczzh_TW.eucTWzzh_tw.euctwzzh_TW.eucTWzzuzzu_ZA.ISO8859-1zzu_zazzu_ZA.ISO8859-10negative_sign(undefined)Convert float to string, taking the locale into account. Set the locale for the given category.  The locale can be
        a string, an iterable of two strings (language code and encoding),
        or None.

        Iterables are converted to strings using the locale aliasing
        engine.  Locale strings are passed directly to the C lib.

        category may be given as one of the LC_* values.

    _percent_re strcoll(string,string) -> int.
        Compares two strings according to the locale.
    unknown locale: %s Returns the current setting for the given locale category as
        tuple (language code, encoding).

        category may be one of the LC_* value except LC_ALL. It
        defaults to LC_CTYPE.

        Except for the code 'C', the language code corresponds to RFC
        1766.  code and encoding can be None in case the values cannot
        be determined.

    locale_encoding_aliasParses a string as a normalized number according to the locale settings.ûzgrouping[   é   zcurrency_symbolÚ zn_sign_posnr   zp_cs_precedesr   zn_cs_precedesr   zmon_groupingÛ    zn_sep_by_spacer   zdecimal_pointÚ.znegative_signr   zpositive_signr   zp_sep_by_spacer   zint_curr_symbolr   zp_sign_posnr   zthousands_sepr   zmon_thousands_sepr   zfrac_digitsr   zmon_decimal_pointr   zint_frac_digitsr   0%%.%if Test function.
     setlocale(integer,string=None) -> string.
            Activates/queries locale processing.
           Encoding: _print_locale.<locals>._init_categoriesLogger.criticalC:\msys64\mingw64\lib\python3.6\loggingaloggergetLoggerClassLogger._logAttempt to overwrite %r in LogRecordFilter.filter_fixupChildren
    Return the class to be used when instantiating a logger.
    LoggerAdapter.hasHandlers${asctime}'stream' or 'filename' should not be specified together with 'handlers'Logger.info(unknown file)(unknown function)
        Return the header string for the specified records.
        Û*   zBASIC_FORMATzBufferingFormatterzCRITICALzDEBUGzERRORzFATALzFileHandlerzFilterz	FormatterzHandlerzINFOz	LogRecordzLoggerzLoggerAdapterzNOTSETzNullHandlerzStreamHandlerzWARNzWARNINGzaddLevelNamezbasicConfigzcaptureWarningszcriticalzdebugzdisablezerrorz	exceptionzfatalzgetLevelNamez	getLoggerzgetLoggerClasszinfozlogzmakeLogRecordzsetLoggerClasszshutdownzwarnzwarningzgetLogRecordFactoryzsetLogRecordFactoryz
lastResortzraiseExceptionslogProcessesemittedNoHandlerWarning
        Get a logger with the specified name (channel name), creating it
        if it doesn't yet exist. This name is a dot-separated hierarchical
        name, such as "a", "a.b", "a.b.c" or similar.

        If a PlaceHolder existed for the specified name [i.e. the logger
        didn't exist but a child of it did], replace it with the created
        logger and fix up the parent/child references which pointed to the
        placeholder to now point to the logger.
        Unknown level: %rLogger.log
    Set the factory to be used when instantiating a log record.

    :param factory: A callable which will be called to instantiate
    a log record.
    
        Log 'msg % args' with severity 'INFO'.

        To pass exception information, use the keyword argument exc_info with
        a true value, e.g.

        logger.info("Houston, we have a %s", "interesting problem", exc_info=1)
        FileHandler.close
        Return the creation time of the specified LogRecord as formatted text.

        This method should be called from format() by a formatter which
        wants to make use of a formatted time. This method can be overridden
        in formatters to provide for any specific requirement, but the
        basic behaviour is as follows: if datefmt (a string) is specified,
        it is used with time.strftime() to format the creation time of the
        record. Otherwise, the ISO8601 format is used. The resulting
        string is returned. This function uses a user-configurable function
        to convert the creation time to a tuple. By default, time.localtime()
        is used; to change this for a particular formatter instance, set the
        'converter' attribute to a function with the same signature as
        time.localtime() or time.gmtime(). To change it for all formatters,
        for example if you want all logging times to be shown in GMT,
        set the 'converter' attribute in the Formatter class.
        
        Log 'msg % args' with the integer severity 'level'.

        To pass exception information, use the keyword argument exc_info with
        a true value, e.g.

        logger.log(level, "We have a %s", "mysterious problem", exc_info=1)
        
        Low-level logging routine which creates a LogRecord and then calls
        all the handlers of this logger to handle the record.
        
        Initialize a logging record with interesting information.
        Filterer.removeFilter
    Disable all logging calls of severity 'level' and below.
    NullHandler.createLockNullHandler.handle
        Acquire a thread lock for serializing access to the underlying I/O.
        
        Initialize the handler.
        
        Initialize the formatter with specified format strings.

        Initialize the formatter either with the specified format string, or a
        default as described above. Allow for specialized date formatting with
        the optional datefmt argument (if omitted, you get the ISO8601 format).

        Use a style parameter of '%', '{' or '$' to specify that you want to
        use one of %-formatting, :meth:`str.format` (``{}``) formatting or
        :class:`string.Template` formatting in your format string.

        .. versionchanged:: 3.2
           Added the ``style`` parameter.
        Manager._fixupParentsPlaceHolder.append
        Delegate a log call to the underlying logger, after adding
        contextual information from this adapter instance.
        formatFooterStreamHandler.__init__Handler.get_namehandleError
        Delegate a critical call to the underlying logger.
        
        Ensure that children of the placeholder ph are connected to the
        specified logger.
        
    Filter instances are used to perform arbitrary filtering of LogRecords.

    Loggers and Handlers can optionally use Filter instances to filter
    records as desired. The base filter class only allows events which are
    below a certain point in the logger hierarchy. For example, a filter
    initialized with "A.B" will allow events logged by loggers "A.B",
    "A.B.C", "A.B.C.D", "A.B.D" etc. but not "A.BB", "B.A.B" etc. If
    initialized with the empty string, all events are passed.
    --- Logging error ---

        Initialize with the specified logger being a child of this placeholder.
        Filterer.filter
    Handler instances dispatch logging events to specific destinations.

    The base handler class. Acts as a placeholder which defines the Handler
    interface. Handlers can optionally use Formatter instances to format
    records as desired. By default, no formatter is specified; in this case,
    the 'raw' message as determined by record.message is logged.
    
        See if the underlying logger has any handlers.
        
        Pass a record to all relevant handlers.

        Loop through all handlers for this logger and its parents in the
        logger hierarchy. If no handler was found, output a one-off error
        message to sys.stderr. Stop searching up the hierarchy whenever a
        logger with the "propagate" attribute set to zero is found - that
        will be the last logger whose handlers are called.
        
    Log a message with severity 'WARNING' on the root logger. If the logger has
    no handlers, call basicConfig() to add a console handler with a pre-defined
    format.
    
    This handler does nothing. It's intended to be used to avoid the
    "No handlers could be found for logger XXX" one-off warning. This is
    important for library code, which may contain code to log events. If a user
    of the library does not configure logging, the one-off warning might be
    produced; to avoid this, the library developer simply needs to instantiate
    a NullHandler and add it to the top-level logger of the library module or
    package.
    loggerMap
        Is this logger enabled for level 'level'?
        Logger.__repr___checkLevelloggerDict{levelname}:{name}:{message}
        Get the effective level for the underlying logger.
        _srcfileformatStack
        Release the I/O thread lock.
        LoggerAdapter._logLogged from file %s, line %s

        Emit a record.

        If a formatter is specified, it is used to format the record.
        The record is then written to the stream with a trailing newline.  If
        exception information is present, it is formatted using
        traceback.print_exception and appended to the stream.  If the stream
        has an 'encoding' attribute, it is used to determine how to do the
        output to the stream.
        stack_infohandlerListFileHandler._openLogger.removeHandler
    PlaceHolder instances are used in the Manager logger hierarchy to take
    the place of nodes for which no loggers have been defined. This class is
    intended for internal use only and not as part of the public API.
    Level not an integer or a valid string: %r
        Tidy up any resources used by the handler.

        This version removes the handler from an internal map of handlers,
        _handlers, which is used for handler lookup by name. Subclasses
        should ensure that this gets called from overridden close()
        methods.
        
        Ensure all logging output has been flushed.

        This version does nothing and is intended to be implemented by
        subclasses.
        LoggerAdapter.exception
        Process the logging message and keyword arguments passed in to
        a logging call to insert contextual information. You can either
        manipulate the message itself, the keyword args or both. Return
        the message and kwargs modified (or not) to suit your needs.

        Normally, you'll only need to override this one method in a
        LoggerAdapter subclass for your specific needs.
        dfsFormatter.usesTime
        Initialize the list of filters to be an empty list.
        
        Add the specified logger as a child of this placeholder.
        
    Add a handler to the internal cleanup list using a weak reference.
    
        Initialize a filter.

        Initialize with the name of the logger which, together with its
        children, will have its events allowed through the filter. If no
        name is specified, allow every event.
        
    Return the textual representation of logging level 'level'.

    If the level is one of the predefined levels (CRITICAL, ERROR, WARNING,
    INFO, DEBUG) then you get the corresponding string. If you have
    associated levels with names using addLevelName then the name you have
    associated with 'level' is returned.

    If a numeric value corresponding to one of the defined levels is passed
    in, the corresponding string representation is returned.

    Otherwise, the string "Level %s" % level is returned.
    
    Log 'msg % args' with the integer severity 'level' on the root logger. If
    the logger has no handlers, call basicConfig() to add a console handler
    with a pre-defined format.
    
    Perform any cleanup actions in the logging system (e.g. flushing
    buffers).

    Should be called at application exit.
    
    A base class for loggers and handlers which allows them to share
    common code.
    _startTime
    Associate 'levelName' with 'level'.

    This is used when converting levels to text during message formatting.
    
        Delegate a warning call to the underlying logger.
        
        Call the handlers for the specified record.

        This method is used for unpickled records received from a socket, as
        well as those created locally. Logger-level filtering is applied.
        
        Do whatever it takes to actually log the specified logging record.

        This version is intended to be implemented by subclasses and so
        raises a NotImplementedError.
        _logRecordFactoryHandler.formatbaseFilename
        Format the specified record.

        If a formatter is set, use it. Otherwise, use the default formatter
        for the module.
        
        Return the message for this LogRecord.

        Return the message for this LogRecord after merging any user-supplied
        arguments with the message.
        
    This class is like a StreamHandler using sys.stderr, but always uses
    whatever sys.stderr is currently set to rather than the value of
    sys.stderr at handler construction time.
    Logger.warn
        Log 'msg % args' with severity 'CRITICAL'.

        To pass exception information, use the keyword argument exc_info with
        a true value, e.g.

        logger.critical("Houston, we have a %s", "major disaster", exc_info=1)
        
        Delegate an info call to the underlying logger.
        Logger.exception
    A formatter suitable for formatting a number of records.
    Handler.releaseLogRecord.__str___levelToName
        Delegate a debug call to the underlying logger.
        
        Set the class to be used when instantiating a logger with this Manager.
        
    A root logger is not that different to any other logger, except that
    it must have a logging level and there is only one instance of it in
    the hierarchy.
    
        Initialize the handler.

        If stream is not specified, sys.stderr is used.
        <LogRecord: %s, %s, %s, %s, "%s">07 February 2010
        This method is provided as an extension point for specialized
        formatting of stack information.

        The input data is a string as returned from a call to
        :func:`traceback.print_stack`, but with the last trailing newline
        removed.

        The base implementation just returns the value passed in.
        _defaultFormatternamelen
        Initialize the adapter with a logger and a dict-like object which
        provides contextual information. This constructor signature allows
        easy stacking of LoggerAdapters, if so desired.

        You can effectively pass keyword arguments as shown in the
        following example:

        adapter = LoggerAdapter(someLogger, dict(p1=v1, p2="v2"))
        
        Low-level log implementation, proxied to allow nested logger adapters.
        
        Log 'msg % args' with severity 'DEBUG'.

        To pass exception information, use the keyword argument exc_info with
        a true value, e.g.

        logger.debug("Houston, we have a %s", "thorny problem", exc_info=1)
        LoggerAdapter.setLevel
        Open the current base file with the (original) mode and encoding.
        Return the resulting stream.
        Handler.emitLoggerAdapter.critical
        Emit a record.

        If the stream was not opened because 'delay' was specified in the
        constructor, open it before calling the superclass's emit.
        
        Log 'msg % args' with severity 'WARNING'.

        To pass exception information, use the keyword argument exc_info with
        a true value, e.g.

        logger.warning("Houston, we have a %s", "bit of a problem", exc_info=1)
        ${levelname}:${name}:${message}_handlerList
        Optionally specify a formatter which will be used to format each
        individual record.
        _addHandlerRef
        Set the specified level on the underlying logger.
        StrFormatStyle.formatrootnodeLogger.debugnlen
    Implementation of showwarnings which redirects to logging, which will first
    check to see if the file parameter is None. If a file is specified, it will
    delegate to the original warnings implementation of showwarning. Otherwise,
    it will call warnings.formatwarning and will log the resulting string to a
    warnings logger named "py.warnings" with level logging.WARNING.
    callHandlers
        Conditionally emit the specified logging record.

        Emission depends on filters which may have been added to the handler.
        Wrap the actual emission of the record with acquisition/release of
        the I/O thread lock. Returns whether the filter passed the record for
        emission.
        _StderrHandler.streamFormatter.formatExceptionLogger.__init__
        Open the specified file and use it as the stream for logging.
        _defaultLastResort<%s (%s)>processName
        Determine if a record is loggable by consulting all the filters.

        The default is to allow the record to be logged; any filter can veto
        this and the record is then dropped. Returns a zero value if a record
        is to be dropped, else non-zero.

        .. versionchanged:: 3.2

           Allow filters to be just callables.
        
        Set the factory to be used when instantiating a log record with this
        Manager.
        NullHandler.emitdefault_time_format
    Set the class to be used when instantiating a logger. The class should
    define __init__() such that only a name argument is required, and the
    __init__() should call Logger.__init__()
    LoggerAdapter.getEffectiveLevelasctime_formatHandler.acquirePlaceHolder.__init__'stream' and 'filename' should not be specified togetherCall stack:
<%s %s (%s)>Manager.setLogRecordFactoryManager._fixupChildrenBufferingFormatter.formatHeaderdefault_msec_formatLogRecord.__init__Message: %r
Arguments: %s
Logger.callHandlersLoggerAdapter.__repr__
    Log a message with severity 'ERROR' on the root logger. If the logger has
    no handlers, call basicConfig() to add a console handler with a pre-defined
    format.
    
    Return the factory to be used when instantiating a log record.
    
        Set the logging level of this logger.  level must be an int or a str.
        
        Delegate an error call to the underlying logger.
        linefmtVinay Sajip <vinay_sajip@red-dove.com>LoggerAdapter.debugFormatter.formatStack
    Remove a handler reference from the internal cleanup list.
    sinfoHandler.setLevelrelativeCreatedloggerClassLogRecord.getMessageStringTemplateStyle.usesTimefindCaller
        Format the specified records and return the result as a string.
        Logger.findCaller0.5.1.2Unknown moduleC:\msys64\mingw64\lib\python3.6\logging\__init__.pyUnable to print the message and arguments - possible formatting error.
Use the traceback above to help find the error.
LoggerAdapter.infoFileHandler.__repr__logMultiprocessing
    Log a message with severity 'CRITICAL' on the root logger. If the logger
    has no handlers, call basicConfig() to add a console handler with a
    pre-defined format.
    Formatter.formatTime
        Handle errors which occur during an emit() call.

        This method should be called from handlers when an exception is
        encountered during an emit() call. If raiseExceptions is false,
        exceptions get silently ignored. This is what is mostly wanted
        for a logging system - most users will not care about errors in
        the logging system, they are more interested in application errors.
        You could, however, replace this with a custom handler if you wish.
        The record which was being processed is passed in to this method.
        
    Instances of the Logger class represent a single logging channel. A
    "logging channel" indicates an area of an application. Exactly how an
    "area" is defined is up to the application developer. Since an
    application can have any number of areas, logging channels are identified
    by a unique string. Application areas can be nested (e.g. an area
    of "input processing" might include sub-areas "read CSV files", "read
    XLS files" and "read Gnumeric files"). To cater for this natural nesting,
    channel names are organized into a namespace hierarchy where levels are
    separated by periods, much like the Java or Python package namespace. So
    in the instance given above, channel names might be "input" for the upper
    level, and "input.csv", "input.xls" and "input.gnu" for the sub-levels.
    There is no arbitrary limit to the depth of nesting.
    
        See if this logger has any handlers configured.

        Loop through all handlers for this logger and its parents in the
        logger hierarchy. Return True if a handler was found, else False.
        Stop searching up the hierarchy whenever a logger with the "propagate"
        attribute set to zero is found - that will be the last logger which
        is checked for the existence of handlers.
        
    Log a message with severity 'ERROR' on the root logger, with exception
    information. If the logger has no handlers, basicConfig() is called to add
    a console handler with a pre-defined format.
    PercentStyle_STYLES
        Initialize the manager with the root node of the logger hierarchy.
        asctime_searchhdlrLoggerAdapter.logBufferingFormatter.formatFooter<module logging>
    Do basic configuration for the logging system.

    This function does nothing if the root logger already has handlers
    configured. It is a convenience method intended for use by simple scripts
    to do one-shot configuration of the logging package.

    The default behaviour is to create a StreamHandler which writes to
    sys.stderr, set a formatter using the BASIC_FORMAT format string, and
    add the handler to the root logger.

    A number of optional keyword arguments may be specified, which can alter
    the default behaviour.

    filename  Specifies that a FileHandler be created, using the specified
              filename, rather than a StreamHandler.
    filemode  Specifies the mode to open the file, if filename is specified
              (if filemode is unspecified, it defaults to 'a').
    format    Use the specified format string for the handler.
    datefmt   Use the specified date/time format.
    style     If a format string is specified, use this to specify the
              type of format string (possible values '%', '{', '$', for
              %-formatting, :meth:`str.format` and :class:`string.Template`
              - defaults to '%').
    level     Set the root logger level to the specified level.
    stream    Use the specified stream to initialize the StreamHandler. Note
              that this argument is incompatible with 'filename' - if both
              are present, 'stream' is ignored.
    handlers  If specified, this should be an iterable of already created
              handlers, which will be added to the root handler. Any handler
              in the list which does not have a formatter assigned will be
              assigned the formatter created in this function.

    Note that you could specify a stream created using open(filename, mode)
    rather than passing the filename and mode in. However, it should be
    remembered that StreamHandler does not close its stream (since it may be
    using sys.stdout or sys.stderr), whereas FileHandler closes its stream
    when the handler is closed.

    .. versionchanged:: 3.2
       Added the ``style`` parameter.

    .. versionchanged:: 3.3
       Added the ``handlers`` parameter. A ``ValueError`` is now thrown for
       incompatible arguments (e.g. ``handlers`` specified together with
       ``filename``/``filemode``, or ``filename``/``filemode`` specified
       together with ``stream``, or ``handlers`` specified together with
       ``stream``.
    
        Set the formatter for this handler.
        threadName_loggerClassStack (most recent call last):
logger not derived from logging.Logger: 
    If capture is true, redirect all warnings to the logging package.
    If capture is False, ensure that warnings are not redirected to logging
    but to their original destinations.
    RootLogger.__init__
    A handler class which writes logging records, appropriately formatted,
    to a stream. Note that this class does not close the stream, as
    sys.stdout or sys.stderr may be used.
    $asctime
        Acquire the I/O thread lock.
        Logger.handle
        Remove the specified handler from this logger.
        
        Flushes the stream.
        
        Initialize the logger with the name "root".
        The 'warn' function is deprecated, use 'warning' insteaddefault_formatLogger.hasHandlers
    Return a logger with the specified name, creating it if necessary.

    If no name is specified, return the root logger.
    LoggerAdapter.name
        Initialize the logger with a name and an optional level.
        Logger.warningHandler.set_nameLoggerAdapter.process
        Ensure that there are either loggers or placeholders all the way
        from the specified logger to the root of the logger hierarchy.
        <%s %s(%s)>
        A factory method which can be overridden in subclasses to create
        specialized LogRecords.
        Logger.getChildNo handlers could be found for logger "%s"
_tplUnrecognised argument(s): %sReturn the frame object for the caller's stack frame.Manager.setLoggerClassBufferingFormatter.__init__
    Formatter instances are used to convert a LogRecord to text.

    Formatters need to know how a LogRecord is constructed. They are
    responsible for converting a LogRecord to (usually) a string which can
    be interpreted by either a human or an external system. The base Formatter
    allows a formatting string to be specified. If none is supplied, the
    default value of "%s(message)" is used.

    The Formatter can be initialized with a format string which makes use of
    knowledge of the LogRecord attributes - e.g. the default value mentioned
    above makes use of the fact that the user's message and arguments are pre-
    formatted into a LogRecord's message attribute. Currently, the useful
    attributes in a LogRecord are described by:

    %(name)s            Name of the logger (logging channel)
    %(levelno)s         Numeric logging level for the message (DEBUG, INFO,
                        WARNING, ERROR, CRITICAL)
    %(levelname)s       Text logging level for the message ("DEBUG", "INFO",
                        "WARNING", "ERROR", "CRITICAL")
    %(pathname)s        Full pathname of the source file where the logging
                        call was issued (if available)
    %(filename)s        Filename portion of pathname
    %(module)s          Module (name portion of filename)
    %(lineno)d          Source line number where the logging call was issued
                        (if available)
    %(funcName)s        Function name
    %(created)f         Time when the LogRecord was created (time.time()
                        return value)
    %(asctime)s         Textual time when the LogRecord was created
    %(msecs)d           Millisecond portion of the creation time
    %(relativeCreated)d Time in milliseconds when the LogRecord was created,
                        relative to the time the logging module was loaded
                        (typically at application startup time)
    %(thread)d          Thread ID (if available)
    %(threadName)s      Thread name (if available)
    %(process)d         Process ID (if available)
    %(message)s         The result of record.getMessage(), computed just as
                        the record is emitted
    exc_text
    Release the module-level lock acquired by calling _acquireLock().
    %s,%03dManager.getLoggerLoggerAdapter.__init__emit must be implemented by Handler subclasses
        Format the specified record as text.

        The record's attribute dictionary is used as the operand to a
        string formatting operation which yields the returned string.
        Before formatting the dictionary, a couple of preparatory steps
        are carried out. The message attribute of the record is computed
        using LogRecord.getMessage(). If the formatting string uses the
        time (as determined by a call to usesTime(), formatTime() is
        called to format the event time. If there is exception information,
        it is formatted using formatException() and appended to the message.
        StreamHandler.flushLogger.makeRecord
        Initializes the instance - basically setting the formatter to None
        and the filter list to empty.
        
        Remove the specified filter from this handler.
        StreamHandler.emitLoggerAdapter.manager
        Log 'msg % args' with severity 'ERROR'.

        To pass exception information, use the keyword argument exc_info with
        a true value, e.g.

        logger.error("Houston, we have a %s", "major problem", exc_info=1)
        
        Get a logger which is a descendant to this one.

        This is a convenience method, such that

        logging.getLogger('abc').getChild('def.ghi')

        is the same as

        logging.getLogger('abc.def.ghi')

        It's useful, for example, when the parent logger is named using
        __name__ rather than a literal string.
        _warnings_showwarning
    There is [under normal circumstances] just one Manager instance, which
    holds the hierarchy of loggers.
    _removeHandlerRefLoggerAdapter.warningStyle must be one of: %s
        Check if the format uses the creation time of the record.
        _StderrHandler.__init__PercentStyle.__init__
        Format and return the specified exception information as a string.

        This default implementation just uses
        traceback.print_exception()
        Handler.handleErrorFileHandler.__init__Formatter.formatMessage
        Return the footer string for the specified records.
        Stub.The 'warn' method is deprecated, use 'warning' instead
    A LogRecord instance represents an event being logged.

    LogRecord instances are created every time something is logged. They
    contain all the information pertinent to the event being logged. The
    main information passed in is in msg and args, which are combined
    using str(msg) % args to create the message field of the record. The
    record also includes information such as when the record was created,
    the source line where the logging call was made, and any exception
    information to be logged.
    Filterer.__init__
        Get the effective level for this logger.

        Loop through this logger and its parents in the logger hierarchy,
        looking for a non-zero logging level. Return the first one found.
        
        Find the stack frame of the caller so that we can note the source
        file name, line number and function name.
        
Logging package for Python. Based on PEP 282 and comments thereto in
comp.lang.python.

Copyright (C) 2001-2016 Vinay Sajip. All Rights Reserved.

To use, simply 'import logging' and log away!

        Set the logging level of this handler.  level must be an int or a str.
        %Y-%m-%d %H:%M:%S
        Add the specified filter to this handler.
        Logger.getEffectiveLevel__status__Logger.addHandlerHandler.setFormatterStreamHandler.__repr__Filterer.addFilterPercentStyle.usesTimeisEnabledFor
    Acquire the module-level lock for serializing access to shared data.

    This should be released with _releaseLock().
    level must be an integer
        Convenience method for logging an ERROR with exception information.
        Logger.isEnabledForStringTemplateStyle.format
    Log a message with severity 'DEBUG' on the root logger. If the logger has
    no handlers, call basicConfig() to add a console handler with a pre-defined
    format.
    
    An adapter for loggers which makes it easier to specify contextual
    information in logging output.
    
    Log a message with severity 'INFO' on the root logger. If the logger has
    no handlers, call basicConfig() to add a console handler with a pre-defined
    format.
    Logger.setLevelStringTemplateStyle.__init__
    Make a LogRecord whose attributes are defined by the specified dictionary,
    This function is useful for converting a logging event received over
    a socket connection (which is sent as a dictionary) into a LogRecord
    instance.
    LoggerAdapter.errorLoggerAdapter.isEnabledForFileHandler.emit
        Add the specified handler to this logger.
        PercentStyle.formatlogThreads
        Determine if the specified record is to be logged.

        Is the specified record to be logged? Returns 0 for no, nonzero for
        yes. If deemed appropriate, the record may be modified in-place.
        
    A handler class which writes formatted logging records to disk files.
    Logger.errorA logger name must be a string
        Closes the stream.
        
        Delegate an exception call to the underlying logger.
        LZMAFile.readlineLZMAFile.__init__FORMAT_AUTOLZMAFile.close_lzmaDecompress a block of data.

    Refer to LZMADecompressor's docstring for a description of the
    optional arguments *format*, *check* and *filters*.

    For incremental decompression, use an LZMADecompressor instead.
    Interface to the liblzma compression library.

This module provides a class for reading and writing compressed files,
classes for incremental (de)compression, and convenience functions for
one-shot (de)compression.

These classes and functions support both the XZ and legacy LZMA
container formats, as well as raw compressed data streams.
LZMAFile.writable<module lzma>Compress a block of data.

    Refer to LZMACompressor's docstring for a description of the
    optional arguments *format*, *check*, *preset* and *filters*.

    For incremental compression, use an LZMACompressor instead.
    LZMAFile.tellRead up to size uncompressed bytes from the file.

        If size is negative or omitted, read until EOF is reached.
        Returns b"" if the file is already at EOF.
        Cannot specify a preset compression level when opening a file for readingLZMAFile.filenoÛ$   z
CHECK_NONEzCHECK_CRC32zCHECK_CRC64zCHECK_SHA256zCHECK_ID_MAXzCHECK_UNKNOWNzFILTER_LZMA1zFILTER_LZMA2zFILTER_DELTAz
FILTER_X86zFILTER_IA64z
FILTER_ARMzFILTER_ARMTHUMBzFILTER_POWERPCzFILTER_SPARCzFORMAT_AUTOz	FORMAT_XZzFORMAT_ALONEz
FORMAT_RAWzMF_HC3zMF_HC4zMF_BT2zMF_BT3zMF_BT4z	MODE_FASTzMODE_NORMALzPRESET_DEFAULTzPRESET_EXTREMEzLZMACompressorzLZMADecompressorzLZMAFilez	LZMAErrorzopenzcompressz
decompresszis_check_supportedWrite a bytes object to the file.

        Returns the number of uncompressed bytes written, which is
        always len(data). Note that due to buffering, the file on disk
        may not reflect the data written until close() is called.
        LZMAFile.peekLZMAFile.read1lz_modeLZMAFile.writeRead up to size uncompressed bytes, while trying to avoid
        making multiple reads from the underlying stream. Reads up to a
        buffer's worth of data if size is negative.

        Returns b"" if the file is at EOF.
        Open an LZMA-compressed file in binary or text mode.

    filename can be either an actual file name (given as a str, bytes,
    or PathLike object), in which case the named file is opened, or it
    can be an existing file object to read from or write to.

    The mode argument can be "r", "rb" (default), "w", "wb", "x", "xb",
    "a", or "ab" for binary mode, or "rt", "wt", "xt", or "at" for text
    mode.

    The format, check, preset and filters arguments specify the
    compression settings, as for LZMACompressor, LZMADecompressor and
    LZMAFile.

    For binary mode, this function is equivalent to the LZMAFile
    constructor: LZMAFile(filename, mode, ...). In this case, the
    encoding, errors and newline arguments must not be provided.

    For text mode, an LZMAFile object is created, and wrapped in an
    io.TextIOWrapper instance with the specified encoding, error
    handling behavior, and line ending(s).

    Open an LZMA-compressed file in binary mode.

        filename can be either an actual file name (given as a str,
        bytes, or PathLike object), in which case the named file is
        opened, or it can be an existing file object to read from or
        write to.

        mode can be "r" for reading (default), "w" for (over)writing,
        "x" for creating exclusively, or "a" for appending. These can
        equivalently be given as "rb", "wb", "xb" and "ab" respectively.

        format specifies the container format to use for the file.
        If mode is "r", this defaults to FORMAT_AUTO. Otherwise, the
        default is FORMAT_XZ.

        check specifies the integrity check to use. This argument can
        only be used when opening a file for writing. For FORMAT_XZ,
        the default is CHECK_CRC64. FORMAT_ALONE and FORMAT_RAW do not
        support integrity checks - for these formats, check must be
        omitted, or be CHECK_NONE.

        When opening a file for reading, the *preset* argument is not
        meaningful, and should be omitted. The *filters* argument should
        also be omitted, except when format is FORMAT_RAW (in which case
        it is required).

        When opening a file for writing, the settings used by the
        compressor can be specified either as a preset compression
        level (with the *preset* argument), or in detail as a custom
        filter chain (with the *filters* argument). For FORMAT_XZ and
        FORMAT_ALONE, the default is to use the PRESET_DEFAULT preset
        level. For FORMAT_RAW, the caller must always specify a filter
        chain; the raw compressor does not support preset compression
        levels.

        preset (if provided) should be an integer in the range 0-9,
        optionally OR-ed with the constant PRESET_EXTREME.

        filters (if provided) should be a sequence of dicts. Each dict
        should have an entry for "id" indicating ID of the filter, plus
        additional entries for options to the filter.
        A file object providing transparent LZMA (de)compression.

    An LZMAFile can act as a wrapper for an existing file object, or
    refer directly to a named file on disk.

    Note that LZMAFile provides a *binary* file interface - data read
    is returned as bytes, and data to be written must be given as bytes.
    Change the file position.

        The new position is specified by offset, relative to the
        position indicated by whence. Possible values for whence are:

            0: start of stream (default): offset must not be negative
            1: current stream position
            2: end of stream; offset must not be positive

        Returns the new file position.

        Note that seeking is emulated, so depending on the parameters,
        this operation may be extremely slow.
        LZMAFile.seekableLZMAFile.readablememlimitLZMAFile.closedCannot specify an integrity check when opening a file for readingC:\msys64\mingw64\lib\python3.6\lzma.pyMenuWindow.reset_active_pagemy_actionsMilestone 5:
Diagnosis Integration
with Hx/PEadd_ui_from_stringButtonsTypeon_menu_choices_toggledOrientationMilestone 4:
Self-Assessment with
Random Ailmentschoice_listMilestone 1:
Depth of PalpationMenuBar.create_ui_managerMenuBar.build_barmenu_xmlMenuBar.on_menu_ab_quitget_widgetno ports to closeSTOCK_QUITmilestone_4_labeladd_actionsMenuBar.on_menu_choices_toggledMenuBar.on_menu_choices_changedMenuBar.add_choices_menu_actionscnc_thread not foundread_menu_xml_listcnc_thread foundpost_assessment_labelnot doing itMilestone 2:
Surface Area Coverage/>
	stopping soundsmilestone_5_labelMessageTypeMenuWindow.hide_disconnection_warningmilestone_1_labelmilestone_2_labeladd_accel_groupC:\msys64\home\cbper\menu.pyopt_lenuimanageraccelgroupMenuBar.read_menu_xmlMenuBar.read_menu_xml_listmenu_xml_stringMenuWindow.show_disconnection_warning/MenuBarActionGroupMenuWindow.__init__ Mende (Sierra Leone)ToggleAction_popup_messageMenuWindow.show_do_not_touch_modalMenuWindow.attach_new_case_observeron_home_clickport_settings.tensioner_portMenuBar.on_home_clicklocale_optionsinsert_action_groupMilestone 3:
Abnormality DetectionMenuBar._popup_messageout_menu_xmlComparative AssessmentoutMenu.xmlddx_practicenum_listlang_dictget_accel_groupMenuBar.add_ab_menu_actionsstopping devicesMessageDialogabMenu.xmlno port settings foundUIManagerVERTICAL<module menu>self_practice/usr/local/etc/httpd/conf/mime.typesûz.azapplication/octet-streamz.aizapplication/postscriptz.aifzaudio/x-aiffz.aifczaudio/x-aiffz.aiffzaudio/x-aiffz.auzaudio/basicz.avizvideo/x-msvideoz.batz
text/plainz.bcpiozapplication/x-bcpioz.binzapplication/octet-streamz.bmpzimage/x-ms-bmpz.cz
text/plainz.cdfzapplication/x-netcdfz.cpiozapplication/x-cpioz.cshzapplication/x-cshz.cssztext/cssz.csvztext/csvz.dllzapplication/octet-streamz.doczapplication/mswordz.dotzapplication/mswordz.dvizapplication/x-dviz.emlzmessage/rfc822z.epszapplication/postscriptz.etxztext/x-setextz.exezapplication/octet-streamz.gifz	image/gifz.gtarzapplication/x-gtarz.hz
text/plainz.hdfzapplication/x-hdfz.htmz	text/htmlz.htmlz	text/htmlz.icozimage/vnd.microsoft.iconz.iefz	image/iefz.jpez
image/jpegz.jpegz
image/jpegz.jpgz
image/jpegz.jszapplication/javascriptz.jsonzapplication/jsonz.kshz
text/plainz.latexzapplication/x-latexz.m1vz
video/mpegz.m3uzapplication/vnd.apple.mpegurlz.m3u8zapplication/vnd.apple.mpegurlz.manzapplication/x-troff-manz.mezapplication/x-troff-mez.mhtzmessage/rfc822z.mhtmlzmessage/rfc822z.mifzapplication/x-mifz.movzvideo/quicktimez.moviezvideo/x-sgi-moviez.mp2z
audio/mpegz.mp3z
audio/mpegz.mp4z	video/mp4z.mpaz
video/mpegz.mpez
video/mpegz.mpegz
video/mpegz.mpgz
video/mpegz.mszapplication/x-troff-msz.nczapplication/x-netcdfz.nwszmessage/rfc822z.ozapplication/octet-streamz.objzapplication/octet-streamz.odazapplication/odaz.p12zapplication/x-pkcs12z.p7czapplication/pkcs7-mimez.pbmzimage/x-portable-bitmapz.pdfzapplication/pdfz.pfxzapplication/x-pkcs12z.pgmzimage/x-portable-graymapz.plz
text/plainz.pngz	image/pngz.pnmzimage/x-portable-anymapz.potzapplication/vnd.ms-powerpointz.ppazapplication/vnd.ms-powerpointz.ppmzimage/x-portable-pixmapz.ppszapplication/vnd.ms-powerpointz.pptzapplication/vnd.ms-powerpointz.pszapplication/postscriptz.pwzzapplication/vnd.ms-powerpointz.pyztext/x-pythonz.pyczapplication/x-python-codez.pyozapplication/x-python-codez.qtzvideo/quicktimez.razaudio/x-pn-realaudioz.ramzapplication/x-pn-realaudioz.raszimage/x-cmu-rasterz.rdfzapplication/xmlz.rgbzimage/x-rgbz.roffzapplication/x-troffz.rtxztext/richtextz.sgmztext/x-sgmlz.sgmlztext/x-sgmlz.shzapplication/x-shz.sharzapplication/x-sharz.sndzaudio/basicz.sozapplication/octet-streamz.srczapplication/x-wais-sourcez.sv4cpiozapplication/x-sv4cpioz.sv4crczapplication/x-sv4crcz.svgzimage/svg+xmlz.swfzapplication/x-shockwave-flashz.tzapplication/x-troffz.tarzapplication/x-tarz.tclzapplication/x-tclz.texzapplication/x-texz.texizapplication/x-texinfoz.texinfozapplication/x-texinfoz.tifz
image/tiffz.tiffz
image/tiffz.trzapplication/x-troffz.tsvztext/tab-separated-valuesz.txtz
text/plainz.ustarzapplication/x-ustarz.vcfztext/x-vcardz.wavzaudio/x-wavz.webmz
video/webmz.wizzapplication/mswordz.wsdlzapplication/xmlz.xbmzimage/x-xbitmapz.xlbzapplication/vnd.ms-excelz.xlszapplication/vnd.ms-excelz.xmlztext/xmlz.xpdlzapplication/xmlz.xpmzimage/x-xpixmapz.xslzapplication/xmlz.xwdzimage/x-xwindowdumpz.zipzapplication/zip0/etc/httpd/mime.typestypes_map_invMimeTypesREG_SZread_windows_registry/usr/local/lib/netscape/mime.types.ZAdd a mapping between a type and an extension.

        When the extension is already known, the new
        type will replace the old one. When the type
        is already known the extension will be added
        to the list of known extensions.

        If strict is true, information will be added to
        list of standard types, else to the list of non-standard
        types.
        image/jpgMimeTypes.read_windows_registry.<locals>.enum_typessuffix_mapC:\msys64\mingw64\lib\python3.6\mimetypes.pytext/xul<module mimetypes>guess_all_extensionsGuess the extensions for a file based on its MIME type.

    Return value is a list of strings giving the possible filename
    extensions, including the leading dot ('.').  The extension is not
    guaranteed to have been associated with any particular data
    stream, but would be mapped to the MIME type `type' by
    guess_type().  If no extension can be guessed for `type', None
    is returned.

    Optional `strict' argument when false adds a bunch of commonly found,
    but non-standard types.
    Guess the extensions for a file based on its MIME type.

        Return value is a list of strings giving the possible filename
        extensions, including the leading dot ('.').  The extension is not
        guaranteed to have been associated with any particular data stream,
        but would be mapped to the MIME type `type' by guess_type().

        Optional `strict' argument when false adds a bunch of commonly found,
        but non-standard types.
        common_typesmimedb/etc/apache/mime.types.svg.gz.tazread_mime_typesMimeTypes.guess_typeMimeTypes.guess_all_extensionsGuess the extension for a file based on its MIME type.

    Return value is a string giving a filename extension, including the
    leading dot ('.').  The extension is not guaranteed to have been
    associated with any particular data stream, but would be mapped to the
    MIME type `type' by guess_type().  If no extension can be guessed for
    `type', None is returned.

    Optional `strict' argument when false adds a bunch of commonly found,
    but non-standard types.
    
        Load the MIME types database from Windows registry.

        If strict is true, information will be added to
        list of standard types, else to the list of non-standard
        types.
        Add a mapping between a type and an extension.

    When the extension is already known, the new
    type will replace the old one. When the type
    is already known the extension will be added
    to the list of known extensions.

    If strict is true, information will be added to
    list of standard types, else to the list of non-standard
    types.
    subkeyMimeTypes.guess_extensionknownfiles.picsubkeyname.midiContent TypeMimeTypes.add_type
        Read a single mime.types-format file.

        If strict is true, information will be added to
        list of standard types, else to the list of non-standard
        types.
        /usr/local/etc/mime.types/etc/apache2/mime.typesEnumKeyapplication/rtfMimeTypes.__init__image/pictreadfp.rtf.pictMIME-types datastore.

    This datastore can handle information from mime.types-style files
    and supports basic determination of MIME type from a filename or
    URL, and can guess a reasonable extension given a MIME type.
    .xulHKEY_CLASSES_ROOTMimeTypes.readfp.pctGuess the type of a file based on its URL.

    Return value is a tuple (type, encoding) where type is None if the
    type can't be guessed (no or unknown suffix) or a string of the
    form type/subtype, usable for a MIME Content-type header; and
    encoding is None for no encoding or the name of the program used
    to encode (e.g. compress or gzip).  The mappings are table
    driven.  Encoding suffixes are case sensitive; type suffixes are
    first tried case sensitive, then case insensitive.

    The suffixes .tgz, .taz and .tz (case sensitive!) are all mapped
    to ".tar.gz".  (This is table-driven too, using the dictionary
    suffix_map).

    Optional `strict' argument when false adds a bunch of commonly found, but
    non-standard types.
    
        Read a single mime.types-format file, specified by pathname.

        If strict is true, information will be added to
        list of standard types, else to the list of non-standard
        types.
        encodings_maphkcrGuess the MIME type of a file.

This module defines two useful functions:

guess_type(url, strict=True) -- guess the MIME type and encoding of a URL.

guess_extension(type, strict=True) -- guess the extension for a given MIME type.

It also contains the following, for tuning the behavior:

Data:

knownfiles -- list of files to parse
inited -- flag set when init() has been called
suffix_map -- dictionary mapping suffixes to suffixes
encodings_map -- dictionary mapping suffixes to encodings
types_map -- dictionary mapping suffixes to types

Functions:

init([files]) -- parse a list of files, default knownfiles (on Windows, the
  default values are taken from the registry)
read_mime_types(file) -- parse one file, return a dictionary or None
Guess the extension for a file based on its MIME type.

        Return value is a string giving a filename extension,
        including the leading dot ('.').  The extension is not
        guaranteed to have been associated with any particular data
        stream, but would be mapped to the MIME type `type' by
        guess_type().  If no extension can be guessed for `type', None
        is returned.

        Optional `strict' argument when false adds a bunch of commonly found,
        but non-standard types.
        audio/midi_default_mime_typesGuess the type of a file based on its URL.

        Return value is a tuple (type, encoding) where type is None if
        the type can't be guessed (no or unknown suffix) or a string
        of the form type/subtype, usable for a MIME Content-type
        header; and encoding is None for no encoding or the name of
        the program used to encode (e.g. compress or gzip).  The
        mappings are table driven.  Encoding suffixes are case
        sensitive; type suffixes are first tried case sensitive, then
        case insensitive.

        The suffixes .tgz, .taz and .tz (case sensitive!) are all
        mapped to '.tar.gz'.  (This is table-driven too, using the
        dictionary suffix_map.)

        Optional `strict' argument when False adds a bunch of commonly found,
        but non-standard types.
        C:\msys64\mingw64\lib\python3.6\multiprocessing\__init__.py<module multiprocessing>Connection._pollERROR_PIPE_BUSYrbytesready_handlesPipeClient
        Close the bound socket or named pipe of `self`.
        FILE_GENERIC_WRITEreduce_pipe_connectionopenmodeobsizeibsize_mmap_counterPipeConnection._close
    Returns a listener object.

    This is a wrapper for a bound socket which is 'listening' for
    connections, or for a Windows named pipe.
    
    Return the types of the address

    This can be 'AF_INET', 'AF_UNIX', or 'AF_PIPE'
    _CloseHandleshouldn't get here; expected KeyboardInterruptready_objectsFILE_GENERIC_READ_ConnectionBase.close
        Return a connection object connected to the pipe given by `address`
        got end of file during messageWhether there is any input available to be read_xml_dumps
        Connection class based on a Windows named pipe.
        Overlapped I/O is used, so the handles must have been created
        with FILE_FLAG_OVERLAPPED.
        _ConnectionBase._check_readable_new_handleaddress_typeinvalid handlebuffer length < offset + sizeConnectNamedPipe
        Receive bytes data as a bytes object.
        ConnectionWrapper.send_xml_loads_ConnectionBase.__del___ConnectionBase.polladdress type of %r unrecognized_ConnectionBase._check_writablewaithandle_to_objCreateNamedPipeoffset is negativePeekNamedPipe_ConnectionBase._check_closed<module multiprocessing.connection>PIPE_READMODE_MESSAGEobject_list_finalize_pipe_listenerSocketListener.closeoffset too large\\.\pipe\pyc-%d-%d-closesocketPipeListener.acceptPIPE_TYPE_MESSAGEShould not get here_ConnectionBase.filenoMESSAGE_LENGTH_ConnectionBase.readablelistener created with address=%rlast_accepted_last_accepted_ConnectionBase.__enter___init_timeoutERROR_BROKEN_PIPE_ready_errors_handle_queueconnection is read-only_ConnectionBase.send_bytesPIPE_WAITERROR_SEM_TIMEOUTbad message length_get_more_data#WELCOME#PipeListener._finalize_pipe_listenerlistener-File descriptor or handle of the connection#FAILURE#SetNamedPipeHandleState_ConnectionBase.recv_bytesTrue if the connection is writablereduce_connection_unlink
    Returns a connection to the address of a `Listener`
    message = %rSocketClient
    Representation of a socket which is bound to an address and listening
    PipeConnection._recv_bytesauthkey should be a byte string_ConnectionBase.closedPipeConnection._get_more_data
        Representation of a named pipe
        NMPWAIT_WAIT_FOREVERSend a (picklable) object
    Connection class based on an arbitrary file descriptor (Unix only), or
    a socket handle (Windows).
    _bad_message_lengthFamily %s is not recognized.digest sent was rejected
    Return an arbitrary free address for the given family
    WAIT_ABANDONED_0C:\msys64\mingw64\lib\python3.6\multiprocessing\connection.pywaitresWaitNamedPiperebuild_pipe_connectionrecv_bytes_into
    Checks if the family is valid for the current environment.
    _ConnectionBase.writablenwrittenReceive a (picklable) objectXmlListener.accept_got_empty_messagenegative maxlengthov_listERROR_NETNAME_DELETEDPIPE_UNLIMITED_INSTANCESPipeListener._new_handleERROR_MORE_DATASocketListener.acceptdigest received was wrongPIPE_ACCESS_DUPLEXat least one of `readable` and `writable` must be TrueFILE_FLAG_FIRST_PIPE_INSTANCEclosing listener with address=%r
    Return a connection object connected to the socket given by `address`
    ERROR_NO_DATAPipeConnection._send_bytesSocketListener.__init__PipeListener.__init__rebuild_connection_ConnectionBase._bad_message_lengthconnection is write-only_family
        Accept a connection on the bound socket or named pipe of `self`.

        Returns a `Connection` object.
        
        Receive bytes data into a writeable bytes-like object.
        Return the number of bytes read.
        
        Wait till an object in object_list is ready/readable.

        Returns list of those objects in object_list which are ready/readable.
        default_family_WaitSelector#CHALLENGE#
        Returns pair of connection objects at either end of a pipe
        ConnectionWrapper.recvPipeConnection._poll_ConnectionBase.recv_bytes_into_ConnectionBase.__exit__CONNECTION_TIMEOUTfd2WaitForMultipleObjectslistener is closed_exhaustive_waithandle is closedConnectionWrapper.__init___validate_familySend the bytes data from a bytes-like objectunrecognized familyfd1True if the connection is readablenegative offset_ConnectionBase.__init__PIPE_ACCESS_INBOUNDBaseContext.cpu_countProcess._PopenC:\msys64\mingw64\lib\python3.6\multiprocessing\context.pyReturns a manager associated with a running server process

        The managers methods such as `Lock()`, `Condition()` and `Queue()`
        can be used to create shared objects.
        cannot set start method of concrete contextBaseContext.freeze_supportReturns a process pool objectBaseContext.Arrayreducerget_all_start_methodsSpawnProcess._PopenReturns a barrier objectBaseContext.LockReturns a synchronized shared objectBaseContext.PoolReturns a recursive lock objectBaseContext.EventBaseContext.log_to_stderrDefaultContext.get_start_methodReturns a condition objectcannot find context for %rDefaultContext.get_all_start_methodsReturns a shared objectBaseContext.BarrierForkServerProcessReturns an event objectBaseContext.RawArrayBaseContext.ManagerCheck whether this is a fake forked process in a frozen executable.
        If so then run code specified by commandline and exit.
        ForkServerContext_actual_contextSets the path to a python.exe or pythonw.exe binary used to run
        child processes instead of sys.executable when using the 'spawn'
        start method.  Useful for people embedding Python.
        BaseContext.allow_connection_picklingBaseContext.get_start_methodControls how objects will be reduced to a form that can be
        shared with other processes.Returns a shared arrayReturns a non-recursive lock objectBaseContext.SimpleQueueBaseContext._check_availableBaseContext.JoinableQueueSet list of module names to try to load in forkserver process.
        This is really just a hint.
        DefaultContext.set_start_methodForkProcess._Popencontext has already been setReturns a bounded semaphore objectBaseContext.set_start_methodspawning_popenBaseContext.RLockBaseContext.QueueBaseContext.get_loggerBaseContext.set_executableReturn package logger -- if it does not already exist then
        it is created.
        BaseContext.PipeTurn on logging and add a handler which prints to stderrForkServerContext._check_availableReturns a queue objectInstall support for sending connections and sockets
        between processes
        sharedctypesBaseContext.ValueForkContextReturns two connection object connected by a pipeBaseContext.reducerBaseContext.set_forkserver_preloadBaseContext.get_context_concrete_contextspopen_spawn_win32Returns a semaphore objectDefaultContext.get_context<module multiprocessing.context>DefaultContext.__init__forkserver start method not availableBaseContext.RawValuecannot determine number of cpusBaseContext.SemaphoreReturns a synchronized shared arrayBaseContext.BoundedSemaphoreForkServerProcess._PopenSpawnContext%s objects should only be shared between processes through inheritanceBaseContext.ConditionReturns the number of CPUs in the systemDummyProcess.exitcodeC:\msys64\mingw64\lib\python3.6\multiprocessing\dummy\__init__.pyValue._setValue._get_start_calledmultiprocessing.dummy<%s(%r, %r)><module multiprocessing.dummy>DummyProcess.startDummyProcess.__init__<module multiprocessing.dummy.connection>_backlog_queueConnection.pollConnection.__enter__C:\msys64\mingw64\lib\python3.6\multiprocessing\dummy\connection.pyConnection.__exit__modules_names_forkserver_addressForkServer.connect_to_new_process_forkserver_alive_fddesired_keysunexpected EOFshould not get herelistener_fdstfd_inherited_fdsMAXFDS_TO_SENDSIGCHLDmultiprocessing.forkserverForkServer.ensure_runningMake sure that a fork server is running.

        This can be called from any process.  Note that usually a child
        process will just reuse the forkserver started by its parent, so
        ensure_running() will do nothing.
        C:\msys64\mingw64\lib\python3.6\multiprocessing\forkserver.pyalive_r<module multiprocessing.forkserver>ForkServer.__init__Run forkserver.write_unsignedalive_wForkServer.set_forkserver_preloadmodule_names must be a list of stringsallfds_serve_onetoo many fdsRequest forkserver to create a child process.

        Returns a pair of fds (status_r, data_w).  The calling process can read
        the child process's pid and (eventually) its returncode from status_r.
        The calling process should write to data_w the pickled preparation and
        process data.
        ForkServer.ensure_running.<locals>.<genexpr>ForkServer.get_inherited_fdsfrom multiprocessing.forkserver import main; main(%d, %d, %r, **%r)UNSIGNED_STRUCTrfds_forkserver_pid_preload_modulesReturn list of fds inherited from parent process.

        This returns None if the current process was not started by fork
        server.
        ForkServer.set_forkserver_preload.<locals>.<genexpr>_lastpiddupfdArena.__init__Heap._mallocmultiprocessing.heapArena.__getstate___free_pending_blocks_len_to_seqprev_blockBufferWrapper.create_memoryviewPAGESIZEC:\msys64\mingw64\lib\python3.6\multiprocessing\heap.pynew_stoprebuild_arenaHeap._roundup_pending_free_blocks_absorbpym-%d-next_block_arenasallocating a new mmap of length %dHeap._freeBufferWrapper.__init__<module multiprocessing.heap>pym-%d-%sHeap._absorbArena.__setstate___allocated_blocksHeap.malloc_start_to_blockHeap.freetagname_stop_to_blockArena is unpicklable because forking was enabled when it was createdHeap._free_pending_blocksHeap.__init__Cannot find name for new mmapreduce_arenaBaseListProxymethod_to_typeid©ÚselfÚconnÚrecvÚsendÚ	id_to_objÚ
methodnameÚobjÚrequestÚidentÚargsÚkwdsÚexposedÚ	gettypeidÚkeÚ	second_keÚfunctionÚresÚeÚmsgÚtypeidÚridentÚrexposedÚtokenÚfallback_funcÚresultIteratorProxy.throw ... exception was %rserializerBaseProxy.__deepcopy__resetting stdout, stderr
    Send a message to manager using connection `c` and return response
    DECREF %rBarrierProxy.partiesserver not yet startedServer.fallback_getvalue
        Shutdown this process
        ConditionProxy.wait_for
        Create a server, report its address and run it
        EventProxy.wait
        Return representation of the referent (or a fall-back if that fails)
        manager serving at %r#GETVALUEBarrierProxy.brokenhas_keyEventProxy.setsending shutdown message to manager---------------------------------------------------------------------------PoolProxy.__exit__view_type
    Return a list of names of methods of `obj` which do not start with '_'
    ValueProxy.get
        Spawn a server process for this manager object
        _Client#RETURNBaseManager.startServer re-enabled tracking & INCREF %rAcquirerProxy.__exit__BaseManager.__enter__ListProxy.__imul__BaseManager._run_server_increfServer.increfNamespaceProxy.__setattr__rebuild_as_listfallback_str
        Shutdown the manager process; will be registered as a finalizer
        callmethodview_typesDictProxyrequesting creation of a shared %r object; '__str__()' failed>BaseManager._finalize_managerincref failed: %sAcquirerProxy.acquire_ServerListProxy.__iadd__manager still alive after terminateServer.decrefmanager_ownedtls_idsetIteratorProxy.__iter__ArrayProxyproxytypecreate_methodRebuild a proxy owned by manager, token=%rBaseManager._create
        Return the methods of the shared object indicated by token
        public_methodsIteratorProxy.sendSHUTDOWN
        Return server object with serve_forever() method and address attribute
        BaseProxy._connectProcessLocalSet.__init__.<locals>.<lambda>  %s:       refcount=%s
    %s
        Connect manager object to the server process
        <module multiprocessing.managers>IteratorProxy.__next__
        Run the server forever
        _exposed_MakeProxyTypefallback_mapping_callmethodall_methods
        Register a typeid with the manager type
        
    A base for proxies of shared objects
    
    Function used for unpickling proxy objects.
    ProcessLocalSet.__reduce__RemoteError
        Return the number of shared objects
        ValueProxy.setDECREF %r -- manager already shutdownBaseManager._debug_infoServer.dummyBaseManager.register.<locals>.tempBarrierProxy.waitAutoProxy[%s]manager received shutdown messageUnserializable message: %s

        Spawn a new thread to serve this connection
        Server.number_of_objects... decref failed %sBaseProxy.__str__thread %r has no more proxies so closing conn
    Subclass of `BaseManager` which supports a number of shared object types.

    The types registered are those intended for the synchronization
    of threads, plus `dict`, `list` and `Namespace`.

    The `multiprocessing.Manager()` function creates started instances of
    this class.
    
        Return some info about the servers shared objects and connections
        owned_by_manager skipped INCREF of %rmaking connection to manager%r is not a stringBarrierProxy.abort
        Try to call a method of the referrent and return a copy of the result
        _ListenerServer.serve_clientaccept_connection<%s object, typeid %r at %#x>BaseProxy._after_fork_serializeraccepter#TRACEBACKBaseManager.__init__RebuildProxy#ERRORToken.__repr__exception in thread serving %rToken.__getstate__
        Handle a new connection
        _isauto#PROXYBaseManager.start.<locals>.<genexpr>_decref_address_to_localServer.serve_forever_number_of_objectstrying to `terminate()` manager processServer DECREF skipping %rBaseProxy._callmethodBaseManager.joinBaseProxy._decref
        Get a copy of the value of the referent
        RemoteError.__str___manager_serverServer.handle_requestBasePoolProxyBaseProxy.__reduce__Server.accepterNamespaceProxy.__getattr__
---------------------------------------------------------------------------
AcquirerProxy.release
    Return a list of names of methods of `obj`
    EventProxy.is_set ... request was %rPoolProxy.__enter___owned_by_manager_mutexdef %s(self, *args, **kwds):
        return self._callmethod(%r, args, kwds)BaseManager.connectNamespaceProxy.__delattr__ConditionProxy.notify_allUnrecognized message type
    Base class for managers
    id_to_local_proxy_objServer.accept_connection
        Handle requests from the proxies in a particular process/thread
        got EOF -- exiting thread serving %rconvert_to_error_method_to_typeid_
        Return some info --- useful to spot problems with refcounting
        BaseProxy._increfBarrierProxy.reset
        Create a new shared object; return the token and exposed tuple
        reduce_array
        Create a new shared object and return its id
        #UNSERIALIZABLEFailure to send message: %rServer.fallback_reprC:\msys64\mingw64\lib\python3.6\multiprocessing\managers.py
    Server class which runs in a process controlled by a manager object
    %s(typeid=%r, address=%r, id=%r)Server.createBaseProxy.__init__id_to_refcount©zBaseListProxy)z__add__z__contains__z__delitem__z__getitem__z__len__z__mul__z__reversed__z__rmul__z__setitem__zappendzcountzextendzindexzinsertzpopzremovezreversezsortz__imul__BaseManager._number_of_objectsmethod %r of %r object is not in exposed=%rstop_eventthread %r does not own a connection
    Return an auto-proxy for `token`
    EventProxy.clearBaseProxy._getvalueBarrierProxy.n_waitingstarting server thread to service %r
    Type to uniquely indentify a shared object
    IteratorProxy.closeToken.__init__
    Return a proxy type whose methods are given by `exposed`
    listener_clientToken.__setstate__get_serverBaseManager.__exit__BaseProxy.__repr__%r callable returned object with id %r
        Number of shared objects
         ... message was %rServer.debug_infoServer.fallback_str__stderr__BaseManager.get_serverBaseManager.<lambda>disposing of obj with id %rValue.setAcquirerProxy.__enter__
        Join the manager process (if it has been spawned)
        Value.getServer.get_methodsServer.shutdownIMapIteratortask handler sending sentinel to result handlertask handler found thread._state != RUNworker got EOFError or OSError -- exitingtask_batchesIMapIterator.nextdoing set_length()PoolWorkermappererror_callback_unsortedMaybeEncodingErrormaxtasksPool.apply_help_stuff_finishmultiprocessing.poolMapResult.__init__ThreadPool._help_stuff_finish_guarded_task_generationjoining pool workers_result_handler_jobtask handler got sentinelCleanup after any worker processes which have exited due to reaching
        their specified lifetime.  Returns True if any workers were cleaned up.
        result handler got sentinel
        Apply `func` to each element in `iterable`, collecting the results
        in a list that is returned.
        _task_handlerresult handler got EOFError/OSError -- exitingterminating poolApplyResult.readyClean up any exited workers and start replacements for them.
        Pool._map_async
        Helper function to implement map, starmap and their async counterparts.
        wrap_exceptionThreadPool.Process_maxtasksperchildPool.starmap_asyncIMapUnorderedIterator._setPool.__reduce__IMapIterator._setremoving tasks from inqueue until task handler finishedApplyResult.__init__Pool.__exit__joining result handler
        Asynchronous version of `apply()` method.
        
        Equivalent of `map()` -- can be MUCH slower than `Pool.map()`.
        ApplyResult.getjoining worker handlerjob_counterterminating workersC:\msys64\mingw64\lib\python3.6\multiprocessing\pool.py_chunksizeresult_jobApplyResult.successfulstarmapstartaskseqtask handler got OSError when sending sentinelsresult handler found thread._state=TERMINATEPool._maintain_pooljoining task handler_wrap_exceptionworker exiting after %d tasksPool._handle_workersensuring that outqueue is not fullclosing pooltask handler exitingMaybeEncodingError.__str__<module multiprocessing.pool>finalizing pool
    Class which supports an async version of applying functions to arguments.
    MapResult._setProvides a generator of tasks for imap and imap_unordered with
        appropriate handling for iterables which throw exceptions during
        iteration.result handler ignoring extra sentinel_taskqueuepool objects cannot be passed between processes or pickledPool._guarded_task_generationThreadPool._setup_queues_quick_get_handle_tasksPool.terminateIMapIterator.__iter__task handler sending sentinel to workersBring the number of pool processes up to the specified number,
        for use after reaping workers which have exited.
        _worker_handlersuccess_resultIMapIterator._set_lengthPool.imap_unordered.<locals>.<genexpr>Pool.apply_asyncPool not runningPool._repopulate_pool
        Asynchronous version of `starmap()` method.
        _outqueue_terminate_poolPool.imap.<locals>.<genexpr>Pool.__enter__Pool._join_exited_workersPool._terminate_pool_inqueuePool.map_asynchelping task handler/workers to finish
        Like `imap()` method but ordering of results is arbitrary.
        
        Asynchronous version of `map()` method.
        Pool._handle_tasks
        Like `map()` method but the elements of the `iterable` are expected to
        be iterables as well and will be unpacked as arguments. Hence
        `func` and (a, b) becomes func(a, b).
        ThreadPool.__init___quick_putresult handler exiting: len(cache)=%s, thread._state=%sIMapIterator.__init___error_callbackNumber of processes must be at least 1_helper_reraises_exceptioncleaning up worker %dadded worker_get_tasks_number_leftPossible encoding error while sending result: %s_initargs_initializerPool.joinApplyResult.wait<%s: %s>MaybeEncodingError.__init__Pickle-able helper function for use by _guarded_task_generation.Pool._handle_resultsMaybeEncodingError.__repr__worker got sentinel -- exitingPool._get_tasksworker handler exitingPool.closeError sending result: '%s'. Reason: '%s'
        Equivalent of `func(*args, **kwds)`.
        ApplyResult._setWraps possible unpickleable errors, so they can be
    safely sent through the socket.<module multiprocessing.popen_fork>C:\msys64\mingw64\lib\python3.6\multiprocessing\popen_fork.pyC:\msys64\mingw64\lib\python3.6\multiprocessing\popen_forkserver.py<module multiprocessing.popen_forkserver>No support for sending fds between processesmultiprocessing.popen_spawn_posixC:\msys64\mingw64\lib\python3.6\multiprocessing\popen_spawn_posix.py<module multiprocessing.popen_spawn_posix>to_childrhandlewhandlewfd
    Start a subprocess to run the code of a process object
    Popen.__init__.<locals>.<genexpr><module multiprocessing.popen_spawn_win32>C:\msys64\mingw64\lib\python3.6\multiprocessing\popen_spawn_win32.pycan only start a process object created by current processchild process calling self.run()_process_counterPickling an AuthenticationString object is disallowed for security reasons
        Wait until child process terminates
        process exiting with exitcode %d
        Terminate process; sends SIGTERM signal or uses TerminateProcess()
        
        Start child process
        daemonic processes are not allowed to have childrenC:\msys64\mingw64\lib\python3.6\multiprocessing\process.pyBaseProcess.__init__.<locals>.<genexpr>
        Method to be run in sub-process; can be overridden in sub-class
        can only join a child processold_processBaseProcess._Popencan only join a started process<module multiprocessing.process>BaseProcess.daemon
        Set authorization key of process
        
        Set whether process is a daemon
        
    Return process object representing the current process
    BaseProcess.name
        Return identifier (PID) of process or `None` if it has yet to start
        _MainProcess.__init__BaseProcess.terminatecannot start a process twice_current_processprocess has already started
    Process objects represent activity that is run in a separate process

    The class is analogous to `threading.Thread`
    BaseProcess.ident
        Return whether process is a daemon
        
        Return a file descriptor (Unix) or handle (Windows) suitable for
        waiting for process termination.
        stopped[%s]<%s(%s, %s%s)>BaseProcess.startcan only test a child processAuthenticationString.__reduce___parent_pid
    Return list of process objects corresponding to live child processes
    BaseProcess.authkeyProcess %s:
BaseProcess.joinBaseProcess._bootstrapBaseProcess.is_aliveBaseProcess.sentinel_exitcode_to_nameBaseProcess.__repr__
        Return exit code of process or `None` if it has yet to stop
        
        Return whether process is alive
        BaseProcess.exitcodeprocess not startedBaseProcess.run_jointhreadJoinableQueue.__init__Queue.cancel_join_thread()telling queue thread to quitnotemptywritelockignore_epipenacquirenreleasebpopleftwacquirewreleaseQueue._start_threadjoining queue threadJoinableQueue.task_done<module multiprocessing.queues>... done self._thread.start()Queue.__getstate__Queue.join_thread()... queue thread already deadQueue._finalize_close... queue thread joined_wlockJoinableQueue.joinJoinableQueue.__getstate__JoinableQueue.__setstate__starting thread to feed data to pipeSimpleQueue.emptySimpleQueue.__setstate__Queue._after_fork()feeder thread got sentinel -- exitingQueueFeederThreadQueue._finalize_join_joincancelledSimpleQueue.__getstate__Queue._start_thread()doing self._thread.start()_notemptySimpleQueue.puterror in queue thread: %s_opidQueue.close_semQueue._feedJoinableQueue.putC:\msys64\mingw64\lib\python3.6\multiprocessing\queues.pySimpleQueue.getSimpleQueue.__init___is_zero_unfinished_taskspopen_objDupHandle.detachtarget_processcmsg_data_reduce_method_accessPicklable wrapper for a handle.DupHandle.__init__OpenProcesssource_pidSend an array of fds over an AF_UNIX socket.Duplicate a handle.  (target_process is a handle not a pid!)SCM_RIGHTSAbstractReducer.__init__frombytesRegister a reduce function for a type.CMSG_LENcmsg_typeSend a handle over a local connection.ancdataForkingPickler.dumps_C.fACKNOWLEDGEReplacement for pickle.dump() using ForkingPickler.Receive an array of fds over an AF_UNIX socket.Abstract base class for use in implementing a Reduction class
    suitable for use in replacing the standard reduction mechanism
    used in multiprocessing.cmsg_levelForkingPickler.__init__Get the handle.  This should only be called once.bytes_sizeReturn a wrapper for an fd.PROCESS_DUP_HANDLE_reduce_socketdid not receive acknowledgement of fdsource_process_handleC:\msys64\mingw64\lib\python3.6\multiprocessing\reduction.py<module multiprocessing.reduction>_rebuild_socketDUPLICATE_CLOSE_SOURCEForkingPickler.registerreceived %d items of ancdata_copyreg_dispatch_tableSCM_RIGHTS appears not to be availableInvalid data receivedSteal a handle from process identified by source_pid._rebuild_partialReceive a handle over a local connection._extra_reducers_reduce_method_descriptor_reduce_partialPickler subclass used by multiprocessing.DupFd.__init__.<locals>.sendStop the background thread and clear registered resources.DupSocket.detachRegister resource, returning an identifier.new_sock_ResourceSharer.stopnew_fdManager for resouces using background thread._ResourceSharer._serveDupSocket.__init__get_connectionDupFd.detachReturn connection from which to receive identified resource.DupSocket.__init__.<locals>.send_resource_sharerstarting listener and thread for sending handles<module multiprocessing.resource_sharer>DupFd.__init__.<locals>.closeGet the socket.  This should only be called once.Wrapper for fd which can be used at any time.C:\msys64\mingw64\lib\python3.6\multiprocessing\resource_sharer.py_ResourceSharer.__init___ResourceSharer._start_ResourceSharer thread did not stop when asked_ResourceSharer.get_connectionGet the fd.  This should only be called once.Picklable wrapper for a socket._old_locks_afterfork_ResourceSharer._afterfork_ResourceSharer.registerC:\msys64\mingw64\lib\python3.6\multiprocessing\semaphore_tracker.py<module multiprocessing.semaphore_tracker>semaphore_tracker: process died unexpectedly, relaunching.  Some semaphores might leak.SemaphoreTrackerSemaphoreTracker.getfdREGISTERUNREGISTERRun semaphore tracker.Make sure that semaphore tracker process is running.

        This can be run from any process.  Usually a child process will use
        the semaphore created by its parent.SemaphoreTracker.unregisterfrom multiprocessing.semaphore_tracker import main;main(%d){0}:{1}
Unregister name of semaphore with semaphore tracker.SemaphoreTracker.ensure_runningunrecognized command %rSemaphoreTracker.__init__SemaphoreTracker.registersemaphore_tracker: %r: %sname too longsemaphore_tracker: There appear to be %d leaked semaphores to clean up at shutdownRegister name of semaphore with semaphore tracker.SemaphoreTracker._send
    Returns a ctypes array allocated from shared memory
    typecode_to_typenew_objSynchronizedBase.get_lockreduce_ctype
    Return a synchronization wrapper for a Value
    object already synchronizedSynchronizedArray.__setslice__SynchronizedBase.__reduce____getslice__
    Returns a ctypes object allocated from shared memory
    SynchronizedBase.__exit__SynchronizedArray.__getslice__prop_cacherebuild_ctype'%r' has no method 'acquire'SynchronizedBase.__init__make_propertyclass_cacheC:\msys64\mingw64\lib\python3.6\multiprocessing\sharedctypes.pySynchronizedBase.get_objSynchronizedArray.__getitem__SynchronizedBase.__repr__
    Return a synchronization wrapper for a RawArray
    SynchronizedStringSynchronizedBase.__enter___new_valueSynchronizedArray.__len__
def get%s(self):
    self.acquire()
    try:
        return self._obj.%s
    finally:
        self.release()
def set%s(self, value):
    self.acquire()
    try:
        self._obj.%s = value
    finally:
        self.release()
%s = property(get%s, set%s)
multiprocessing.sharedctypesSynchronizedArray.__setitem__synchronized.<locals>.<genexpr><%s wrapper for %s><module multiprocessing.sharedctypes>old_main_modules--multiprocessing-forkpreparation_data
    Set sys.modules['__main__'] to module at main_path
    current_mainmain_content
        An attempt has been made to start a new process before the
        current process has finished its bootstrapping phase.

        This probably means that you are not using fork to start your
        child processes and you have forgotten to use the proper idiom
        in the main module:

            if __name__ == '__main__':
                freeze_support()
                ...

        The "freeze_support()" line can be omitted if the program
        is not going to be frozen to produce an executable.from_parent_check_not_importing_mainfrom multiprocessing.spawn import spawn_main; spawn_main(%s)_fixup_main_from_path
    Return whether commandline indicates we are forking
    
    Run code specified by data received over pipe
    _fixup_main_from_nameinit_main_from_pathmain_mod_name
    Run code for process object if this in not the main process
    get_command_line.<locals>.<genexpr>C:\msys64\mingw64\lib\python3.6\multiprocessing\spawn.py_python_exe
    Returns prefix of command line used for spawning a child process
    is_forkingsys_argv<module multiprocessing.spawn>
    Return info about parent needed by child to unpickle process object
    
    Try to get current process ready to unpickle process object
    ipythonorig_dirinit_main_from_namelog_level_wait_semaphoreSemLock._cleanupSemLock._make_methods<%s(value=%s, maxvalue=%s)>unlink_nowcannot find name for semaphorelock is not ownedBarrier.__setstate__SemLock._make_nameSEMAPHORESemLock.__init__<%s(value=%s)>Semaphore.get_valuenum_waitersRLock.__repr__recreated blocker with handle %rSomeOtherProcess<%s(owner=%s)>Condition.__setstate__multiprocessing.synchronizeSemLock.__init__.<locals>._after_forkBoundedSemaphore.__repr__SemLock.__exit___is_mineBarrier._countRECURSIVE_MUTEXmust acquire() condition before using wait()This platform lacks a functioning sem_open implementation, therefore, the required synchronization primitives needed will not function, see issue 3770.Condition._make_methodsCondition.__getstate__created semlock with handle %sSemLock.__setstate__Barrier._stateSomeOtherThreadRLock.__init__Barrier.__getstate___woken_countSemLock.__getstate__C:\msys64\mingw64\lib\python3.6\multiprocessing\synchronize.pysleepers<module multiprocessing.synchronize>_sleeping_countSemLock.__enter__running the remaining "atexit" finalizersprocess shutting down_afterfork_counter_run_finalizers.<locals>.<lambda>finalizer no longer registered<%s object, dead>calling %sFinalize.__call__ForkAwareLocal.__reduce__ForkAwareLocal.__init__
    Turn on logging and add a handler which prints to stderr
    passfdsfd too largeminpriority<%s object, callback=%sSC_OPEN_MAX_exitingcalling terminate() for daemon %sfinalizer calling %s with args %s and kwargs %sclose_all_fds_exceptrunning all "atexit" finalizers with priority >= 0Finalize.still_activeForkAwareThreadLock.__init__
    Run all finalizers whose exit priority is not None and at least minpriority

    Finalizers with highest priority are called first; finalizers with
    the same priority will be called in reverse order of creation.
    calling join() for process %s_exithandlers_afterfork_registryForkAwareThreadLock.__enter__pymp-ForkAwareThreadLock._resetcreated temp directory %s
    Class which supports object finalization using weakrefs
    
        Return whether this finalizer is still waiting to invoke callback
        _finalizer_counter<module multiprocessing.util>Finalize.__init__errpipe_write
        Cancel finalization of the object
        errpipe_readDEFAULT_LOGGING_FORMAT, exitprority=closerange
    Returns true if the process is shutting down
    LOGGER_NAME, kwargs=, args=finalizer ignored because different process[%(levelname)s/%(processName)s] %(message)sFinalize.__repr__ForkAwareThreadLock.__exit__ForkAwareLocal.__init__.<locals>.<lambda>Finalize.cancelafter forker raised exception %s
        Run the callback unless it has already been called or cancelled
        C:\msys64\mingw64\lib\python3.6\multiprocessing\util.py
    Returns logger used by multiprocessing
    netrc.authenticatorsmalformed %s entry %s terminated by %s.netrcdefault_netrcDump the class data in the format of a .netrc file.An object-oriented interface to .netrc files.NetrcParseError~/.netrc access too permissive: access permissions must restrict access to only the ownertoplevelsaved_lineno<module netrc>NetrcParseError.__init__macdefentrynamefownerbad follower token %rnetrc._parsemacdef ~/.netrc file owner (%s) does not match current user (%s)C:\msys64\mingw64\lib\python3.6\netrc.pyCould not find .netrc: $HOME is not set	password NetrcParseError.__str__netrc.__repr__Exception raised on syntax errors in the .netrc file.uid %smacrosbad toplevel token %rnetrc.__init__	account 
	login %s (%s, line %s)Return a (user, account, password) tuple for given host.C:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\nodesC:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\nodes\__init__.py Assignment related nodes.

The most simple assignment statement ``a = b`` is what we have here. All others
are either re-formulated using temporary variables, e.g. ``a, b = c`` or are
attribute, slice, subscript assignments.

The deletion is a separate node unlike in CPython where assigning to ``NULL`` is
internally what deletion is. But deleting is something entirely different to us
during code generation, which is why we keep them separate.

Tracing assignments in SSA form is the core of optimization for which we use
the traces.

StatementAssignmentVariableName.getVariableNamepropagatedassignment sourceStatementAssignmentVariableName.getDetailsStatementDelVariable.setVariableStatementAssignmentVariable.mayRaiseExceptionStatementDelVariable.getVariableTraceStatementDelVariableName.getVariableNameStatementAssignmentVariable.getStatementNiceNameStatementDelVariableName.getDetailsStatementReleaseVariable.computeStatementStatementDelVariable.__init__setAssignSourceStatementAssignmentVariable.needsReleasePreviousValueStatementDelVariableName.computeStatementStatementAssignmentVariable.isInplaceSuspectStatementAssignmentVariable.getDetailReduced assignment of %s from itself to mere access of it. Precursor of StatementDelVariable used during tree building phase

    StatementAssignmentVariableName.getStatementNiceNameStatementDelVariable.getDetailsStatementDelVariable.mayHaveSideEffectsStatementReleaseVariable.mayRaiseExceptionStatementDelVariableName.__init__StatementReleaseVariable.getDetailsForDisplayStatementAssignmentVariable.getDetailsForDisplayStatementDelVariable.mayRaiseExceptionStatementReleaseVariable.fromXML Deleting a variable.

        All del forms that are not to attributes, slices, subscripts
        use this.

        The target can be any kind of variable, temporary, local, global, etc.

        Deleting a variable is something we trace in a new version, this is
        hidden behind target variable reference, which has this version once
        it can be determined.

        Tolerance means that the value might be unset. That can happen with
        re-formulation of ours, and Python3 exception variables.
    StatementDelVariable.fromXMLStatementDelVariable.getDetailsForDisplayStatementAssignmentVariable.getVariableTraceStatementDelVariable.getPreviousVariableTraceStatementAssignmentVariable.markAsInplaceSuspectStatementAssignmentVariable.computeStatement.<locals>.<lambda>StatementDelVariable.isTolerantStatementAssignmentVariableName.__init__Removed assignment of %s from itself which is known to be defined.StatementDelVariable.computeStatementStatementReleaseVariable.__init__Dropped dead assignment statement to '%s'.Dropped %s assignment statement to '%s'.StatementDelVariable.makeClone Releasing a variable.

        Just release the value, which of course is not to be used afterwards.

        Typical code: Function exit, try/finally release of temporary
        variables.
    StatementAssignmentVariable.makeCloneAssignment raises exception in assigned value, removed assignment.variable assignment statement<module nodes.AssignNodes>STATEMENT_DEL_VARIABLE_NAMEStatementAssignmentVariable.fromXMLlast_traceSide effects of assignments promoted to statements.Removed tolerant 'del' statement of '%s' without effect.StatementReleaseVariable.getVariableStatementAssignmentVariable.__init__StatementAssignmentVariable.setVariableStatementReleaseVariable.getVariableTraceUninitialized %s is not released.StatementReleaseVariable.setVariable Assignment to a variable from an expression.

        All assignment forms that are not to attributes, slices, subscripts
        use this.

        The source might be a complex expression. The target can be any kind
        of variable, temporary, local, global, etc.

        Assigning a variable is something we trace in a new version, this is
        hidden behind target variable reference, which has this version once
        it can be determined.
    StatementReleaseVariable.mayHaveSideEffectsof variable %sStatementAssignmentVariable.getVariableNameStatementAssignmentVariableName.computeStatementC:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\nodes\AssignNodes.py Precursor of StatementAssignmentVariable used during tree building phase

    is_tempSTATEMENT_ASSIGNMENT_VARIABLE_NAMEStatementDelVariable.getVariableNameto variable %sC:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\nodes\AsyncgenNodes.pyExpressionAsyncgenObjectBody.needsGeneratorReturnExitExpressionMakeAsyncgenObject.mayRaiseExceptionExpressionMakeAsyncgenObject.mayHaveSideEffectsEXPRESSION_ASYNCGEN_OBJECT_BODYExpressionMakeAsyncgenObject.getClosureVariableVersionsExpressionAsyncgenObjectBody.needsCreation Nodes for async generator objects and their creations.

Async generator are turned into normal functions that create generator objects,
whose implementation lives here. The creation itself also lives here.

ExpressionMakeAsyncgenObject.getDetailsForDisplay<module nodes.AsyncgenNodes>ExpressionAsyncgenObjectBody.__init__ExpressionAsyncgenObjectBody.needsGeneratorReturnHandlingExpressionAsyncgenObjectBody.markAsNeedsGeneratorReturnHandlingExpressionMakeAsyncgenObject.__init__ExpressionAsyncgenObjectBody.isUnoptimizedExpressionMakeAsyncgenObject.computeExpressionExpressionMakeAsyncgenObject.getCodeObjectExpressionAsyncgenObjectBody.getFunctionNameC:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\nodes\AttributeNodes.py<module nodes.AttributeNodes>ExpressionAttributeLookup.isKnownToBeIterable Looking up an attribute of an object.

        Typically code like: source.attribute_name
    StatementAssignmentAttribute.getAttributeNameStatementAssignmentAttribute.getDetailattribute assignment statementExpressionBuiltinHasattr.__init__attribute del statementExpressionAttributeLookup.setAttributeNameReplaced call to built-in 'getattr' with constant attribute '%s' to mere attribute lookup Special lookup up an attribute of an object.

        Typically from code like this: with source: pass

        These directly go to slots, and are performed for with statements
        of Python2.7 or higher.
    ExpressionBuiltinHasattr.computeExpression.<locals>.<lambda>attribute %s from %sExpressionAttributeLookup.mayRaiseExceptionExpressionAttributeLookup.getAttributeNameStatementDelAttribute.getStatementNiceNameExpressionBuiltinGetattr.computeExpressionStatementDelAttribute.computeStatementExpressionAttributeLookup.__init__ExpressionAttributeLookupSpecial.computeExpressionExpressionBuiltinSetattr.__init__to attribute %s Built-in "setattr".

        Typical code like this: setattr(source, attribute, value)
     Attribute nodes

Knowing attributes of an object is very important, esp. when it comes to 'self'
and objects and classes.

There will be a methods "computeExpression*Attribute" to aid predicting them,
with many variants for setting, deleting, and accessing. Also there is some
complication in the form of special lookups, that won't go through the normal
path, but just check slots.

Due to ``getattr`` and ``setattr`` built-ins, there is also a different in the
computations for objects and for compile time known strings. This reflects what
CPython also does with "tp_getattr" and "tp_getattro".

These nodes are therefore mostly delegating the work to expressions they
work on, and let them decide and do the heavy lifting of optimization
and annotation is happening in the nodes that implement these compute slots.
 Built-in "getattr".

        Typical code like this: getattr(source, attribute, default)

        The default is optional, but computed before the lookup is done.
    StatementAssignmentAttribute.setAttributeNameExpressionBuiltinGetattr.__init__ExpressionAttributeLookup.getDetailsStatementDelAttribute.getDetailsStatementAssignmentAttribute.computeStatementExpressionAttributeLookup.computeExpressionCall to 'hasattr' pre-computed. Deletion of an attribute.

        Typically from code like: del source.attribute_name

        The source may be complex expression. Deleting an attribute has its on
        slot on the source, which gets to decide if it knows it will work or
        not, and what value it will be.
    StatementDelAttribute.setAttributeNameExpressionBuiltinSetattr.computeExpression Assignment to an attribute.

        Typically from code like: source.attribute_name = expression

        Both source and expression may be complex expressions, the source
        is evaluated first. Assigning to an attribute has its on slot on
        the source, which gets to decide if it knows it will work or not,
        and what value it will be.
    StatementDelAttribute.getAttributeNameStatementDelAttribute.__init__StatementAssignmentAttribute.getDetailsStatementAssignmentAttribute.__init__StatementAssignmentAttribute.getStatementNiceNameExpressionBuiltinComplex2.computeExpressionsubnode_imag<module nodes.BuiltinComplexNodes> Node for the calls to the 'complex' built-in.

subnode_realExpressionBuiltinComplex1.computeExpressionExpressionBuiltinComplex1.getTypeShapeExpressionBuiltinComplex1.__init__C:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\nodes\BuiltinComplexNodes.pyExpressionBuiltinComplex2.getTypeShapeExpressionBuiltinComplex2.__init__ExpressionBuiltinChr.isKnownToBeIterable<module nodes.BuiltinDecodingNodes>ExpressionBuiltinOrd.isKnownToBeIterableC:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\nodes\BuiltinDecodingNodes.py Built-in ord/chr nodes

These are good for optimizations, as they give a very well known result. In the case of
'chr', it's one of 256 strings, and in case of 'ord' it's one of 256 numbers, so these can
answer quite a few questions at compile time.

ExpressionBuiltinStaticmethod.computeExpression Built-in staticmethod/classmethod nodes

These are good for optimizations, as they give a very well known result, changing
only the way a class member is being called. Being able to avoid going through a
C call to the built-ins resulting wrapper, will speed up things.
C:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\nodes\BuiltinDecoratorNodes.pyExpressionBuiltinClassmethod.isKnownToBeIterableExpressionBuiltinStaticmethod.isKnownToBeIterableExpressionBuiltinStaticmethod.__init__ExpressionBuiltinClassmethod.getTypeShape<module nodes.BuiltinDecoratorNodes>ExpressionBuiltinClassmethod.computeExpressionExpressionBuiltinClassmethod.__init__ExpressionBuiltinStaticmethod.getTypeShapeExpressionBuiltinDict.hasShapeDictionaryExactExpressionBuiltinDict.hasOnlyConstantArgumentsExpressionBuiltinDict.computeExpression.<locals>.<lambda>ExpressionBuiltinDict.mayRaiseException<module nodes.BuiltinDictNodes>C:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\nodes\BuiltinDictNodes.pyExpressionBuiltinDict.__init__Replace 'dict' call with constant arguments.arg_pairpos_iteration_lengthReplace 'dict' built-in call dictionary creation from arguments.BuiltinIteratorNodes Node for the calls to the 'dict' built-in.

ExpressionBuiltinDict.__init__.<locals>.<genexpr>ExpressionBuiltinId.getTypeShape Format related nodes format/bin/oct/hex/ascii.

These will most often be used for outputs, and the hope is, the type prediction or the
result prediction will help to be smarter, but generally these should not be that much
about performance critical.

ExpressionBuiltinBin.getTypeShapeExpressionBuiltinHex.getTypeShapeRemoved useless 'format' on '%s' value.ExpressionBuiltinAscii.getTypeShapeExpressionBuiltinId.computeExpressionExpressionBuiltinId.extractSideEffectssetFormatSpecExpressionBuiltinFormat.computeExpressionExpressionBuiltinOct.getTypeShapeRemoved id taking for unused result.ExpressionBuiltinId.computeExpressionDropExpressionBuiltinFormat.__init__C:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\nodes\BuiltinFormatNodes.pyExpressionBuiltinId.getIntValueExpressionBuiltinFormat.getTypeShape<module nodes.BuiltinFormatNodes>ExpressionBuiltinId.mayHaveSideEffectsC:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\nodes\BuiltinHashNodes.pyExpressionBuiltinHash.mayRaiseException<module nodes.BuiltinHashNodes>ExpressionBuiltinHash.computeExpressionExpressionBuiltinHash.__init__ Node the calls to the 'hash' built-in.

This is a specific thing, which must be calculated at run time, but we can
predict things about its type, and the fact that it won't raise an exception
for some types, so it is still useful. Also calls to it can be accelerated
slightly.
ExpressionBuiltinInt1.__init__ShapeTypeLongDerivedC:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\nodes\BuiltinIntegerNodes.pybase_only_valueExpressionBuiltinIntLong2Base.computeExpression.<locals>.<lambda>ShapeTypeIntOrLongDerived.getTypeNameExpressionBuiltinInt1.computeExpressionsubnode_base Node for the calls to the 'int' and 'long' (Python2) built-ins.

These are divided into variants for one and two arguments and they have a
common base class, because most of the behavior is the same there. The ones
with 2 arguments only work on strings, and give errors otherwise, the ones
with one argument, use slots, "__int__" and "__long__", so what they do does
largely depend on the arguments slot.
ExpressionBuiltinIntLong2Base.__init__ShapeTypeLongDerived.getTypeNamegetBaseint() missing string argumentExpressionBuiltinLong1.__init__<module nodes.BuiltinIntegerNodes>%s built-in call with only base argumentExpressionBuiltinLong1.computeExpressionExpressionBuiltinLong1.mayRaiseExceptionExpressionBuiltinInt1.getTypeShapeExpressionBuiltinInt2.getTypeShapeExpressionBuiltinLong1.getTypeShapeExpressionBuiltinLong2.getTypeShapeExpressionAsyncIter.isKnownToBeIterableAtMinExpressionBuiltinIter1.mayRaiseExceptionExpressionAsyncNext.computeExpressionExpressionAsyncIter.computeExpressionExpressionBuiltinIter1.mayHaveSideEffectsExpressionAsyncIter.onReleaseExpressionBuiltinIter1.computeExpressionIter1ExpressionBuiltinIter1.isKnownToBeIterableExpressionAsyncIter.extractSideEffectsExpressionBuiltinIter1.canPredictIterationValuesEliminated useless iterator creation.too many values to unpack (expected %d)ExpressionBuiltinIter1.getIterationValueExpressionAsyncIter.mayHaveSideEffectsExpressionBuiltinIter1.onReleaseExpressionBuiltinIter1.getIterationLengthStatementSpecialUnpackCheck.getStatementNiceNamecannot unpack non-iterable %s objectDetermined iteration end check to be always true.ExpressionBuiltinIter1.isKnownToBeIterableAtMinDetermined iteration end check to always raise.iteration check statementExpressionAsyncIter.mayRaiseExceptionExpressionBuiltinIter1.extractSideEffectsExpressionBuiltinIter1.getTypeShape<module nodes.BuiltinIteratorNodes>ExpressionBuiltinIter1.isKnownToBeIterableAtMaxExpressionAsyncNext.__init__C:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\nodes\BuiltinIteratorNodes.pyExpressionAsyncIter.isKnownToBeIterableAtMaxExpressionBuiltinIter2.__init__StatementSpecialUnpackCheck.getCountExpressionBuiltinIter2.getTypeShapeExpressionBuiltinIter1.computeExpressionNext1ExpressionBuiltinIter2.computeExpressionExpressionBuiltinIterForUnpack.simulatorStatementSpecialUnpackCheck.__init__ExpressionBuiltinIter2.computeExpressionIter1ExpressionAsyncIter.getIterationLengthStatementSpecialUnpackCheck.getDetailsStatementSpecialUnpackCheck.computeStatementPridicted 'next' value from iteration.<module nodes.BuiltinLenNodes>ExpressionBuiltinLen.getIntegerValueExpressionBuiltinLen.computeExpressionExpressionBuiltinLen.mayRaiseExceptionC:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\nodes\BuiltinLenNodes.pyExpressionBuiltinLen.getTypeShapeExpressionSpecialUnpack.getDetailsExpressionBuiltinNext1.computeExpressionExpressionBuiltinNext2.computeExpressionExpressionBuiltinNext2.__init__ExpressionSpecialUnpack.getExpected<module nodes.BuiltinNextNodes>ExpressionSpecialUnpack.getCountC:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\nodes\BuiltinNextNodes.pyExpressionSpecialUnpack.__init__ExpressionBuiltinNext1.__init__ Node for the calls to the 'next' built-in and unpacking special next.

    The unpacking next has only special that it raises a different exception
    text, explaining things about its context.
ExpressionBuiltinOpenMixinExpressionBuiltinOpen.__init__ExpressionBuiltinOpenMixin.getTypeShape Node the calls to the 'open' built-in.

This is a rather two sided beast, as it may be read or write. And we would like to be able
to track it, so we can include files into the executable, or write more efficiently.
<module nodes.BuiltinOpenNodes>ExpressionBuiltinOpenMixin.computeExpressionC:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\nodes\BuiltinOpenNodes.py Node the calls to the 'range' built-in.

This is a rather complex beast as it has many cases, is difficult to know if
it's sizable enough to compute, and there are complex cases, where the bad
result of it can be predicted still, and these are interesting for warnings.

ExpressionBuiltinXrange2.getIterationLengthExpressionBuiltinRange3.getIterationLengthExpressionBuiltinRangeBase.getStep<module nodes.BuiltinRangeNodes>ExpressionBuiltinRange2.getIterationValueExpressionBuiltinXrange2.computeExpressionExpressionBuiltinXrangeBase.getTypeShapeExpressionBuiltinRange3.isKnownToBeIterableExpressionBuiltinRangeBase.computeExpressionIter1estimateExpressionBuiltinRange1.getIterationLengthExpressionBuiltinXrangeBase.getLowExpressionBuiltinXrange2.getIterationValueExpressionBuiltinRange3.getIterationValueExpressionBuiltinRangeBase.computeBuiltinSpecExpressionBuiltinRangeBase.__init__ExpressionBuiltinXrangeBase.mayHaveSideEffectsExpressionBuiltinRangeBase.getTruthValueExpressionBuiltinRange3.__init__Replaced 'range' with 'xrange' built-in call.ExpressionBuiltinRange3.canPredictIterationValuesExpressionBuiltinRangeBase.getLowExpressionBuiltinXrange2.__init__ExpressionBuiltinRangeBase.computeBuiltinSpec.<locals>.<lambda>ExpressionBuiltinXrange1.__init__ExpressionBuiltinRangeBase.getTypeShapeExpressionBuiltinRangeBase.mayHaveSideEffectsExpressionBuiltinXrangeBase.getStepExpressionBuiltinXrange3.__init__ExpressionBuiltinRangeBase.getHighExpressionBuiltinXrange1.getIterationValueExpressionBuiltinXrangeBase.computeExpressionIter1ExpressionBuiltinXrange1.getIterationLengthExpressionBuiltinRangeBase.canPredictIterationValuesExpressionBuiltinRange2.getIterationLengthExpressionBuiltinXrange3.computeExpressionExpressionBuiltinXrangeBase.getHighExpressionBuiltinRange1.isKnownToBeIterableExpressionBuiltinXrange1.computeExpression Base class for xrange nodes with 1/2/3 arguments. ExpressionBuiltinRange2.isKnownToBeIterableExpressionBuiltinXrangeBase.mayRaiseExceptionExpressionBuiltinRange2.computeExpressionC:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\nodes\BuiltinRangeNodes.pymakeExpressionBuiltinXrangeExpressionBuiltinXrange3.getIterationLengthExpressionBuiltinRange1.computeExpressionExpressionBuiltinRange1.getIterationValueExpressionBuiltinXrangeBase.computeBuiltinSpec.<locals>.<lambda> Base class for range nodes with 1/2/3 arguments. ExpressionBuiltinXrangeBase.canPredictIterationValuesExpressionBuiltinXrangeBase.__init__ExpressionBuiltinXrangeBase.getTruthValueExpressionBuiltinRange1.__init__ExpressionBuiltinRangeBase.mayRaiseExceptionExpressionBuiltinRange3.computeExpressionExpressionBuiltinXrange3.getIterationValueExpressionBuiltinRange2.__init__ExpressionBuiltinRef.isCompileTimeConstantExpressionBuiltinExceptionRef.getCompileTimeConstantExpressionBuiltinExceptionRef.isCompileTimeConstantExpressionBuiltinAnonymousRef.__init__ExpressionBuiltinAnonymousRef.getStringValuecreateBuiltinMakeExceptionExpressionBuiltinExceptionRef.computeExpressionCallExpressionBuiltinRef.computeExpressionRawExpressionBuiltinRefBase.getStrValueExpressionBuiltinRefBase.isKnownToBeHashableDetected built-in exception making.quick_namesExpressionBuiltinRefBase.getBuiltinNameExpressionBuiltinRef.computeExpressionCallC:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\nodes\BuiltinRefNodes.pyExpressionBuiltinAnonymousRef.getCompileTimeConstantExpressionBuiltinRef.isKnownToBeIterable Tree nodes for built-in references.

There is 2 major types of built-in references. One is the values from
built-ins, the other is built-in exceptions. They work differently and
mean different things, but they have similar origin, that is, access
to variables only ever read.

ExpressionBuiltinExceptionRef.mayRaiseExceptionExpressionBuiltinRef.getStringValueExpressionBuiltinExceptionRef.computeExpressionRawExpressionBuiltinRef.__init__<module nodes.BuiltinRefNodes>ExpressionBuiltinExceptionRef.__init__ExpressionBuiltinRefBase.__init__ExpressionBuiltinRef.getCompileTimeConstantExpressionBuiltinExceptionRef.computeExpressionCall.<locals>.createBuiltinMakeExceptionExpressionBuiltinAnonymousRef.isCompileTimeConstantExpressionBuiltinRefBase.mayRaiseExceptionExpressionBuiltinRefBase.mayHaveSideEffectsExpressionBuiltinRefBase.getDetailsExpressionBuiltinExceptionRef.getDetailsExpressionBuiltinAnonymousRef.computeExpressionRaw Node the calls to the 'sum' built-in.

This is a rather challenging case for optimization, as it has C code behind
it that could be in-lined sometimes for more static analysis.

<module nodes.BuiltinSumNodes>ExpressionBuiltinSumBase.__init__ExpressionBuiltinSumBase.computeBuiltinSpecExpressionBuiltinSum1.__init__ExpressionBuiltinSum2.computeExpressionExpressionBuiltinSumBase.computeBuiltinSpec.<locals>.<lambda>ExpressionBuiltinSum1.computeExpressionExpressionBuiltinSum2.__init__C:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\nodes\BuiltinSumNodes.pyPredicted truth value of built-in bool argumentShapeTypeStrDerivedExpressionBuiltinUnicode.getTypeShapeExpressionBuiltinBool.computeExpression Built-in type nodes tuple/list/set/float/str/unicode etc.

These are all very simple and have predictable properties, because we know their type and
that should allow some important optimizations.
ExpressionBuiltinBytes1.getTypeShapeExpressionBuiltinFloat.__init__ExpressionBuiltinFloat.getTypeShapeShapeTypeStrDerived.getTypeNameShapeTypeUnicodeDerived.getTypeNameShapeTypeFloatDerived.getTypeNameExpressionBuiltinBytes1.computeExpressionExpressionBuiltinUnicodeBase.computeExpression<module nodes.BuiltinTypeNodes>ExpressionBuiltinContainerBaseExpressionBuiltinContainerBase.computeExpressionExpressionBuiltinStr.computeExpressionPredicted 'str' built-in resultExpressionBuiltinContainerBase.__init__ExpressionBuiltinFloat.computeExpressionExpressionBuiltinBytearray3.__init__ExpressionBuiltinBool.getTypeShapeExpressionBuiltinTypeBaseShapeTypeBytesDerivedExpressionBuiltinStr.getTypeShapeExpressionBuiltinBytes1.__init__C:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\nodes\BuiltinTypeNodes.pyExpressionBuiltinBytearray1.__init__ShapeTypeBytesDerived.getTypeNameExpressionBuiltinBytes3.getTypeShapeExpressionBuiltinUnicodeBase.__init__ExpressionBuiltinFloat.mayRaiseExceptionExpressionBuiltinBytearray1.getTypeShapeExpressionBuiltinBytearray3.getTypeShapeExpressionBuiltinBytes1.mayRaiseExceptionExpressionBuiltinBytearray3.computeExpressionC:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\nodes\BuiltinVarsNodes.pyExpressionBuiltinVars.__init__ Builtin vars node.

Not used much, esp. not in the form with arguments. Maybe used in some meta programming,
and hopefully can be predicted, because at run time, it is hard to support.
<module nodes.BuiltinVarsNodes>ExpressionBuiltinVars.computeExpressionExpressionCallEmpty.isExpressionCallExpressionCall.extractSideEffectsPreCallhas_kwExpressionCallNoKeywords.isExpressionCallExpressionCallEmpty.computeExpressionExpressionCallNoKeywords.getCallKwExpressionCall.isExpressionCallExpressionCallNoKeywords.__init__ Make the most simple call node possible.

        By avoiding the more complex classes, we can achieve that there is
        less work to do for analysis.
    ExpressionCallNoKeywords.extractSideEffectsPreCallExpressionCallKeywordsOnly.__init__ExpressionCallNoKeywords.computeExpressionExpressionCallKeywordsOnly.extractSideEffectsPreCall Call node

Function calls and generally calling expressions are the same thing. This is
very important, because it allows to predict most things, and avoid expensive
operations like parameter parsing at run time.

There will be a method "computeExpressionCall" to aid predicting them in other
nodes.
ExpressionCall.computeExpressionExpressionCallEmpty.getCallArgsExpressionCallKeywordsOnly.getCallArgs<module nodes.CallNodes>ExpressionCallKeywordsOnly.computeExpressionExpressionCall.__init__ExpressionCallKeywordsOnly.isExpressionCallC:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\nodes\CallNodes.pyExpressionCallEmpty.__init__ExpressionCallEmpty.extractSideEffectsPreCallExpressionCallEmpty.getCallKwC:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\nodes\Checkers.pynodes.Checkers Node children checkers.

The role of checkers is to make sure that node children have specific value
types only.

ExpressionClassBody.getDocExpressionClassBody.mayHaveSideEffectsExpressionClassBody.computeExpressionRawgetBasesgetMetaclassExpressionClassBody.markAsDirectlyCalledExpressionClassBody.getDetailsExpressionClassBody.isEarlyClosuretype_dictExpressionSelectMetaclass.computeExpressionOutlineNodesExpressionClassBody.mayRaiseExceptionExpressionClassBody.fromXMLExpressionBuiltinType3.computeExpression Nodes for classes and their creations.

The classes are are at the core of the language and have their complexities.

ExpressionClassBody.getLocalsScopeExpressionClassBody.__init__<module nodes.ClassNodes>ExpressionClassBody.getDetailsForDisplaylocals_%s_%dC:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\nodes\ClassNodes.pyExpressionClassBody.isUnoptimizedExpressionSelectMetaclass.__init__ExpressionClassBody.getVariableForClosurenamed %sExpressionBuiltinType3.__init__co_new_localsCodeObjectSpec.getLineNumberCodeObjectSpec.getFlagHasClosureValue<CodeObjectSpec %(co_kind)s '%(co_name)s' with %(co_varnames)r>CodeObjectSpec.getFutureSpecCodeObjectSpec.updateLocalNamesCodeObjectSpec.getCodeObjectNameco_has_closureco_is_optimizedC:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\nodes\CodeObjectSpecs.pyCodeObjectSpec.updateLocalNames.<locals>.<genexpr>CodeObjectSpec.getCodeObjectKindCodeObjectSpec.hasStarListArgCodeObjectSpec.getArgumentCount Add detected local variables after closure has been decided.

        CodeObjectSpec.getKwOnlyParameterCountCodeObjectSpec.__init__CodeObjectSpec.setFlagNewLocalsValue Code object specifications.

For code objects that will be attached to module, function, and generator
objects, as well as tracebacks. They might be shared.

CodeObjectSpec.getVarNameslocal_namesCodeObjectSpec.getFlagIsOptimizedValueCodeObjectSpec.__repr__CodeObjectSpec.getFlagNewLocalsValueCodeObjectSpec.setFlagIsOptimizedValueCodeObjectSpec.getFilename<module nodes.CodeObjectSpecs>CodeObjectSpec.hasStarDictArgCodeObjectSpec.setFlagHasClosureValueCodeObjectSpec.getDetailsExpressionComparisonIsNOT.__init__ExpressionComparisonBase.computeExpressionOperationNotExpressionComparisonBase.getSimulatorExpressionComparisonInNotInBase.getDetails Nodes for comparisons.

Removed %s comparison for unused result.ExpressionComparisonBase.__init__ExpressionComparisonExceptionMatch.__init__Replaced negated comparison with inverse comparison.ExpressionComparisonIs.__init__C:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\nodes\ComparisonNodes.pyExpressionComparisonInNotInBase.mayRaiseExceptionBoolExpressionComparisonBase.getDetailsExpressionComparisonIsIsNotBase.computeExpressionDropExpressionComparisonNOTIn.__init__ExpressionComparisonExceptionMatch.getDetailsExpressionComparisonBase.computeExpression.<locals>.<lambda>ExpressionComparisonBase.isExpressionComparisonExpressionComparison.__init__ExpressionComparisonInNotInBase.computeExpressionmatch_valueExpressionComparisonIsIsNotBase.extractSideEffects<module nodes.ComparisonNodes>Determined values to not alias and therefore result of '%s' comparison.ExpressionComparisonIsIsNotBase.__init__Comparison of constant arguments.ExpressionComparisonBase.getComparatorExpressionComparisonBase.getOperandsDetermined values to alias and therefore result of %s comparison.ExpressionComparisonExceptionMatch.getSimulatorExpressionComparisonIsIsNotBase.mayRaiseExceptionBoolExpressionComparisonIn.__init__ExpressionComparisonInNotInBase.__init__ExpressionComparisonIsIsNotBase.getDetailsExpressionConditionalBoolBase.mayHaveSideEffectsBoolStatementConditional.isStatementAbortingExpressionConditionalBoolBase.__init__truth_value_use_leftleft_may_raiseExpressionConditionalBoolBase.computeExpressionRawcondition_may_raisebranch_yes_collectionbranch_no_collectionExpressionConditional.mayHaveSideEffectsBoolExpressionConditional.computeExpressionRawExpressionConditionalAND.__init__Condition for branch was predicted to be always %s.Removed conditional statement without effect.Conditional expression predicted to no case.C:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\nodes\ConditionalNodes.pyConditional expression predicted to yes case.ExpressionConditional.__init__getBranchesconditional yes branchConditional %s statements already raises implicitly in condition, removing branches.Conditional expression already raises implicitly in condition, removing branches.StatementConditional.getStatementNiceNameExpressionConditional.getBranchesconditional expression yes branchconditional no branchStatementConditional.__init__ExpressionConditional.mayRaiseExceptionBoolStatementConditional.mayBreakBoth branches have no effect, reduced to evaluate condition.Conditional '%s' expression predicted right value.truth_value_use_rightsetBranchYesStatementConditional.needsFrameConditional '%s' expression predicted to left value.StatementConditional.mayRaiseExceptionStatementConditional.computeStatementStatementConditional.mayContinueEmpty 'yes' branch for conditional statement treated with inverted condition check.ExpressionConditionalOR.__init__setBranchNo<module nodes.ConditionalNodes>conditional_kind Conditional nodes.

These is the conditional expression '(a if b else c)' and the conditional
statement, 'if a: ... else: ...' and there is no 'elif', because that is
expressed via nesting of conditional statements.
boolean %s right branchconditional expression no branchConditional statements already raises implicitly in condition, removing branches.Removed conditional branch not taken due to false condition value.ExpressionConditionalBoolBase.mayRaiseExceptionBoolRemoved 'else' branch not taken due to true condition value.StatementConditional.mayReturnbranch statementExpressionConstantRefBase.computeExpressionRawExpressionConstantSetRef.__init__isExpressionConstantBytesRefExpressionConstantIntRefExpressionConstantSliceRef.__init__ExpressionConstantBytearrayRef.getTypeShapeExpressionConstantFalseRef.getTypeShapeExpressionConstantFrozensetEmptyRef.getDetailsExpressionConstantTypeRefthe_empty_tupleExpressionConstantBytesRef.isExpressionConstantBytesRefExpressionConstantFrozensetRef.__init__ExpressionConstantUnicodeRef.getTypeShapeExpressionConstantTrueRef.__init__ExpressionConstantRefBase.isKnownToBeIterablethe_empty_frozensetExpressionConstantTrueRef.getTypeShapeExpressionConstantListRefExpressionConstantListEmptyRefExpressionConstantFloatRef<module nodes.ConstantRefNodes>ExpressionConstantListRef.getTypeShapeIteration over constant %s changed to tuple.<Node %s value %r at %s %s>ExpressionConstantXrangeRefExpressionConstantRefBase.isKnownToBeHashableExpressionConstantRefBase.getStrValuePredicted call of constant value to exception raise.ExpressionConstantBytesRef.getTypeShapeisExpressionConstantIntRefisExpressionConstantBytearrayRefExpressionConstantStrRef.isExpressionConstantStrRefExpressionConstantRefBase.getDetailsExpressionConstantComplexRefExpressionConstantFloatRef.__init__ExpressionConstantRefBase.isKnownToBeIterableAtMinExpressionConstantIntRef.isExpressionConstantIntRefExpressionConstantUnicodeRef.isExpressionConstantUnicodeRefisExpressionConstantFloatRefExpressionConstantRefBase.__repr__ExpressionConstantRefBase.isUnicodeConstantExpressionConstantSetEmptyRefisExpressionConstantLongRefExpressionConstantRefBase.isStringConstantisExpressionConstantSliceRefExpressionConstantXrangeRef.getTypeShapeExpressionConstantRefBase.extractSideEffectsExpressionConstantEllipsisRef.getTypeShapeExpressionConstantRefBase.extractUnhashableNodeExpressionConstantSetEmptyRef.getDetailsisExpressionConstantSetRefExpressionConstantRefBase.getIterationValueExpressionConstantDictEmptyRef.getDetailsthe_empty_listExpressionConstantEllipsisRef.getDetailsExpressionConstantRefBase.getDetailsForDisplayExpressionConstantRefBase.getIterationValueRangeExpressionConstantTupleRef.__init__ExpressionConstantRefBase.isMappingExpressionConstantFrozensetRef.getTypeShapeisExpressionConstantTupleRefExpressionConstantRefBase.getCompileTimeConstantExpressionConstantFloatRef.isExpressionConstantFloatRefthe_empty_setExpressionConstantRefBase.getIterationValues.<locals>.<genexpr>ExpressionConstantRefBase.computeExpressionCallExpressionConstantFalseRef.__init__ExpressionConstantRefBase.isIndexConstantExpressionConstantSliceRef.isExpressionConstantSliceRefExpressionConstantStrRef.__init__ExpressionConstantRefBase.isIterableConstantExpressionConstantTypeRef.__init__ExpressionConstantListRef.__init__ExpressionConstantNoneRef.getTypeShapeExpressionConstantBytearrayRef.__init__ExpressionConstantTypeRef.isExpressionConstantTypeRefExpressionConstantComplexRef.__init__ExpressionConstantLongRef.isExpressionConstantLongRefisExpressionConstantDictRefExpressionConstantBytearrayRef.isExpressionConstantBytearrayRefExpressionConstantUnicodeRef.__init__ExpressionConstantRefBase.getIndexValueExpressionConstantFrozensetEmptyRef.__init__ExpressionConstantTypeRef.computeExpressionCallExpressionConstantLongRef.getTypeShapeExpressionConstantNoneRef.getDetailsExpressionConstantStrRef.getTypeShapeExpressionConstantSetRef.getTypeShapeExpressionConstantBytesRef.__init__ExpressionConstantTupleEmptyRefToo large constant (%s %d) encountered at %s.ExpressionConstantSliceRef.getTypeShapeExpressionConstantTupleEmptyRef.__init__'%s' object is not callableExpressionConstantIntRef.getTypeShapeExpressionConstantSetRef.isExpressionConstantSetRefExpressionConstantRefBase.__init__ExpressionConstantRefBase.getIntegerValueExpressionConstantDictRef.hasShapeDictionaryExactthe_empty_dictExpressionConstantTypeRef.getTypeShapeExpressionConstantDictRef.isExpressionConstantDictRef Node for constant expressions. Can be all common built-in types.

ExpressionConstantIntRef.__init__ExpressionConstantTupleEmptyRef.getDetailsExpressionConstantComplexRef.isExpressionConstantComplexRefIteration of non-iterable constant.ExpressionConstantNoneRef.__init__ExpressionConstantRefBase.isExpressionConstantRefExpressionConstantRefBase.getStringValueExpressionConstantRefBase.computeExpressionIter1ExpressionConstantXrangeRef.__init__ExpressionConstantDictEmptyRef.__init__ExpressionConstantRefBase.isNumberConstantExpressionConstantFloatRef.getTypeShapeExpressionConstantDictRef.getTypeShapeExpressionConstantLongRef.__init__ExpressionConstantDictRef.__init__ExpressionConstantRefBase.getMappingPairsExpressionConstantTupleRef.getTypeShapeExpressionConstantSetEmptyRef.__init__ExpressionConstantRefBase.mayHaveSideEffectsExpressionConstantRefBase.getIterationLengthExpressionConstantFalseRef.getDetailsExpressionConstantRefBase.computeExpressionIter1.<locals>.<lambda>ExpressionConstantXrangeRef.isExpressionConstantXrangeRefExpressionConstantListEmptyRef.getDetailsExpressionConstantRefBase.isMappingWithConstantStringKeysExpressionConstantFrozensetRef.isExpressionConstantFrozensetRefExpressionConstantRefBase.canPredictIterationValuesExpressionConstantRefBase.isMutableC:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\nodes\ConstantRefNodes.pyExpressionConstantRefBase.getMappingStringKeyPairsExpressionConstantRefBase.isIndexableExpressionConstantTrueRef.getDetailsisBoolConstantExpressionConstantTupleRef.isExpressionConstantTupleRefExpressionConstantEllipsisRef.__init__ExpressionConstantListRef.isExpressionConstantListRefExpressionConstantListEmptyRef.__init__ExpressionConstantRefBase.isBoolConstantExpressionMakeSequenceBaseExpressionMakeTuple.getTypeShape%s with constant arguments.ExpressionMakeSequenceBase.getTruthValueExpressionMakeSequenceBase.isKnownToBeIterableAtMinExpressionMakeSequenceBase.computeExpressionDropExpressionMakeSet.__init__ExpressionMakeSequenceBase.computeExpression.<locals>.<lambda>ExpressionMakeList.getSimulatorExpressionMakeSet.getSimulatorExpressionMakeTuple.__init__ExpressionMakeSequenceBase.getIterationValueRangeC:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\nodes\ContainerMakingNodes.pymySetExpressionMakeSequenceBase.getIterationValuesExpressionMakeSetLiteral.getSimulator.<locals>.mySetExpressionMakeSequenceBase.mayHaveSideEffectsBoolExpressionMakeSequenceBase.mayRaiseExceptionExpressionMakeTuple.getSimulator Nodes that build containers.

ExpressionMakeSet.getIterationMaxLengthIteration over set reduced to tuple.ExpressionMakeSet.mayRaiseExceptionExpressionMakeSet.getTypeShapeExpressionMakeSequenceBase.computeExpression.<locals>.<lambda>.<locals>.<genexpr>ExpressionMakeSequenceBase.canPredictIterationValuesExpressionMakeList.getTypeShapeExpressionMakeSequenceBase.getSequenceKindExpressionMakeList.computeExpressionIter1Sequence creation raises exceptionelement_countExpressionMakeSet.getIterationLengthExpressionMakeSet.getIterationMinLengthExpressionMakeList.__init__ExpressionMakeSequenceBase.getSimulatorExpressionMakeSequenceBase.isExpressionMakeSequenceExpressionMakeSet.computeExpressionIter1<module nodes.ContainerMakingNodes>Iteration over list reduced to tuple.ExpressionMakeSequenceBase.__init__ExpressionMakeList.getIterationLengthExpressionMakeTuple.getIterationLength<module nodes.ContainerOperationNodes>ExpressionSetOperationUpdate.computeExpressionExpressionSetOperationUpdate.__init__ExpressionListOperationPop.computeExpressionExpressionListOperationExtend.__init__ExpressionListOperationPop.__init__ Operations on Containers.

C:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\nodes\ContainerOperationNodes.pyStatementListOperationAppend.computeStatementStatementListOperationAppend.__init__ExpressionListOperationExtend.computeExpressionStatementSetOperationAdd.computeStatementStatementSetOperationAdd.__init__ExpressionCoroutineObjectBody.needsGeneratorReturnHandlingC:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\nodes\CoroutineNodes.pyExpressionAsyncWait.markAsExceptionPreservingExpressionMakeCoroutineObject.getDetailsExpressionAsyncWait.computeExpressionExpressionMakeCoroutineObject.getClosureVariableVersionsExpressionAsyncWait.__init__ExpressionCoroutineObjectBody.__init__ Nodes for coroutine objects and their creations.

Coroutines are turned into normal functions that create generator objects,
whose implementation lives here. The creation itself also lives here.

ExpressionMakeCoroutineObject.getDetailsForDisplayExpressionMakeCoroutineObject.computeExpressionExpressionCoroutineObjectBody.needsGeneratorReturnExitExpressionAsyncWait.isExceptionPreservingExpressionMakeCoroutineObject.__init__EXPRESSION_COROUTINE_OBJECT_BODYExpressionCoroutineObjectBody.markAsNeedsGeneratorReturnHandlingExpressionMakeCoroutineObject.mayHaveSideEffectsExpressionMakeCoroutineObject.mayRaiseException<module nodes.CoroutineNodes>ExpressionMakeCoroutineObject.getCodeObjectExpressionCoroutineObjectBody.isUnoptimizedExpressionCoroutineObjectBody.needsCreationExpressionCoroutineObjectBody.getFunctionNameExpressionKeyValuePair.__init__ExpressionMakeDict.computeExpressionIter1StatementDictOperationSet.__init__ExpressionKeyValuePair.computeExpressionExpressionMakeDict.getMappingPairsExpressionDictOperationNOTIn.computeExpressionExpressionMakeDict.hasShapeDictionaryExactExpressionMakeDict.getIterationMinLengthExpressionMakeDict.computeExpressionDropExpressionKeyValuePair.mayRaiseExceptionpair_countExpressionMakeDict.getIterationLengthExpressionDictOperationGet.__init__unhashable type: '%s'ExpressionMakeDict.isMapping<module nodes.DictionaryNodes>ExpressionMakeDict.getMappingStringKeyPairsExpressionDictOperationNOTIn.__init__StatementDictOperationRemove.mayRaiseExceptionExpressionMakeDict.mayHaveSideEffectsBoolStatementDictOperationSet.mayRaiseExceptionStatementDictOperationUpdate.__init__ExpressionMakeDict.isKnownToBeIterablepair2 Nodes that build dictionaries.

The "pair" is a sub-structure of the dictionary, representing a key/value pair
that is the child of the dictionary creation.

ExpressionDictOperationGet.computeExpressionExpressionDictOperationIn.__init__subnode_keyExpressionMakeDict.getIterationMaxLengthEXPRESSION_KEY_VALUE_PAIRExpressionMakeDict.isMappingWithConstantStringKeysExpressionDictOperationIn.computeExpressionDictionary key is known to not be hashable.ExpressionMakeDict.__init__C:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\nodes\DictionaryNodes.pyStatementDictOperationRemove.__init__ExpressionMakeDict.canPredictIterationValuesStatementDictOperationSet.computeStatementCreated dictionary found to be constant.key_partExpressionMakeDict.mayRaiseExceptionis_constantStatementDictOperationRemove.computeStatementStatementDictOperationUpdate.computeStatementExpressionMakeDict.getIterationValueExpressionKeyValuePair.extractSideEffectsExpressionMakeDict.getTruthValueStatementRaiseExceptionMixinExpressionCaughtExceptionTypeRef.mayHaveSideEffectsStatementRaiseException.__init__ExpressionRaiseException.computeExpressionDrop<module nodes.ExceptionNodes>exception raise statementExpressionCaughtExceptionTracebackRef.computeExpressionRawStatementReraiseException.getStatementNiceNameExpressionCaughtExceptionTracebackRef.__init__implicit exception raise statementStatementReraiseException.needsFrameExpressionRaiseException.willRaiseExceptionExplicit raise already raises implicitly building exception value.ExpressionCaughtExceptionValueRef.mayHaveSideEffectsStatementRaiseException.computeStatementPropagated implicit raise expression to raise statement.StatementRaiseExceptionImplicit.getStatementNiceNameExpressionCaughtExceptionTypeRef.__init__exception re-raise statementExpressionBuiltinMakeException.mayRaiseExceptionExpressionCaughtExceptionValueRef.__init__StatementRaiseExceptionMixin.isStatementRaiseExceptionExpressionBuiltinMakeException.getDetailsExpressionCaughtExceptionTracebackRef.mayHaveSideEffectsExpressionRaiseException.__init__
Explicit raise already raises implicitly building exception cause. Nodes related to raising and making exceptions.

ExpressionBuiltinMakeException.getExceptionNameStatementRaiseException.needsFrameExpressionCaughtExceptionValueRef.computeExpressionRawExplicit raise already raises implicitly building exception traceback.ExpressionBuiltinMakeException.__init__StatementRaiseExceptionMixin.isStatementAbortingStatementReraiseException.computeStatementExpressionBuiltinMakeException.computeExpressionreraise_finallyExpressionCaughtExceptionTypeRef.computeExpressionRawStatementRaiseException.getStatementNiceNameC:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\nodes\ExceptionNodes.py This node type is only produced via optimization.

    CPython only knows exception raising as a statement, but often the raising
    of exceptions can be predicted to occur as part of an expression, which it
    replaces then.
    StatementExec.setChildExec statement raises implicitly when determining globals argument.<module nodes.ExecEvalNodes>previous_tracesExpressionBuiltinExecfile.computeExpressionDropRemoved sync back to locals without locals.Exec statement raises implicitly when determining locals argument.Replaced built-in exec call to exec statement in early closure context.C:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\nodes\ExecEvalNodes.pyChanged 'execfile' with unused result to 'exec' on class level.ExpressionBuiltinExec.computeExpressionDropStatementLocalsDictSync.computeStatementExpressionBuiltinExec.__init__ExpressionBuiltinCompile.__init__StatementExec.computeStatementExpressionBuiltinExecfile.__init__StatementLocalsDictSync.getPreviousVariablesTraces Nodes concern with exec and eval builtins.

These are the dynamic codes, and as such rather difficult. We would like
to eliminate or limit their impact as much as possible, but it's difficult
to do.
StatementLocalsDictSync.__init__ExpressionBuiltinCompile.computeExpressionExpressionBuiltinEval.computeExpressionExpressionBuiltinEval.__init__Exec statement raises implicitly when determining source code argument.StatementLocalsDictSync.mayRaiseExceptionStatementExec.__init__ExpressionBase.computeExpressionSetSliceExpressionBase.computeExpressionSetAttributeExpressionBase.mayRaiseExceptionAttributeCheckObjectExpressionBase.computeExpressionSetSubscriptExpressionChildHavingBase.childSetterstring_valueExpressionChildrenHavingBase.__init__ExpressionBase.computeExpressionSubscriptCompileTimeConstantExpressionBase.computeExpressionIntCompileTimeConstantExpressionBase.computeExpressionBytes.<locals>.<lambda>Compile time constant bytes value pre-computed.computed_attributeExpressionBase.computeExpressionLongchecked_valueExpressionBase.isCompileTimeConstant<module nodes.ExpressionBases>ExpressionChildHavingBase.setChildExpressionBase.mayRaiseExceptionBytesExpressionBase.computeExpressionAttributeCompileTimeConstantExpressionBase.mayRaiseExceptionAttributeLookupExpressionBase.isIndexableint() argument must be a string, a bytes-like object or a number, not '%s'Compile time constant long value pre-computed.ExpressionBase.hasShapeUnicodeExactCompile time constant len value pre-computed.ExpressionBase.mayRaiseExceptionFloathas_lenExpressionBase.computeExpressionDelSliceExpressionChildHavingBase.childGetterExpressionBase.mayRaiseExceptionLong Compute an expression.

            Default behavior is to just visit the child expressions first, and
            then the node "computeExpression". For a few cases this needs to
            be overloaded, e.g. conditional expressions.
        CompileTimeConstantExpressionBase.computeExpressionSlice.<locals>.<lambda>ExpressionBase.computeExpressionOperationNotExpressionBase.computeExpressionAttributeSpecialExpressionBase.extractUnhashableNodecomplex() argument must be a string or a number, not '%s'float() argument must be a string or a numberExpressionChildHavingBase.getCloneArgs.<locals>.<genexpr>ExpressionBase.onRelease Unless we are told otherwise, everything may raise for name import. sub_expressions Does an expression have exactly a unicode shape.

        ExpressionBase.getTypeValue Unless we are told otherwise, everything may have a side effect for bool check.  Unless we are told otherwise, everything may raise in __float__.  Has a value that we can use at compile time.

            Yes or no. If it has such a value, simulations can be applied at
            compile time and e.g. operations or conditions, or even calls may
            be executed against it.
        ExpressionBase.computeExpressionRaw Type of the node.

        mayRaiseExceptionAttributeLookupObject Value that "int" or "PyNumber_Int" (sp) would give, if known.

            Otherwise it is "None" to indicate unknown. Users must not
            forget to take side effects into account, when replacing a
            node with its string value.
        For '%s' the expression '%s' will raise.ExpressionBase.mayRaiseExceptionInCompileTimeConstantExpressionBase.isCompileTimeConstantCompileTimeConstantExpressionBase.computeExpressionFloat.<locals>.<lambda> Does an expression have exactly a string shape.

        ExpressionBase.computeExpressionImportName Unless we are told otherwise, it's not indexable. CompileTimeConstantExpressionBase.computeExpressionLong.<locals>.<lambda>Predicted 'len' result from value shape. Does a node have exactly a dictionary shape.

        argument of type '%s' object is not iterableExpressionChildHavingBase.computeExpressionRaw.<locals>.<lambda>CompileTimeConstantExpressionBase.mayRaiseExceptionAttributeLookupSpecialExpressionBase.isKnownToBeHashableExpressionBase.computeExpressionNext1ExpressionSpecBasedComputationBase.computeBuiltinSpec.<locals>.<lambda>ExpressionBase.mayRaiseExceptionIntExpressionBase.getIterationMaxLengthExpressionBase.mayRaiseExceptionAttributeLookupObjectExpressionChildHavingBase.replaceChild.<locals>.<genexpr>Subscript of constant with constant value.Compile time constant negation truth value pre-computed.CompileTimeConstantExpressionBase.mayRaiseExceptionBoolCompile time constant float value pre-computed.Built-in call to '%s' pre-computed.ExpressionBase.computeExpressionLenExpressionBase.computeExpressionAsyncIterCompileTimeConstantExpressionBase.mayHaveSideEffectsExpressionChildHavingBase.getVisitableNodesNamedExpressionBase.computeExpressionDelSubscript The type shape tells us, if "len" is available.

        ExpressionChildHavingBase.getChildC:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\nodes\ExpressionBases.py Unless we are told otherwise, everything may raise for attribute check. Slicing of constant with constant lower index only.CompileTimeConstantExpressionBase.computeExpressionAttributeCompileTimeConstantExpressionBase.computeExpressionComparisonIn Unless we are told otherwise, everything may raise being iterated. ExpressionBase.computeExpressionComplexExpressionBase.computeExpressionDrop.<locals>.<lambda> Unless we are told otherwise, everything may raise in __long__. ExpressionBase.getStrValueExpressionBase.hasShapeStrExactExpressionChildHavingBase.__init__CompileTimeConstantExpressionBase.computeExpressionLen.<locals>.<lambda>Compile time constant int value pre-computed.CompileTimeConstantExpressionBase.computeExpressionSubscript.<locals>.<lambda>ExpressionBase.mayHaveSideEffectsBool The type shape tells us, if "iter" is available.

        int() argument must be a string or a number, not '%s'CompileTimeConstantExpressionBase.mayHaveSideEffectsBoolAttribute '%s' pre-computed.ExpressionBuiltinSingleArgBase.computeExpression Unless we are told otherwise, everything may raise for attribute access. long() argument must be a string or a number, not '%s'CompileTimeConstantExpressionBase.computeExpressionInt.<locals>.<lambda>CompileTimeConstantExpressionBase.isKnownToHaveAttributeExpressionBase.getTypeShape Node as integer value, if possible.CompileTimeConstantExpressionBase.mayRaiseExceptionAttributeCheckExpressionBase.getIntValue Can be iterated at all (count is None) or exactly count times.

            Yes or no. If it can be iterated a known number of times, it may
            be asked to unpack itself.
        ExpressionBase.getCompileTimeConstant Expression base classes.

These classes provide the generic base classes available for
expressions. They have a richer interface, mostly related to
abstract execution, and different from statements.

Removed %s without effect. Node as string value, if possible.ExpressionBase.onContentEscapesCompileTimeConstantExpressionBase.computeExpressionOperationNot.<locals>.<lambda>ExpressionBase.hasShapeSlotIterExpressionBase.getValueShape Replace this node with computation result.  The type shape tells us, if "next" is available.

        ExpressionBase.getStringValueSlicing of constant with no indexes.ExpressionBase.computeExpressionDelAttribute Value that "len" or "PyObject_Size" would give at maximum, if known.

            Otherwise it is "None" to indicate unknown.
        ExpressionBase.computeExpressionCallExpressionChildrenHavingBase.computeExpressionRaw.<locals>.<lambda>ExpressionBuiltinSingleArgBase.__init__ExpressionBase.hasShapeSlotNextCompileTimeConstantExpressionBase.isMutableExpressionBase.getIterationLengthExpressionBase.getTruthValue Return known truth value. The "None" value indicates unknown. CompileTimeConstantExpressionBase.computeExpressionAttribute.<locals>.<lambda>ExpressionChildHavingBase.childSetter.<locals>.setterCompileTimeConstantExpressionBase.__init__ExpressionBase.getIterationMinLengthSlicing of constant with constant upper index only.ExpressionBase.isKnownToBeIterableAtMin Value that "len" or "PyObject_Size" would give, if known.

            Otherwise it is "None" to indicate unknown.
        ExpressionBase.computeExpressionIter1 Is the value hashable, i.e. suitable for dictionary/set keying. Value that "str" or "PyObject_Str" would give, if known.

            Otherwise it is "None" to indicate unknown. Users must not
            forget to take side effects into account, when replacing a
            node with its string value.
         Value that "len" or "PyObject_Size" would give at minimum, if known.

            Otherwise it is "None" to indicate unknown.
        Predicted '%s' on compiled time constant values. Unless we are told otherwise, everything may raise in __bytes__. float() argument must be a string or a number, not '%s'ExpressionChildHavingBase.childGetter.<locals>.getter Unless we are told otherwise, everything may raise in __int__. ExpressionBase.hasShapeSlotLenExpressionBase.hasShapeDictionaryExactCompileTimeConstantExpressionBase.computeExpressionComparisonIn.<locals>.<lambda>Slicing of constant with constant indexes. Unless we are told otherwise, everything may raise being checked. ExpressionBase.getIntegerValueExpressionBase.isKnownToBeIterableAtMaxExpressionBase.mayRaiseExceptionImportName For use during variable closure phase. Finalize attributes.

        StatementsFrameBase.__init__StatementsFrameBase.getCodeObjectSTATEMENTS_FRAME_GENERATORSTATEMENTS_FRAME_COROUTINEcheckFrameStatementsneeds_frame_exception_preserveSTATEMENTS_FRAME_FUNCTIONStatementsFrameBase.getGuardModeStatementsFrameCoroutine.__init__outside_preStatementsFrameBase.fromXMLStatementsFrameBase.computeStatementsSequenceStatementsFrameFunction.__init__ Check that frames statements list value proper.

    Must not be None, must not contain None, and of course only statements
    sequences, or statements, may be empty.
    StatementsFrameFunction.hasStructureMemberStatementsFrameModule.__init__Removed useless frame object of '%s'.StatementsFrameAsyncgen.__init__StatementsFrameBase.markAsFrameExceptionPreservingStatementsFrameBase.needsFrameExceptionPreservingStatementsFrameModule.hasStructureMemberStatementsFrameBase.getVarNamesStatementsFrameBase.getDetailsForDisplayoutside_postclosure_providerC:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\nodes\FrameNodes.pyStatementsFrameAsyncgen.hasStructureMemberSTATEMENTS_FRAME_MODULE<module nodes.FrameNodes>StatementsFrameBase.isStatementsFrameStatementsFrameBase.updateLocalNamesStatementsFrameBase.needsExceptionFramePreservationStatementsFrameGenerator.__init__ Frame nodes.

The frame attaches name and other frame properties to a scope, where it is
optional. For use in tracebacks, their created frame objects, potentially
cached are essential.

Otherwise, they are similar to statement sequences, so they inherit from
them.

STATEMENTS_FRAME_ASYNCGENRemoved empty frame object of '%s'.StatementsFrameGenerator.hasStructureMemberStatementsFrameCoroutine.hasStructureMember Shared function call.

        This is for calling created function bodies with multiple users. Not
        clear if such a thing should exist. But what this will do is to have
        respect for the fact that there are multiple such calls.
    ExpressionFunctionCreation.mayRaiseExceptionExpressionFunctionBodyBase.addNonlocalsDeclarationReplaced call to created function body '%s' to argument errorFunction call to '%s' in-lined.named %s with %sExpressionFunctionBodyBase.consumeNonlocalDeclarationsneedsExceptionReturnValueExpressionFunctionBody.markAsExceptionReturnValueconvertNoneConstantOrEmptyDictToNoneExpressionFunctionRef.__init__ExpressionFunctionCreation.getDetailsExpressionFunctionBodyBase.getVariablesExpressionFunctionRef.getDetailsExpressionFunctionCreation.getCodeObjectExpressionFunctionCreation.getNameExecuted '__qualname__' resolution to '%s'.ExpressionFunctionBodyBase.isEarlyClosureExpressionFunctionCreation.getClosureVariableVersionsExpressionFunctionBodyBase.getLocalVariablesExpressionFunctionBody.needsDirectCallneeds_creationEXPRESSION_FUNCTION_QUALNAME_REFExpressionFunctionCall.getClosureVariableVersionsparameter_spec_argsExpressionFunctionRef.mayHaveSideEffectsExpressionFunctionBody.getDetailExpressionFunctionBody.mayRaiseExceptionExpressionFunctionBody.getParametersExpressionFunctionCreation.__init__<module nodes.FunctionNodes>ExpressionFunctionBodyBase.getVariableForAssignmentargs_tuplegetCallCostExpressionFunctionBody.markAsNeedsCreationcomputeFunctionRawneeds_directExpressionFunctionBodyBase.getFunctionQualnameExpressionFunctionBodyBase.getContainingClassDictCreationreturn_exceptionExpressionFunctionBodyBase.discardFlagExpressionFunctionEntryPointBase.computeFunctionExpressionFunctionBodyBase.hasVariableNameExpressionFunctionBody.computeFunctionExpressionFunctionBodyBase.getVariableForReferenceExpressionFunctionBody.getDoc Nodes for functions and their creations.

Lambdas are functions too. The functions are at the core of the language and
have their complexities.

Creating a CPython function object is an optional thing. Some things might
only be used to be called directly, while knowing exactly what it is. So
the "ExpressionFunctionCreation" might be used to provide that kind of
CPython reference, and may escape.

Coroutines and generators live in their dedicated module and share base
classes.
ExpressionFunctionBody.needsCreationExpressionFunctionBodyBase.demoteClosureVariableExpressionFunctionBody.getParentExpressionFunctionCreation.fromXMLExpressionFunctionBodyBase.getEntryPointcreateOutlineFromCall Early closure taking means immediate binding of references.

        Normally it's good to lookup name references immediately, but not for
        functions. In case of a function body it is not allowed to do that,
        because a later assignment needs to be queried first. Nodes need to
        indicate via this if they would like to resolve references at the same
        time as assignments.
        ExpressionFunctionBodyBase.removeUserVariableExpressionFunctionCreation.getDetailsForDisplayExpressionFunctionBody.fromXMLExpressionFunctionCreation.computeExpressionCallExpressionFunctionBodyBase.mayRaiseExceptionExpressionFunctionBodyBase.getLocalVariableNamesExpressionFunctionEntryPointBase.computeFunctionRawref_nameExpressionFunctionRef.getDetailsForDisplayExpressionFunctionBody.getDetailsForDisplayExpressionFunctionCall.computeExpressioncall_specExpressionFunctionCreation.getCallCoststatements_sequenceC:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\nodes\FunctionNodes.pyExpressionFunctionBodyBase.computeExpressionExpressionFunctionBody.markAsDirectlyCalledReplaced call to created function body '%s' with direct function call.ExpressionFunctionBody.__init__EXPRESSION_FUNCTION_BODYExpressionFunctionRef.computeExpressionRawExpressionFunctionBodyBase.getUserLocalVariablesExpressionFunctionBodyBase.getOutlineLocalVariablesExpressionFunctionCall.mayRaiseExceptionExpressionFunctionQualnameRef.computeExpressionRawExpressionFunctionBodyBase.hasFlagneeds_visitExpressionFunctionBody.mayHaveSideEffectsExpressionFunctionBodyBase.createProvidedVariableExpressionFunctionBody.computeExpressionCallExpressionFunctionRef.getFunctionBodycross_module_useExpressionFunctionBodyBase.__init__EXPRESSION_FUNCTION_REFExpressionFunctionEntryPointBase.__init__ExpressionFunctionCall.__init__ExpressionFunctionCreation.createOutlineFromCallExpressionFunctionBodyBase.getFunctionName Function __qualname__ new in CPython3.3

        Should contain some kind of full name descriptions for the closure to
        recognize and will be used for outputs.
        ExpressionFunctionRef.getNameExpressionFunctionBody.isCrossModuleUsedExpressionFunctionBodyBase.hasClosureVariableExpressionFunctionBodyBase.getUserLocalVariables.<locals>.<genexpr>ExpressionFunctionBodyBase.takeVariableForClosureExpressionFunctionBody.markAsCrossModuleUsedExpressionFunctionBodyBase.getVariableForClosureExpressionFunctionBody.isCompileTimeConstantExpressionFunctionQualnameRef.__init__ExpressionFunctionBody.needsExceptionReturnValueExpressionFunctionBodyBase.isExpressionFunctionBodyBaseExpressionFunctionBodyBase.removeClosureVariableisPythonMainModuleisGeneratorStopisFuturePrintfuture_printFutureSpec.enableUnicodeLiteralsFutureSpec.enableAbsoluteImportFutureSpec.isFutureDivision_future_division_defaultFutureSpec.asFlags_future_generator_stop_defaultFutureSpec.__repr__<module nodes.FutureSpecs>FutureSpec.isFuturePrintFutureSpec.enableGeneratorStopFutureSpec.__init__ Specification record for future flags.

A source reference also implies a specific set of future flags in use by the
parser at that location. Can be different inside a module due to e.g. the
in-lining of "exec" statements with their own future imports, or in-lining of
code from other modules.
FutureSpec.enableBarry<FutureSpec %s>FutureSpec.isAbsoluteImportFutureSpec.enableFuturePrintbarry_bdflFutureSpec.enableFutureDivisionFutureSpec.cloneFutureSpec.isGeneratorStop Create a list of C identifiers to represent the flag values.

            This is for use in code generation and to restore from
            saved modules.
        C:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\nodes\FutureSpecs.py_future_absolute_import_default<module nodes.GeneratorNodes>ExpressionGeneratorObjectBody.__init__ExpressionGeneratorObjectBody.markAsNeedsGeneratorReturnHandlingStatementGeneratorReturnNone.getStatementNiceNameExpressionMakeGeneratorObject.getClosureVariableVersionsReturnNodesExpressionMakeGeneratorObject.getDetailsStatementGeneratorReturnNone.__init__ExpressionMakeGeneratorObject.computeExpressionEXPRESSION_GENERATOR_OBJECT_BODYStatementGeneratorReturn.getStatementNiceNameStatementGeneratorReturnNone.isStatementGeneratorReturnC:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\nodes\GeneratorNodes.pyStatementGeneratorReturn.computeStatementgenobj Nodes for generator objects and their creations.

Generators are turned into normal functions that create generator objects,
whose implementation lives here. The creation itself also lives here.

ExpressionMakeGeneratorObject.__init__ExpressionMakeGeneratorObject.mayHaveSideEffectsExpressionGeneratorObjectBody.needsGeneratorReturnExitExpressionGeneratorObjectBody.needsCreationExpressionGeneratorObjectBody.computeFunctionGenerator return value is always None.ExpressionMakeGeneratorObject.getCodeObjectExpressionGeneratorObjectBody.getFunctionNameisExpressionConstantNoneRefExpressionGeneratorObjectBody.needsGeneratorReturnHandlinggenerator return statementStatementGeneratorReturn.isStatementGeneratorReturnStatementGeneratorReturn.__init__ExpressionMakeGeneratorObject.mayRaiseExceptionExpressionBuiltinGlobals.__init__ExpressionBuiltinGlobals.mayRaiseExceptionExpressionBuiltinLocalsRef.__init__ExpressionBuiltinLocalsRef.getLocalsScopeC:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\nodes\GlobalsLocalsNodes.pyExpressionBuiltinLocalsUpdated.__init__ExpressionBuiltinLocalsUpdated.getLocalsScopeExpressionBuiltinLocalsBaseExpressionBuiltinLocalsCopy.computeExpressionRaw.<locals>._sortedExpressionBuiltinLocalsBase.mayHaveSideEffectsExpressionBuiltinLocalsBase.__init__ExpressionBuiltinDir1.computeExpressionExpressionBuiltinLocalsBase.mayRaiseExceptionExpressionBuiltinLocalsRef.computeExpressionRawExpressionBuiltinLocalsUpdated.computeExpressionRawExpressionBuiltinLocalsBase.getVariableTracesExpressionBuiltinGlobals.mayHaveSideEffects<module nodes.GlobalsLocalsNodes> Globals/locals/dir1 nodes

These nodes give access to variables, highly problematic, because using them,
the code may change or access anything about them, so nothing can be trusted
anymore, if we start to not know where their value goes.

The "dir()" call without arguments is reformulated to locals or globals calls.
ExpressionBuiltinLocalsCopy.computeExpressionRaw.<locals>._sorted.<locals>.<lambda>Statically predicted locals dictionary.Locals does not escape, no write back needed.ExpressionBuiltinGlobals.computeExpressionRawExpressionBuiltinImport.mayRaiseException Hard coded import names, e.g. of "os.path.dirname"

        These are directly created for some Python mechanics.
    module_fullpathExpressionImportName.getDetailExpressionImportModuleNameHard.mayRaiseException_addUsedModules_considerExpressionBuiltinImport.mayRaiseExceptionImportNameimport_itemsub_imported_modulepackage_moduleExpressionImportName.getImportLevelExpressionImportModuleNameHard.getDetailsExpressionImportName.getImportNameExpressionImportModuleNameHard.mayHaveSideEffectsExpressionImportName.mayRaiseExceptionstar import statementExpressionImportModuleHard.mayHaveSideEffects Hard coded import names, e.g. of "__future__"

        These are directly created for some Python mechanics, but also due to
        compile time optimization for imports of statically known modules.
    ExpressionBuiltinImport.computeExpressionStatementImportStar.getStatementNiceNameStatementImportStar.computeStatementgetFromListExpressionImportModuleHard.computeExpressionRawReplaced '__import__' call with non-string module name argument.ExpressionImportModuleHard.getDetailsExpressionImportModuleNameHard.getImportNameExpressionImportModuleNameHard.__init__ExpressionBuiltinImport._considerExpressionImportModuleNameHard.getModuleNameC:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\nodes\ImportNodes.pyStatementImportStar.getLocalsDictScopeExpressionImportModuleNameHard.computeExpressionRawExpressionImportName.computeExpressionExpressionBuiltinImport.__init__ExpressionBuiltinImport._attemptRecursionimport_list_modulesExpressionBuiltinImport._addUsedModulesNot recursing to '%(full_path)s' (%(filename)s), please specify --recurse-none (do not warn), --recurse-all (recurse to all), --recurse-not-to=%(full_path)s (ignore it), --recurse-to=%(full_path)s (recurse to it) to change.ExpressionImportModuleHard.mayRaiseExceptionExpressionImportModuleHard.__init__ExpressionBuiltinImport.getTypeShapeStatementImportStar.__init__ExpressionBuiltinImport.computeExpression.<locals>.<lambda><module nodes.ImportNodes>StatementImportStar.mayRaiseExceptionExpressionImportModuleHard.getModuleName Nodes related to importing modules or names.

Normally imports are mostly relatively static, but Nuitka also attempts to
cover the uses of "__import__" built-in and other import techniques, that
allow dynamic values.

If other optimizations make it possible to predict these, the compiler can go
deeper that what it normally could. The import expression node can recurse.
package_modules_warned_aboutExpressionImportName.getDetailsimport %s from %sExpressionImportName.__init__ Module for node class mixins that indicate runtime determined node facts.

These come into play after finalization only. All of the these attributes (and
we could use properties instead) are determined once or from a default and then
used like this.

MarkUnoptimizedFunctionIndicatorMixin.__init__MarkUnoptimizedFunctionIndicatorMixin.getLocalsScopeC:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\nodes\IndicatorMixins.pyMarkNeedsAnnotationsMixin.__init__EntryPointMixin.getTraceCollection For use during building only. Indicate "__annotations__" need.  Mixin for indication that a function contains an exec or star import.

        These do not access global variables directly, but check a locals dictionary
        first, because they do.
    unqualified_execunoptimized_localsMarkUnoptimizedFunctionIndicatorMixin.isUnoptimizedMarkNeedsAnnotationsMixin.needsAnnotationsDictionaryMarkUnoptimizedFunctionIndicatorMixin.isUnqualifiedExecEntryPointMixin.setTraceCollectionnodes.IndicatorMixinsMarkNeedsAnnotationsMixin.markAsNeedsAnnotationsDictionaryneeds_annotations_dictEntryPointMixin.__init__<module nodes.IndicatorMixins>StatementSetLocals.mayRaiseExceptioncall_node_cloneExpressionLocalsVariableRef.getLocalsDictScopeExpressionLocalsVariableRef.getDetailsForDisplayStatementSetLocals.getDetailsExpressionLocalsVariableRef.mayRaiseExceptionlocals mapping init statementExpressionLocalsVariableCheck.computeExpressionRawStatementLocalsDictOperationSet.mayRaiseExceptionlocals dictionary init statementStatementLocalsDictOperationSet.getLocalsDictScopeMoved call of uncertain dict variable to inside.StatementReleaseLocals.__init__StatementLocalsDictOperationDel.getLocalsDictScopefallback node usage Nodes that deal with locals, as dict or mapping.

The mapping types can be optimized into dict types, and the ones with
fallback can be optimized to no fallback variants.

StatementSetLocals.getStatementNiceNameStatementLocalsDictOperationDel.getStatementNiceNameStatementSetLocalsDictionary.__init__ExpressionLocalsVariableRefORFallback.computeExpressionCallExpressionLocalsVariableRefORFallback.computeExpressionRawlocals dictionary value del statementStatementLocalsDictOperationDel.getVariableNameExpressionLocalsVariableCheck.getVariableNameStatementLocalsDictOperationSet.computeStatementStatementSetLocalsDictionary.mayRaiseExceptionStatementLocalsDictOperationSet.getVariableNameStatementLocalsDictOperationDel.computeStatementStatementLocalsDictOperationSet.getStatementNiceNameStatementSetLocalsDictionary.getStatementNiceNameStatementReleaseLocals.getDetailslocals dictionary release statementExpressionLocalsVariableCheck.getDetailsStatementSetLocals.getLocalsScope<module nodes.LocalsDictNodes>StatementLocalsDictOperationSet.getDetails_variable_tracelocals dictionary value set statementbranch_fallbackStatementReleaseLocals.computeStatementExpressionLocalsVariableRefORFallback.getDetailsExpressionLocalsVariableRefORFallback.getLocalsDictScopeStatementLocalsDictOperationSet.__init__StatementLocalsDictOperationDel.mayRaiseExceptionStatementReleaseLocals.getStatementNiceNameName '%s' cannot be in locals dict.ExpressionLocalsVariableCheck.__init__isExpressionBuiltinRefExpressionLocalsMappingVariableRefORFallbackStatementSetLocals.computeStatementStatementReleaseLocals.mayRaiseExceptionExpressionLocalsVariableRef.__init__may_raise_setExpressionLocalsVariableRefORFallback.mayRaiseExceptionEXPRESSION_LOCALS_MAPPING_VARIABLE_REF_OR_FALLBACKStatementSetLocals.getDetailsForDisplayStatementLocalsDictOperationDel.__init__Setting locals already raises implicitly building new locals.ExpressionLocalsVariableRef.computeExpressionRawStatementReleaseLocals.getLocalsScopeStatementSetLocals.__init__may_raise_delC:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\nodes\LocalsDictNodes.pyExpressionLocalsVariableRef.computeExpressionCallStatementLocalsDictOperationDel.getDetailsExpressionLocalsVariableRefORFallback.__init__ExpressionLocalsVariableRef.getVariableNameExpressionLocalsVariableRefORFallback.getVariableNameExpressionLocalsVariableCheck.getLocalsDictScopeName '%s' must be in locals dict.LocalsMappingHandle.getTypeShapeLocalsDictHandle.getCodeNameLocalsDictHandle.__init__LocalsDictHandle.getTypeShape<%s of %s>LocalsDictHandle.getName This module maintains the locals dict handles. LocalsDictHandle.getLocalsDictVariableC:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\nodes\LocalsScopes.pynodes.LocalsScopesLocalsDictHandle.__repr__<module nodes.LocalsScopes>loop_end_traces<module nodes.LoopNodes>loop statementloop continue statementloop_variablesRemoved useless loop with immediate 'break' statement.loop_entry_tracesStatementLoopBreak.__init__C:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\nodes\LoopNodes.pyStatementLoopBreak.mayRaiseExceptionStatementLoopBreak.isStatementAbortinglast_statementStatementLoopContinue.__init__StatementLoop.mayContinueStatementLoop.isStatementAborting Loop nodes.

There are for and loop nodes, but both are reduced to loops with break/continue
statements for it. These re-formulations require that optimization of loops has
to be very general, yet the node type for loop, becomes very simple.
continue_collectionStatementLoop.mayReturnStatementLoopBreak.getStatementNiceNameStatementLoop.mayRaiseExceptionStatementLoopContinue.getStatementNiceNamesetLoopBodyRemoved useless terminal 'continue' as last statement of loop.outer_trace_collectionStatementLoop.computeStatementStatementLoopBreak.computeStatementStatementLoopContinue.mayContinueStatementLoop.mayBreakStatementLoopBreak.mayBreakStatementLoop.__init__loop break statementStatementLoopContinue.isStatementAbortingStatementLoopContinue.mayRaiseExceptioncomputeLoopBodyStatementLoop.computeLoopBodyStatementLoop.getStatementNiceNameStatementLoopContinue.computeStatementUsing constant '__name__' value.ExpressionModuleAttributePackageRef.computeExpressionRawUsing constant '__spec__' value for main module.ExpressionModuleAttributeNameRef.computeExpressionRawExpressionModuleAttributeLoaderRef.computeExpressionRawExpressionModuleAttributeBase.mayRaiseException Module/Package attribute nodes

The represent special values of the modules. The __name__, __package__ and
__file__ values can all be highly dynamic and version dependent. These nodes
are intended to allow for as much compile time optimization as possible,
despite this difficulty.

C:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\nodes\ModuleAttributeNodes.py<module nodes.ModuleAttributeNodes>ExpressionModuleAttributeFileRef.computeExpressionRawUsing constant '__package__' value.ExpressionModuleAttributeBase.__init__ExpressionModuleAttributeSpecRef.computeExpressionRawExpressionModuleAttributeBase.getDetailsUsing original '__file__' value.CompiledPythonModule.getOutlineLocalVariablesPythonShlibModule.getParentModulecluster_%sCompiledPythonModule.fromXMLavoid_duplicatesCompiledPythonModule.getUnusedFunctionsadd_subgraph Read the .pyi file if present and scan for dependencies. makeTraceNodeNamePythonShlibModule.getUsedModulespyi_depsPythonShlibModule.getPyIFilenamePYTHON_INTERNAL_MODULECompiledPythonModule.startTraversalfunction_workPythonModuleBasePythonMainModule.getDetailsPythonInternalModule.__init__CompiledPythonModule.getOutputFilenamefunc_argsPythonModuleBase.isMainModuleCompiledPythonModule.getCrossUsedFunctionsCompiledPythonPackage.getOutputFilenameCompiledPythonModule.addUsedFunctionCompiledPythonModule.createProvidedVariableCompiledPythonModule.getFilenameCompiledPythonModule.getParent_reasonPythonShlibModule.getFilenameUncompiledPythonModule.getByteCodemain_filenamePythonInternalModule.isInternalModuleCompiledPythonModule.isUnoptimized Module/Package nodes

The top of the tree. Packages are also modules. Modules are what hold a program
together and cross-module optimizations are the most difficult to tackle.
CompiledPythonModule.isEarlyClosure__internalCompiledPythonModule.computeModuleCompiledPythonModule.addCrossUsedFunctionCompiledPythonModule.getLocalsScopeUncompiledPythonModule.setUsedModulesGraph for %sPYTHON_SHLIB_MODULEPythonModuleBase.__init__PythonModuleBase.getCodeNamenode_name Get Python type description filename. CompiledPythonModule.asGraphPythonModuleBase.getFullNameprev_tracePythonModuleBase.getCompileTimeFilenameCompiledPythonModule.addFunctionnode_namesUncompiledPythonModule.isUserProvidedCompiledPythonModule.getTraceCollectionsuser_localsCompiledPythonModule.getVariableForReferenceCompiledPythonPackage.__init__<module nodes.ModuleNodes>CompiledPythonModule.removeUserVariablePythonMainModule.__init__PythonMainModule.fromXMLCompiledPythonModule.getUserLocalVariablesCompiledPythonModule.isCompiledPythonModuleCompiledPythonModule.getLocalVariablesUncompiledPythonModule.startTraversalUncompiledPythonModule.getUsedModulesactive_functionsPythonShlibModule._readPyPIFilePythonModuleBase.getPackageadd_node Compiled Python Module

    COMPILED_PYTHON_MODULEcross_used_functionsCompiledPythonModule.getVariableForClosurePythonShlibModule.startTraversalContaining package of recursed module '%s'.CompiledPythonModule.getVariablesCompiledPythonModule.hasVariableNameCompiledPythonModule.getContainingClassDictCreationC:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\nodes\ModuleNodes.pyCompiledPythonModule.getCodeName Must be bytecode as it's used in CPython library initialization. UncompiledPythonModule.getFilenameCompiledPythonModule.getFutureSpecPythonModuleBase.getNameUncompiledPythonModule.isUncompiledPythonModuleCompiledPythonModule.getDetailsPythonModuleBase.attemptRecursionPythonShlibModule.__init__UNCOMPILED_PYTHON_PACKAGE<frozen %s>PYTHON_MAIN_MODULE%s/ %s %s %sadd_edgeCompiledPythonModule.getDetailsForDisplayCompiledPythonModule.getFunctionFromCodeNamePythonInternalModule.getOutputFilenameCompiledPythonModule.getUsedFunctionsCompiledPythonModule.getVariableForAssignmentyellowPythonMainModule.getOutputFilenamePythonShlibModule.getDetailspackage_kindUNCOMPILED_PYTHON_MODULECompiledPythonModule.__init__CompiledPythonModule.getParentVariableProviderCompiledPythonModule.asGraph.<locals>.makeTraceNodeNameCompiledPythonPackage.canHaveExternalImportsCompiledPythonModule.getEntryPointUncompiledPythonPackagePythonModuleBase.isInternalModuleUncompiledPythonModule.__init__PythonMainModule.isMainModulePythonModuleBase.getRunTimeFilenameUncompiledPythonModule.isTechnicalCompiledPythonModule.hasClosureVariableChildrenHavingMixin.getCloneArgs Mixin for nodes that accept variables from closure givers. ChildrenHavingMixin.getChildeffective_source_refC:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\nodes\NodeBases.pyNodeBase.getVisitableNodesStatementChildHavingBase.childSetter.<locals>.setterStatementChildHavingBase.childGetterNodeBase.mayBreak Unless we are told otherwise, everything may raise everything. NodeBase.getChildNameClosureGiverNodeMixin.hasProvidedVariablecompat_lineNodeBase.getName Base class for all statements.

    ClosureTakerMixin.getClosureVariableIndexChildrenHavingMixin.getVisitableNodesNodeBase.getChildNameNiceChildrenHavingMixin.childGetterisOrderRelevantClosureGiverNodeMixin.getTempVariablesNodeBase.isExpressionConstantRefNodeBase.getDescriptionNodeBase.replaceWithClosureTakerMixin.getClosureVariablesNodeBase.isStatementReraiseExceptionChildrenHavingMixin.__init__ Bug compatible line numbers information.

            See above.
        NodeBase.mayReturn'%s' with %s Description of the node, intended for use in __repr__ and
            graphical display.

        CodeNodeMixinStatementChildHavingBase.getVisitableNodeschild_type<module nodes.NodeBases>StatementChildHavingBase.replaceChild.<locals>.<genexpr> Unless we are told otherwise, everything may have a side effect. SideEffectsFromChildrenMixin.extractSideEffectsNodeBase.isParentVariableProviderChildrenHavingMixin.getCloneArgs.<locals>.<genexpr>StatementChildrenHavingBase.__init__NodeBase.extractSideEffects Is the node aborting, control flow doesn't continue after this node.  NodeMetaClassesNodeBase.getSourceReferenceStatementBase.getStatementNiceNameClosureGiverNodeMixin.removeTempVariableStatementChildHavingBase.getCloneArgs.<locals>.<genexpr>NodeBase.willRaiseExceptionNodeBase.isNumberConstantPythonCompiledPackageNodeBase.setCompatibleSourceReferenceClosureGiverNodeMixin.registerProvidedVariablegetChildUIDStatementBase.computeStatementSubExpressions.<locals>.<lambda>SideEffectsFromChildrenMixin.mayHaveSideEffectsNodeBase.getDetailsChildrenHavingMixin.childSetterNodeBase.__init__ClosureGiverNodeMixin.getProvidedVariableCodeNodeMixin.__init__NodeBase.getCloneArgsFor %s the expression '%s' will raise.CodeNodeMixin.getChildUIDCodeNodeMixin.getNameStatementChildHavingBase.childGetter.<locals>.getterNodeBase.getParentReturnConsumer Node base classes.

These classes provide the generic base classes available for nodes,
statements or expressions alike. There is a dedicated module for
expression only stuff.

 Return the parent that is a function.

        ClosureGiverNodeMixin.createTempVariable Blass class for nodes that provide variables for closure takers. ClosureGiverNodeMixin.createProvidedVariableNodeBase.mayRaiseExceptionundescribed statement%s$$$%s%sNodeBase.mayHaveSideEffectsNodeBase.getDetailsForDisplay Parent of the node. Every node except modules have to have a parent.

        NodeBase.isExpressionSideEffectsCodeNodeMixin.getCodeName Details of the node, intended for re-creation.

            We are not using the pickle mechanisms, but this is basically
            part of what the constructor call needs. Real children will
            also be added.

        ClosureGiverNodeMixin.allocateTempScopetemp_scopesChildrenHavingMixin.getVisitableNodesNamed Bug compatible line numbers information.

            As CPython outputs the last bit of bytecode executed, and not the
            line of the operation. For example calls, output the line of the
            last argument, as opposed to the line of the operation start.

            For tests, we wants to be compatible. In improved more, we are
            not being fully compatible, and just drop it altogether.
        NodeBase.getCompatibleSourceReferenceClosureGiverNodeMixin.allocateTempVariable<Node %s>NodeBase.mayContinue Unless we are told otherwise, nothing may raise anything.  Details of the node, intended for use in __repr__ and dumps.

            This is also used for XML.
        StatementChildHavingBase.setChildNodeBase.fromXMLNodeBase.getParentModule Compute a statement.

            Default behavior is to just visit the child expressions first, and
            then the node "computeStatement". For a few cases this needs to
            be overloaded.
        NodeBase.needsFrameClosureTakerMixin.addClosureVariablesub_childStatementChildHavingBase.__init__NodeBase.dumpStatementChildHavingBase.getVisitableNodesNamed Unless defined otherwise, the expression is the side effect. ClosureTakerMixin.hasTakenVariableNodeBase.isOrderRelevantNodeBase.isCompiledPythonModuleClosureGiverNodeMixin.getProvidedVariableOrderNodeBase.isExpressionMakeSequenceClosureTakerMixin.getTakenVariableNodeBase.isExpressionCallNodeBase.isStatementsFrame Details of the node, intended for use in __repr__ and graphical
            display.

        NodeBase.asXmlTextmakeChildChildrenHavingMixin.replaceChild.<locals>.<genexpr> Unless we are tolder otherwise, this depends on exception raise. ClosureTakerMixin.getParentVariableProvidergetNodeClassFromKindPythonCompiledModuleNodeBase.makeCloneNodeBase.getParentStatementsFrameProblem cloning nodeChildrenHavingMixin.childSetter.<locals>.setterNodeBase.isExpressionOutlineFunctionBodyBaseEXPRESSION_BUILTIN_ClosureGiverNodeMixin.allocatePreserverIdNodeBase.visitNodeBase.__repr__StatementChildHavingBase.getChildClosureTakerMixin.__init__ClosureGiverNodeMixin.__init__NodeBase.isExpressionFunctionBodyBaseNodeBase.isStatementAbortingNodeBase.getParentVariableProviderNodeBase.isExpressionBuiltinNodeBase.getVisitableNodesNamedClosureTakerMixin.getClosureVariables.<locals>.<lambda> Return the role in the current parent, subject to changes.

        ChildrenHavingMixin.setChildNodeBase.isExpressionOperationBinaryNodeBase.getParentFunctionChildrenHavingMixin.childGetter.<locals>.getter Return the parent that is module.

         These are just helpers to create nodes, often to replace existing nodes

These are for use in optimizations and computations, and therefore cover
mostly exceptions and constants.

Often cyclic dependencies kicks in, which is why this module is mostly only
imported locally. Note: It's intended to be reversed, this module will make
the local imports instead, as these local imports look ugly everywhere else,
making it more difficult to use.
SideEffectNodesC:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\nodes\NodeMakingHelpers.pymerged_statements Predicted to raise an exception.makeStatementOnlyNodesFromExpressions.<locals>.<genexpr>%s: Will always raise exception: "%s(%s)" With a computation function, execute it and return constant result or
        exception node.

    Raising for use of '%s' on %s '%s'.wrapExpressionWithSideEffects.<locals>.<genexpr>makeCompileTimeConstantReplacementNode Helper function that merges nested statement sequences.  Predicted constant result.<module nodes.NodeMakingHelpers>wrapStatementWithSideEffects.<locals>.<genexpr>C:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\nodes\NodeMetaClasses.pykind_to_name_partchecker_methodcheckKind Node meta classes.

This provides meta classes for nodes, currently only one. These do all kinds
of checks, and add methods automatically.

nodes.NodeMetaClassesis_mixinNodeCheckMetaClass.__init__last_mixinNodeCheckMetaClass.__init__.<locals>.checkKindNodeCheckMetaClass.__new__NodeCheckMetaClass.__init__.<locals>.convert_checkBases<module nodes.NodeMetaClasses>left_lengthExpressionOperationBinary.__init__ExpressionOperationUnary.getOperandssubnode_operand Nodes for unary and binary operations.

No short-circuit involved, boolean 'not' is an unary operation like '-' is,
no real difference.
ExpressionOperationBase.getOperatorExpressionOperationBinaryMultExpressionOperationBinaryAdd.computeExpressionC:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\nodes\OperatorNodes.pysubnode_rightExpressionOperationNOT.computeExpressionExpressionOperationBinary.<genexpr>ExpressionOperationUnary.computeExpressionExpressionOperationBinary.getOperandsExpressionOperationBinaryAdd.getDetailsExpressionOperationNOT.getDetailsExpressionOperationBase.unmarkAsInplaceSuspectExpressionOperationUnary.isExpressionOperationUnaryoperand_valueExpressionOperationBinaryAdd.__init__ExpressionOperationUnary.computeExpression.<locals>.<lambda>ExpressionOperationBinary.isExpressionOperationBinaryExpressionOperationBinaryDivmod.__init__ExpressionOperationBase.__init__ExpressionOperationBinaryMult.getValueShapeExpressionOperationBinaryDivmod.getTypeShapeExpressionOperationBinaryMult.__init__ExpressionOperationUnary.__init__Operator '*' with constant arguments.right_lengthOperator '%s' with constant arguments.ExpressionOperationNOT.getTruthValueExpressionOperationBase.isInplaceSuspectExpressionOperationNOT.mayRaiseExceptionExpressionOperationBase.markAsInplaceSuspectExpressionOperationBinaryAdd.computeExpression.<locals>.<lambda>ExpressionOperationBinary.computeExpression.<locals>.<lambda>subnode_leftExpressionOperationNOT.mayRaiseExceptionBoolOperator '%s' with constant argument.ExpressionOperationBinaryInplaceExpressionOperationBinaryMult.getIterationLengthLowered in-place binary operation of compile time constant to binary operation.ExpressionOperationBase.getDetailsExpressionOperationNOT.mayHaveSideEffectsisExpressionMakeDictExpressionOperationBinaryMult.computeExpressionExpressionOperationBinaryMult.getTypeShape<module nodes.OperatorNodes>ExpressionOperationNOT.__init__ExpressionOperationBase.getSimulatorExpressionOperationBinaryInplace.isExpressionOperationBinaryExpressionOperationBinaryInplace.__init__ExpressionOperationBinaryInplace.computeExpressionExpressionOperationBinaryMult.getDetailsExpressionOperationBinaryMult.computeExpression.<locals>.<lambda>ExpressionOperationNOT.mayHaveSideEffectsBoolExpressionOperationNOT.extractSideEffectsExpressionOperationBase.isKnownToBeIterableExpressionOperationBinaryMult.extractSideEffectsExpressionOutlineBody.getEntryPointExpressionOutlineFunctionBodyBase.mayRaiseExceptionfirst_statementExpressionOutlineBody.__init__ExpressionOutlineFunctionBodyBase.computeExpressionRawExpressionOutlineFunctionBodyBase.__init__<module nodes.OutlineNodes>ExpressionOutlineFunctionBodyBase.getCodeName Outlined expression code.

        This is for a call to a piece of code to be executed in a specific
        context. It contains an exclusively owned function body, that has
        no other references, and can be considered part of the calling
        context.

        It must return a value, to use as expression value.
    ExpressionOutlineFunctionBodyBase.getOutlineTempScopeExpressionOutlineFunctionBodyBase.getDetailsForDisplayOutline function is now exception raise, use directly.Outline function '%s' is now simple return, use directly.ExpressionOutlineFunctionBodyBase.allocateTempScopeExpressionOutlineBody.getContainingClassDictCreationOutline '%s' is now simple return, use directly.ExpressionOutlineBody.getCodeNameExpressionOutlineBody.willRaiseExceptionOutline is now exception raise, use directly.ExpressionOutlineBody.allocateTempScopeC:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\nodes\OutlineNodes.pyExpressionOutlineBody.isExpressionOutlineBodyExpressionOutlineFunctionBodyBase.willRaiseExceptionExpressionOutlineFunction.isEarlyClosureExpressionOutlineFunctionBodyBase.allocateTempVariableExpressionOutlineFunction.isUnoptimizedExpressionOutlineBody.getDetailsExpressionOutlineBody.computeExpressionRawExpressionOutlineBody.allocateTempVariableExpressionOutlineFunctionBodyBase.getClosureVariableExpressionOutlineBody.mayRaiseException Outline nodes.

We use them for re-formulations and for in-lining of code. They are expressions
that get their value from return statements in their code body. They do not
own anything by themselves. It's just a way of having try/finally for the
expressions, or multiple returns, without running in a too different context.
 Outlined function code.

        This is for a call to a function to be called in-line to be executed
        in a specific context. It contains an exclusively owned function body,
        that has no other references, and can be considered part of the calling
        context.

        As normal function it must return a value, to use as expression value,
        but we know we only exist once.

        Once this has no frame, it can be changed to a mere outline expression.
    ExpressionOutlineFunctionBodyBase.isExpressionOutlineFunctionBodyBaseExpressionOutlineFunctionBodyBase.getEntryPointExpressionOutlineFunctionBodyBase.getTraceCollectionExpressionOutlineFunction.getLocalsScopeExpressionOutlineBody.getOutlineTempScopeC:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\nodes\PrintNodes.pyException raise in 'print' statement arguments converted to explicit raise.StatementPrintNewline.computeStatementStatementPrintValue.computeStatementStatementPrintValue.__init__StatementPrintValue.mayRaiseExceptionStatementPrintNewline.__init__Side effects printed item promoted to statements.Exception raise in 'print' statement destination converted to explicit raise. Print nodes.

Right now there is only the print statement, but in principle, there should
also be the print function here. These perform output, which can be combined
if possible, and could be detected to fail, which would be perfect.

Predicting the behavior of 'print' is not trivial at all, due to many special
cases.
StatementPrintNewline.mayRaiseException<module nodes.PrintNodes>StatementReturnConstantStatementReturnConstantBase.getExpressionStatementReturn.computeStatementStatementReturnConstant.__init__StatementReturnNone.getConstantStatementReturnConstant.getConstantStatementReturnFalseStatementReturnNone.__init__ExpressionReturnedValueRef.mayHaveSideEffectsStatementReturnConstantBase.getConstantStatementReturnFalse.getConstantStatementReturnTrueStatementReturn.mayRaiseExceptionStatementReturn.isStatementAbortingReturn value is always constant.StatementReturnConstantBase.computeStatementStatementReturnConstantBase.isStatementAbortingStatementReturnConstantBase.__init__StatementReturnFalse.__init__StatementReturnConstantBase.mayRaiseExceptionStatementReturnConstantBase.getStatementNiceNameExpressionReturnedValueRef.mayRaiseExceptionStatementReturnTrue.__init__C:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\nodes\ReturnNodes.py Return node

This one exits functions. The only other exit is the default exit of functions with 'None' value, if no return is done.
<module nodes.ReturnNodes>ExpressionReturnedValueRef.__init__StatementReturnConstantBase.isStatementReturn The returned constant value.

        StatementReturn.__init__StatementReturnTrue.getConstantStatementReturnConstant.getDetailsExpressionReturnedValueRef.computeExpressionRawsetSideEffectsExpressionSideEffects.getTruthValueC:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\nodes\SideEffectNodes.pyExpressionSideEffects.willRaiseExceptionnew_side_effectsExpressionSideEffects.isExpressionSideEffectsExpressionSideEffects.__init__ Node that models side effects.

Sometimes, the effect of an expression needs to be had, but the value itself
does not matter at all.
real_valueExpressionSideEffects.computeExpressionRemoved empty side effects.Turned side effects of expression only statement into statements.nodes.SideEffectNodescheckSideEffectsRemove nested side effects.<module nodes.SideEffectNodes>ExpressionSideEffects.computeExpressionDropStatementAssignmentSlice.computeStatementExpressionSliceLookup.isKnownToBeIterable Slice nodes.

Slices are important when working with lists. Tracking them can allow to
achieve more compact code, or predict results at compile time.

There will be a method "computeExpressionSlice" to aid predicting them.
getStopExpressionBuiltinSlice.mayRaiseExceptionC:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\nodes\SliceNodes.pySlice assignment raises exception in assigned value, removed assignment.ExpressionSliceLookup.__init__
Slice del raises exception in lower slice boundary value, removed delSlice assignment raises exception in upper slice boundary value, removed assignment.StatementAssignmentSlice.__init__setUpperExpressionSliceLookup.computeExpressionExpressionBuiltinSlice.__init__setLowerSlice assignment raises exception in sliced value, removed assignment.<module nodes.SliceNodes>ExpressionBuiltinSlice.computeExpressionStatementDelSlice.__init__StatementDelSlice.computeStatementSlice assignment raises exception in lower slice boundary value, removed assignment.Slice del raises exception in sliced value, removed del
Slice del raises exception in upper slice boundary value, removed delStatementsSequence.trimStatementsStatementPublishException.mayRaiseExceptionStatementPreserveFrameException.getPreserverIdStatementPreserveFrameException.needsFrameStatementsSequence.mergeStatementsSequenceStatementExpressionOnly.mayHaveSideEffectsStatementPreserveFrameException.getDetailsStatementPublishException.__init__mayRaiseExceptionOrAbortStatementsSequence.isStatementsSequenceStatementsSequence.computeStatementexpression %sStatementRestoreFrameException.getPreserverIdold_statementsremoveStatementStatementRestoreFrameException.computeStatementStatementsSequence.needsFrameC:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\nodes\StatementNodes.pyStatementsSequence.__init__<module nodes.StatementNodes>Removed frame preservation for generators.StatementPublishException.computeStatementStatementExpressionOnly.getDetailmerge_indexStatementsSequence.removeStatement Nodes for statements.

StatementRestoreFrameException.__init__ Check that statements list value property.

    Must not be None, must not contain None, and of course only statements,
    may be empty.
    StatementsSequence.computeStatementsSequenceStatementExpressionOnly.getStatementNiceNameStatementRestoreFrameException.mayRaiseExceptionStatementsSequence.mayBreakcheckStatementsStatementsSequence.mayRaiseExceptionOrAbortStatementPreserveFrameException.computeStatementStatementsSequence.mayHaveSideEffectsStatementsSequence.getStatementNiceNameStatementsSequence.mayReturnStatementsSequence.isStatementAbortingStatementExpressionOnly.computeStatementStatementPreserveFrameException.mayRaiseExceptionstatements sequenceStatementRestoreFrameException.getDetailsStatementsSequence.mayContinueStatementExpressionOnly.__init__StatementPreserveFrameException.__init__StatementExpressionOnly.mayRaiseExceptionExpressionStringConcatenation.__init__ Node dedicated to "".join() code pattern.

This is used for Python 3.6 fstrings re-formulation and has pretty direct
code alternative to actually looking up that method from the empty string
object, so it got a dedicated node, also to perform optimizations specific
to this.
C:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\nodes\StringConcatenationNodes.pyExpressionStringConcatenation.computeExpression<module nodes.StringConcatenationNodes>ExpressionStringConcatenation.getTypeShape<module nodes.SubscriptNodes> Subscript node.

Subscripts are important when working with lists and dictionaries. Tracking
them can allow to achieve more compact code, or predict results at compile time.

There is be a method "computeExpressionSubscript" to aid predicting them in the
other nodes.
ExpressionSubscriptLookup.computeExpressionsubscript assignment statementStatementDelSubscript.computeStatementStatementAssignmentSubscript.__init__C:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\nodes\SubscriptNodes.pyExpressionSubscriptLookup.isKnownToBeIterableStatementAssignmentSubscript.computeStatementStatementDelSubscript.getStatementNiceNamesubscript del statementExpressionSubscriptLookup.__init__StatementDelSubscript.__init__StatementAssignmentSubscript.getStatementNiceNameThis statement does raise but didn't annotate an exception exit.Removed now empty try statement.setBlockBreakHandlertried block statementStatementTry.__init__StatementTry.computeStatement.<locals>.explainStatementTry.isStatementAbortingexcept handlerFalsely assuming tried block may raise, but no statement says so.Reduced scope of tried block.StatementTry.getStatementNiceNametry startStatementTry.mayRaiseExceptionC:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\nodes\TryNodes.py Nodes for try/except/finally handling.

This is the unified low level solution to trying a block, and executing code
when it returns, break, continues, or raises an exception. See Developer
Manual for how this maps to try/finally and try/except as in Python.
setBlockReturnHandler<module nodes.TryNodes>Removed useless try, all handlers removed.setBlockExceptHandlerStatementTry.computeStatement.<locals>.explain.<locals>.<genexpr>StatementTry.mayContinue Trailing statements at %s.StatementTry.mayBreakStatementTry.mayReturnStatementTry.needsFrame©ÚselfÚtrace_collectionÚtriedÚexcept_handlerÚbreak_handlerÚcontinue_handlerÚreturn_handlerÚcollection_startÚabort_contextÚresultÚbreak_collectionsÚcontinue_collectionsÚreturn_collectionsÚexception_collectionsÚtried_may_raiseÚcollection_exception_handlingÚ	statementÚcollection_breakÚcollection_continueÚcollection_returnÚtried_statementsÚpre_statementsÚtried_statementÚpost_statementsÚexplainsetBlockTrysetBlockContinueHandlerreturn handler Leading statements at %s.getObjectExpressionBuiltinType1.mayHaveSideEffectsExpressionBuiltinType1.computeExpressionDropExpressionBuiltinType1.getTypeShapeRemoved type taking for unused result.ExpressionBuiltinIsinstance.__init__C:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\nodes\TypeNodes.pyExpressionBuiltinSuper.computeExpressionReplaced predictable type lookup with builtin type '%s'.ExpressionBuiltinType1.mayRaiseExceptionExpressionBuiltinIsinstance.computeExpression.<locals>.<lambda> The type1 node.

This one just determines types. It's great for optimization. We may be able to
predict its value, but knowing it. In that case, we have a built-in name
reference for that type to convert to, or when checking the result of it, we
will then know it's limited after the fact.

Built-in call to 'isinstance' computed.ExpressionBuiltinSuper.__init__<module nodes.TypeNodes>ExpressionVariableRef.isTargetVariableRefExpressionVariableRefBase.computeExpressionDelSubscriptExpressionTempVariableRef.isKnownToBeIterableAtMaxExpressionTempVariableRef.isKnownToBeIterableAtMin Node for variable references.

These represent all variable references in the node tree. Can be in assignments
and its expressions, changing the meaning of course dramatically.

Subscript assignment to dictionary lowered to dictionary assignment.ExpressionTempVariableRef.__init__Module variable '%s' found to be built-in reference.ExpressionVariableLocalNameRef.needsFallbackValue propagated for temp '%s'.ExpressionVariableRef.fromXMLExpressionTempVariableRef.mayRaiseException These are used before the actual variable object is known from VariableClosure.

        The special thing about this as opposed to ExpressionVariableNameRef is that
        these must remain local names and cannot fallback to outside scopes. This is
        used for __annotations__.

    ExpressionVariableRefBase.computeExpressionSetSubscript<module nodes.VariableRefNodes>ExpressionVariableRef.getTypeShapeExpressionTempVariableRef.isTargetVariableRefExpressionVariableRef.computeExpressionCallExpressionVariableRefBase.computeExpressionSubscriptExpressionVariableRefBase.getVariableTraceExpressionVariableRefBase.computeExpressionComparisonInExpressionTempVariableRef.mayHaveSideEffectsExpressionVariableRefBase.getVariableNameExpressionTempVariableRef.getDetailsForDisplayExpressionVariableRef.mayRaiseExceptionExpressionVariableNameRef.__init__ExpressionTempVariableRef.fromXMLCheck '%s' on dictionary lowered to dictionary '%s'.Subscript look-up to dictionary lowered to dictionary look-up.ExpressionVariableRef.getVariableNameExpressionTempVariableRef.getTypeShapeExpressionVariableNameRef.getDetailsReplaced read-only module attribute '__package__' with module attribute reference.ExpressionVariableRef.onContentEscapesC:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\nodes\VariableRefNodes.pyExpressionVariableNameRef.isExpressionVariableNameRefReplaced read-only module attribute '__spec__' with module attribute reference.EXPRESSION_VARIABLE_LOCAL_NAME_REFExpressionVariableRef.mayHaveSideEffectsExpressionTempVariableRef.computeExpressionNext1ExpressionVariableRef.hasShapeDictionaryExactExpressionTempVariableRef.computeExpressionRawSubscript del to dictionary lowered to dictionary del.ExpressionVariableRef.getDetailsForDisplayModule variable '%s' found to be built-in exception reference.ExpressionVariableRef.setVariableVariable access of not initialized variable '%s'ExpressionVariableRef.__init__Replaced read-only module attribute '__name__' with module attribute reference.ExpressionTempVariableRef.mayRaiseExceptionImportNameReplaced read-only module attribute '__loader__' with module attribute reference.ExpressionVariableRef.isKnownToBeIterableExpressionVariableRef.computeExpressionRawExpressionVariableRefBase.__init__ExpressionTempVariableRef.onContentEscapesEXPRESSION_VARIABLE_NAME_REFExpressionVariableNameRef.needsFallbackExpressionVariableNameRef.computeExpressionRawExpressionVariableNameRef.getVariableNameExpressionYield.__init__ExpressionYield.markAsExceptionPreservingExpressionYieldFrom.markAsExceptionPreservingExpressionYieldFrom.__init__ Yield node.

The yield node returns to the caller of the generator and therefore may execute
absolutely arbitrary code, from the point of view of this code. It then returns
something, which may often be 'None', but doesn't have to be.

Often it will be used as a statement, which should also be reflected in a
dedicated node.
ExpressionYieldFrom.computeExpression<module nodes.YieldNodes>ExpressionYield.isExceptionPreservingC:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\nodes\YieldNodes.py Yielding an expression.

        Typical code: yield expression

        Can only happen in a generator. Kind of explicitly suspends and
        resumes the execution. The user may inject any kind of exception
        or give any return value. The value of "None" is the most common
        though, esp. if it's not used.

    ExpressionYieldFrom.isExceptionPreservingExpressionYield.computeExpression Yielding from an expression.

        Typical code: yield from expression (Python3)

        Can only happen in a generator and only in Python3. Similar to yield,
        but implies a loop and exception propagation to the yield from generator
        if such. Kind of explicitly suspends and resumes the execution. The
        user may inject any kind of exception or give any return value. Having
        a return value is what makes Python3 generators special, and with yield
        from, that value is the expression result.
    C:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\nodes\shapes\__init__.pynodes.shapeslistiteratorShapeTypeStr.hasShapeSlotIterShapeTypeSet.hasShapeSlotFloatShapeTypeSlice.hasShapeSlotContainsShapeTypeXrange.hasShapeSlotFloatShapeTypeFrozenset.hasShapeSlotFloatShapeTypeFrozenset.hasShapeSlotLongShapeTypeInt.hasShapeSlotIntShapeTypeStaticmethod.hasShapeSlotContainsShapeTypeLong.hasShapeSlotIntShapeTypeInt.hasShapeSlotFloatShapeTypeStrIterator.getTypeNameShapeTypeTupleIterator.getTypeNameShapeTypeTuple.hasShapeSlotLenShapeTypeXrange.hasShapeSlotContainsShapeTypeNoneType.hasShapeSlotLenShapeTypeModule.hasShapeSlotIntShapeTypeUnicode.hasShapeSlotFloatShapeTypeStrIterator.hasShapeSlotLenShapeTypeSlice.hasShapeSlotLongShapeTypeEllipsisType.hasShapeSlotLongShapeTypeBytes.hasShapeSlotContainsShapeTypeBytearray.hasShapeSlotContainsShapeTypeModule.hasShapeSlotFloatShapeTypeIntOrLong.hasShapeSlotNextShapeTypeTupleIterator.hasShapeSlotLenShapeTypeUnicode.hasShapeSlotNextShapeTypeSet.hasShapeSlotLenShapeTypeComplex.hasShapeSlotContainsShapeTypeFloat.hasShapeSlotComplexShapeTypeFloat.hasShapeSlotContainsShapeTypeClassmethod.hasShapeSlotIntShapeTypeXrangeIteratorShapeTypeLong.hasShapeSlotComplexShapeTypeList.hasShapeSlotLongShapeTypeTuple.hasShapeSlotContainsdictionary-keyiteratorShapeTypeClassmethod.hasShapeSlotLenShapeTypeModule.hasShapeModuleShapeTypeDict.hasShapeSlotComplexShapeTypeFile.hasShapeSlotComplexShapeTypeNoneType.hasShapeSlotIntShapeTypeUnicode.hasShapeSlotLenShapeTypeStaticmethod.hasShapeSlotComplexShapeTypeBool.getCTypeShapeTypeBytes.hasShapeSlotLongShapeTypeTuple.hasShapeSlotLongShapeTypeXrange.hasShapeSlotIntShapeTypeStaticmethod.hasShapeSlotIntShapeTypeList.getShapeIterShapeTypeType.hasShapeSlotIterShapeTypeList.hasShapeSlotNextShapeTypeStaticmethod.hasShapeSlotLongShapeTypeFrozenset.hasShapeSlotComplexShapeTypeDict.hasShapeSlotLongShapeTypeBool.hasShapeSlotLensetiteratorShapeTypeIntOrLong.hasShapeSlotIterShapeTypeUnicode.hasShapeSlotIntShapeTypeType.hasShapeSlotIntShapeTypeEllipsisType.getTypeNameShapeTypeList.hasShapeSlotLenShapeTypeLong.hasShapeSlotNextShapeTypeFloat.getTypeNameShapeTypeBytesIterator.hasShapeSlotLenShapeTypeXrange.hasShapeSlotComplexShapeTypeListIterator.getTypeNameShapeTypeUnicode.hasShapeSlotComplexShapeTypeLong.hasShapeSlotIterShapeTypeFile.hasShapeSlotNextShapeTypeFloat.hasShapeSlotLongShapeTypeFile.hasShapeSlotIntShapeTypeStrOrUnicode.hasShapeSlotComplexStandardShapesrangeiteratorShapeTypeXrange.hasShapeSlotLongShapeTypeFloat.hasShapeSlotLenShapeTypeSlice.getTypeNameShapeTypeInt.getTypeNameShapeTypeStr.hasShapeSlotLongShapeTypeUnicode.hasShapeSlotLongShapeTypeClassmethod.hasShapeSlotIterShapeTypeFloat.hasShapeSlotIntShapeTypeDictIterator.hasShapeSlotLenShapeTypeSetIterator.hasShapeSlotLenShapeTypeComplex.hasShapeSlotNextShapeTypeUnicode.hasShapeSlotIterShapeTypeSet.hasShapeSlotComplexShapeTypeComplex.getTypeNameShapeTypeInt.hasShapeSlotNextShapeTypeSlice.hasShapeSlotComplexShapeTypeXrangeIterator.getTypeNameShapeTypeNoneType.hasShapeSlotIterShapeTypeXrange.hasShapeSlotLenShapeTypeIntOrLong.hasShapeSlotLongShapeTypeXrangeIterator.hasShapeSlotLenShapeTypeDict.hasShapeSlotLenShapeTypeEllipsisType.hasShapeSlotFloatShapeTypeLong.hasShapeSlotContainsShapeTypeLong.getTypeNameShapeTypeSlice.hasShapeSlotLenShapeTypeComplex.hasShapeSlotComplexShapeTypeEllipsisType.hasShapeSlotIntShapeTypeXrange.getShapeIterShapeTypeTuple.hasShapeSlotIntShapeTypeIntOrLong.hasShapeSlotLenShapeTypeTuple.hasShapeSlotFloatShapeTypeInt.hasShapeSlotIterShapeTypeType.hasShapeSlotNextShapeTypeUnicodeIterator.hasShapeSlotLenShapeTypeInt.hasShapeSlotLenShapeTypeSlice.hasShapeSlotNextShapeTypeSet.hasShapeSlotContainsShapeTypeBytearray.hasShapeSlotLongShapeTypeBytes.hasShapeSlotFloatShapeTypeModule.hasShapeSlotNextShapeTypeClassmethod.getTypeNameShapeTypeSet.hasShapeSlotNextShapeTypeEllipsisType.hasShapeSlotLenShapeTypeComplex.hasShapeSlotLenShapeTypeFile.hasShapeSlotIterShapeTypeLong.hasShapeSlotLongC:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\nodes\shapes\BuiltinTypeShapes.pyShapeTypeList.hasShapeSlotFloatShapeTypeUnicode.hasShapeSlotContainsShapeTypeSlice.hasShapeSlotIterShapeTypeFrozenset.hasShapeSlotNextShapeTypeTuple.hasShapeSlotIterShapeTypeStrOrUnicode.hasShapeSlotContainsShapeTypeStr.hasShapeSlotComplexShapeTypeIntOrLong.hasShapeSlotFloatShapeTypeModule.hasShapeSlotLenShapeTypeType.hasShapeSlotComplexShapeTypeComplex.hasShapeSlotIterShapeTypeSlice.hasShapeSlotIntShapeTypeFile.hasShapeSlotContainsShapeTypeBytes.hasShapeSlotIntShapeTypeClassmethod.hasShapeSlotNextShapeTypeList.hasShapeSlotContainsShapeTypeStr.hasShapeSlotContainsShapeTypeClassmethod.hasShapeSlotComplexShapeTypeStr.hasShapeSlotLenShapeTypeClassmethod.hasShapeSlotFloatShapeTypeFile.hasShapeSlotLenShapeTypeType.hasShapeSlotContainsShapeTypeBytes.hasShapeSlotLenShapeTypeFile.getTypeNameShapeTypeDict.getTypeNameShapeTypeStrOrUnicode.hasShapeSlotLongShapeTypeDict.hasShapeSlotIntShapeTypeLong.hasShapeSlotLenShapeTypeList.hasShapeSlotIntShapeTypeBool.hasShapeSlotNextShapeTypeComplex.hasShapeSlotLongShapeTypeBytearray.hasShapeSlotIntShapeTypeSet.getShapeIterShapeTypeStrOrUnicode.hasShapeSlotFloatShapeTypeBytearrayIteratorShapeTypeSet.hasShapeSlotIntShapeTypeBytearray.hasShapeSlotIterShapeTypeBool.getTypeNameShapeTypeStaticmethod.hasShapeSlotIterShapeTypeClassmethod.hasShapeSlotLongShapeTypeStaticmethod.getTypeNameShapeTypeStaticmethod.hasShapeSlotFloatShapeTypeStrOrUnicode.hasShapeSlotIntShapeTypeBool.hasShapeSlotComplexShapeTypeBytes.hasShapeSlotNextShapeTypeFloat.hasShapeSlotIterShapeTypeDict.hasShapeSlotNextShapeTypeDict.hasShapeSlotIterShapeTypeBytearray.getTypeNameShapeTypeStrOrUnicode.hasShapeSlotLenShapeTypeSetIterator.getTypeNameShapeTypeType.hasShapeSlotFloatShapeTypeList.getTypeNameShapeTypeEllipsisType.hasShapeSlotNextShapeTypeDict.getShapeIterShapeTypeUnicode.getShapeIterShapeTypeBytes.hasShapeSlotIterShapeTypeFrozenset.hasShapeSlotIterShapeTypeFrozenset.getShapeIterShapeTypeFile.hasShapeSlotFloatShapeTypeBool.hasShapeSlotIntShapeTypeNoneType.hasShapeSlotLong Shapes for Python built-in types.

ShapeTypeList.hasShapeSlotComplexShapeTypeStrOrUnicode.hasShapeSlotIterShapeTypeUnicodeIterator.getTypeNameShapeTypeBytes.hasShapeSlotComplexShapeTypeDict.hasShapeSlotContainsShapeTypeStr.getTypeNameShapeTypeNoneType.hasShapeSlotContainsShapeTypeBytesIterator.getTypeNameShapeTypeFloat.hasShapeSlotNextShapeTypeUnicode.getTypeNameShapeTypeNoneType.hasShapeSlotFloatShapeTypeIntOrLong.hasShapeSlotComplexShapeTypeBytes.getShapeIterShapeTypeSet.hasShapeSlotLongShapeTypeModule.getTypeNameShapeTypeStr.getShapeIterShapeTypeComplex.hasShapeSlotIntShapeTypeBool.hasShapeSlotIterShapeTypeModule.hasShapeSlotContainsShapeTypeBytearray.hasShapeSlotLenShapeTypeFrozenset.hasShapeSlotIntShapeTypeTuple.hasShapeSlotNextShapeTypeBytearrayIterator.getTypeNameShapeTypeBytearrayIterator.hasShapeSlotLenShapeTypeXrange.hasShapeSlotIterShapeTypeIntOrLong.hasShapeSlotContainsShapeTypeEllipsisType.hasShapeSlotIterShapeTypeSet.hasShapeSlotIterShapeTypeDictIterator.getTypeNameShapeTypeStaticmethod.hasShapeSlotNextShapeTypeLong.hasShapeSlotFloatShapeTypeType.hasShapeSlotLongShapeTypeTuple.getShapeIterShapeTypeType.getTypeNametupleiteratorShapeTypeClassmethod.hasShapeSlotContainsShapeTypeType.hasShapeSlotLenShapeTypeInt.hasShapeSlotComplexShapeTypeFloat.hasShapeSlotFloatShapeTypeModule.hasShapeSlotLongShapeTypeFrozenset.hasShapeSlotContainsShapeTypeXrange.getTypeName<module nodes.shapes.BuiltinTypeShapes>ShapeTypeModule.hasShapeSlotComplexShapeTypeFrozenset.getTypeNameShapeTypeNoneType.hasShapeSlotComplexShapeTypeEllipsisType.hasShapeSlotContainsShapeTypeSet.getTypeNameShapeTypeTuple.getTypeNameShapeTypeBytearray.hasShapeSlotComplexShapeTypeIntOrLong.hasShapeSlotIntShapeTypeTuple.hasShapeSlotComplexShapeTypeDict.hasShapeSlotFloatShapeTypeList.hasShapeSlotIterShapeTypeXrange.hasShapeSlotNextShapeTypeBool.hasShapeSlotLongShapeTypeStr.hasShapeSlotFloatShapeTypeInt.hasShapeSlotLongShapeTypeFile.hasShapeSlotLongShapeTypeBool.hasShapeSlotFloatShapeTypeInt.hasShapeSlotContainsShapeTypeBytearray.hasShapeSlotNextShapeTypeBool.hasShapeSlotContainsdictkey_iteratorShapeTypeBytearray.hasShapeSlotFloatShapeTypeBytearray.getShapeIterShapeTypeBytes.getTypeNameShapeTypeListIterator.hasShapeSlotLenShapeTypeFrozenset.hasShapeSlotLenShapeTypeStaticmethod.hasShapeSlotLenShapeTypeModule.hasShapeSlotIterShapeTypeNoneType.getTypeNameShapeTypeEllipsisType.hasShapeSlotComplexShapeTypeComplex.hasShapeSlotFloatShapeTypeSlice.hasShapeSlotFloatShapeTypeNoneType.hasShapeSlotNextShapeTypeStr.hasShapeSlotIntShapeTypeStrOrUnicode.hasShapeSlotNextShapeTypeStr.hasShapeSlotNextShapeBase.hasShapeSlotBytesShapeLargeConstantValueShapeUnknown.hasShapeSlotLongShapeIterator.hasShapeSlotLenShapeUnknown.hasShapeSlotNextShapeBase.getCTypeShapeIterator.hasShapeSlotFloatShapeLargeConstantValue.getTypeShapeShapeUnknown.hasShapeSlotFloatShapeBase.getTypeNameShapeBase.getShapeIterValueShapeUnknown.getTypeShapeShapeUnknown.hasShapeSlotComplexShapeLargeConstantValue.isConstantShapeBase.hasShapeModuleShapeIterator.hasShapeSlotIter Standard shapes that commonly appear. ShapeIterator.hasShapeSlotIntShapeIterator.hasShapeSlotNextValueShapeBaseShapeIterator.hasShapeSlotContainsShapeLargeConstantValuePredictable.__init__ShapeUnknown.hasShapeSlotContainsShapeUnknown.hasShapeSlotBytesValueShapeBase.hasShapeSlotLen<module nodes.shapes.StandardShapes>ShapeLargeConstantValue.__init__ShapeUnknown.hasShapeSlotIterShapeUnknown.hasShapeSlotLenC:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\nodes\shapes\StandardShapes.pyShapeLargeConstantValue.hasShapeSlotLenShapeIterator.hasShapeSlotLongShapeIterator.getShapeIterShapeUnknown.hasShapeSlotIntHOMEPATHHOMEDRIVEExpand shell variables of the forms $var, ${var} and %var%.

    Unknown variables are left unchanged._get_bothseps_getfinalpathnameCommon pathname manipulations, WindowsNT/95 version.

Instead of importing this module directly, import os and refer to this
module as os.path.
_get_colon\\?\bsep_getvolumepathnameÛ'   znormcasezisabszjoinz
splitdrivezsplitzsplitextzbasenamezdirnamezcommonprefixzgetsizezgetmtimezgetatimezgetctimezislinkzexistszlexistszisdirzisfilezismountz
expanduserz
expandvarsznormpathzabspathzsplitunczcurdirzpardirzsepzpathsepzdefpathzaltsepzextsepzdevnullzrealpathzsupports_unicode_filenameszrelpathzsamefilezsameopenfilezsamestatz
commonpathvarcharspathlennormcase() argument must be str or bytes, not %rspecial_prefixes_-index2Paths don't have the same driveC:\msys64\mingw64\lib\python3.6\ntpath.pyMSYSTEMresult_driveresult_pathp_drivep_pathntpath.splitunc is deprecated, use ntpath.splitdrive insteadstart_abs.;C:\binUSERPROFILEdrivesplitsstart_restpath_absstart_drivepath is on mount %r, start on mount %rpath_restSplit a pathname into drive/UNC sharepoint and relative path specifiers.
    Returns a 2-tuple (drive_or_unc, path); either part may be empty.

    If you assign
        result = splitdrive(p)
    It is always true that:
        result[0] + result[1] == p

    If the path contained a drive letter, drive_or_unc will contain everything
    up to and including the colon.  e.g. splitdrive("c:/dir") returns ("c:", "/dir")

    If the path contained a UNC path, the drive_or_unc will contain the host name
    and share up to but not including the fourth directory separator character.
    e.g. splitdrive("//host/computer/dir") returns ("//host/computer", "/dir")

    Paths cannot contain both a drive letter and a UNC path.

    Expand ~ and ~user constructs.

    If user or $HOME is unknown, do nothing._getfullpathname<module ntpath>path_drivebaltsepSplit a pathname.

    Return tuple (head, tail) where tail is everything after the final slash.
    Either part may be empty.Test whether a path is a symbolic link.
    This will always return false for Windows prior to 6.0.
    Test whether a path is a mount point (a drive root, the root of a
    share, or a mounted volume)Normalize case of pathname.

    Makes all characters lowercase and all slashes into backslashes.Deprecated since Python 3.1.  Please use splitdrive() instead;
    it now handles UNC paths.

    Split a pathname into UNC mount point and relative path specifiers.

    Return a 2-tuple (unc, rest); either part may be empty.
    If unc is not empty, it has the form '//host/mount' (or similar
    using backslashes).  unc+rest is always the input path.
    Paths containing drive letters never have a UNC part.
    Return the absolute version of a path._get_altsepConvert a NT pathname to a file URL and vice versa.OS-specific conversion from a relative URL of the 'file' scheme
    to a file system path; not recommended for general use.Bad path: OS-specific conversion from a file system path to a relative URL
    of the 'file' scheme; not recommended for general use.C:\msys64\mingw64\lib\python3.6\nturl2path.pyBad URL: ///////-selfIntegral.__rand__True if self != 0. Called for bool(self).Complex.__radd__other / selfRational.denominatorself <= otherRetrieve the imaginary component of this number.

        This should subclass Real.
        Complex.__mul__Real.__trunc__Complex.__bool__Complex.__pos__float(self) == float(int(self))C:\msys64\mingw64\lib\python3.6\numbers.pyReal.__rdivmod__To Complex, Real adds the operations that work on real numbers.

    In short, those are: a conversion to float, trunc(), divmod,
    %, <, <=, >, and >=.

    Real also provides defaults for the derived operations.
    float(self) = self.numerator / self.denominator

        It's important that this conversion use the integer's "true"
        division rather than casting one side to float before dividing
        so that ratios of huge integers convert without overflowing.

        other & selfComplex.conjugateother | selfself / other: Should promote to float when necessary.Integral.numeratorReal.__complex__Integral.__ror__ndigitsIntegral.__int__Rational.numeratorReal.__mod__.numerator and .denominator should be in lowest terms.Integers have a denominator of 1.Called whenever an index is needed, such as in slicingConjugate is a no-op for Reals.+selfAll numbers inherit from this class.

    If you just want to check if an argument x is a number, without
    caring what kind, use isinstance(x, Number).
    Real.__round__Integral.__pow__other * selfComplex.__neg__Rational.__float__Real numbers have no imaginary component.Integral.__lshift__Complex.__rmul__Return a builtin complex instance. Called for complex(self).Real.conjugateself | other(x+y*i).conjugate() returns (x-y*i).Integral.__invert__Real.__ceil__Finds the greatest Integral <= self.Integral.__xor__~selfIntegral.__or__Real.__rmod__Complex.__rtruediv__Real.imagself << otherother + selfself // other: The floor() of self/other.Complex.__truediv__Finds the least Integral >= self.Complex.__abs__Integral.denominatorComplex.__rsub__self >> otherother // self: The floor() of other/self.Real.__le__other ^ selfComplex.__sub__other >> selfbase ** selfdivmod(self, other): The pair (self // other, self % other).

        Sometimes this can be computed faster than the pair of
        operations.
        Real.__floordiv__Real numbers are their real component.Retrieve the real component of this number.

        This should subclass Real.
        Integral.__rshift__<module numbers>other << selfComplex.__complex__Real.__divmod__Integral.__rlshift__Complex.__pow__Complex.realReal.__floor__Abstract Base Classes (ABCs) for numbers, according to PEP 3141.

TODO: Fill out more detailed documentation on the operators.Integral.__index__Real.__lt____rrshift__divmod(other, self): The pair (self // other, self % other).

        Sometimes this can be computed faster than the pair of
        operations.
        other % selfAny Real can be converted to a native float object.

        Called for float(self).self ^ otherComplex.__rpow__self & otherself**exponent; should promote to float or complex when necessary.complex(self) == complex(float(self), 0)Integers are their own numerators.Complex.__eq__self ** exponent % modulus, but maybe faster.

        Accept the modulus argument if you want to support the
        3-argument version of pow(). Raise a TypeError if exponent < 0
        or any argument isn't Integral. Otherwise, just implement the
        2-argument version described in Complex.
        Integral adds a conversion to int and the bit-string operations.Returns the Real distance from 0. Called for abs(self).trunc(self): Truncates self to an Integral.

        Returns an Integral i such that:
          * i>0 iff self>0;
          * abs(i) <= abs(self);
          * for any Integral j satisfying the first two conditions,
            abs(i) >= abs(j) [i.e. i has "maximal" abs among those].
        i.e. "truncate towards 0".
        Complex defines the operations that work on the builtin complex type.

    In short, those are: a conversion to complex, .real, .imag, +, -,
    *, /, abs(), .conjugate, ==, and !=.

    If it is given heterogenous arguments, and doesn't have special
    knowledge about them, it should fall back to the builtin complex
    type as described below.
    Integral.__rxor__Integral.__rrshift__Rounds self to ndigits decimal places, defaulting to 0.

        If ndigits is omitted or None, returns an Integral, otherwise
        returns a Real. Rounds half toward even.
        Complex.imagReal.__float__Complex.__add__Integral.__float__self < other

        < on Reals defines a total ordering, except perhaps for NaN.Integral.__and__Real.__rfloordiv__Real.realC:\msys64\home\cbper\observer.pyObserver.__init__Observer.disconnectconnect_firstObserver.alertObserver.connect
Observer allows objects to alert other objects to changes.
<module observer>Observer.connect_firstINPLACE_POWERROT_TWOBINARY_TRUE_DIVIDEINPLACE_ANDLOAD_NAMEGET_ITERJUMP_FORWARDSTORE_ATTRIMPORT_FROMLOAD_DEREFDELETE_SUBSCRSTORE_ANNOTATIONSETUP_LOOPROT_THREEBEFORE_ASYNC_WITHDELETE_ATTRSETUP_ANNOTATIONSWITH_CLEANUP_FINISHPRINT_EXPRLOAD_CONSThasnargsUNARY_POSITIVEBUILD_MAPBUILD_SETFOR_ITERC:\msys64\mingw64\lib\python3.6\opcode.pyDUP_TOPCONTINUE_LOOPPOP_JUMP_IF_TRUECALL_FUNCTION_KW<module opcode>BUILD_LIST_UNPACKDUP_TOP_TWOSTORE_SUBSCRWITH_CLEANUP_STARTSETUP_WITHJUMP_ABSOLUTEINPLACE_MODULOLOAD_CLASSDEREFINPLACE_SUBTRACTINPLACE_XORSTORE_FASTBINARY_MODULOJUMP_IF_FALSE_OR_POPLIST_APPENDPOP_TOPLOAD_GLOBALSETUP_EXCEPTLOAD_ATTRCALL_FUNCTION_EXBUILD_TUPLESETUP_ASYNC_WITHBUILD_SLICEBINARY_RSHIFTBINARY_LSHIFTLOAD_BUILD_CLASSLOAD_FASTBUILD_MAP_UNPACK_WITH_CALLUNPACK_EXBUILD_TUPLE_UNPACK_WITH_CALLCOMPARE_OPBINARY_ORYIELD_VALUEGET_AITER
opcode module - potentially shared between dis and other modules which
operate on bytecodes (e.g. peephole optimizers).
BREAK_LOOPUNARY_INVERTMAP_ADDSTORE_DEREFBINARY_MULTIPLYGET_YIELD_FROM_ITERINPLACE_MULTIPLYSTORE_NAMEBINARY_XORBUILD_CONST_KEY_MAPLOAD_CLOSURESETUP_FINALLYBINARY_ADDEND_FINALLYBUILD_STRINGBINARY_ANDBINARY_FLOOR_DIVIDEDELETE_FASTINPLACE_FLOOR_DIVIDEGET_AWAITABLEBINARY_POWERINPLACE_TRUE_DIVIDEPOP_JUMP_IF_FALSEINPLACE_LSHIFTPOP_EXCEPTSTORE_GLOBALUNPACK_SEQUENCEstack_effectDELETE_NAMEBUILD_SET_UNPACKjrel_opINPLACE_ORINPLACE_ADDDELETE_GLOBALINPLACE_MATRIX_MULTIPLYPOP_BLOCKDELETE_DEREFRAISE_VARARGSGET_ANEXTBINARY_SUBSCRJUMP_IF_TRUE_OR_POPBINARY_SUBTRACTBINARY_MATRIX_MULTIPLYSET_ADDUNARY_NEGATIVEINPLACE_RSHIFT<%r>IMPORT_STARdef_opjabs_opname_opitemgetter.__init__.<locals>.func.<locals>.<genexpr>Same as abs(a).Same as a /= b.Same as not a.Same as del a[b].__length_hint__ must be integer, not %sSame as a[b].methodcaller.__init__'%s' object cannot be interpreted as an integerSame as a + b.methodcaller needs at least one argument, the method nameattrgetter.__reduce__gettersindexOf__itruediv__
    Return a callable object that fetches the given item(s) from its operand.
    After f = itemgetter(2), the call f(r) returns r[2].
    After g = itemgetter(2, 5, 3), the call g(r) returns (r[2], r[5], r[3])
    Same as a //= b.iconcatSame as a >>= b.Same as a + b, for a and b sequences.
Operator Interface

This module exports a set of functions corresponding to the intrinsic
operators of Python.  For example, operator.add(x, y) is equivalent
to the expression x+y.  The function names are those used for special
methods; variants without leading and trailing '__' are also provided
for convenience.

This is the pure Python implementation of the module.
attrgetter.__init__.<locals>.funcmethod name must be a stringSame as a @= b.Same as a // b.attrgetter.__repr____imatmul____concat__Same as a is not b.attribute name must be a stringSame as a += b.Same as a >> b.__not__itemgetter.__reduce__
    Return an estimate of the number of items in obj.
    This is useful for presizing containers when building from an iterable.

    If the object supports len(), the result will be exact. Otherwise, it may
    over- or under-estimate by an arbitrary amount. The result will be an
    integer >= 0.
    Same as a %= b.methodcaller.__call____ifloordiv__Same as +a.Same as a | b.Same as a != b.Same as a @ b.Û6   zabszaddzand_z
attrgetterzconcatzcontainszcountOfzdelitemzeqzfloordivzgezgetitemzgtziaddziandziconcatz	ifloordivzilshiftzimatmulzimodzimulzindexzindexOfzinvzinvertziorzipowzirshiftzis_zis_notzisubz
itemgetterzitruedivzixorzlezlength_hintzlshiftzltzmatmulzmethodcallerzmodzmulzneznegznot_zor_zposzpowzrshiftzsetitemzsubztruedivztruthzxor__ipow__Same as a.__index__().Same as a *= b.Same as a[b] = c.Same as a &= b.Same as a ^= b.Same as a <<= b.Same as a << b.Return the first index of b in a.Same as -a.itemgetter.__call__Same as a -= b.__inv__<module operator>Same as a < b.
    Return a callable object that fetches the given attribute(s) from its operand.
    After f = attrgetter('name'), the call f(r) returns r.name.
    After g = attrgetter('name', 'date'), the call g(r) returns (r.name, r.date).
    After h = attrgetter('name.first', 'name.last'), the call h(r) returns
    (r.name.first, r.name.last).
    __irshift__Same as ~a.Return the number of times b occurs in a.Same as a * b.'%s' object can't be concatenatedSame as a |= b.attrgetter.__call__
    Return a callable object that calls the given method on its operand.
    After f = methodcaller('name'), the call f(r) returns r.name().
    After g = methodcaller('name', 'date', foo=1), the call g(r) returns
    r.name('date', foo=1).
    Same as a <= b.__iconcat__Same as a is b.Same as a / b.attrgetter.__init__.<locals>.func.<locals>.<genexpr>__matmul__sequence.index(x): x not in sequenceSame as a & b.__length_hint__() should return >= 0Return True if a is true, False otherwise.Same as a - b.C:\msys64\mingw64\lib\python3.6\operator.pyitemgetter.__repr__Same as a % b.Same as a ** b.Same as a ^ b.Same as b in a (note reversed operands).Same as a > b.methodcaller.__reduce__Same as a >= b.__ilshift__methodcaller.__repr__methodcaller.__repr__.<locals>.<genexpr>__imod__Same as a **= b.Same as a == b.Same as a += b, for a and b sequences.C:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\optimizationsC:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\optimizations\__init__.py Demotion of compiled modules to bytecode modules.

 Demote a compiled module to uncompiled (bytecode).

    <module optimizations.BytecodeDemotion>Demoting module '%s' to bytecode from '%s'.C:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\optimizations\BytecodeDemotion.py In-lining of functions.

Done by assigning the argument values to variables, and producing an outline
from the in-lined function.
function_source_refargument_namesC:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\optimizations\FunctionInlining.pynuitka.tree.TreeHelperscall_source_refnuitka.nodes.AssignNodesnuitka.tree.Extractionsnuitka.nodes.OutlineNodes<module optimizations.FunctionInlining>pygraphvizmodule_graphC:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\optimizations\Graphs.pyCannot import pygraphviz module, no graphing capability.computation_counters Graph optimization states.

These are not the graphs you might be thinking of. This is for rending the
progress of optimization into images.
_addModuleGraphoptimizations.GraphsAGraph<module optimizations.Graphs>nuitka.nodes.NodeBasesNext global optimization pass.optimizeUnusedClosureVariablesMemory usage changed during optimization of '%s': %soptimizeCompiledPythonModuleTagsDoing module dependency considerations for '{module_name}':Initial optimization pass.optimizeUnusedUserVariables{source_ref} : {tags} : {message}optimizeShlibModuleDoing module local optimizations for '{module_name}'.optimizeUnusedTempVariablesnew_roots_is_verboseRemove unused local variable '%s'.nuitka.TreeXML Control the flow of optimizations applied to node tree.

Applies abstract execution on all so far known modules until no more
optimization is possible. Every successful optimization to anything might
make others possible.
xml reloadedused_module_namecurrent_moduletag_setinitial_passRemove unused closure variable '%s'.PASS 1:retextMemory usage {memory}:areEmptyTracesoptimizeModuleoptimizeVariablesPASS 2 ... :optimizeUnusedAssignmentsoptimizeUncompiledPythonModuleOptimizing module '{module_name}', {remaining:d} more modules to go after that.makeOptimizationPass.<locals>.<genexpr>out.xmlxml orig_traceProgressC:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\optimizations\Optimization.pyrestoreFromXMLoptimizations.Optimization Indicate a change to the optimization framework.

    unused_function<module optimizations.Optimization> Make a single pass for optimization, indication potential completion.

    out2.xmlInterrupted while working on '%s'._checkXMLPersistenceopen_extractormakeFloat0par1_namerepr_extractorcompile_extractor.<locals>.wrapExpressionBuiltinCompileCreationselectVarsEmptyClasswrapExpressionBuiltinExecCreationmakeComplex0super(): no argumentsoct_extractorcomplex_extractor.<locals>.makeComplex0list_extractormakeLocalsNodewrapEvalBuiltinisStatementExecReplaced call to built-in '%s' with binary operation '%s'.execfile_extractor.<locals>.wrapExpressionBuiltinExecfileCreationchr_extractormakeOrd0staticmethod_extractor.<locals>.makeStaticmethod0sum_extractor.<locals>.makeSum0selectIntBuiltinimport_extractorselectBytesBuiltinset_extractorselectComplexBuiltinmakeLong0object_variablemakeBytearray0selectNextBuiltinClassReplaced call to built-in '%s' with built-in call '%s'.range expected at least 1 arguments, got 0wrapIterCreationmakeRange0Replaced call to built-in '%s' with exception raise.selectRangeBuiltinglobals_reflocals_refexecfile_callwrapExpressionBuiltinDictCreationmakeReprOperatorid_extractor Describe the change for better understanding.

    locals_extractorfloat_extractor.<locals>.makeFloat0dir_extractor.<locals>.buildDirEmptyCasebytes_extractor.<locals>.makeBytes0sum expected at least 1 arguments, got 0wrapSliceslice_extractor.<locals>.wrapSlicerange_extractor.<locals>.selectRangeBuiltintype_extractorxrange_extractorunicode_extractorclassmethod_extractor.<locals>.makeStaticmethod0long_extractor.<locals>.selectIntBuiltineval_extractor.<locals>.wrapEvalBuiltinglobals_extractorReplaced call to built-in '%s' with constant value.makeInt0iter_extractorisExpressionRaiseExceptionstring_fixupdict_extractorsuper_extractor.<locals>.wrapSuperBuiltinmakeFormat0inspect_nodefrozenset_extractorrange_extractor.<locals>.makeRange0iter_extractor.<locals>.wrapIterCreationselectXrangeBuiltinascii_extractorint_extractor.<locals>.makeInt0dict expected at most 1 arguments, got %ddict_extractor.<locals>.wrapExpressionBuiltinDictCreationsum_extractor.<locals>.selectSumBuiltinClassù                next_extractor.<locals>.selectNextBuiltinClassstr_extractorstrip_choiceexec_callxrange_extractor.<locals>.selectXrangeBuiltinmakeOpen0super(): __class__ cell not foundord_extractor.<locals>.makeOrd0Replaced call to built-in '%s' with call.len_extractoreval_callrange expected 1 arguments, got 0ord() takes exactly one argument (0 given)_describeNewNodevars_extractor.<locals>.selectVarsEmptyClassopen_extractor.<locals>.makeOpen0bin_extractorexec_extractorhash_extractorgetattr_extractorlong_extractor.<locals>.makeLong0Replaced call to built-in '%s' with unary operation '%s'.format() takes at least 1 argument (0 given)exec_extractor.<locals>.wrapExpressionBuiltinExecCreationhasattr_extractorhex_extractorrepr_extractor.<locals>.makeReprOperator Optimize calls to built-in references to specific built-in calls.

For built-in name references, we check if it's one of the supported built-in
types, and then specialize for the ones, where it makes sense.
acceptable_builtin_typessetattr_extractordivmod_extractorclassmethod expected 1 arguments, got 0xrange_extractor.<locals>.makeXrange0locals_extractor.<locals>.makeLocalsNodetuple_extractorReplaced call to built-in '%s' with outlined call.type_arg_ownerC:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\optimizations\OptimizeBuiltinCalls.pycomplex_extractor.<locals>.selectComplexBuiltinisinstance_extractorint_extractor.<locals>.selectIntBuiltinbytearray_extractorxrange requires 1-3 int argumentsstaticmethod expected 1 arguments, got 0bytearray_extractor.<locals>.selectNextBuiltinClass_builtin_white_listReplaced dynamic "__import__" call with static built-in call.Required argument 'file' (pos 1) not found<module optimizations.OptimizeBuiltinCalls>bool_extractorformat_extractor.<locals>.makeFormat0bytes_extractor.<locals>.selectBytesBuiltintype() takes 1 or 3 argumentsbytearray_extractor.<locals>.makeBytearray0TagSet.addallowed_tags Tags and set of it.

Used by optimization to keep track of the current state of optimization, these
tags trigger the execution of optimization steps, which in turn may emit these
tags to execute other steps.

TagSet.checkread_only_mvarC:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\optimizations\Tags.pyoptimizations.Tags<module optimizations.Tags>TagSet.onSignalTraceCollectionBase.onLoopBreakTraceCollectionBranch.initVariableTraceCollectionBase.addOutlineFunctionValueTracesvariable_versionsCollectionTracingMixin_initVariableInit_initVariableUninitTraceCollectionBase.getVariableTraceCollectionStartpointMixin.getLoopContinueCollectionsCollectionStartpointMixin.onLoopContinueTraceCollectionBase.getExceptionRaiseCollectionsTraceCollectionBranch.dumpActiveTracesCollectionStartpointMixin.getVariableTracesCollectionTracingMixin.markCurrentVariableTraceoutline_functionsTraceCollectionBase.getLoopContinueCollectionsTraceCollectionBase.getCompileTimeComputationResultcollection_replaceCollectionStartpointMixin.getExceptionRaiseCollectionsCollectionStartpointMixin.onExceptionRaiseExitTraceCollectionBase.onExceptionRaiseExitCollectionStartpointMixin.makeAbortStackContextvalue_statesTraceCollectionFunction.__init__TraceCollectionBase.getLoopBreakCollectionsparameter_variableTraceCollectionBase.onVariableDelTraceCollectionBase.onVariableContentEscapesold_continue_collectionsold_locals_scopeTraceCollectionBranch.computeBranchTraceCollectionBase.makeLocalsDictContexttrace_mergelocals_dict_variable Merge two alternative branches into this trace.

            This is mostly for merging conditional branches, or other ways
            of having alternative control flow. This deals with up to two
            alternative branches to both change this collection.
        TraceCollectionBase.onExpressionTraceCollectionBase.getFunctionReturnCollectionsold_break_collectionsold_return_collectionsold_exception_collectionsaddVariableTracemarkActiveVariableAsUnknowndumpTracesTraceCollectionBranch.onLocalsDictEscapedTraceCollectionBase.mustAliasraisable_exceptions_variable_descTraceCollectionBase.signalChangeTraceCollectionBase.makeAbortStackContextTraceCollectionBase.onVariableSetTraceCollectionBase.replaceBranchProblem with statement at %s:
-> %s_getCurrentVariableVersionCollectionTracingMixin.markActiveVariablesAsUnknownCollectionStartpointMixin.onLoopBreakTraceCollectionBase.removeAllKnowledgeActive are: Trace collection (also often still referred to as constraint collection).

At the core of value propagation there is the collection of constraints that
allow to propagate knowledge forward or not.

This is about collecting these constraints and to manage them.
<%s for %s at 0x%x>CollectionTracingMixin.__init__CollectionTracingMixin.markActiveVariableAsLoopMergeold_traceTraceCollectionBranch.__init__addVariableMergeMultipleTraceCollectionStartpointMixin.addOutlineFunctionTraceCollectionBase.addVariableTraceTraceCollectionBase.initIteratorValue This contains for logic for maintaining active traces.

        They are kept for "variable" and versions.
    TraceCollectionBase.onUsedModuleCollectionStartpointMixin.updateVariablesFromCollectionTraceCollectionBranch.dumpTracesTraceCollectionModule.onUsedModuleTraceCollectionBase.resetValueStatesCollectionStartpointMixin.initVariableCollectionStartpointMixin.getOutlineFunctionsCollectionStartpointMixin.dumpActiveTracesTraceCollectionBase.onLocalsUsageTraceCollectionModule.getUsedModulesCollectionStartpointMixin.makeLocalsDictContextCollectionTracingMixin.getVariableCurrentTracegetActiveVariablesCollectionStartpointMixin.addVariableMergeMultipleTraceTraceCollectionBase.onStatementTraceCollectionBase.onLocalsDictEscapedConstraint collection state: %sTraceCollectionBase.__init__CollectionStartpointMixin.getLoopBreakCollectionsTraceCollectionBase.onLoopContinueCollectionStartpointMixin.onFunctionReturnCollectionStartpointMixin._initVariableInitTraceCollectionBase.mergeMultipleBranches<module optimizations.TraceCollections>TraceCollectionBase.__repr__TraceCollectionBase.mustNotAlias Get the current value trace associated to this variable

            It is also created on the fly if necessary. We create them
            lazy so to keep the tracing branches minimal where possible.
        TraceCollectionBase.addVariableMergeMultipleTraceCollectionStartpointMixin.getVariableTracesAllTraceCollectionBase.onFunctionReturnCollectionStartpointMixin.dumpTracesCollectionStartpointMixin.__init__CollectionStartpointMixin.hasVariableTraceTraceCollectionBase.hasVariableTraceTraceCollectionBase.getIteratorNextCountCollectionStartpointMixin.addVariableTraceCollectionStartpointMixin.getFunctionReturnCollectionsCollectionTracingMixin._getCurrentVariableVersionCollectionTracingMixin.markActiveVariableAsUnknownTraceCollectionBase.removeKnowledgeCollectionTracingMixin.getActiveVariablesCollectionStartpointMixin.initVariableUnknownCollectionStartpointMixin._initVariableUninitTraceCollectionBase.onControlFlowEscapeTraceCollectionBase.onIteratorNextTraceCollectionBase.mergeBranchesC:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\optimizations\TraceCollections.pyTraceCollectionModule.__init__CollectionStartpointMixin.onLocalsDictEscapedValueTraceUnknown.addPotentialUsageValueTraceMerge.mustHaveValueValueTraceBase.hasPotentialUsages<ValueTraceUninit of {owner}><ValueTraceInit of {owner}>ValueTraceLoopMerge.hasDefiniteUsages  Starts initializedValueTraceBase.__init__<ValueTraceAssign at {source_ref} of {value}>ValueTraceMerge.addPotentialUsageValueTraceBase.hasShapeDictionaryExactcontinue_tracesValueTraceUninit.mustNotHaveValueclosure_usagesValueTraceBase.getNameUsageCountValueTraceBase.isMergeTraceValueTraceAssign.__init__usage_countloop_finished  Starts unknownValueTraceBase.mustNotHaveValue Merge of two or more traces.

        Happens at the end of conditional blocks. This is "phi" in
        SSA theory. Also used for merging multiple "return", "break" or
        "continue" exits.
    has_potential_usagesValueTraceBase.isUninitTraceValueTraceBase.getReplacementNodeValueTraceBase.getPreviousValueTraceBase.isInitTraceValueTraceUnknown.__init__ValueTraceInit.__init__ValueTraceUnknown.addUsageValueTraceBase.addUsageValueTraceMerge.mustNotHaveValueValueTraceInit.dump<ValueTraceMerge of {previous}>ValueTraceBase.addNameUsageValueTraceBase.getOwnerValueTraceLoopMerge.__init__replace_it  Merge of %s  Starts assignedValueTraceBase.addPotentialUsageValueTraceLoopMerge.getPrevious  -> has %s usagesValueTraceUnknown.addNameUsageValueTraceUnknown.isUnknownTraceoptimizations.ValueTracesValueTraceAssign.hasShapeDictionaryExactValueTraceMerge.addNameUsagename_usagesis_escapedValueTraceAssign.getReplacementNodeValueTraceUninit.dumpValueTraceLoopMerge.isMergeTraceValueTraceBase.getDefiniteUsagesValueTraceUninit.__init__ValueTraceUninit.isUninitTraceValueTraceLoopMerge.getNameUsageCountValueTraceAssign.dumpValueTraceMerge.__repr__ValueTraceBase.isAssignTraceValueTraceInit.__repr__ValueTraceBase.isUnknownTraceValueTraceMerge.dumpValueTraceUnknown.dumpValueTraceBase.onValueEscapeValueTraceLoopMerge.addLoopContinueTraces  -> value escapesValueTraceUninit.__repr__C:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\optimizations\ValueTraces.pyValueTraceBase.mustHaveValueValueTraceBase.addClosureUsageValueTraceMerge.__init__ValueTraceInit.isInitTraceValueTraceAssign.getAssignNode<module optimizations.ValueTraces>  Starts out uninitializedValueTraceMerge.hasShapeDictionaryExactValueTraceLoopMerge.hasPotentialUsages<ValueTraceUnknown of {owner}>ValueTraceBase.hasDefiniteUsagesisEscapedValueTraceMerge.addUsageValueTraceAssign.setReplacementNodeValueTraceAssign.__repr__ Merge of loop wrap around with loop start value.

        Happens at the start of loop blocks. This is for loop closed SSA, to
        make it clear, that the entered value, cannot be trusted inside the
        loop.

        They will start out with just one previous, and later be updated with
        all of the variable versions at loop continue times.
    ValueTraceUnknown.__repr__ValueTraceBase.isEscaped Value trace objects.

Value traces indicate the flow of values and merges their versions for
the SSA (Single State Assignment) form being used in Nuitka.

Values can be seen as:

* Unknown (maybe initialized, maybe not, we cannot know)
* Uninit (definitely not initialized, first version, or after "del" statement)
* Init (definitely initialized, e.g. parameter variables)
* Merge (result of diverged code paths, loop potentially)

ValueTraceAssign.isAssignTraceValueTraceMerge.isMergeTraceTYPED_ACTIONSOptionParser.print_helpOptionContainer.format_descriptionoption %s: invalid %s value: %roption %s: invalid choice: %r (choose from %s)OptionParser.format_option_help_update_careful_match_long_opt
    Raised if an ambiguous option is seen on the command line.
    no such option: %sHelpFormatter.set_long_opt_delimiteropt_str
        parse_args(args : [string] = sys.argv[1:],
                   values : Values = None)
        -> (values : Values, args : [string])

        Parse the command-line options found in 'args' (default:
        sys.argv[1:]).  Any errors result in a call to 'error()', which
        by default prints the usage message to stderr and calls
        sys.exit() with an error message.  On success returns a pair
        (values, args) where 'values' is a Values instance (with all
        your option values) and 'args' is the list of arguments left
        over after parsing options.
        had_explicit_valueat least one option string must be suppliedOptionContainer._share_option_mappingsAmbiguousOptionErrorOption.__init__choices must be a list of strings ('%s' supplied)make_optionSUPPRESS_USAGEIndentedHelpFormatterTitledHelpFormatterOptParseErrorOptionConflictErrorOptionValueErrorBadOptionErrorcheck_choiceAmbiguousOptionError.__str___short_optstakes_valuelong_optsUsage: %s
Option.get_opt_stringcheck_valuesOptionParser._process_long_optC:\msys64\mingw64\lib\python3.6\optparse.pyOptionParser.__init___check_destexpand_prog_nameexpand_defaultA powerful, extensible, and easy-to-use option parser.

By Greg Ward <gward@python.net>

Originally distributed as Optik.

For support, use the optik-users@lists.sourceforge.net mailing list
(http://lists.sourceforge.net/lists/listinfo/optik-users).

Simple usage example:

   from optparse import OptionParser

   parser = OptionParser()
   parser.add_option("-f", "--file", dest="filename",
                     help="write report to FILE", metavar="FILE")
   parser.add_option("-q", "--quiet",
                     action="store_false", dest="verbose", default=True,
                     help="don't print status messages to stdout")

   (options, args) = parser.parse_args()
c_option%s option does not take a valueValues._updatedisable_interspersed_argsambiguous option: %s (%s?)_parse_numOptionParser.disable_interspersed_argsoption %s: %sOptionParser.get_default_valuesOptionParser._process_short_optsformat_option_stringsIndentedHelpFormatter.format_headingOptionParser.enable_interspersed_argssee OptionParser.destroy().OptionParser.parse_argsstore_option_stringsOptionParser.exit_check_opt_strings
    Raised if conflicting options are added to an OptionParser.
    _parse_intOptionContainer._check_conflictread_moduleno such option %rOptionParser.set_process_default_valuescallback supplied (%r) for non-callback option_long_opt_fmtinvalid argumentsValues.read_fileOptionParser.add_option_groupAmbiguousOptionError.__init__print_versionSet parsing to stop on the first non-option. Use this if
        you have a command processor which runs another command that
        has options of its own and you want to make sure these options
        don't get confused.
        OptParseError.__init__Option.takes_valueSUPPRESSHELPIndentedHelpFormatter.__init__HelpFormatter.format_optionSet parsing to not stop on the first non-option, allowing
        interspersing switches with command arguments. This is the
        default behavior. See also disable_interspersed_args() and the
        class documentation description of the attribute
        allow_interspersed_args.add_optionshas_option_set_opt_stringsOption._set_opt_stringsNO_DEFAULT_VALUEHelpFormatter.dedentset_description_get_all_optionssingularconflict_opts_create_option_listOption._check_opt_strings
        Declare that you are done with this OptionParser.  This cleans up
        reference cycles so the OptionParser (and all objects referenced by
        it) can be garbage-collected promptly.  After calling destroy(), the
        OptionParser is unusable.
        OptionParser.expand_prog_namecallback_args, if supplied, must be a tuple: not %rHelpFormatter.set_parserwordmap_add_help_option%defaultmust not supply a type for action %r
    Raised if an invalid option is seen on the command line.
    Option._check_destValues._update_looseOptionGroup._create_option_listmust supply a list of choices for type 'choice'%(option)s option requires %(number)d arguments_init_parsing_statecallback_kwargsBadOptionError.__init__OptionParser._add_help_optionOptionContainer.get_optionget_option_groupHelpFormatter.format_usageOption._check_choice_builtin_cvtOption.take_actionconflicting option string(s): %sOption._check_type
        Update the option values from an arbitrary dictionary, but only
        use keys from dict that already have a corresponding attribute
        in self.  Any keys in dict without a corresponding attribute
        are silently ignored.
        OptionContainer.remove_optionlopt
Copyright (c) 2001-2006 Gregory P. Ward.  All rights reserved.
Copyright (c) 2002-2006 Python Software Foundation.  All rights reserved.

Redistribution and use in source and binary forms, with or without
modification, are permitted provided that the following conditions are
met:

  * Redistributions of source code must retain the above copyright
    notice, this list of conditions and the following disclaimer.

  * Redistributions in binary form must reproduce the above copyright
    notice, this list of conditions and the following disclaimer in the
    documentation and/or other materials provided with the distribution.

  * Neither the name of the author nor the names of its
    contributors may be used to endorse or promote products derived from
    this software without specific prior written permission.

THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS
IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED
TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A
PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE AUTHOR OR
CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
HelpFormatter.format_descriptionOptParseError.__str__get_usageset_usageOptionParser.print_usageOptionParser._populate_option_list'nargs' must not be supplied for action %r_add_version_optionOptionContainer.destroy'const' must not be supplied for action %rOptionParser.check_values_short_opt_fmt%s: error: %s
TitledHelpFormatter.format_usage_check_constFormat help with underlined section headers.
    Option.__str__callback_args supplied for non-callback optionValues.read_moduleFormat help with indented section bodies.
    Values._update_carefulinvalid conflict_resolution value %rHelpFormatter.store_option_stringsinvalid metavar delimiter for short options: %r1.5.3OptionParser.set_defaultstandard_option_listfloating-pointHelpFormatter.expand_defaultOptionContainer.format_helpOptionParser.set_usageOption._set_attrsHelpFormatter.set_short_opt_delimiterOption._check_nargs
        check_values(values : Values, args : [string])
        -> (values : Values, args : [string])

        Check that the supplied option values and leftover arguments are
        valid.  Returns the option values and leftover arguments
        (possibly adjusted, possibly completely new -- whatever you
        like).  Default implementation just returns the passed-in
        values; subclasses may override as desired.
        Option._check_action_match_abbrev(s : string, wordmap : {string : Option}) -> string

    Return the string key in 'wordmap' for which 's' is an unambiguous
    abbreviation.  If 's' is found to be ambiguous or doesn't match any of
    'words', raise BadOptionError.
    OptionContainer.add_optionshort_firstadd_option(Option)
           add_option(opt_str, ..., kwarg=val, ...)
        TitledHelpFormatter.format_headingOptionParser._create_option_listOption._check_callbackmust not supply choices for type %rprint_version(file : file = stdout)

        Print the version message for this program (self.version) to
        'file' (default stdout).  As with print_usage(), any occurrence
        of "%prog" in self.version is replaced by the current program's
        name.  Does nothing if self.version is empty or undefined.
        _process_argsOptionContainer.has_optionOptionContainer.set_conflict_handlerOptionParser.format_helpcallback_kwargs supplied for non-callback optionValues.__eq__OptionGroup.destroyOptionGroup.format_helpBadOptionError.__str__CONST_ACTIONSget_prog_nameOptionParser._add_version_optionOption.convert_valueinvalid option string %r: must be at least two characters long_create_option_mappingsOptionParser.format_epilogoption_classinvalid option type: %rOptionGroup.set_titleOptionParser._process_argsOptionParser._get_argsOption.processoption_groupscallback not callable: %rOptionParser.get_descriptionprint_help(file : file = stdout)

        Print an extended help message, listing all options and any
        help text provided with them, to 'file' (default stdout).
        OptionParser.get_usageopt_width
        Format a paragraph of free-form text for inclusion in the
        help output at the current indentation level.
        error(msg : string)

        Print a usage message incorporating 'msg' to stderr and exit.
        If you override this in a subclass, it should not return -- it
        should either exit or raise an exception.
        OptionParser.errorValues.ensure_valueinvalid OptionGroup (wrong parser)OptionContainer.set_descriptionTYPE_CHECKEROptionContainer._create_option_mappingsHelpFormatter.format_option_strings
        Update the option values from an arbitrary dictionary,
        using all keys from the dictionary regardless of whether
        they have a corresponding attribute in self or not.
        OptionContainer.get_description
    Class attributes:
      standard_option_list : [Option]
        list of standard options that will be accepted by all instances
        of this parser class (intended to be overridden by subclasses).

    Instance attributes:
      usage : string
        a usage string for your program.  Before it is displayed
        to the user, "%prog" will be expanded to the name of
        your program (self.prog or os.path.basename(sys.argv[0])).
      prog : string
        the name of the current program (to override
        os.path.basename(sys.argv[0])).
      description : string
        A paragraph of text giving a brief overview of your program.
        optparse reformats this paragraph to fit the current terminal
        width and prints it when the user requests help (after usage,
        but before the list of options).
      epilog : string
        paragraph of help text to print after option help

      option_groups : [OptionGroup]
        list of option groups in this parser (option groups are
        irrelevant for parsing the command-line, but very useful
        for generating help)

      allow_interspersed_args : bool = true
        if true, positional arguments may be interspersed with options.
        Assuming -a and -b each take a single argument, the command-line
          -ablah foo bar -bboo baz
        will be interpreted the same as
          -ablah -bboo -- foo bar baz
        If this flag were false, that command line would be interpreted as
          -ablah -- foo bar -bboo baz
        -- ie. we stop processing options as soon as we see the first
        non-option argument.  (This is the tradition followed by
        Python's getopt module, Perl's Getopt::Std, and other argument-
        parsing libraries, but it is generally annoying to users.)

      process_default_values : bool = true
        if true, option default values are processed similarly to option
        values from the command line: that is, they are passed to the
        type-checking function for the option's type (as long as the
        default value is a string).  (This really only matters if you
        have defined custom types; see SF bug #955889.)  Set it to false
        to restore the behaviour of Optik 1.4.1 and earlier.

      rargs : [string]
        the argument list currently being parsed.  Only set when
        parse_args() is active, and continually trimmed down as
        we consume arguments.  Mainly there for the benefit of
        callback options.
      largs : [string]
        the list of leftover arguments that we have skipped while
        parsing options.  If allow_interspersed_args is false, this
        list is always empty.
      values : Values
        the set of option values currently being accumulated.  Only
        set when parse_args() is active.  Also mainly for callbacks.

    Because of the 'rargs', 'largs', and 'values' attributes,
    OptionParser is not thread-safe.  If, for some perverse reason, you
    need to parse command-line arguments simultaneously in different
    threads, use different OptionParser instances.

    CHECK_METHODSOptionParser.print_versioncheck_builtinnot an Option instance: %rHelpFormatter.indentOption._check_const
    Raised if an Option instance is created with invalid or
    inconsistent arguments.
    default_tagOptionParser.get_version<%s at 0x%x: %s>STORE_ACTIONSunknown action %roption_idTitledHelpFormatter.__init__<module optparse>OptionParser._init_parsing_stateOption.check_value_process_args(largs : [string],
                         rargs : [string],
                         values : Values)

        Process command-line arguments and populate 'values', consuming
        options and arguments from 'rargs'.  If 'allow_interspersed_args' is
        false, stop at the first non-option argument.  If true, accumulate any
        interspersed non-option arguments in 'largs'.
        OptionContainer.format_option_helpReturn a comma-separated list of option strings & metavariables.not an OptionGroup instance: %r
    Raised if an invalid option value is encountered on the command
    line.
    %s  %s
_long_opts_match_long_opt(opt : string) -> string

        Determine which long option string 'opt' matches, ie. which one
        it is an unambiguous abbreviation for.  Raises BadOptionError if
        'opt' doesn't unambiguously match any long option string.
        
    Abstract base class for formatting option help.  OptionParser
    instances should use one of the HelpFormatter subclasses for
    formatting help; by default IndentedHelpFormatter is used.

    Instance attributes:
      parser : OptionParser
        the controlling OptionParser instance
      indent_increment : int
        the number of columns to indent per nesting level
      max_help_position : int
        the maximum starting column for option help text
      help_position : int
        the calculated starting column for option help text;
        initially the same as the maximum
      width : int
        total number of columns for output (pass None to constructor for
        this value to be taken from the $COLUMNS environment variable)
      level : int
        current indentation level
      current_indent : int
        current indentation level (in columns)
      help_width : int
        number of columns available for option help text (calculated)
      default_tag : str
        text to replace with each option's default value, "%default"
        by default.  Set to false value to disable default value expansion.
      option_strings : { Option : str }
        maps Option instances to the snippet of help text explaining
        the syntax of that option, e.g. "-h, --help" or
        "-fFILE, --file=FILE"
      _short_opt_fmt : str
        format string controlling how short options with values are
        printed in help text.  Must be either "%s%s" ("-fFILE") or
        "%s %s" ("-f FILE"), because those are the two syntaxes that
        Optik supports.
      _long_opt_fmt : str
        similar but for long options; must be either "%s %s" ("--file FILE")
        or "%s=%s" ("--file=FILE").
    print_usage(file : file = stdout)

        Print the usage message for the current program (self.usage) to
        'file' (default stdout).  Any occurrence of the string "%prog" in
        self.usage is replaced with the name of the current program
        (basename of sys.argv[0]).  Does nothing if self.usage is empty
        or not defined.
        OptionContainer.__init__OptionParser.get_prog_nameSUPPRESSUSAGEValues.__init__OptionGroup.__init__OptionParser._match_long_optinvalid metavar delimiter for long options: %rinvalid long option string %r: must start with --, followed by non-dashinvalid short option string %r: must be of the form -x, (x any non-dash char)OptionParser._get_all_optionsinvalid keyword arguments: %scallback_kwargs, if supplied, must be a dict: not %rsubclasses must implementValues.__str__IndentedHelpFormatter.format_usageHelpFormatter.format_epilogOptionParser.get_option_groupinvalid update mode: %r
    Abstract base class.

    Class attributes:
      standard_option_list : [Option]
        list of standard options that will be accepted by all instances
        of this parser class (intended to be overridden by subclasses).

    Instance attributes:
      option_list : [Option]
        the list of Option objects contained by this OptionContainer
      _short_opt : { string : Option }
        dictionary mapping short option strings, eg. "-f" or "-X",
        to the Option instances that implement them.  If an Option
        has multiple short option strings, it will appear in this
        dictionary multiple times. [1]
      _long_opt : { string : Option }
        dictionary mapping long option strings, eg. "--file" or
        "--exclude", to the Option instances that implement them.
        Again, a given Option can occur multiple times in this
        dictionary. [1]
      defaults : { string : any }
        dictionary mapping option destination names to default
        values for each destination [1]

    [1] These mappings are common to (shared by) all components of the
        controlling OptionParser, where they are initially created.

    
    Instance attributes:
      _short_opts : [string]
      _long_opts : [string]

      action : string
      type : string
      dest : string
      default : any
      nargs : int
      const : any
      choices : [string]
      callback : function
      callback_args : (any*)
      callback_kwargs : { string : any }
      help : string
      metavar : string
    ALWAYS_TYPED_ACTIONSHAVE_LCHFLAGSputenvspawnlpeHAVE_UNLINKATspawnlp(mode, file, *args) -> integer

Execute file (which is looked for along $PATH) with arguments from
args in a subprocess with the supplied environment.
If mode == P_NOWAIT return the pid of the process.
If mode == P_WAIT return the process's exit code if it exits normally;
otherwise return -SIG, where SIG is the signal that killed it. path_listbMS_WINDOWS_Environ.__delitem__argrestno os specific module foundspawnveHAVE_FCHOWNATenv cannot contain 'PATH' and b'PATH' keysfstatvfs_Environ.__init__last_exc_createenviron.<locals>.check_strpath_type_wrap_close.__init__removedirsHAVE_FSTATATfollowlinksexecleenviron({{{}}})_have_functionsspawnve(mode, file, args, env) -> integer

Execute file with arguments from args in a subprocess with the
specified environment.
If mode == P_NOWAIT return the pid of the process.
If mode == P_WAIT return the process's exit code if it exits normally;
otherwise return -SIG, where SIG is the signal that killed it. spawnvpencodedkeyHAVE_FDOPENDIRHAVE_LUTIMESHAVE_LCHOWN_Environ.__repr__.<locals>.<genexpr>execvexecvp(file, args)

    Execute the executable file (which is searched for along $PATH)
    with argument list args, replacing the current process.
    args may be a list or tuple of strings. 'dir_fd' is an invalid keyword argument for this functionsupports_bytes_environpath_reprENOTDIR_fwalkspawnle(mode, file, *args, env) -> integer

Execute file with arguments from args in a subprocess with the
supplied environment.
If mode == P_NOWAIT return the pid of the process.
If mode == P_WAIT return the process's exit code if it exits normally;
otherwise return -SIG, where SIG is the signal that killed it. _unsetenvencodekey_fscodec.<locals>.fsdecodeGet an environment variable, return None if it doesn't exist.
    The optional second argument can specify an alternate default.
    key, default and the result are str.HAVE_FUTIMESATbytes expected, not %s_Environ.copydecodevaluewalk_intotoppathtopdownnondirsexeclpeHAVE_MKFIFOATgetfilesystemencodeerrorsexecle(file, *args, env)

    Execute the executable file with argument list args and
    environment env, replacing the current process. encodevaluecdirexecvpeHAVE_UTIMENSATHAVE_FEXECVEexecvpe(file, args, env)

    Execute the executable file (which is searched for along $PATH)
    with argument list args and environment env , replacing the
    current process.
    args may be a list or tuple of strings. renames__fspath__HAVE_FACCESSATinvalid mode %r_Environ.setdefaultHAVE_FPATHCONFHAVE_MKDIRATargv must be a tuple or a listnew_pathReturn the path representation of a path-like object.

    If str or bytes is passed in, it is returned unchanged. Otherwise the
    os.PathLike interface is used to get the path representation. If the
    path representation is not str or bytes, TypeError is raised. If the
    provided path is not str, bytes, or os.PathLike, TypeError is raised.
    HAVE_READLINKATexeclpe(file, *args, env)

    Execute the executable file (which is searched for along $PATH)
    with argument list args and environment env, replacing the current
    process. _putenv_Environ.__getitem__Decode filename (an os.PathLike, bytes, or str) from the filesystem
        encoding with 'surrogateescape' error handler, return str unchanged. On
        Windows, use 'strict' error handler if the file system encoding is
        'mbcs' (which is the default encoding).
        P_NOWAITO_wrap_close.closeHAVE_FSTATVFSspawnlpe(mode, file, *args, env) -> integer

Execute file (which is looked for along $PATH) with arguments from
args in a subprocess with the supplied environment.
If mode == P_NOWAIT return the pid of the process.
If mode == P_WAIT return the process's exit code if it exits normally;
otherwise return -SIG, where SIG is the signal that killed it. argv first element cannot be emptyHAVE_FUTIMENSOS routines for NT or Posix depending on what system we're on.

This exports:
  - all functions from posix or nt, e.g. unlink, stat, etc.
  - os.path is either posixpath or ntpath
  - os.name is either 'posix' or 'nt'
  - os.curdir is a string representing the current directory (always '.')
  - os.pardir is a string representing the parent directory (always '..')
  - os.sep is the (or a most common) pathname separator ('/' or '\\')
  - os.extsep is the extension separator (always '.')
  - os.altsep is the alternate pathname separator (None or '/')
  - os.pathsep is the component separator used in $PATH etc
  - os.linesep is the line separator in text files ('\r' or '\n' or '\r\n')
  - os.defpath is the default search path for executables
  - os.devnull is the file path of the null device ('/dev/null', etc.)

Programs that import and use 'os' stand a better chance of being
portable between different platforms.  Of course, they must then
only use functions that are defined by all platforms (e.g., unlink
and opendir), and leave all pathname manipulation to os.path
(e.g., split and join).
HAVE_FCHDIR_Environ.__iter__HAVE_FTRUNCATEdecodekeywalk_dirsscandir_itis_symlink_spawnvefHAVE_RENAMEATinvalid fd type (%s, expected integer)HAVE_MKNODATC:\msys64\mingw64\lib\python3.6\os.pyHAVE_SYMLINKATexpected str, bytes or os.PathLike object, not supports_effective_idsHAVE_FCHMODATPathLike.__fspath__Returns the sequence of directories that will be searched for the
    named executable (similar to a shell) when launching a process.

    *env* must be an environment variable dict or None.  If *env* is None,
    os.environ will be used.
    _wrap_close.__enter__pathconfsaved_tb_Environ.__setitem__wpidsaved_exc_createenviron.<locals>.encodekeyHAVE_OPENAT<module os>spawnl(mode, file, *args) -> integer

Execute file with arguments from args in a subprocess.
If mode == P_NOWAIT return the pid of the process.
If mode == P_WAIT return the process's exit code if it exits normally;
otherwise return -SIG, where SIG is the signal that killed it. spawnvp(mode, file, args) -> integer

Execute file (which is looked for along $PATH) with arguments from
args in a subprocess.
If mode == P_NOWAIT return the pid of the process.
If mode == P_WAIT return the process's exit code if it exits normally;
otherwise return -SIG, where SIG is the signal that killed it. HAVE_LSTATHAVE_LINKAT_wrap_close.__getattr__Return the file system path representation of the object.Abstract base class for implementing the file system path protocol.Directory tree generator.

        This behaves exactly like walk(), except that it yields a 4-tuple

            dirpath, dirnames, filenames, dirfd

        `dirpath`, `dirnames` and `filenames` are identical to walk() output,
        and `dirfd` is a file descriptor referring to the directory `dirpath`.

        The advantage of fwalk() over walk() is that it's safe against symlink
        races (when follow_symlinks is False).

        If dir_fd is not None, it should be a file descriptor open to a directory,
          and top should be relative; top will then be relative to that directory.
          (dir_fd is always supported for fwalk.)

        Caution:
        Since fwalk() yields file descriptors, those are only valid until the
        next iteration step, so you should dup() them if you want to keep them
        for a longer period.

        Example:

        import os
        for root, dirs, files, rootfd in os.fwalk('python/Lib/email'):
            print(root, "consumes", end="")
            print(sum([os.stat(name, dir_fd=rootfd).st_size for name in files]),
                  end="")
            print("bytes in", len(files), "non-directory files")
            if 'CVS' in dirs:
                dirs.remove('CVS')  # don't visit CVS directories
        popen() does not support unbuffered streamsremovedirs(name)

    Super-rmdir; remove a leaf directory and all empty intermediate
    ones.  Works like rmdir except that, if the leaf directory is
    successfully removed, directories corresponding to rightmost path
    segments will be pruned away until either the whole path is
    consumed or an error occurs.  Errors during this latter phase are
    ignored -- they generally mean that a directory was not empty.

    Encode filename (an os.PathLike, bytes, or str) to the filesystem
        encoding with 'surrogateescape' error handler, return bytes unchanged.
        On Windows, use 'strict' error handler if the file system encoding is
        'mbcs' (which is the default encoding).
        exec_func_wrap_close.__exit__PathLike.__subclasshook__str expected, not %sspawnvpe(mode, file, args, env) -> integer

Execute file (which is looked for along $PATH) with arguments from
args in a subprocess with the supplied environment.
If mode == P_NOWAIT return the pid of the process.
If mode == P_WAIT return the process's exit code if it exits normally;
otherwise return -SIG, where SIG is the signal that killed it. _Environ.__len__getenvbDirectory tree generator.

    For each directory in the directory tree rooted at top (including top
    itself, but excluding '.' and '..'), yields a 3-tuple

        dirpath, dirnames, filenames

    dirpath is a string, the path to the directory.  dirnames is a list of
    the names of the subdirectories in dirpath (excluding '.' and '..').
    filenames is a list of the names of the non-directory files in dirpath.
    Note that the names in the lists are just names, with no path components.
    To get a full path (which begins with top) to a file or directory in
    dirpath, do os.path.join(dirpath, name).

    If optional arg 'topdown' is true or not specified, the triple for a
    directory is generated before the triples for any of its subdirectories
    (directories are generated top down).  If topdown is false, the triple
    for a directory is generated after the triples for all of its
    subdirectories (directories are generated bottom up).

    When topdown is true, the caller can modify the dirnames list in-place
    (e.g., via del or slice assignment), and walk will only recurse into the
    subdirectories whose names remain in dirnames; this can be used to prune the
    search, or to impose a specific order of visiting.  Modifying dirnames when
    topdown is false is ineffective, since the directories in dirnames have
    already been generated by the time dirnames itself is generated. No matter
    the value of topdown, the list of subdirectories is retrieved before the
    tuples for the directory and its subdirectories are generated.

    By default errors from the os.scandir() call are ignored.  If
    optional arg 'onerror' is specified, it should be a function; it
    will be called with one argument, an OSError instance.  It can
    report the error to continue with the walk, or raise the exception
    to abort the walk.  Note that the filename is available as the
    filename attribute of the exception object.

    By default, os.walk does not follow symbolic links to subdirectories on
    systems that support them.  In order to get this functionality, set the
    optional argument 'followlinks' to true.

    Caution:  if you pass a relative pathname for top, don't change the
    current working directory between resumptions of walk.  walk never
    changes the current directory, and assumes that the client doesn't
    either.

    Example:

    import os
    from os.path import join, getsize
    for root, dirs, files in os.walk('python/Lib/email'):
        print(root, "consumes", end="")
        print(sum([getsize(join(root, name)) for name in files]), end="")
        print("bytes in", len(files), "non-directory files")
        if 'CVS' in dirs:
            dirs.remove('CVS')  # don't visit CVS directories

    renames(old, new)

    Super-rename; create directories as necessary and delete any left
    empty.  Works like rename, except creation of any intermediate
    directories needed to make the new pathname good is attempted
    first.  After the rename, directories corresponding to rightmost
    path segments of the old name will be pruned until either the
    whole path is consumed or a nonempty directory is found.

    Note: this function can fail with the new directory structure made
    if you lack permissions needed to unlink the leaf directory or
    file.

    HAVE_LCHMODmakedirs(name [, mode=0o777][, exist_ok=False])

    Super-mkdir; create a leaf directory and all intermediate ones.  Works like
    mkdir, except that any intermediate path segment (not just the rightmost)
    will be created if it does not exist. If the target directory already
    exists, raise an OSError if exist_ok is False. Otherwise no exception is
    raised.  This is recursive.

    _createenviron.<locals>.decodeNot stopped, signaled or exited???_fscodec.<locals>.fsencodespawnv(mode, file, args) -> integer

Execute file with arguments from args in a subprocess.
If mode == P_NOWAIT return the pid of the process.
If mode == P_WAIT return the process's exit code if it exits normally;
otherwise return -SIG, where SIG is the signal that killed it. Get an environment variable, return None if it doesn't exist.
        The optional second argument can specify an alternate default.
        key, default and the result are bytes.expected {}.__fspath__() to return str or bytes, not {}invalid cmd type (%s, expected string)execlp(file, *args)

    Execute the executable file (which is searched for along $PATH)
    with argument list args, replacing the current process. _execvpeexecl(file, *args)

    Execute the executable file with argument list args, replacing the
    current process. _wrap_close.__iter__C:\msys64\home\cbper\palpationgrid.py<module palpationgrid>Ãõ(\ÂÝ?ëQ¸ë?©ÚselfÚeventÚareaÚpressure_listÚmaxÚwidthÚheightÚcrÚrow0_x_startÚrow0_y_startÚx_between_columnsÚy_between_columnsÚx_between_rowsÚy_between_rowsÚcircle_radiusÚ	set_colorÚcr_fillÚcr_draw_rectangleÚcr_set_colorÚcr_draw_arcÚcircle_angleÚrowÚ
pressure_iÚrow_xÚrow_yÚcolÚthis_circle_xÚthis_circle_yset_source_rgbaCircleGrid.set_colorÙÎ÷Sã¥?{®Gáz?CircleGrid.draw_backgroundCircleGrid.draw_gridway_too_hardºI+?--commandfind_functionProduce a reasonable default.Restart_rstr.__repr__(Pdb) ENTERING RECURSIVE DEBUGGERexec(compile(%r, %r, 'exec'))do_runenvHomePdb.do_jumpdo_continuedo_stepdo_nextdo_returndo_quitcmdlistcomplete_enableCurrently displaying:
Program interrupted. (Use 'cont' to resume).Pdb.do_commandsPdb.do_unaliasdef\s+%s\s*[(]_runscriptPdb.interactiondisable bpnumber [bpnumber ...]
        Disables the breakpoints given as a space separated list of
        breakpoint numbers.  Disabling a breakpoint means it cannot
        cause the program to stop execution, but unlike clearing a
        breakpoint, it remains in the list of breakpoints and can be
        (re-)enabled.
        do_retvalcall_tracingPdb.reset_complete_bpnumberPdb._getval_complete_locationBreakpoint %d is now unconditional.do_exithc:Pdb.setupPdb.lookupmodule--KeyboardInterrupt--Pdb.defaultFiledo_interactcomplete_clEOF
        Handles the receipt of EOF as a command.
        Newest framewith arguments:d(own) [count]
        Move the current frame count (default one) levels down in the
        stack trace (to a newer frame).
        numberlistWill stop next time breakpoint %d is reached.New condition set for breakpoint %d.old_command_defscommands_silentdisplay %s: %r  [old: %r]** raised %s **Pdb._complete_bpnumberDeleted %sPdb.help_execcl(ear) filename:lineno
cl(ear) [bpnumber [bpnumber...]]
        With a space separated list of breakpoint numbers, clear
        those breakpoints.  Without argument, clear all breaks (but
        first ask confirmation).  With a filename:lineno argument,
        clear all breaks at that line in that file.
        [EOF]<module pdb>exc_linenoPdb.do_enable"until" line number is smaller than current line numbercondition bpnumber [condition]
        Set a new condition for the breakpoint, an expression which
        must evaluate to true before the breakpoint is honored.  If
        condition is absent, any existing condition is removed; i.e.,
        the breakpoint is made unconditional.
        Enabled %sPdb.messagewhatis arg
        Print the type of the argument.
        do_displaydo_disabletbreak [ ([filename:]lineno | function) [, condition] ]
        Same arguments as break, but sets a temporary breakpoint: it
        is automatically deleted when first hit.
        do_pNot yet returned!complete_commandsignore bpnumber [count]
        Set the ignore count for the given breakpoint number.  If
        count is omitted, the ignore count is set to 0.  A breakpoint
        becomes active when the ignore count is zero.  When non-zero,
        the count is decremented each time the breakpoint is reached
        and the breakpoint is not disabled and any associated
        condition evaluates to true.
        debug code
        Enter a recursive debugger that steps through the code
        argument (which is an arbitrary expression or statement to be
        executed in the current environment).
         	
`@#$%^&*()=+[{]}\|;:'",<>?Pdb.prelooph(elp)
        Without argument, print the list of available commands.
        With a command name as argument, print help about that command.
        "help pdb" shows the full pdb documentation.
        "help exec" gives help on the ! command.
        Pdb._cmdloopcomplete_printPdb.do_helpPdb.do_EOFdo_longlistYou can only jump within the bottom frameUncaught exception. Entering post mortem debuggingcommands_definingprint_stack_tracebreaklistClass %s.%s--command=Pdb.do_disabledo_whatisUsage: commands [bnum]
        ...
        end--Call--Interpret the argument as though it had been typed in response
        to the prompt.

        Checks whether this line is typed at the normal prompt or in
        a breakpoint command list definition.
        Handle alias expansion and ';;' separator.import x; x.main()Disabled %scountstrÛ"   zhelpzwherezdownzupzbreakztbreakzclearzdisablezenablezignorez	conditionzcommandszstepznextzuntilzjumpzreturnzretvalzrunzcontinuezlistzlonglistzargsÚpzppzwhatiszsourcezdisplayz	undisplayzinteractzaliaszunaliaszdebugzquittmpArgrun [args...]
        Restart the debugged python program. If a string is supplied
        it is split with "shlex", and the result is used as the new
        sys.argv.  History, breakpoints, actions and debugger options
        are preserved.  "restart" is an alias for "run".
        Jump failed: %scomplete_ppBlank or commentPdb.do_ignoreunt(il) [lineno]
        Without argument, continue execution until the line with a
        number greater than the current one is reached.  With a line
        number, continue execution until a line with a number greater
        or equal to that is reached.  In both cases, also stop when
        the current frame returns.
        Custom displayhook for the exec in default(), which prevents
        assignment of the _ variable in the builtins.
        %s = %rcommands_resumingPdb.do_whatisdo_untA valid traceback must be passed if no exception is being handleddo_ppcommand definition aborted, old commands restoredPdb.do_aliasClear all breaks? TESTCMDRunning 'cont' or 'step' will restart the programbp_commandsPdb.do_interactdo_ll_user_requested_quitdo_restartThis function is called if an exception occurs,
        but only if we are to stop at or just below this level.curframePdb._complete_expressionnewframenot displaying %scomplete_whatisdo_upC:\msys64\mingw64\lib\python3.6\pdb.pycomplete_ignore1 crossingenable bpnumber [bpnumber ...]
        Enables the breakpoints given as a space separated list of
        breakpoint numbers.
        Invalid frame count (%s)curframe_localsPdb._getval_exceptString that doesn't quote its repr.do_debugreadrcThe specified object %r is not a function or was not found along sys.path.s(tep)
        Execute the current line, stop at the first possible occasion
        (either in a function that is called or in the current
        function).
        longlist | ll
        List the whole source code for the current function or frame.
        Pdb.do_retvalcommands_bnumPdb.do_nextPdb._runscript_help_orderThis function is called when we stop or break at this line.Pdb._complete_locationPdb.user_callBreakpoint %d at %s:%dlineinfoprompt_backThe program exited via sys.exit(). Exit status:Bad lineno: %sp expression
        Print the value of the expression.
        Pdb.bp_commandsPdb.do_until_print_linessave_stdinn(ext)
        Continue execution until the next line in the current function
        is reached or it returns.
        Pdb.user_exceptionrcLinescomplete_source_previous_sigint_handlerThe 'jump' command requires a line numberNum Type         Disp Enb   WherePdb.do_conditionThis function is called when a return trap is set here.Pdb._select_framealias [name [command [parameter parameter ...] ]]
        Create an alias called 'name' that executes 'command'.  The
        command must *not* be enclosed in quotes.  Replaceable
        parameters can be indicated by %1, %2, and so on, while %* is
        replaced by all the parameters.  If no command is given, the
        current alias for name is shown. If no name is given, all
        aliases are listed.

        Aliases may be nested and can contain anything that can be
        legally typed at the pdb prompt.  Note!  You *can* override
        internal pdb commands with aliases!  Those internal commands
        are then hidden until the alias is removed.  Aliasing is
        recursively applied to the first word of the command line; all
        other words in the line are left alone.

        As an example, here are two useful aliases (especially when
        placed in the .pdbrc file):

        # Print instance variables (usage "pi classInst")
        alias pi for k in %1.__dict__.keys(): print("%1.",k,"=",%1.__dict__[k])
        # Print instance variables in self
        alias ps pi self
        rcFileCall every command that was set for the current active breakpoint
        (if there is one).

        Returns True if the normal interaction function must be called,
        False otherwise.prompt_prefixPdb.do_listcomplete_conditionb(reak) [ ([filename:]lineno | function) [, condition] ]
        Without argument, list all breaks.

        With a line number argument, set a break at this line in the
        current file.  With a function name, set a break at the first
        executable line of that function.  If a second argument is
        present, it is a string specifying an expression which must
        evaluate to true before the breakpoint is honored.

        The line number may be prefixed with a filename and a colon,
        to specify a breakpoint in another file (probably one that
        hasn't been loaded yet).  The file is searched for on
        sys.path; the .py suffix may be omitted.
         will be restarteda(rgs)
        Print the argument list of the current function.
        lastcmd_backdo_btw(here)
        Print a stack trace, with the most recent frame at the bottom.
        An arrow indicates the "current frame", which determines the
        context of most commands.  'bt' is an alias for this command.
        set_completer_delimsallow_kbdintCheck whether specified line seems to be executable.

        Return `lineno` if it is, 0 if not (e.g. a docstring, comment, blank
        line or EOF). Warning: testing is not comprehensive.
        print_stack_entrylasti2linenoPdb.onecmdr(eturn)
        Continue execution until the current function returns.
        do_argsdo_tbreakPdb._print_linesPost mortem debugger finished. The argv0Handles one command line during command list definition.Pdb.do_clearPdb.do_returnunalias name
        Delete the specified alias.
        display [expression]

        Display the value of the expression if it changed, each time execution
        stops in the current frame.

        Without expression, list all display expressions for the current frame.
        Pdb.help_pdbcomplete_displaycomplete_clearpost_mortem%s = *** undefined ***%r not found from sys.pathPdb.do_stepline_prefixcomplete_unaliascommands [bpnumber]
        (com) ...
        (com) end
        (Pdb)

        Specify a list of commands for breakpoint number bpnumber.
        The commands themselves are entered on the following lines.
        Type a line containing just 'end' to terminate the commands.
        The commands are executed when the breakpoint is hit.

        To remove all commands from a breakpoint, type commands and
        follow it immediately with end; that is, give no commands.

        With no bpnumber argument, commands refers to the last
        breakpoint set.

        You can use breakpoint commands to start your program up
        again.  Simply use the continue command, or step, or any other
        command that resumes execution.

        Specifying any command resuming execution (currently continue,
        step, next, return, jump, quit and their abbreviations)
        terminates the command list (as if that command was
        immediately followed by end).  This is because any time you
        resume execution (even with a simple next or step), you may
        encounter another breakpoint -- which could have its own
        command list, leading to ambiguities about which list to
        execute.

        If you use the 'silent' command in the command list, the usual
        message about stopping at a breakpoint is not printed.  This
        may be desirable for breakpoints that are to print a specific
        message and then continue.  If none of the other commands
        print anything, you will see no sign that the breakpoint was
        reached.
        execRcLinesNo help for %r; please do not run Python with -OO if you need command helpPdb.handle_command_defPdb.forgetPdb.print_stack_entrydo_wherePdb.complete_undisplayPdb.do_upInvalid line number (%s)Pdb.do_undisplay
The Python Debugger Pdb
=======================

To use the debugger in its simplest form:

        >>> import pdb
        >>> pdb.run('<a statement>')

The debugger's prompt is '(Pdb) '.  This will stop in the first
function call in <a statement>.

Alternatively, if a statement terminated with an unhandled exception,
you can use pdb's post-mortem facility to inspect the contents of the
traceback:

        >>> <a statement>
        <exception traceback>
        >>> import pdb
        >>> pdb.pm()

The commands recognized by the debugger are listed in the next
section.  Most can be abbreviated as indicated; e.g., h(elp) means
that 'help' can be typed as 'h' or 'help' (but not as 'he' or 'hel',
nor as 'H' or 'Help' or 'HELP').  Optional arguments are enclosed in
square brackets.  Alternatives in the command syntax are separated
by a vertical bar (|).

A blank line repeats the previous command literally, except for
'list', where it lists the next 11 lines.

Commands that the debugger doesn't recognize are assumed to be Python
statements and are executed in the context of the program being
debugged.  Python statements can also be prefixed with an exclamation
point ('!').  This is a powerful way to inspect the program being
debugged; it is even possible to change variables or call functions.
When an exception occurs in such a statement, the exception name is
printed but the debugger's state is not changed.

The debugger supports aliases, which can save typing.  And aliases can
have parameters (see the alias help entry) which allows one a certain
level of adaptability to the context under examination.

Multiple commands may be entered on a single line, separated by the
pair ';;'.  No intelligence is applied to separating the commands; the
input is split at the first ';;', even if it is in the middle of a
quoted string.

If a file ".pdbrc" exists in your home directory or in the current
directory, it is read in and executed as if it had been typed at the
debugger prompt.  This is particularly useful for aliases.  If both
files exist, the one in the home directory is read first and aliases
defined there can be overridden by the local file.  This behavior can be
disabled by passing the "readrc=False" argument to the Pdb constructor.

Aside from aliases, the debugger is not directly programmable; but it
is implemented as a class from which you can derive your own debugger
class, which you can make as fancy as you like.


Debugger commands
=================

Causes a debugger to be restarted for the debugged python program.Pdb.do_continuedo_breakpp expression
        Pretty-print the value of the expression.
        j(ump) lineno
        Set the next line that will be executed.  Only available in
        the bottom-most frame.  This lets you jump back and execute
        code again, or jump forward to skip code that you don't want
        to run.

        It should be noted that not all jumps are allowed -- for
        instance it is not possible to jump into the middle of a
        for loop or out of a finally clause.
        Will ignore next %s of breakpoint %d.Pdb.do_ppPdb.complete_unaliasRestartingu(p) [count]
        Move the current frame count (default one) levels up in the
        stack trace (to an older frame).
        Print a range of lines.Pdb.lineinfocurrent_linenoFunction %sdo_downPdb.user_linePdb.errorPdb.do_debugPdb.sigint_handlerc(ont(inue))
        Continue execution, only stop when a breakpoint is encountered.
        checklineError in argument: %r%d crossingsOldest framePdb.precmddo_rvdo_source_wait_for_mainpyfilePdb.execRcLinesThe program finished and will be restarted__exception__--Return--*interactive*Pdb.displayhookcomplete_tbreakPdb.do_tbreakPdb.do_sourcePdb.do_downPdb.do_breakusage: pdb.py [-c command] ... pyfile [arg] ...

Debug the Python program given by pyfile.

Initial commands are read from .pdbrc files in your home directory
and in the current directory, if they exist.  Commands supplied with
-c are executed after commands from .pdbrc files.

To let the script run until an exception occurs, use "-c continue".
To let the script run up to a given line X in the debugged file, use
"-c 'until X'".curindexcomplete_debugPdb.do_runHelper function for break/clear parsing -- may be overridden.

        lookupmodule() translates (possibly incomplete) file or module name
        into an absolute file name.
        undisplay [expression]

        Do not display the expression any more in the current frame.

        Without expression, clear all display expressions for the current frame.
        complete_disablePdb.do_longlistq(uit)
exit
        Quit from the debugger. The program being executed is aborted.
        l(ist) [first [,last] | .]

        List source code for the current file.  Without arguments,
        list 11 lines around the current line or continue the previous
        listing.  With . as argument, list 11 lines around the current
        line.  With one argument, list 11 lines starting at that line.
        With two arguments, list the given range; if the second
        argument is less than the first, it is a count.

        The current line in the current frame is indicated by "->".
        If an exception is being debugged, the line where the
        exception was originally raised or propagated is indicated by
        ">>", if it differs from the current line.
        source expression
        Try to get source code for the given object and display it.
        Pdb.do_quitcomplete_breakPdb.do_displayLEAVING RECURSIVE DEBUGGERPdb.do_whereinteract

        Start an interactive interpreter whose global namespace
        contains all the (global and local) names found in the current scope.
        retval
        Print the return value for the last return of a function.
        commands_dopromptPdb.do_argsPdb.user_returnPdb.checklinePdb.print_stack_trace(!) statement
        Execute the (one-line) statement in the context of the current
        stack frame.  The exclamation point can be omitted unless the
        first word of the statement resembles a debugger command.  To
        assign to a global variable you must always prefix the command
        with a 'global' command, e.g.:
        (Pdb) global list_options; list_options = ['-l']
        (Pdb)
        _Unframer.load_frame<module pickle>load_pop_markload_setitemsfix_importsescape_decode_batch_setitemsREDUCEload_short_binbytes_Pickler.get_Unpickler.load_ext1BINPERSID_Unpickler.load_getobj2lastnamer_name_mappingr_import_mapping_Unpickler.load_markLONG_BINPUTsave_persistent_idBINGETload_short_binunicode_Unpickler.load_persidload_binunicode8NEWOBJ_EX_Unpickler.load_setitems_Pickler.put_Pickler.save_typeload_frozensetload_protoclear_memo_Unpickler.load_unicodeSTACK_GLOBAL requires strfunc from save_reduce() must be callable_Unpickler.load_long_binget_Pickler.save_reduce_Unpickler.load_obj_Pickler.save_bool_Unpickler.load_tuple_Unpickler.load_binintload_newobj_ex_Pickler.save_setpickle protocol must be <= %dEXT specifies code <= 0NEWTRUEargs[0] from {} args has no __new__commit_framesubpathAPPENDS_file_readline_Unpickler.load_binputdictitemscompatible_formats_Stop.__init___Pickler.memoizeWrite a pickled representation of obj to the open file.BINBYTES exceeds system's maximum size of %d bytesload_empty_dictionary_Unpickler.load_build_Framer.end_framingload_long4metastackCreate portable serialized representations of Python objects.

See module copyreg for a mechanism for registering custom picklers.
See module pickletools source for extensive comments.

Classes:

    Pickler
    Unpickler

Functions:

    dump(object, file)
    dumps(object) -> string
    load(file) -> object
    loads(string) -> object

Misc variables:

    __version__
    format_version
    compatible_formats

args[0] from __newobj__ args has the wrong classload_stack_globalstart_framing_Framer.__init__BINUNICODEFROZENSET_Pickler.save_dictEMPTY_LISTload_instbeginning of a new frame before end of current framedecode_longframe_sizeunsupported persistent id encountered_Pickler.save_globalargs from save_reduce() must be a tupleThis takes a binary file for writing a pickle data stream.

        The optional *protocol* argument tells the pickler to use the
        given protocol; supported protocols are 0, 1, 2, 3 and 4.  The
        default protocol is 3; a backward-incompatible protocol designed
        for Python 3.

        Specifying a negative protocol version selects the highest
        protocol version supported.  The higher the protocol used, the
        more recent the version of Python needed to read the pickle
        produced.

        The *file* argument must have a write() method that accepts a
        single bytes argument. It can thus be a file object opened for
        binary writing, an io.BytesIO instance, or any other custom
        object that meets this interface.

        If *fix_imports* is True and *protocol* is less than 3, pickle
        will try to map the new Python 3 names to the old module names
        used in Python 2, so that the pickle data stream is readable
        with Python 2.
        _Framer.writeload_tuple2BINUNICODE8 exceeds system's maximum size of %d bytesload_globalDEFAULT_PROTOCOLcan't pickle global identifier '%s.%s' using pickle protocol %i\u005cload_stopload_additems_unframerpersistent IDs in protocol 0 must be ASCII strings_Unpickler.load_long4_Unpickler.load_short_binbytesget_extensionA common base class for the other pickling exceptions._Unpickler.load_short_binunicode_Unpickler.__init__load_binint2Clears the pickler's "memo".

        The memo is the data structure that remembers which objects the
        pickler has already seen, so that shared or recursive objects
        are pickled by reference and not by value.  This method is
        useful when re-using picklers.
        Decode a long from a two's complement little-endian binary string.

    >>> decode_long(b'')
    0
    >>> decode_long(b"\xff\x00")
    255
    >>> decode_long(b"\xff\x7f")
    32767
    >>> decode_long(b"\x00\xff")
    -256
    >>> decode_long(b"\x00\x80")
    -32768
    >>> decode_long(b"\x80")
    -128
    >>> decode_long(b"\x7f")
    127
    PickleErrorEMPTY_SETI00
save_bytesstopinstBINSTRING pickle has negative byte countload_false_Pickler.save_tupleTUPLE3BININT2_BATCHSIZE\u000aload_empty_setCan't load pickle from unicode stringload_intnegative PUT argument_Pickler.save_strTUPLE1pickle exhausted before end of frame_Unpickler.load_falseThis exception is raised when an unpicklable object is passed to the
    dump() method.

    POP_MARKLONG pickle has negative byte count_Unpickler.load_proto%s must return string or tupleload_ext2load_tuple1_Unpickler.load_newobjSHORT_BINBYTESUnpickler.__init__() was not called by %s.__init__()LONG1save_long_Pickler._batch_setitemsEMPTY_TUPLE_Unpickler.load_long1_Unpickler.load_newobj_exload_ext4Can't pickle %r: it's not the same object as %s.%sBINBYTES8load_float_file_write_Unpickler.load_binget_Unpickler.load_binint2This exception is raised when there is a problem unpickling an object,
    such as a security violation.

    Note that other exceptions may also be raised during unpickling, including
    (but not necessarily limited to) AttributeError, EOFError, ImportError,
    and IndexError.

    persistent_loadload_append_Pickler.save_long_Unpickler.load_additemsBINBYTES8 exceeds system's maximum size of %d bytes_Unpickler.load_ext2load_appends[A-Z][A-Z0-9_]+$_Unpickler.pop_markSETITEMsave_frozenset_Unpickler.load_binbytes8Can't pickle %r: it's not found as %s.%sSHORT_BINSTRING_tuplesize2code_decode_stringload_listload_empty_list_Unpickler.load_short_binstringload_putset_obj_Unpickler.load_string_Unpickler.find_classunsupported pickle protocol: %dUnpicklingError_Unpickler._instantiate_Unpickler.load_instNEWFALSE_Unpickler.load_pop_markcurrent_frameload_memoize_Unpickler.get_extensionSHORT_BINUNICODEBINUNICODE exceeds system's maximum size of %d bytes_Unpickler.load_dup_Unpickler.load_stack_globallist_objfile_tell_Unframer.readPicklingError_Unpickler.load_binpersid_Unpickler.load_binunicode8_Unpickler.load_empty_set_Unpickler.load_globalEncode a long to a two's complement little-endian binary string.
    Note that 0 is a special case, returning an empty string, to save a
    byte in the LONG1 pickling context.

    >>> encode_long(0)
    b''
    >>> encode_long(255)
    b'\xff\x00'
    >>> encode_long(32767)
    b'\xff\x7f'
    >>> encode_long(-256)
    b'\x00\xff'
    >>> encode_long(-32768)
    b'\x00\x80'
    >>> encode_long(-128)
    b'\x80'
    >>> encode_long(127)
    b'\x7f'
    >>>
    negative BINPUT argumentload_nonenegative LONG_BINPUT argument_Framer.start_framing_Unpickler.load_binint1_Pickler.save_floatThis takes a binary file for reading a pickle data stream.

        The protocol version of the pickle is detected automatically, so
        no proto argument is needed.

        The argument *file* must have two methods, a read() method that
        takes an integer argument, and a readline() method that requires
        no arguments.  Both methods should return bytes.  Thus *file*
        can be a binary file object opened for reading, an io.BytesIO
        object, or any other custom object that meets this interface.

        The file-like object must have two methods, a read() method
        that takes an integer argument, and a readline() method that
        requires no arguments.  Both methods should return bytes.
        Thus file-like object can be a binary file object opened for
        reading, a BytesIO object, or any other custom object that
        meets this interface.

        Optional keyword arguments are *fix_imports*, *encoding* and
        *errors*, which are used to control compatibility support for
        pickle stream generated by Python 2.  If *fix_imports* is True,
        pickle will try to map the old Python 2 names to the new names
        used in Python 3.  The *encoding* and *errors* tell pickle how
        to decode 8-bit string instances pickled by Python 2; these
        default to 'ASCII' and 'strict', respectively. *encoding* can be
        'bytes' to read theses 8-bit string instances as bytes objects.
        Can't get attribute {!r} on {!r}EMPTY_DICTLONG4Can't pickle %r object: %r_Pickler._batch_appends_Unpickler.load_frame_Unpickler.load_reduce_FRAME_SIZE_TARGET_Unpickler.load_tuple3save_none_Pickler.__init__args[0] from {} args has the wrong classBINFLOAT_Pickler.persistent_id_Pickler.clear_memo_Unpickler.load_frozensetload_empty_tupleload_binstringfile must have a 'write' attribute_Unpickler.load_long_binputEXT1Read a pickled object representation from the open file.

        Return the reconstituted object hierarchy specified in the file.
        _Unpickler.persistent_loadTUPLE2listitemsI01
_Unpickler.load_empty_list_Pickler.dump_Unpickler._decode_stringSETITEMS_Unpickler.load_ext4frame size > sys.maxsize: %dwhichmoduleADDITEMS_Unpickler.load_empty_tuple_Unpickler.load_trueunregistered extension code %dFind the module an object belong to.EXT4_Unpickler.load_dict_Pickler.save_bytesthe STRING opcode argument must be quotedTuple returned by %s must have two to five elementssave_list_Pickler.save_none_Unpickler.load_tuple2_Unpickler.load_binfloatLONG_BINGETin constructor for %s: %s_Unpickler.load_memoizePickler.__init__() was not called by %s.__init__()C:\msys64\mingw64\lib\python3.6\pickle.py_Unpickler.load_int_Unpickler.load_stopStore an object in the memo._Unpickler.load_binstringMEMOIZE_Unframer.readline_Framer.commit_frame_Unpickler.load_float_Unpickler.load_empty_dictionary_Unpickler.load_list_Unpickler.load_put_Unpickler.load_appends_Unframer.__init___Pickler.save_persargs[0] from __newobj__ args has no __new___Unpickler.load_tuple1_Pickler.save_listCan't get local attribute {!r} on {!r}_Unpickler.load_noneBININT1_Pickler.save_frozensetImpImporter.find_moduleModuleInfomodule_finder name ispkgarchiveiter_zipimport_modulesmod_typeImpLoader.get_sourcedircontentspkgfileCan't open %s: %s
iter_importersImpLoader.get_codepath_itemRetrieve a finder for the given path item

    The returned finder is cached in sys.path_importer_cache
    if it was newly created by a path hook.

    The cache (or part of it) can be cleared manually if a
    rescan of sys.path_hooks is necessary.
    Get a resource from a package.

    This is a wrapper round the PEP 302 loader get_data API. The package
    argument should be the name of a package, in standard module format
    (foo.bar). The resource argument should be in the form of a relative
    filename, using '/' as the path separator. The parent directory name '..'
    is not allowed, and nor is a rooted name (starting with a '/').

    The function returns a binary string, which is the contents of the
    specified resource.

    For packages located in the filesystem, which have already been imported,
    this is the rough equivalent of

        d = os.path.dirname(sys.modules[package].__file__)
        data = open(os.path.join(d, resource), 'rb').read()

    If the package cannot be located or loaded, or it uses a PEP 302 loader
    which does not support get_data(), then None is returned.
    <module pkgutil>ImpLoader.get_dataImpLoader.get_filename_reopenReturn the finder-specific module spec._zip_directory_cacheExtend a package's path.

    Intended use is to place the following code in a package's __init__.py:

        from pkgutil import extend_path
        __path__ = extend_path(__path__, __name__)

    This will add to the package's __path__ all subdirectories of
    directories on sys.path named after the package.  This is useful
    if one wants to distribute different parts of a single logical
    package as multiple directories.

    It also looks for *.pkg files beginning where * matches the name
    argument.  This feature is similar to *.pth files (see site.py),
    except that it doesn't special-case lines starting with 'import'.
    A *.pkg file is trusted at face value: apart from checking for
    duplicates, all entries found in a *.pkg file are added to the
    path, regardless of whether they are exist the filesystem.  (This
    is a feature.)

    If the input path is not a list (as is the case for frozen
    packages) it is returned unchanged.  The input path is not
    modified; an extended copy is returned.  Items are only appended
    to the copy at the end.

    It is assumed that sys.path is a sequence.  Items of sys.path that
    are not (unicode or 8-bit) strings referring to existing
    directories are ignored.  Unicode items of sys.path that cause
    errors when used as filenames may cause this function to raise an
    exception (in line with os.path.isdir() behavior).
    _get_delegatefinal_nameresource_nameFind a "loader" object for fullname

    This is a backwards compatibility wrapper around
    importlib.util.find_spec that converts most failures to ImportError
    and only returns the loader rather than the full spec
    ImpImporter.iter_modulesRelative module name {!r} not supportedA namedtuple with minimal info about a module.module_or_nameImpLoader._fix_nameImpLoader.load_moduleC:\msys64\mingw64\lib\python3.6\pkgutil.pyzipimporterImpLoader._reopenwalk_packages.<locals>.seenYield finders for the given module name

    If fullname contains a '.', the finders will be for the package
    containing fullname, otherwise they will be all registered top level
    finders (i.e. those on both sys.meta_path and sys.path_hooks).

    If the named module is in a package, that package is imported as a side
    effect of invoking this function.

    If no module name is specified, all top level finders are produced.
    simplegenericYields ModuleInfo for all modules recursively
    on path, or, if path is None, all accessible modules.

    'path' should be either None or a list of paths to look for
    modules in.

    'prefix' is a string to output on the front of every module name
    on output.

    Note that this function must import all *packages* (NOT all
    modules!) on the given path, in order to access the __path__
    attribute to find submodules.

    'onerror' is a function which gets called with one argument (the
    name of the package which was being imported) if any exception
    occurs while trying to import a package.  If no onerror function is
    supplied, ImportErrors are caught and ignored, while all other
    exceptions are propagated, terminating the search.

    Examples:

    # list all modules python can access
    walk_packages()

    # list all submodules of ctypes
    walk_packages(ctypes.__path__, ctypes.__name__+'.')
    ImpLoader.__init__iter_importer_modulesLoader for module %s cannot handle module %sUtilities to support packages.Error while finding loader for {!r} ({}: {})ImpLoader.is_packageImpLoader._get_delegatesname_pkg_iter_file_finder_modules_import_impImpImporter.__init__PEP 302 Finder that wraps Python's "classic" import algorithm

    ImpImporter(dirname) produces a PEP 302 finder that searches that
    directory.  ImpImporter(None) produces a PEP 302 finder that searches
    the current sys.path, plus any modules that are frozen or built-in.

    Note that ImpImporter does not currently support being used by placement
    on sys.meta_path.
    This emulation is deprecated, use 'importlib' insteadYields ModuleInfo for all submodules on path,
    or, if path is None, all top-level modules on sys.path.

    'path' should be either None or a list of paths to look for
    modules in.

    'prefix' is a string to output on the front of every module name
    on output.
    Get a "loader" object for module_or_name

    Returns None if the module cannot be found or imported.
    If the named module is not already imported, its containing package
    (if any) is imported, in order to establish the package __path__.
    PEP 302 Loader that wraps Python's "classic" import algorithm
    OpenKeyEx Returns the Python version as string 'major.minor.patchlevel'

        Note that unlike the Python sys.version, the returned value
        will always include the patchlevel (it defaults to 0).

    use_syscmd_verPROCESSOR_ARCHITECTUREverfilescsidpython_branchuname %s 2> %sproduct_type([\w.+]+)\s*\(#?([^,]+),\s*([\w ]+),\s*([\w :]+)\)\s*\[PyPy [^\]]+\]?_gitvendor Returns the (true) processor name, e.g. 'amdk6'

        An empty string is returned if the value cannot be
        determined. Note that many platforms do not provide this
        information or simply return the same value as for machine(),
        e.g.  NetBSD does this.

    OpenLinuxfailed to parse PyPy sys.version: %sPROCESSOR_ARCHITEW6432OpenVMSfull_distribution_nameuname_resultsystem node release version machine processorjava.vm.versiondistnamesupported_distswin16post2012ServerR2_default_architecturePower MacintoshSYI$_CPUmac_verlibc_ver_libc_searchsupported_platformscommand failed Returns the system's release, e.g. '2.2.0' or 'NT'

        An empty string is returned if the value cannot be determined.

    fileoutuse os.popen insteadsubversionvm_vendor_UNIXCONFDIR_mac_ver_xmlWindowsPElinux_distributionversioninfo_platform.<locals>.<genexpr>_mercurial Returns a string identifying the Python implementation.

        Currently, the following implementations are identified:
          'CPython' (C implementation of Python),
          'IronPython' (.NET implementation of Python),
          'Jython' (Java implementation of Python),
          'PyPy' (Python implementation of Python).

     Returns a string identifying the Python implementation
        revision.

        For CPython this is the Subversion revision from which the
        Python binary was built.

        If not available, an empty string is returned.

    ([\d.]+)\s*\(IronPython\s*[\d.]+\s*\(([\d.]+)\) on ([\w.]+ [\d.]+(?: \(\d+-bit\))?)\)os_version([\w.+]+)\s*\(#?([^,]+)(?:,\s*([\w ]*)(?:,\s*([\w :]*))?)?\)\s*\[([^\]]+)\]?java.vm.namealt_versionjava.vm.vendor Returns a string identifying the compiler used for compiling
        Python.

    GLIBCos_arch Returns a single string identifying the underlying platform
        with as much useful information as possible (but no more :).

        The output is intended to be human readable rather than
        machine parseable. It may look different on different
        platforms and this is intended.

        If "aliased" is true, the function will use aliases for
        various platforms that report system names which differ from
        their common names, e.g. SunOS will be reported as
        Solaris. The system_alias() function is used to implement
        this.

        Setting terse to true causes the function to return only the
        absolute minimum information needed to identify the platform.

    _pypy_sys_version_parserredhat Returns the system/OS name, e.g. 'Linux', 'Windows' or 'Java'.

        An empty string is returned if the value cannot be determined.

    python_version_tupleDIST_IDENTvminfoosinfovm_namevm_releaseos_name_release_filenamebuildnobuilddatebuildtime/usr/lib/setup16bit©ÚaliasedÚterseÚresultÚsystemÚnodeÚreleaseÚversionÚmachineÚ	processorÚrelÚversÚcsdÚptypeÚplatformÚdistnameÚdistversionÚdistidÚlibcnameÚlibcversionÚrÚvÚvminfoÚos_nameÚ
os_versionÚos_archÚbitsÚlinkagegentoo/var/adm/inst-log/info Version interface for Jython.

        Returns a tuple (release, vendor, vminfo, osinfo) with vminfo being
        a tuple (vm_name, vm_release, vm_vendor) and osinfo being a
        tuple (os_name, os_version, os_arch).

        Values which cannot be determined are set to the defaults
        given as parameters (which all default to '').

    SP{}service_pack_majorCloseKey Tries some special tricks to get the distribution
        information in case the default method fails.

        Currently supports older SuSE Linux, Caldera OpenLinux and
        Slackware Linux distributions.

    (?:([\w ]+) ([\w.]+) .*\[.* ([\d.]+)\])/etc/.installedUnitedLinuxlibcinitRhapsodywinver_supported_distsIronPython\s*([\d\.]+)(?: \(([\d\.]+)\))? on (.NET [\d\.]+)failed to parse CPython sys.version: %sgetProperty Tries to determine the name of the Linux OS distribution name.

        The function first looks for a distribution release file in
        /etc and then reverts to _dist_try_harder() in case no
        suitable files are found.

        supported_dists may be given to define the set of Linux
        distributions to look for. It defaults to a list of currently
        supported Linux distributions identified by their release file
        name.

        If full_distribution_name is true (default), the full
        distribution read from the OS is returned. Otherwise the short
        name taken from supported_dists is used.

        Returns a tuple (distname, version, id) which default to the
        args given as parameters.

     Fairly portable uname interface. Returns a tuple
        of strings (system, node, release, version, machine, processor)
        identifying the underlying platform.

        Note that unlike the os.uname function this also returns
        possible processor information as an additional tuple entry.

        Entries which cannot be determined are set to ''.

    _ironpython26_sys_version_parserglibcglibcversionsoversionwin32_ver_distname_lsb_release_versionCurrentType
    Copyright (c) 1999-2000, Marc-Andre Lemburg; mailto:mal@lemburg.com
    Copyright (c) 2000-2010, eGenix.com Software GmbH; mailto:info@egenix.com

    Permission to use, copy, modify, and distribute this software and its
    documentation for any purpose and without fee or royalty is hereby granted,
    provided that the above copyright notice appear in all copies and that
    both that copyright notice and this permission notice appear in
    supporting documentation or portions thereof, including modifications,
    that you make.

    EGENIX.COM SOFTWARE GMBH DISCLAIMS ALL WARRANTIES WITH REGARD TO
    THIS SOFTWARE, INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY AND
    FITNESS, IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY SPECIAL,
    INDIRECT OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING
    FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT,
    NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF OR IN CONNECTION
    WITH THE USE OR PERFORMANCE OF THIS SOFTWARE !

_follow_symlinks_norm_versionrocks_syscmd_filePROCESSOR_IDENTIFIERMS-DOS_ironpython_sys_version_parserplatform_version(\w+)[-_](release|version)IRIX64turbolinux_platform_cacheyellowdog_WIN32_CLIENT_RELEASESdist() and linux_distribution() functions are deprecated in Python 3.5dist\(\) and linux_distribution\(\) functions are deprecated .*_java_getpropMSDOS1.0.8debianfedoracentosmandrakemandrivaslackwaremageiaMacOS X Server<module platform>_parse_release_file2003Server Returns a tuple (buildno, builddate) stating the Python
        build number and date as strings.

     Interface to the system's file command.

        The function uses the -b option of the file command to have it
        omit the filename in its output. Follow the symlinks. It returns
        default in case the command should fail.

    2008ServerR2 Tries to determine the libc version that the file executable
        (which defaults to the Python interpreter) is linked against.

        Returns a tuple of strings (lib,version) which default to the
        given parameters in case the lookup fails.

        Note that the function has intimate knowledge of how different
        libc versions add symbols to the executable and thus is probably
        only useable for executables compiled using gcc.

        The file is read and scanned in chunks of chunksize bytes.

    _sys_version_cacheProductVersion Interface to the system's uname command.
    java.versionfailed to parse Jython sys.version: %sDEV_NULL_ver_output Returns (system, release, version) aliased to common
        marketing names used for some systems.

        It also does some reordering of the information in some cases
        where it would otherwise cause confusion.

     Returns a parsed version of Python's sys.version as tuple
        (name, version, branch, revision, buildno, builddate, compiler)
        referring to the Python implementation name, version, branch,
        revision, build number, build date/time as string and the compiler
        identification string.

        Note that unlike the Python sys.version, the returned value
        for the Python version will always include the patchlevel (it
        defaults to '.0').

        The function returns empty strings for tuple entries that
        cannot be determined.

        sys_version may be given to parse an alternative version
        string, e.g. if the version was read from a different Python
        interpreter.

    û)é   é    z2000)r   é   zXP)r   é   z
2003Server)r   Nzpost2003)é   r   zVista)r   r   ú7)r   r   ú8)r   é   z8.1)r   Nzpost8.1)é
   r   z10)r	   Nzpost100 Tries to determine the name of the Linux OS distribution name.

        The function first looks for a distribution release file in
        /etc and then reverts to _dist_try_harder() in case no
        suitable files are found.

        Returns a tuple (distname, version, id) which default to the
        args given as parameters.

     (64bit)no_os_uname_uname_cachejava.os.arch_syscmd_uname_linux_distribution Returns a string identifying the Python implementation
        branch.

        For CPython this is the Subversion branch from which the
        Python binary was built.

        If not available, an empty string is returned.

    ([^0-9]+)(?: release )?([\d.]+)[^(]*(?:\((.+)\))?VAXMicrosoftjava_ver Returns the system's release version, e.g. '#3 on degas'

        An empty string is returned if the value cannot be determined.

     This module tries to retrieve as much platform-identifying data as
    possible. It makes this information available via function APIs.

    If called from the command line, it prints the platform
    information concatenated as single string to stdout. The output
    format is useable as part of a filename.

C:\msys64\mingw64\lib\python3.6\platform.py Helper to format the platform string in a filename
        compatible format e.g. "system-version-machine".
     Portable popen() interface.
    failed to parse IronPython sys.version: %spython_implementationSOFTWARE\Microsoft\Windows NT\CurrentVersion_WIN32_SERVER_RELEASESCOFFjava.os.namejava.vendorMIN_DIST_VERSION(__libc_init)|(GLIBC_([0-9.]+))|(libc(_\w+)?\.so(?:\.(\d[0-9.]*))?) Returns the Python version as tuple (major, minor, patchlevel)
        of strings.

        Note that unlike the Python sys.version, the returned value
        will always include the patchlevel (it defaults to 0).

    getsyipython_revisioncommand /c vercmd /c ver In case filepath is a symlink, follow it until a
        real file is reached.
     Normalize the version and build strings and return a single
        version string using the format major.minor.build (or patchlevel).
     Get MacOS version information and return it as tuple (release,
        versioninfo, machine) with versioninfo being a tuple (version,
        dev_stage, non_release_version).

        Entries which cannot be determined are set to the parameter values
        which default to ''. All tuple entries are strings.
    Service Pack  Returns the computer's network name (which may not be fully
        qualified)

        An empty string is returned if the value cannot be determined.

     Returns the machine type, e.g. 'i386'

        An empty string is returned if the value cannot be determined.

     Helper to determine the node name of this machine.
    slack-version-64-bitMicrosoft Windowscpu_number(.+) release ([\d.]+)[^(]*(?:\((.+)\))? Queries the given executable (defaults to the Python interpreter
        binary) for various architecture information.

        Returns a tuple (bits, linkage) which contains information about
        the bit architecture and the linkage format used for the
        executable. Both values are returned as strings.

        Values that cannot be determined are returned as given by the
        parameter presets. If bits is given as '', the sizeof(pointer)
        (or sizeof(long) on Python version < 1.5.2) is used as
        indicator for the supported pointer size.

        The function relies on the system's "file" command to do the
        actual work. This is available on most if not all Unix
        platforms. On some non-Unix platforms where the "file" command
        does not exist and the executable is set to the Python interpreter
        binary defaults from _default_architecture are used.

    java.os.versionn32bit Tries to figure out the OS version used and returns
        a tuple (system, release, version).

        It uses the "ver" shell command for this which is known
        to exists on Windows, DOS. XXX Others too ?

        In case this fails, the given parameters are used as
        defaults.

    dict_typewrite_dictmaxbinsizewritePlist_scalars_is_fmt_binary_PlistParser.begin_dictend_integer_DumbXMLWriter_DumbXMLWriter.__init__ParseFilebomwrite_array_ref_size_PlistParser.handle_end_element_PlistWriter.__init__>BBQnum_objects
    Read a .plist from a path or file. pathOrFile should either
    be a file name, or a readable binary file object.

    This function is deprecated, use load instead.
    top_object_DumbXMLWriter.writeln_BinaryPlistParser.parse_objtableend_date return the size of the next object.The writePlist function is deprecated, use dump() insteadplistlib.py -- a tool to generate and parse MacOSX .plist files.

The property list (.plist) file format is a simple XML pickle supporting
basic object types, like dictionaries, lists, numbers and strings.
Usually the top level object is a dictionary.

To write out a plist file, use the dump(value, file)
function. 'value' is the top level object, 'file' is
a (writable) file object.

To parse a plist from a file, use the load(file) function,
with a (readable) file object as the only argument. It
returns the top level object (again, usually a dictionary).

To work with plist data in bytes objects, you can use loads()
and dumps().

Values can be strings, integers, floats, booleans, tuples, lists,
dictionaries (but only with string keys), Data, bytes, bytearray, or
datetime.datetime objects.

Generate Plist example:

    pl = dict(
        aString = "Doodah",
        aList = ["A", "B", 12, 32.1, [1, 2, 3]],
        aFloat = 0.1,
        anInt = 728,
        aDict = dict(
            anotherString = "<hello & hi there!>",
            aUnicodeValue = "M\xe4ssig, Ma\xdf",
            aTrueValue = True,
            aFalseValue = False,
        ),
        someData = b"<binary gunk>",
        someMoreData = b"<lots of binary gunk>" * 10,
        aDate = datetime.datetime.fromtimestamp(time.mktime(time.gmtime())),
    )
    with open(fileName, 'wb') as fp:
        dump(pl, fp)

Parse Plist example:

    with open(fileName, 'rb') as fp:
        pl = load(fp)
    print(pl["aKey"])
_InternalDict.__getattr__Write 'value' to a .plist file. 'fp' should be a (writable)
    file object.
    end_falsesort_version_BinaryPlistParser._read_objectPlist.__init___PlistParser.end_arrayPlistFormatFMT_XML FMT_BINARYend_dict>BBL
        read the object by reference.

        May recursively read sub-objects (content of an array/dict/set)
        </plist>
    Return 'value' as a plist-formatted bytes object.

    This function is deprecated, use dumps instead.
    unsupported type: %send_realmaxlinelengthRead a .plist file from a bytes object.
    Return the unpacked root object (which usually is a dictionary).
    missing value for key '%s' at line %dtokenLreadPlistreadPlistFromByteswritePlistToBytesInvalidFileException_read_intsadd_object_PlistParser.__init__Attribute access from plist dicts is deprecated, use d[key] notation insteadasBase64key_refs_write_objectoffset_table_offsetrootItemsoffset_size>BBH_PlistParser.add_object<plist version="1.0">_decode_base64writeHeader</%s>The writePlistToBytes function is deprecated, use dumps() instead_PlistParser.parseData.fromBase64_BinaryPlistParser._read_refs_controlCharPatwrite_data_BinaryPlistWriter_getrefnum_date_to_stringutf-16be_DumbXMLWriter.simple_elementbegin_array_PlistParser.end_dataend_key_dict_typeInvalidFileException.__init___PlistParser.begin_array_PlistParser.get_data_DumbXMLWriter.end_elementThe readPlist function is deprecated, use load() instead%04d-%02d-%02dT%02d:%02d:%02dZbegin_element_get_size_PlistParser.handle_begin_element_PlistParser.end_integer>BBBDeprecated. Use the load() function instead.offset_formatend_true>BHPlist.fromFile_DumbXMLWriter.begin_element[\x00\x01\x02\x03\x04\x05\x06\x07\x08\x0b\x0c\x0e\x0f\x10\x11\x12\x13\x14\x15\x16\x17\x18\x19\x1a\x1b\x1c\x1d\x1e\x1f]<%s>%s</%s>>5xBBBQQQwrite_bytesbplist00_BinaryPlistWriter._getrefnumRead a .plist file. 'fp' should be (readable) file object.
    Return the unpacked root object (which usually is a dictionary).
    The readPlistFromBytes function is deprecated, use loads() instead_write_size_InternalDict.__delattr__handle_data_PlistWriter.write_arraydata must be as bytes
    Read or write a binary plist file, following the description of the binary
    format.  Raise InvalidFileException in case of error, otherwise return the
    root object.

    see also: http://opensource.apple.com/source/CF/CF-744.18/CFBinaryPList.c
    Data.asBase64C:\msys64\mingw64\lib\python3.6\plistlib.pywrite_value_PlistWriter.write_dict<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE plist PUBLIC "-//Apple//DTD PLIST 1.0//EN" "http://www.apple.com/DTDs/PropertyList-1.0.dtd">
The plistlib.Dict class is deprecated, use builtin dict instead_PlistParser.end_stringcurrent_key<%s/>_BinaryPlistParser._get_size_PlistParser.end_date_PlistWriter.write_valuetokenH_BINARY_FORMAT_PlistParser.end_real_BinaryPlistWriter.__init___object_offsets>Bq_PlistParser.end_key>BL_undefinedkeyRefsvalRefs(?P<year>\d\d\d\d)(?:-(?P<month>\d\d)(?:-(?P<day>\d\d)(?:T(?P<hour>\d\d)(?::(?P<minute>\d\d)(?::(?P<second>\d\d))?)?)?)?)?Z_InternalDict.__setattr__strings can't contains control characters; use bytes insteadì            >BQ_objlistInvalid fileDeprecated. Use the dump() function instead._BinaryPlistWriter._flattenunexpected element at line %dThe Plist class is deprecated, use the load() and dump() functions insteadPLISTHEADER_PlistParser.handle_data_date_from_stringobj_refsData.__eq__Unsupported format: %r_BinaryPlistWriter._write_size_PlistWriter.write_bytes_PlistWriter.write_data_maybe_openThis class has been deprecated. Use dump() and load()
    functions instead, together with regular dict objects.
    _is_fmt_xml
    Wrapper for binary data.

    This class is deprecated, use a bytes object instead.
    _BinaryPlistParser._read_ints.<locals>.<genexpr>Return a bytes object with the contents for a .plist file.
    _objidtable<module plistlib>unexpected key at line %d_BinaryPlistParser._read_object.<locals>.<genexpr>_dateParser_BinaryPlistWriter.write_PlistParser.end_dict
    Write 'value' to a .plist file. 'pathOrFile' may either be a
    file name or a (writable) file object.

    This function is deprecated, use dump instead.
    _PlistParser.end_false_BinaryPlistWriter._write_object_PlistParser.end_true>6xBBQQQ_BinaryPlistParser.__init___count_to_sizeì            
    Read a plist data from a bytes object. Return the root object.

    This function is deprecated, use loads instead.
    Plist.writeData.__repr___FORMATS_ref_formatC:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\pluginsC:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\plugins\__init__.pyNuitkaPluginBase.onModuleDiscoveredNuitkaPluginBase.onModuleEncounter_createTriggerLoadedModuleNuitkaPluginBase.warnUnusedPluginpre_code By default, if given as an implicit import, require it.

        UserPluginBase Consider module imports.

            You will most likely want to look at "module.getFullName()" to get
            the fully qualified module or package name.

            You do not want to overload this method, but rather the things it
            calls, as the "signal_change" part of this API is not to be cared
            about. Most prominently "getImplicitImports()".
        NuitkaPluginBase.recurseToError, implicit module '%s' expected by '%s' not found.option_nameNuitkaPluginBase.onModuleSourceCodeNuitkaPluginBase.getImplicitImportsNuitkaPluginBase.considerDataFiles-preLoadC:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\plugins\PluginBase.pyNuitkaPluginBase.createPostModuleLoadCodetrigger_moduleNuitkaPluginBase.decideCompilation-postLoad

Plugins: Welcome to Nuitka! This is your shortest way to become part of it.

This is to provide the base class for all plug-ins. Some of which are part of
proper Nuitka, and some of which are waiting to be created and submitted for
inclusion by you.

The base class will serve as documentation. And it will point to examples of
it being used.

Error, conflicting options values given.NuitkaPluginBase.decideRecursionpost_codeError, conflicting plug-ins for %strigger_nameNuitkaPluginBase.suppressBuiltinImportWarning_module_package<module plugins.PluginBase>NuitkaPluginBase.createPreModuleLoadCode For user plug-ins.

       Check the base class methods for what you can do.
     Nuitka base class for all plug-ins.

        Derive from "UserPlugin" please.

        The idea is it will allow to make differences for warnings, and traces
        of what is being done. For instance, the code that makes sure PyQt finds
        all his stuff, may want to do reports, but likely, you do not case about
        that enough to be visible by default.

    NuitkaPluginBase.getPluginOptionswarned_unused_pluginsNuitkaPluginBase.considerImplicitImportsInjecting plug-in based post load code for module '%s':NuitkaPluginBase.considerExtraDllsNuitkaPluginBase.onFrozenModuleSourceCodeNuitkaPluginBase._createTriggerLoadedModuleInjecting plug-in based pre load code for module '%s':NuitkaPluginBase.suppressUnknownImportWarningNuitkaPluginBase.isRequiredImplicitImportNuitkaPluginBase.onFrozenModuleBytecodeNuitkaPluginBase.locateModuleUse '--plugin-enable=%s' for: %sNuitkaPluginBase.removeDllDependenciesNuitkaPluginBase.getPluginOptionBoolNuitkaPluginBase.considerFailedImportReferralsError, conflicting enable/disable of plug-in '%s'.Plugins.onModuleSourceCodestandard.MultiprocessingPluginstandard.EnumPluginoptional_plugin_classes

Plugins: Welcome to Nuitka! This is your shortest way to become part of it.

This is to provide the base class for all plug-ins. Some of which are part of
proper Nuitka, and some of which are waiting to be created and submitted for
inclusion by you.

The base class in PluginBase will serve as documentation of available.

standard.ConsiderPyLintAnnotationsPluginplugin_detectoractive_plugin_listPlugins.suppressUnknownImportWarningPlugins.onModuleEncounterPlugins.decideCompilationPlugins.onModuleDiscoveredC:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\plugins\Plugins.py<module plugins.Plugins>initPluginsmust_recursestandard.PySidePyQtPluginPlugins.onFrozenModuleBytecodeimporting_modulePlugins.considerDataFilesplugin_name2plugin_classesextra_dllstandard.DataFileCollectorPluginPlugins.onFrozenModuleSourceCodePlugins.suppressBuiltinImportWarningPlugins.removeDllDependenciesPlugins.considerImplicitImportsPlugins.considerFailedImportReferralsstandard.ImplicitImportsstandard.PmwPluginPlugins.considerExtraDllsError, unknown plug-in '%s' referenced.plugins.standardC:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\plugins\standardC:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\plugins\standard\__init__.pyNuitkaPluginDetectorPylintEclipseAnnotations.isRelevantcomment_onlyUnderstand PyLint/PyDev annotations for warnings.import-errorline_annotationsNuitkaPluginPylintEclipseAnnotations.onModuleSourceCodeNuitkaPluginPylintEclipseAnnotations.__init__pylint-warningsC:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\plugins\standard\ConsiderPyLintAnnotationsPlugin.py Standard plug-in to take advantage of pylint or PyDev annotations.

Nuitka can detect some things that PyLint and PyDev will complain about too,
and sometimes it's a false alarm, so people add disable markers into their
source code. Nuitka does it itself.

This tries to parse the code for these markers and uses hooks to prevent Nuitka
from warning about things, disabled to PyLint or Eclipse. The idea is that we
won't have another mechanism for Nuitka, but use existing ones instead.

The code for this is very incomplete, barely good enough to cover Nuitka's own
usage of PyLint markers. PyDev is still largely to be started. You are welcome
to grow both.

NuitkaPluginDetectorPylintEclipseAnnotations.onModuleSourceCodeF0401NuitkaPluginPylintEclipseAnnotations.onModuleSourceCode.<locals>.<genexpr>NuitkaPluginPylintEclipseAnnotations.suppressUnknownImportWarning<module plugins.standard.ConsiderPyLintAnnotationsPlugin>#.*pylint:\s*disable=\s*([\w,-]+)#\s*pylint:\s*disable=\s*(\w+) Standard plug-in to find data files.

plugins.standard.DataFileCollectorPluginknown_data_filesnose.core<module plugins.standard.DataFileCollectorPlugin>data-filesusage.txtscrapyNuitkaPluginDataFileCollector.isRelevantC:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\plugins\standard\DataFileCollectorPlugin.pyNuitkaPluginDataFileCollector.considerDataFilesEnum workarounds for compiled code.plugins.standard.EnumPluginenum_compatimport enum
try:
    enum.Enum.__new__ = staticmethod(enum.Enum.__new__.__func__)
    enum.IntEnum.__new__ = staticmethod(enum.IntEnum.__new__.__func__)
except AttributeError:
    pass
Monkey patching "enum" for compiled '__new__' methods. This is to make enum module work when compiled with Nuitka.

    <module plugins.standard.EnumPlugin>temp_enum_dict['__new__'] = __new__NuitkaPluginEnumWorkarounds.createPostModuleLoadCodeC:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\plugins\standard\EnumPlugin.pyNuitkaPluginDetectorEnumWorkarounds.onModuleSourceCodeNuitkaPluginDetectorEnumWorkarounds.isRelevant Standard plug-in to make enum module work when compiled.

The enum module provides a free function __new__ in class dictionaries to
manual metaclass calls. These become then unbound methods instead of static
methods, due to CPython only checking for plain uncompiled functions.
pkg_util_externalrequests.packages.urllib3.util.urlPyQt5.QtSerialPortNuitkaPluginPopularImplicitImports.suppressBuiltinImportWarningurllib3.util.responsesix.moves.dbm_gnuPyQt5.QtWidgetsgtk._gtk<module plugins.standard.ImplicitImports>dist_dll_pathrequests.packages.urllib3.packages.ssl_match_hostname._implementationrequests.packages.urllib3.util.responsesix.moves.builtinsQtOpenGLsix.moves.winreg.QtNetworksix.moves.reprlibsix.moves.tkinter_scrolledtextPyQt5.QtPrintSupportpkg_resources._vendor.packaging.specifiersPySide.QtHelp_dbus_bindingssix.moves._threademail.mime.nonmultiparttype(attr) is types.MethodTypeQtDeclarativeQtWebKitQtXmlPatternsQtQmlQtWebKitWidgetsQtMultimediaQtMultimediaWidgetsQtQuickQtQuickWidgetsQtWebSocketsQtSqlunworthy_namespacePyQt5.QtQuickPyQt5.QtQuickWidgetsrequests.packages.idnanumexpr.cpuinforeportlab.rl_settingsPySide.QtSvgsix.moves.html_entitiessix.moves.tkinter_dialogrequests.packages.urllib3.connectionPySide.phononurllib3.util.requestC:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\plugins\standard\ImplicitImports.pyPySide.QtUiToolsrequests.packages.urllib3.util.requestisinstance(attr, types.MethodType)_cffi_backendPyQt5.QtTestrequests.packages.urllib3.util.timeoutsix.moves.http_cookiesPyQt5.QtSvgcythonemail.MIMEMultipartreportlab.rl_configuuidemail.MIMENonMultipart.QtCoreQtDesignerQtScriptTools_QOpenGLFunctions_2_0_QOpenGLFunctions_2_1_QOpenGLFunctions_4_1_CorePyQt5.QtQmlwx._coreemail.MIMETexturllib3.exceptionssix.moves.SimpleHTTPServersix.moves.tkinter_dndPySide.QtSqlsix.moves.tkinter_tkfiledialogsix.moves.xmlrpc_serverPyQt5.QtDesignerPyQt5.QtSqlurllib3.filepostNuitkaPluginPopularImplicitImports.considerExtraDllsuuid_dll_pathNuitkaPluginPopularImplicitImports.__init__requests.packages.urllib3.contrib.pyopenssl Standard plug-in to tell Nuitka about implicit imports.

When C extension modules import other modules, we cannot see this and need to
be told that. This encodes the knowledge we have for various modules. Feel free
to add to this and submit patches to make it more complete.
numpy.f2pyurllib3.fieldspkg_utils_externalsrequests.packages.urllib3.fieldssix.moves.tkinter_messageboxrequests.packages.urllib3.packages.ordered_dictPySide.QtXmllxml.objectifysix.moves.xmlrpc_clientPyQt5.QtWebKitWidgets_yamlsix.moves.tkinter_simpledialoglxml._elementpathsix.moves.tkinter_commondialogrequests.packages.urllib3.util.connectionchardetPyQt5.QtSensorsrequests.packages.urllib3.contrib.socksapt_pkgsix.moves.BaseHTTPServeremail.MIMEBasePIL._imagingtksix.moves.cPicklecryptography.hazmat.bindings._opensslcryptography.hazmat.bindings._constant_timecryptography.hazmat.bindings._paddingurllib3.requestsix.moves.tkinter_filedialogrequests.packages.urllib3.filepostrequests.packages.urllib3._collectionsemail.mime.basesix.moves.email_mime_textemail.mime.multipartPyQt5.QtHelpPyQt5.QtOpenGLPyQt5.QtMultimediaWidgetsPySide.QtGuiNuitkaPluginPopularImplicitImports.decideCompilationNuitkaPluginPopularImplicitImports.getImplicitImportssix.moves.tkinter_tix_dbus_glib_bindingsrequests.packages.urllib3.responsesix.moves.email_mime_multipartsix.moves.http_cookiejarrequests.packages.urllib3.requestnumpy.distutilsnumpy.testingdocutilspyximportIPythonPySide.QtWebKitsix.moves.CGIHTTPServersix.moves.tkinter_fontsix.moves.html_parserPySide.QtOpenGLpkg_resources._vendor.packaging.requirementsurllib3.util.ssl_six.moves.urllib_errorPySide.QtScriptPyQt5.QtNetworkPySide.QtScriptToolsurllib3.poolmanagerPIL._tkinter_finderPyQt5.QtDBussix.moves.urllib_robotparserrequests.packages.urllib3.contrib.ntlmpoolsix.moves.http_client_mysql_exceptionssix.moves._dummy_threadbcrypt._bcryptrequests.packages.urllib3.poolmanagersix.moves.email_mime_nonmultipartsix.moves.configparsersix.moves.copyregtkinter_tksimpledialogsix.moves.queuecairo._cairoPyQt5.QtNetworkAuthgi._errorurllib3.util.retrycryptography._Cryptography_cffi_six.moves.tkinter_colorchooserPySide.QtDeclarativenacl._sodiumrequests.packages.urllib3.exceptionssix.moves.urllib_parseNuitkaPluginPopularImplicitImports.onModuleSourceCodeurllib3.connectionpoolpkg_resources._vendor.packaging.versionrequests.packages.urllib3.util.retryrequests.packages.urllib3.connectionpoolPySide.QtTestrequests.packages.urllib3.util.ssl_six.moves.tkinter_ttkapt_instsix.moves.tkinter_tksimpledialogNuitkaPluginPopularImplicitImports.isRequiredImplicitImportsix.moves.socketserveremail.mime.textsix.moves.email_mime_baserequests.packages.chardetsix.moves.tkinter_constants©zQtGuizQtAssistantzQtDBuszQtDeclarativezQtSqlz
QtDesignerzQtHelpz	QtNetworkzQtScriptzQtQmlzQtScriptToolszQtSvgzQtTestzQtWebKitzQtOpenGLzQtXmlzQtXmlPatternszQtPrintSupportzQtNfczQtWebKitWidgetszQtBluetoothzQtMultimediaWidgetszQtQuickzQtWebChannelzQtWebSocketszQtX11Extrasz_QOpenGLFunctions_2_0z_QOpenGLFunctions_2_1z_QOpenGLFunctions_4_1_Coreunworthy_namespacesgi._gi_cairoNuitkaPluginMultiprocessingWorkarounds.__init__ This is to make multiprocessing work with Nuitka and use compiled code.

        When running in accelerated mode, it's not good to fork a new Python
        instance to run other code, as that won't be accelerated. And when
        run in standalone mode, there may not even be a Python, but it's the
        same principle.

        So by default, this module is on and works around the behavior of the
        "multiprocessing.forking/multiprocessing.spawn" expectations.
    import sys
sys.frozen = 1
sys.executable = sys.argv[0]

__import__("sys").modules["__main__"] = __import__("sys").modules[__name__]
__import__("multiprocessing.spawn").spawn.freeze_support() Standard plug-in to make multiprocessing work well on Windows.

On Windows, the multiprocessing modules forks new processes which then have
to start from scratch. This won't work if there is no "sys.executable" to
point to a "Python.exe" and won't use compiled code by default.

The issue applies to accelerated and standalone mode alike.
nuitka.tree.Building
__import__("sys").modules["__main__"] = __import__("sys").modules[__name__]
__import__("multiprocessing.forking").forking.freeze_support()hexversionslave_main_module_addSlaveMainModuleMultiprocessing workarounds for compiled code on Windows.Multiprocessing plugin needs this to monkey patch it.nuitka.ModuleRegistryNuitkaPluginMultiprocessingWorkarounds.createPostModuleLoadCodeNuitkaPluginMultiprocessingWorkarounds.onModuleEncountermultiprocessing_addedNuitkaPluginMultiprocessingWorkarounds._addSlaveMainModuleplugins.standard.MultiprocessingPlugin<module plugins.standard.MultiprocessingPlugin>NuitkaPluginDetectorMultiprocessingWorkarounds.onModuleSourceCodeMonkey patching "multiprocessing" load environment.from %s import ForkingPickler

class C:
   def f():
       pass

def _reduce_compiled_method(m):
    if m.im_self is None:
        return getattr, (m.im_class, m.im_func.__name__)
    else:
        return getattr, (m.im_self, m.im_func.__name__)

ForkingPickler.register(type(C().f), _reduce_compiled_method)
ForkingPickler.register(type(C.f), _reduce_compiled_method)
Monkey patching "multiprocessing" for compiled methods.__parents_main__C:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\plugins\standard\MultiprocessingPlugin.pyNuitkaPluginDetectorMultiprocessingWorkarounds.isRelevantNuitkaPluginMultiprocessingWorkarounds.createPreModuleLoadCodeLogicalFont\<Pmw\.plugins.standard.PmwPluginpmw_path_hasLoaderC:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\plugins\standard\PmwPlugin.pyError, cannot find any Pmw versions.INITOPT = Pmw.INITOPT
import PmwBlt
Blt = PmwBlt
del PmwBlt
pmw-freezerNuitkaPluginPmw._packagePmw_packagePmw2
######################################################################
### File: 
import PmwColor
Color = PmwColor
del PmwColor
colorCodebltNuitkaPluginDetectorPmw.isRelevant Plugin to pre-process PMW for inclusion.

Proper freezing of Pmw package.

### Loader functions:

_VERSION = '%s'

def setversion(version):
    if version != _VERSION:
        raise ValueError, 'Dynamic versioning not available'

def setalphaversions(*alpha_versions):
    if alpha_versions != ():
        raise ValueError, 'Dynamic versioning not available'

def version(alpha = 0):
    if alpha:
        return ()
    else:
        return _VERSION

def installedversions(alpha = 0):
    if alpha:
        return ()
    else:
        return (_VERSION,)

extraCodePmwLoadermungeFilebltCodeignoreBltCodeneedBltneedColoroutfileimport Pmw\>NuitkaPluginPmw._packagePmw.<locals>._hasLoader<module plugins.standard.PmwPlugin>^Pmw_[0-9]_[0-9](_[0-9])?$
_bltImported = 1
_bltbusyOK = 0
Û   zDialogz	TimeFuncszBalloonz	ButtonBoxz
EntryFieldzGroupzLabeledWidgetzMainMenuBarzMenuBarz
MessageBarzMessageDialogzNoteBookz
OptionMenuzPanedWidgetzPromptDialogzRadioSelectzScrolledCanvaszScrolledFieldzScrolledFramezScrolledListBoxzScrolledTextzHistoryTextzSelectionDialogz
TextDialogzTimeCounterzAboutDialogzComboBoxzComboBoxDialogzCounterzCounterDialogNuitkaPluginDetectorPmw.onModuleDiscoveredNuitkaPluginPmw._packagePmw2.<locals>.mungeFile_font_initialiseimport PmwLogicalFontPmwLogicalFont._font_initialiseNuitkaPluginPmw.onModuleSourceCodelibknotesqml_plugin_dirplugins.standard.PySidePyQtPluginPyQt4.QtCoreiconenginesqt_versionfrom __future__ import print_function

import PyQt%(qt_version)d.QtCore
for v in PyQt%(qt_version)d.QtCore.QCoreApplication.libraryPaths():
    print(v)
import os
guess_path = os.path.join(os.path.dirname(PyQt%(qt_version)d.__file__), "plugins")
if os.path.exists(guess_path):
    print("GUESS:", guess_path)
Inclusion of Qt plugins.GUESS:  Create code to load after a module was successfully imported.

            For Qt we need to set the library path to the distribution folder
            we are running from. The code is immediately run after the code
            and therefore makes sure it's updated properly.
        NuitkaPluginPyQtPySidePlugins.createPostModuleLoadCode.qmlplugin_candidatefrom PyQt%(qt_version)d.QtCore import QCoreApplication
import os

QCoreApplication.setLibraryPaths(
    [
        os.path.join(
           os.path.dirname(__file__),
           "qt-plugins"
        )
    ]
)
printsupportlibakregator.qmlclibkaddressbook Standard plug-in to make PyQt and PySide work well in standalone mode.

To run properly, these need the Qt plug-ins copied along, which have their
own dependencies.
NuitkaPluginPyQtPySidePlugins.removeDllDependenciesSetting Qt library path to distribution folder. Need to avoid loading target
system Qt plug-ins, which may be from another Qt version.imageformatsmediaservice.metainfo.qmltypes.jsc.ttflibkerfuffleC:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\plugins\standard\PySidePyQtPlugin.py This is for plugins of PySide/PyQt4/PyQt5.

        When loads an image, it may use a plug-in, which in turn used DLLs,
        which for standalone mode, can cause issues of not having it.
    libnotesharedlibgwenviewtarget_plugin_dirqml_target_dirbadwordqt_dirsNuitkaPluginPyQtPySidePlugins.considerExtraDllsError, no such Qt plugin family: %slibKF5libkfontinstlibkorganizerlibplasmalibdolphinlibsystemsettingslibkworkspacelibkmaillibmiloulibtaskmanagerlibkonsolelibweather_ionCopying Qt plug-ins 'xml' to '%s'.qmldirNuitkaPluginDetectorPyQtPySidePlugins.isRelevantgetPyQtPluginDirsNuitkaPluginPyQtPySidePlugins.getPyQtPluginDirsCopying Qt plug-ins '%s' to '%s'.hasPluginFamilyNuitkaPluginPyQtPySidePlugins.considerExtraDlls.<locals>.<genexpr><module plugins.standard.PySidePyQtPlugin>NuitkaPluginDetectorPyQtPySidePlugins.onModuleDiscoveredNuitkaPluginPyQtPySidePlugins.__init__NuitkaPluginPyQtPySidePlugins.hasPluginFamilylist_of_portsPortSettings.__init__cnc startedsensor thread gone; trying to closeconnect_bladder<module port_settings>sensor_portcould not initialize: trying to reconnectbladder connectedPortSettings.start_cnc_threadC:\msys64\home\cbper\port_settings.pybladder_command_queuePortSettings.stop_devicesPortSettings.stop_tensionerstart_pressure_pad_threadtensioner_command_queuePortSettings.send_tensioner_commandtensioner connectedport_settings::new_case_selected: Sent enable_adjusment to tensionerpressure pad startedbladder_threadPortSettings.connect_tensionerPortSettings.send_pushback_commandport_settings::new_case_selected: put %s on the bladder command queue.PortSettings.home_cncPortSettings.start_pressure_pad_threadport_settings::new_case_selected: No tensioner_thread, so default to idlePortSettings.initialize_devicesport_settings::stop_tensioner: sent disable_adjustment to tensionerPortSettings.send_cnc_emergency_stopfind_portscnc_queuePortSettings.find_portsPortSettings.new_case_selectedPortSettings.connect_bladderPortSettings.send_cnc_commandbladder_portNormalize case of pathname.  Has no effect under Posixino2ino1dotdot\$(\w+|\{[^}]*\})Return the canonical path of the specified filename, eliminating any
symbolic links encountered in the path.Split a pathname into drive and path. On Posix, drive is always
    empty.dev1<module posixpath>pwentCommon operations on Posix pathnames.

Instead of importing this module directly, import os and refer to
this module as os.path.  The "os.path" name is an alias for this
module on Posix systems; on other systems (e.g. Mac, Windows),
os.path provides the same operations in a manner specific to that
platform, and is an alias to another module (e.g. macpath, ntpath).

Some of this can actually be useful on non-Posix systems too, e.g.
for manipulation of the pathname component of URLs.
newpathnew_compsnormcase() argument must be str or bytes, not '{}'initial_slashesdev2Split a pathname.  Returns tuple "(head, tail)" where "tail" is
    everything after the final slash.  Either part may be empty._joinrealpathpw_dirExpand shell variables of form $var and ${var}.  Unknown variables
    are left unchanged.Return an absolute path.C:\msys64\mingw64\lib\python3.6\posixpath.py_varprogb:/bin:/usr/binÛ&   znormcasezisabszjoinz
splitdrivezsplitzsplitextzbasenamezdirnamezcommonprefixzgetsizezgetmtimezgetatimezgetctimezislinkzexistszlexistszisdirzisfilezismountz
expanduserz
expandvarsznormpathzabspathzsamefilezsameopenfilezsamestatzcurdirzpardirzsepzpathsepzdefpathzaltsepzextsepzdevnullzrealpathzsupports_unicode_filenameszrelpathz
commonpathJoin two or more pathname components, inserting '/' as needed.
    If any component is an absolute path, all previous path components
    will be discarded.  An empty last part will result in a path that
    ends with a separator.Expand ~ and ~user constructions.  If user or $HOME is unknown,
    do nothing.allowancePrettyPrinter._pprint_user_dictPrettyPrinter._pprint_tuplepformat:PrettyPrinter.pformat<module pprint>PrettyPrinter.isreadablemaxlevels_safe_key.__lt__PrettyPrinter._pprint_str_pprint_bytes_pprint_user_stringPrettyPrinter._format_dict_itemsdelimnlnext_entsafereprmappingproxy(_pprint_listPrettyPrinter.format©ÚselfÚobjectÚstreamÚindentÚ	allowanceÚcontextÚlevelÚwriteÚchunksÚlinesÚ
max_width1Ú	max_widthÚiÚlineÚrepÚpartsÚ
max_width2ÚcurrentÚjÚpartÚ	candidatebytearray(PrettyPrinter._pprint_user_string_indent_per_level],
%smaxlen=%s)PrettyPrinter._pprint_ordered_dictPrettyPrinter._pprint_bytesdefault_factory\S*\s*width must be != 0_pprint_chain_mapC:\msys64\mingw64\lib\python3.6\pprint.py©ÚobjectÚcontextÚ	maxlevelsÚlevelÚtypÚrÚobjidÚreadableÚ	recursiveÚ
componentsÚappendÚsafereprÚitemsÚkÚvÚkreprÚ	kreadableÚkrecurÚvreprÚ	vreadableÚvrecurÚformatÚoÚoreprÚ	oreadableÚorecurÚrepFormat object for a specific context, returning a string
        and flags indicating whether the representation is 'readable'
        and whether the object represents a recursive construct.
        PrettyPrinter._pprint_chain_mapPrettyPrinter._pprint_counter<Recursion on %s with id=%s>PrettyPrinter.isrecursivePrettyPrinter._pprint_dict_compact_safe_reprPrettyPrinter.__init__Version of repr() which can handle recursive data structures._pprint_set_safe_repr:Helper function for comparing 2-tuplesDetermine if saferepr(object) is readable by eval().PrettyPrinter._pprint_dequedepth must be > 0_perfcheckHelper function for key functions when sorting unorderable objects.

    The wrapped-object will fallback to a Py2.x style comparison for
    unorderable types (sorting first comparing the type name and then by
    the obj ids).  Does not work recursively, so dict.items() must have
    _safe_key applied to both the key and the value.

    PrettyPrinter._pprint_user_listprinterPrettyPrinter.pprintindent must be >= 0_StringIOPrettyPrinter._pprint_list%s(%s,
%slast_indexFormat a Python object into a pretty-printed representation.Support to pretty-print lists, tuples, & dictionaries recursively.

Very simple, but useful, especially in debugging data structures.

Classes
-------

PrettyPrinter()
    Handle pretty-printing operations onto a stream using a configured
    set of formatting parameters.

Functions
---------

pformat()
    Format a Python object into a pretty-printed representation.

pprint()
    Pretty-print a Python object to a stream [default is sys.stdout].

saferepr()
    Generate a 'standard' repr()-like value, but protect against recursive
    data structures.

_builtin_scalarsPrettyPrinter._pprint_default_dictPrettyPrinter._pprint_bytearray(%s,)PrettyPrinter._pprint_set_safe_key.__init__Determine if object requires a recursive representation.PrettyPrinter._pprint_mappingproxy_format_itemsPrettyPrinter._reprPrettyPrinter._format_items_wrap_bytes_repr_safe_tupleHandle pretty printing operations onto a stream using a set of
        configured parameters.

        indent
            Number of spaces to indent for each level of nesting.

        width
            Attempted maximum number of columns in the output.

        depth
            The maximum depth to print out nested structures.

        stream
            The desired output stream.  If omitted (or false), the standard
            output stream available at construction will be used.

        compact
            If true, several items will be combined in one line.

        tare_dictSensitivitySettings.down_threshold_movedset_rangegiven_tare_listtare_valuesave_thresholds_as_defaultdown_labelC:\msys64\home\cbper\pressurepoints.pyPressureThresholdsSave Sensitivity SettingsPressureList.state_has_changeddown_hscalePressurePointtare.jsontare_button_alignmentTareValues.get_tare_valuesinitial_tare_valuesDeep Palpationnew_dchange-valuetoo_light_threshold_movedPressurePoint._calculate_stateTareValues.tare_values_are_valid_REBOUND_TIMELight Palpationsaved_tare_valuesPressureThresholds.__init__config_slightly_downconfig_downconfig_too_hardset_digitsToo harddirty_callbackTareValues.save_tare_valuesPressurePoint.set_depthSensitivitySettings.too_hard_threshold_movedPressureList.tarenum_pressure_pointsreset_max_depthSensitivitySettings.too_light_threshold_movedSensitivitySettings.tare_button_pressedTare / Zero SensorsPressureThresholds.get_thresholds_DEFAULT_TOO_HARDdefaults_dictnew_depthsset_state_dirty_callbackPressureThresholds.save_thresholds_as_defaultround_digitsPressureList.reset_max_depth_raw_depthpressure_thresholds_DEFAULT_TAREtoo_light_labelconfig_from_file<module pressurepoints>too_hard_hscaleround-digitsPressureThresholds.set_thresholdssave_settings_alignmentPressurePoint.get_statePressurePoint.check_for_reboundCould not save tare values. Values invalid.TareValues.__init__time_diff
PressurePoints models the pressure on the pad
PressurePoint.__init__PressurePoint.get_depthtoo_light_hscalelast_time_below_bluePressureThresholds.dict_contains_required_valuesPressureList.on_new_caseSensitivitySettings.__init__new_sdindirect rebound! Time diff: Using sensitivity settings from PressurePoint.get_max_statePressureList.__init__PressurePoint.reset_max_depthNUM_PRESSURE_POINTSstarted timer on index too_hard_labelsave_settings_buttonsensitivity.jsondirect rebound on index _DEFAULT_SLIGHTLY_DOWN_DEFAULT_DOWNset_tarePressureList.set_state_dirtyPressurePoint.set_tarePressureList.get_pressure_list does not contain the required values. Using defaults.Using tare values from Diverticulitis

Hx:
Pain described as constant
Progressive worsening over time
Pain worsens with defecation
Pain moderate to severe
Location left lower quadrant
Feverish
Age > 60
Age > 40 < 60
Duration of pain < 6 hours prior to presentation
Duration of pain 6 - 12 hours prior to presentation
Gradual onset of pain

PE:
Tenderness in left lower quadrant
Temperature 36.1â37.8Â°C (97-100Â°F)
No abdominal guarding
Decreased bowel sounds
Normal bowel sounds
Guarding in left lower quadrant
Tachycardia
Holds prototype text for each ddx
prototypes.jsonUpper Gastrointestinal Etiology

Hx:
Location epigastric
Pain worsens with lying down
Pain occurs after meals
Acid reflux symptoms
Pain described as burning
Prior episodes of similar pain
Pain moderate to severe
Pain described as constant
Radiation of pain retrosternal
Acute onset of pain
Male
History of alcohol use/abuse
Age > 40 < 60
Age < 40
Duration of pain < 6 hours prior to presentation
Duration of pain 6 - 12 hours prior to presentation
Duration of pain 12 - 24 hours prior to presentation
Radiation of pain to back in midline
Use of aspirin or non-steroidal medications
Pain not worsening over time

PE:
Temperature 36.1â37.8Â°C (97-100Â°F)
Tenderness in sub-xyphoid/epigastric area
No abdominal guarding
Normal bowel sounds
Patient remains stillAppendicitis

Hx:
Pain moderate to severe
Progressive worsening over time
Pain described as constant
Feverish
Age < 40
Location right lower quadrant
Duration of pain 6 - 12 hours prior to presentation
Anorexia
Nausea-vomiting
Duration of pain 12 - 24 hours prior to presentation
Gradual onset of pain

PE:
Tenderness in right lower quadrant
Temperature elevation >37.5 and <38.3Â°C (99.5 to 100.9Â°F)
No abdominal guarding
Decreased bowel sounds
Normal bowel sounds
Guarding in right lower quadrant
Tachycardia
Cholecystitis

Hx:
Location right upper quadrant
Pain moderate to severe
History of gallbladder stones
Progressive worsening over time
Prior episodes of similar pain
Radiation of pain to shoulder/scapula
Duration of pain < 6 hours prior to presentation
Age < 40
Female
Nausea-vomiting
Duration of pain 6 - 12 hours prior to presentation
Age > 40 < 60
Gradual onset of pain
Pain described as colicky/intermittant

PE:
Tenderness in right upper quadrant
Temperature 36.1â37.8Â°C (97-100Â°F)
Normal bowel sounds
No abdominal guarding
Patient constantly movesCholedocolithiasis

Acute onset of pain
Dark urine
Pain moderate to severe
Location right upper quadrant
History of gallbladder stones
Progressive worsening over time
Radiation of pain to shoulder/scapula
Duration of pain < 6 hours prior to presentation
Age > 40 < 60
Duration of pain 6 - 12 hours prior to presentation
Nausea-vomiting
Age < 40
Prior episodes of similar pain
Pain described as colicky/intermittant

PE:
Tenderness in right upper quadrant
Temperature 36.1â37.8Â°C (97-100Â°F)
Normal bowel sounds
No abdominal guarding
Patient constantly moves
Icteric conjunctiva
Tachycardia
Small Bowel Obstruction

Hx:
Pain moderate to severe
Progressive worsening over time
Prior abdominal surgery
Decreased bowel movements
Abdominal fullness/distention
Nausea-vomiting
Duration of pain < 6 hours prior to presentation
Age > 60
Duration of pain 6 - 12 hours prior to presentation
Location periumbilical
Location non-specific
Female
Bilious emesis
Age > 40 < 60
Gradual onset of pain
Pain described as colicky/intermittant

PE:
Temperature 36.1â37.8Â°C (97-100Â°F)
Patient constantly moves
Increased bowel sounds
Distended abdomen
No abdominal guarding
Tympanic abdomen
Tachypnea
TachycardiaPancreatitis

Hx:
Location epigastric
Pain described as constant
Pain moderate to severe
Progressive worsening over time
Nausea-vomiting
Male
History of alcohol use/abuse
Duration of pain < 6 hours prior to presentation
Radiation of pain to back in midline
Pain occurs after meals
History of gallbladder stones
Age < 40
Age > 40 < 60
Duration of pain 6 - 12 hours prior to presentation
Prior episodes of similar pain
Bilious emesis
Pain described as burning

PE:
Tenderness in sub-xyphoid/epigastric area
No abdominal guarding
Temperature 36.1â37.8Â°C (97-100Â°F)
Normal bowel sounds
Patient constantly moves
TachycardiaC:\msys64\home\cbper\prototypetext.pyPrototypeTextBuffer.new_feedback      ,@Example prototype text for ddx {ddx} index {case_index}prototype_tagAcute Enteritis

Hx:
Nausea-vomiting
Feverish
Diarrhea
Age < 40
Location non-specific
Duration of pain 24 - 48 hours prior to presentation
Exposure to others with nausea/vomiting/diarrhea
Duration of pain 12 - 24 hours prior to presentation
Pain not worsening over time
Pain mild
Pain described as colicky/intermittant

PE:
No abdominal guarding
No abdominal tenderness
Temperature elevation >37.5 and <38.3Â°C (99.5 to 100.9Â°F)
Increased bowel sounds
Normal bowel sounds<module prototypetext>PrototypeTextBuffer.__init__get_prototype_textMesenteric Infarction

Hx:
Pain moderate to severe
Acute onset of pain
Age > 60
Pain described as constant
Progressive worsening over time
Duration of pain < 6 hours prior to presentation
History of cardiac irregularities
Radiation of pain to back in midline
Location periumbilical
Pain occurs after meals
Decreased bowel movements
Bloody emesis
Blood with bowel movement

PE:
Patient constantly moves
Temperature 36.1â37.8Â°C (97-100Â°F)
Decreased bowel sounds
Tachycardia
Tachypnea
No abdominal guarding
Change in mental status/confusion
Hypotension
Abdominal wall erythema/edema
Abdominal bruit
Tenderness in sub-xyphoid/epigastric areaPrototypeText.get_prototype_textproto_textPrototypeText.__init__exc_type_nameByte-compile one Python source file to Python bytecode.

    :param file: The source file name.
    :param cfile: The target byte compiled file name.  When not given, this
        defaults to the PEP 3147/PEP 488 location.
    :param dfile: Purported file name, i.e. the file name that shows up in
        error messages.  Defaults to the source file name.
    :param doraise: Flag indicating whether or not an exception should be
        raised when a compile error is found.  If an exception occurs and this
        flag is set to False, a string indicating the nature of the exception
        will be printed, and the function will return to the caller. If an
        exception occurs and this flag is set to True, a PyCompileError
        exception will be raised.
    :param optimize: The optimization level for the compiler.  Valid values
        are -1, 0, 1 and 2.  A value of -1 means to use the optimization
        level of the current interpreter, as given by -O command line options.

    :return: Path to the resulting byte compiled file.

    Note that it isn't necessary to byte-compile Python modules for
    execution efficiency -- Python itself byte-compiles a module when
    it is loaded, and if it can, writes out the bytecode to the
    corresponding .pyc file.

    However, if a Python installation is shared between users, it is a
    good idea to byte-compile all modules upon installation, since
    other users may not be able to write in the source directories,
    and thus they won't be able to write the .pyc file, and then
    they would be byte-compiling every module each time it is loaded.
    This can slow down program start-up considerably.

    See compileall.py for a script/module that uses this module to
    byte-compile all installed files (or all files in selected
    directories).

    Do note that FileExistsError is raised if cfile ends up pointing at a
    non-regular file or symlink. Because the compilation uses a file renaming,
    the resulting file would be regular and thus not the same type of file as
    it was previously.
    File "<string>"{} is a non-regular file and will be changed into a regular one if import writes a byte-compiled file to itSorry: %s: %stbtextException raised when an error occurs while attempting to
    compile the file.

    To raise this exception, use

        raise PyCompileError(exc_type,exc_value,file[,msg])

    where

        exc_type:   exception type to be used in error message
                    type name can be accesses as class variable
                    'exc_type_name'

        exc_value:  exception value to be used in error message
                    can be accesses as class variable 'exc_value'

        file:       name of file being compiled to be used in error message
                    can be accesses as class variable 'file'

        msg:        string message to be written as error message
                    If no value is given, a default exception message will be
                    given, consistent with 'standard' py_compile output.
                    message (or default) can be accesses as class variable
                    'msg'

    Compile several source files.

    The files named in 'args' (or on the command line, if 'args' is
    not specified) are compiled and the resulting bytecode is cached
    in the normal manner.  This function does not search a directory
    structure to locate source files; it only compiles files named
    explicitly.  If '-' is the only parameter in args, the list of
    files is taken from standard input.

    py_excRoutine to "compile" a .py file to a .pyc file.

This module has intimate knowledge of the format of .pyc files.
<py_compile>PyCompileError.__str__C:\msys64\mingw64\lib\python3.6\py_compile.py<module py_compile>PyCompileError.__init__{} is a symlink and will be changed into a regular file if import writes a byte-compiled file to itImport a Python source file or compiled file given its path.HorizontalRule_start_server.<locals>.DocHandler.log_messageErrorDuringImport.__str__use_pagerHelper.listmodules.<locals>.callbackErrors that occurred while trying to import something to document it.MODULE REFERENCE_url_handler.<locals>.html_searchMethods %sispackageSearch ResultsOmit part of a string if needed to make it fit in a maximum length.TOPICWrite out HTML documentation for all modules in a directory tree.TextDoc.indent<dd><tt>%s</tt>complete_urlhtml_indexhtml_topicshtml_keywordshtml_getfilehtml_topicpagehtml_getobjhtml_error:<br>
Data and other attributes %sskipdocsgetdoclocRead one line, using input() when appropriate.Split sequence s via predicate, and return pair ([true], [false]).

    The return value is a 2-tuple of lists,
        ([x for x in s if predicate(x)],
         [x for x in s if not predicate(x)])
    #eeaa77
Here is a list of the punctuation symbols which Python assigns special meaning
to. Enter any symbol to get more help.

<dd><tt>%s</tt></dd>Write HTML documentation to a file in the current directory.Render in text a class tree as returned by inspect.getclasstree().lastupdateshowsymbol_url_handler.<locals>.html_index.<locals>.bltinlinkplaintextProduce text documentation for a data object.<strong>%s</strong>&nbsp;(package)field_orderneedoneforceload#7799eeclean_contentsmore < = class           Help on %s:Format a section with a given heading.HTMLDoc.docmoduleloader_clsGuess whether a path refers to a package directory.HTMLDoc.modulelinkIndex of keywords.modpkginfoHTMLDoc.docclass.<locals>.HorizontalRule.maybecss_pathcss_linkhtml_navbarttypager.<locals>.<lambda>_HTMLDocRender text documentation, given an object or a path to an object.PYTHONDOCSHTMLDoc.docclass.<locals>.spilldescriptorsHelper.showsymbol_url_handler.<locals>.html_navbar_url_handler.<locals>._HTMLDoc
Sorry, topic and keyword documentation is not available because the
module "pydoc_data.topics" could not be found.
\b((http|ftp)://\S+[\w/]|RFC[- ]?(\d+)|PEP[- ]?(\d+)|(self\.)?(\w+))cli.<locals>.BadUsageC:\msys64\mingw64\lib\python3.6\pydoc.pyTextDoc.docclass.<locals>.HorizontalRule.maybe
Here is a list of modules whose name or summary contains '{}'.
If there are any, enter a module name to get more help.

_re_stripid<big><big><strong>%s</strong></big></big>no documentation found for %s
Get the one-line summary out of a module file.search?keyServer commands: [b]rowser, [q]uitinherited from %smodpkgsHTMLRepr.repr_stringServer stopped_url_handler.<locals>.html_error.<locals>.<genexpr>CreditsProduce text documentation for a given module object.<a href="%s.html"><font color="#ffffff">%s</font></a>TextRepr__temp__MANPAGERTextDoc.docclass.<locals>.<lambda>$Revision: Helper._gettopicProduce html documentation for a property.multicolumn<dl>
%s</dl>
get_html_pagepath_hereStatic methods %s:

 
^ *
Helper.introlinkednamedocroutinegreymember descriptor %s.%s.%s©#ÚselfÚobjectÚnameÚmodÚignoredÚallÚpartsÚlinksÚiÚ
linkednameÚheadÚpathÚurlÚfilelinkÚinfoÚversionÚdoclocÚresultÚmodulesÚclassesÚcdictÚkeyÚvalueÚbaseÚmodnameÚmoduleÚfuncsÚfdictÚdataÚdocÚmodpkgsÚimporterÚispkgÚcontentsÚ	classlistHTMLDoc.docmodule.<locals>.<lambda>DocServer<a name="%s">class <strong>%s</strong></a>apropos.<locals>.onerror
<td width="100%%">%s</td></tr></table>_symbols_inverseTextDoc.docclass.<locals>.spilldatabk:p:w_start_server.<locals>.DocServer.serve_until_quitServer ready atCheck if an object is of a type that probably means it's data.r"""HTMLDoc.docdataPage through text by feeding it to another program.Get the doc string or comments for an object.getpager.<locals>.<lambda>classlinkthisclass<strong>%s</strong> = more "%s"reallinkThe pydoc url handler for use with the pydoc server.

    If the content_type is 'text/css', the _pydoc.css style
    sheet is read and returned if it exits.

    If the content_type is 'text/html', then the result of
    get_html_page(url) is returned.
    TextDoc.section((\\[\\abfnrtv\'"]|\\[0-9]..|\\x..|\\u....)+)HTMLDoc.preformat<a name="%s"><strong>%s</strong></a>ErrorDuringImport.__init__©ÚselfÚobjectÚnameÚmodÚfuncsÚclassesÚignoredÚrealnameÚbasesÚcontentsÚpushÚHorizontalRuleÚhrÚmroÚbaseÚspillÚspilldescriptorsÚ	spilldataÚattrsÚmdictÚkeyÚkindÚhomeclsÚvalueÚanchorÚ	thisclassÚ	inheritedÚtagÚtitleÚparentsÚdoc#aa55ccFormat an argument default value as text.Topic or keyword help page.<font face="helvetica, arial">%s</font>TextDoc.formattree.<locals>.<genexpr>The first time this is called, determine what kind of pager to use.<big><big><strong>Index of Modules</strong></big></big>Helper.__init__Produce text documentation for a function or method object.Doc.getdocloc_url_handler.<locals>._HTMLDoc.pageGiven an object or a path to an object, get the object and its name.<tt>%s<br>&nbsp;</tt>
<tr bgcolor="%s"><td rowspan=2>%s</td>
<td colspan=2>%s</td></tr>
<tr><td>%s</td>ûzSTRINGS)ú'z'''zr'zb'z"""ú"zr"zb"z	OPERATORS)ú+ú-Ú*z**ú/z//ú%z<<z>>ú&ú|ú^ú~ú<ú>z<=z>=z==z!=z<>z
COMPARISON)r   r   z<=z>=z==z!=z<>zUNARY)r   r   zAUGMENTEDASSIGNMENT)z+=z-=z*=z/=z%=z&=z|=z^=z<<=z>>=z**=z//=zBITWISE)z<<z>>r   r	   r
   r   zCOMPLEX)ÚjúJ0ûzTYPES)ztypeszRSTRINGS UNICODE NUMBERS SEQUENCES MAPPINGS FUNCTIONS CLASSES MODULES FILES inspectzSTRINGS)zstringsz4str UNICODE SEQUENCES STRINGMETHODS FORMATTING TYPESzSTRINGMETHODS)zstring-methodszSTRINGS FORMATTINGz
FORMATTING)zformatstringsz	OPERATORSzUNICODE)zstringsz:encodings unicode SEQUENCES STRINGMETHODS FORMATTING TYPESzNUMBERS)znumberszINTEGER FLOAT COMPLEX TYPESzINTEGER)zintegersz	int rangezFLOAT)zfloatingz
float mathzCOMPLEX)z	imaginaryzcomplex cmathz	SEQUENCES)ztypesseqz$STRINGMETHODS FORMATTING range LISTSzMAPPINGSzDICTIONARIESz	FUNCTIONS)ztypesfunctionsz	def TYPESzMETHODS)ztypesmethodszclass def CLASSES TYPESzCODEOBJECTS)zbltin-code-objectszcompile FUNCTIONS TYPESzTYPEOBJECTS)zbltin-type-objectsztypes TYPESzFRAMEOBJECTSzTYPESz
TRACEBACKSzTYPESzNONE)zbltin-null-objectÚ zELLIPSIS)zbltin-ellipsis-objectzSLICINGSzSPECIALATTRIBUTES)zspecialattrsr   zCLASSES)ztypesz!class SPECIALMETHODS PRIVATENAMESzMODULES)ztypesmoduleszimportzPACKAGESzimportzEXPRESSIONS)zoperator-summaryzlambda or and not in is BOOLEAN COMPARISON BITWISE SHIFTING BINARY FORMATTING POWER UNARY ATTRIBUTES SUBSCRIPTS SLICINGS CALLS TUPLES LISTS DICTIONARIESz	OPERATORSzEXPRESSIONSz
PRECEDENCEzEXPRESSIONSzOBJECTS)zobjectszTYPESzSPECIALMETHODS)zspecialnameszbBASICMETHODS ATTRIBUTEMETHODS CALLABLEMETHODS SEQUENCEMETHODS MAPPINGMETHODS NUMBERMETHODS CLASSESzBASICMETHODS)zcustomizationzhash repr str SPECIALMETHODSzATTRIBUTEMETHODS)zattribute-accesszATTRIBUTES SPECIALMETHODSzCALLABLEMETHODS)zcallable-typeszCALLS SPECIALMETHODSzSEQUENCEMETHODS)zsequence-typesz(SEQUENCES SEQUENCEMETHODS SPECIALMETHODSzMAPPINGMETHODS)zsequence-typeszMAPPINGS SPECIALMETHODSzNUMBERMETHODS)znumeric-typesz*NUMBERS AUGMENTEDASSIGNMENT SPECIALMETHODSz	EXECUTION)z	execmodelz%NAMESPACES DYNAMICFEATURES EXCEPTIONSz
NAMESPACES)znamingz3global nonlocal ASSIGNMENT DELETION DYNAMICFEATURESzDYNAMICFEATURES)zdynamic-featuresr   zSCOPINGz
NAMESPACESzFRAMESz
NAMESPACESz
EXCEPTIONS)z
exceptionsztry except finally raisezCONVERSIONS)zconversionsr   zIDENTIFIERS)zidentifierszkeywords SPECIALIDENTIFIERSzSPECIALIDENTIFIERS)z
id-classesr   zPRIVATENAMES)zatom-identifiersr   zLITERALS)zatom-literalsz=STRINGS NUMBERS TUPLELITERALS LISTLITERALS DICTIONARYLITERALSzTUPLESz	SEQUENCESzTUPLELITERALS)z	exprlistszTUPLES LITERALSzLISTS)ztypesseq-mutablezLISTLITERALSzLISTLITERALS)zlistszLISTS LITERALSzDICTIONARIES)ztypesmappingzDICTIONARYLITERALSzDICTIONARYLITERALS)zdictzDICTIONARIES LITERALSz
ATTRIBUTES)zattribute-referencesz(getattr hasattr setattr ATTRIBUTEMETHODSz
SUBSCRIPTS)zsubscriptionszSEQUENCEMETHODSzSLICINGS)zslicingszSEQUENCEMETHODSzCALLS)zcallszEXPRESSIONSzPOWER)zpowerzEXPRESSIONSzUNARY)zunaryzEXPRESSIONSzBINARY)zbinaryzEXPRESSIONSzSHIFTING)zshiftingzEXPRESSIONSzBITWISE)zbitwisezEXPRESSIONSz
COMPARISON)zcomparisonszEXPRESSIONS BASICMETHODSzBOOLEAN)zbooleanszEXPRESSIONS TRUTHVALUEz	ASSERTIONzassertz
ASSIGNMENT)z
assignmentzAUGMENTEDASSIGNMENTzAUGMENTEDASSIGNMENT)z	augassignzNUMBERMETHODSzDELETIONzdelz	RETURNINGzreturnz	IMPORTINGzimportzCONDITIONALzifzLOOPING)zcompoundzfor while break continuez
TRUTHVALUE)ztruthz if while and or not BASICMETHODSz	DEBUGGING)zdebuggerzpdbzCONTEXTMANAGERS)zcontext-managerszwith0Generate an HTML page for url.getchar_start_server.<locals>.ServerThread.readyWrap inspect.classify_class_attrs, with fixup for data descriptors._start_server.<locals>.DocServer.server_activate<big><big><strong>Error</strong></big></big>Process a request from an HTML browser.

            The URL received is in self.path.
            Get an HTML page from self.urlhandler and send it.
            getfile?keyProduce HTML documentation for a function or method object.Index of topic texts available.Remove the hexadecimal id from a Python object representation.HTMLDoc.headingTextDoc.formatvaluecould not find objectStart the enhanced pydoc Web server and open a Web browser.

    Use port '0' to start the server on an arbitrary port.
    Set open_browser to False to suppress opening a browser.
    Produce HTML documentation for a module object.HTMLDoc.filelink
            <div style='float:left'>
                Python %s<br>%s
            </div>
            <div style='float:right'>
                <div style='text-align:center'>
                  <a href="index.html">Module Index</a>
                  : <a href="topics.html">Topics</a>
                  : <a href="keywords.html">Keywords</a>
                </div>
                <div>
                    <form action="get" style='display:inline;'>
                      <input type=text name=key size=15>
                      <input type=submit value="Get">
                    </form>&nbsp;
                    <form action="search" style='display:inline;'>
                      <input type=text name=key size=15>
                      <input type=submit value="Search">
                    </form>
                </div>
            </div>
            HTMLDoc.docotherlistkeywords<a href="topic?key=%s">%s</a><a name="%s"><strong>%s</strong></a> = %sProduce HTML documentation for a class object.Convert sys.path into a list of absolute, existing, unique paths.%s.%s.htmlStop the server and this thread nicelyMake a link for an identifier, given name-to-URL mappings.sort_attributes.<locals>.<lambda><a href=".">index</a><br><dl><dt>%s%s</dl>
<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN">
<html><head><title>Pydoc: %s</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
%s</head><body bgcolor="#f0f0f8">%s<div style="clear:both;padding-top:.5em;">%s</div>
</body></html>Page through text on a text terminal._url_handler.<locals>.html_getobj<table width="100%%" summary="list"><tr>%s</tr></table>HTMLDoc.bigsectionHTMLDoc.docclass.<locals>.<lambda>https://docs.python.org/%d.%d/libraryhelp> bad pydoc urlFormat a page heading.TextDoc.docroutinecramimclassHTMLRepr.repr_instancelistsymbolsmakenamerepr_unicodeFormatter class for text documentation.Generate documentation for an object.<p align=right><font color="#909090" face="helvetica,arial"><strong>pydoc</strong> by Ka-Ping Yee&lt;ping@lfw.org&gt;</font>Class methods %s:
<dd><tt>%s</tt></dd>
Doc.failFormatter class for HTML documentation.Split a doc string into a synopsis line (if any) and the rest.pipepagerModuleScannerapropos.<locals>.callbackIndent text by prepending a given prefix to each line.showtopic<dl><dt>Method resolution order:</dt>
is_bytecodemore_xrefstest.pydoc_modHTMLDoc.docpropertygetset descriptor %s.%s.%sserver> HTMLRepr.escapelisttopicshttp://www.python.org/dev/peps/pep-%04d/Make a link for a class.Class for safely making an HTML representation of a Python object..html#Generate Python documentation in HTML or text for interactive use.

At the Python interactive prompt, calling help(thing) on a Python object
documents the object, and calling help() starts up an interactive
help session.

Or, at the shell command line outside of Python:

Run "pydoc <name>" to show documentation on something.  <name> may be
the name of a function, module, package, or a dotted reference to a
class or function within a module or module in a package.  If the
argument contains a path segment delimiter (e.g. slash on Unix,
backslash on Windows) it is treated as the path to a Python source file.

Run "pydoc -k <keyword>" to search for a keyword in the synopsis lines
of all available modules.

Run "pydoc -p <port>" to start an HTTP server on the given port on the
local machine.  Port number 0 can be used to get an arbitrary unused port.

Run "pydoc -b" to start an HTTP server on an arbitrary unused port and
open a Web browser to interactively browse documentation.  The -p option
can be used with the -b option to explicitly specify the server port.

Run "pydoc -w <name>" to write out the HTML documentation for a module
to a file named "<name>.html".

Module docs for core modules are assumed to be in

    https://docs.python.org/X.Y/library/

This can be overridden by setting the PYTHONDOCS environment variable
to a different URL or to a local directory containing the Library
Reference Manual pages.
docsvrStart an HTTP server thread on a specific port.

    Start an HTML/text server thread, so HTML or text documents can be
    browsed dynamically and interactively with a Web browser.  Example use:

        >>> import time
        >>> import pydoc

        Define a URL handler.  To determine what the client is asking
        for, check the URL and content_type.

        Then get or generate some text or HTML code and return it.

        >>> def my_url_handler(url, content_type):
        ...     text = 'the URL sent was: (%s, %s)' % (url, content_type)
        ...     return text

        Start server thread on port 0.
        If you use port 0, the server will pick a random port number.
        You can then use serverthread.port to get the port number.

        >>> port = 0
        >>> serverthread = pydoc._start_server(my_url_handler, port)

        Check that the server is really started.  If it is, open browser
        and get first page.  Use serverthread.url as the starting page.

        >>> if serverthread.serving:
        ...    import webbrowser

        The next two lines are commented out so a browser doesn't open if
        doctest is run on this module.

        #...    webbrowser.open(serverthread.url)
        #True

        Let the server do its thing. We just need to monitor its status.
        Use time.sleep so the loop doesn't hog the CPU.

        >>> starttime = time.time()
        >>> timeout = 1                    #seconds

        This is a short timeout for testing purposes.

        >>> while serverthread.serving:
        ...     time.sleep(.01)
        ...     if serverthread.serving and time.time() - starttime > timeout:
        ...          serverthread.stop()
        ...          break

        Print any errors that may have occurred.

        >>> print(serverthread.error)
        None
   Helper.__repr__isdataTextRepr.repr1_PlainTextDoc.bold_split_list_start_server.<locals>.ServerThread.runPage through text by invoking a program on a temporary file.©ÚselfÚobjectÚnameÚmodÚignoredÚrealnameÚbasesÚmakenameÚtitleÚparentsÚdocÚcontentsÚpushÚmroÚbaseÚHorizontalRuleÚhrÚspillÚspilldescriptorsÚ	spilldataÚattrsÚ	thisclassÚ	inheritedÚtag<a href="getfile?key=%s">%s</a>search_resultData descriptors %sDo a series of global replacements on a string.Mark up some plain text, given a context of symbols to look for.
        Each context dictionary maps object names to anchor names.#bb0000<strong>%s</strong> = <a name="%s">class %s</a>Print all the one-line module summaries that contain a substring.-- more --HTMLDoc.formattree<td width="%d%%" valign=top>Sort the attrs list in-place by _fields and then alphabetically by name<a href="#%s">%s</a>ispathTextRepr.__init__wrapped_text<strong>%s</strong> <em>lambda</em> HTMLDoc.multicolumn<link rel="stylesheet" type="text/css" href="pydoc_data/_pydoc.css">_url_handler.<locals>.html_topicpage.<locals>.bltinlinkFormat a list of items into a multi-column list._escape_stdoutProduce HTML for a class tree as given by inspect.getclasstree().%s [%s, %s]Produce text documentation for a property.emacsFormat literal preformatted text. method of %s instance(less) 2>/dev/nullwritedoc<pre>%s</pre>
Enter any module name to get more help.  Or, type "modules spam" to search
for modules whose name or summary contain the string "spam".
Helper.interactReturn unbuffered tuple of (topic, xrefs).

        If an error occurs here, the exception is caught and displayed by
        the url handler.

        This function duplicates the showtopic method but returns its
        result directly so it can be formatted for display in an html page.
        
Here is a list of available topics.  Enter any topic name to get more help.

Data and other attributes %s:
http://%s:%d/_url_handler.<locals>.get_html_page
Please wait a moment while I gather a list of all available modules...

HTMLRepr.repr1HTMLDoc.markupHTMLDoc.sectionGet a class name and qualify it with a module name if necessary.<p>
<table width="100%%" cellspacing=0 cellpadding=2 border=0 summary="section">
<tr bgcolor="%s">
<td colspan=3 valign=bottom>&nbsp;<br>
<font color="%s" face="helvetica, arial">%s</font></td></tr>
    <big><big><strong>INDEX</strong></big></big><br><a href="%(docloc)s">Module Reference</a>An interruptible scanner that searches module synopses.Produce text documentation for a given class object.<p>%s</p>
Simply print unformatted text.  This is the ultimate fallback.Error - %s#ffc8d8TextRepr.repr_instanceGuido van Rossum, for an excellent programming language.
Tommy Burnette, the original creator of manpy.
Paul Prescod, for all his work on onlinehelp.
Richard Chamberlain, for the first implementation of textdoc.
Helper.helpTextDoc.docdata_start_server.<locals>.DocServer.__init__Helper.__call__©ÚselfÚobjectÚnameÚmodÚsynopÚdescÚresultÚallÚdoclocÚclassesÚkeyÚvalueÚfuncsÚdataÚmodpkgsÚmodpkgs_namesÚimporterÚmodnameÚispkgÚ
submodulesÚ	classlistÚcontentsÚversionÚfileImport a module; handle errors; return None if the module isn't found.

    If the module *is* found but an exception occurs, it's wrapped in an
    ErrorDuringImport exception and reraised.  Unlike __import__, if a
    package path is specified, the module at the end of the path is returned,
    not the package at the beginning.  If the optional 'forceload' argument
    is 1, we reload the module from disk (unless it's a dynamic extension).Related help topics: Format an HTML page.Helper.getline#ee77aaProduce a short description of the given thing.ûú%zOPERATORS FORMATTINGz**zPOWERú,zTUPLES LISTS FUNCTIONSÚ.z ATTRIBUTES FLOAT MODULES OBJECTSz...zELLIPSISú:zSLICINGS DICTIONARYLITERALSú@z	def classú\zSTRINGSÚ_zPRIVATENAMESz__zPRIVATENAMES SPECIALMETHODSú`z
BACKQUOTESú(zTUPLES FUNCTIONS CALLSú)zTUPLES FUNCTIONS CALLSú[zLISTS SUBSCRIPTS SLICINGSú]zLISTS SUBSCRIPTS SLICINGS0render_docRaise an exception for unimplemented types.http://www.rfc-editor.org/rfc/rfc%d.txtdon't know how to document object%s of type %s<dl><dt>%s</dt></dl>
get?key<module pydoc>Format a section with a heading.Class for safely making a text representation of a Python object.<a href="%s.html">%s</a><dt><font face="helvetica, arial">Get and display a source file listing safely._url_handler.<locals>.html_topics.<locals>.bltinlinkHelper.listkeywordsLocate an object by name or dotted path, importing as necessary.Return the location of module docs or None<dd>
%s</dd>
Python Library Documentation: %s<dl><dt>%s</dt>%s</dl>
<big><big><strong>Search Results</strong></big></big>_is_some_method
<table width="100%%" cellspacing=0 cellpadding=2 border=0 summary="heading">
<tr bgcolor="%s">
<td valign=bottom>&nbsp;<br>
<font color="%s" face="helvetica, arial">&nbsp;<br>%s</font></td
><td align=right valign=bottom
><font color="%s" face="helvetica, arial">%s</font></td></tr></table>
    
<tr><td bgcolor="%s">%s</td><td>%s</td>Produce HTML documentation for a data object._url_handler.<locals>.html_getfile_start_server.<locals>.DocHandler.do_GET<%s.%s instance><%s instance>docserverFile: %sHelper.listtopicsMethods %s:
<font color="#909090">%s</font>Built-in ModulesTextDoc.docproperty%s; charset=UTF-8 unbound %s methodStart the server.No Python documentation found for %r.
Use help() to get the interactive help utility.
Use help(str) for help on the str class.Remove boldface formatting from text.CREDITSSUBMODULESGenerate an HTML index for a directory of modules._start_server.<locals>.ServerThread.stopDecide what method to use for paging through text.Helper.showtopicunknown content type %r for url %skey = %sTextDoc._docdescriptorMake a link for a module or package to display in an index.allmethodsModuleScanner.runMake a link for a module.<dl><dt>%s</dl>
writedocs_url_handler.<locals>.html_search.<locals>.callbackTextDoc.docmodule<a href="%s.html#%s">%s</a>nextmoduleserver_help_msgkeyfuncproblem in %s - %s: %s<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN">
<html><head><title>Python: %s</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
</head><body bgcolor="#f0f0f8">
%s
</body></html>marginalia<font color="#c040c0">\1</font>selfdot_repr_instancefile %r does not exist<big><big><strong>File Listing</strong></big></big>Package Contents<dl><dt><strong>%s</strong></dt>
could not find topic
You are now leaving help and returning to the Python interpreter.
If you want to ask for help on a particular object directly from the
interpreter, you can type "help(object)".  Executing "help('string')"
has the same effect as typing a particular string at the help> prompt.
_url_handler.<locals>.html_search.<locals>.onerrornamelink<dd>%s</dd>
TextDoc.docotherHTMLDoc.classlinkgetfile %sHTMLDoc.docclass.<locals>.HorizontalRule.__init__Helper.listsymbolsûzFalseÚ zNoner   zTruer   zandzBOOLEANzaszwithzassert)zassertr   zbreak)zbreakz	while forzclass)zclasszCLASSES SPECIALMETHODSzcontinue)zcontinuez	while forzdef)zfunctionr   zdel)zdelzBASICMETHODSzelifzifzelse)zelsez	while forzexceptztryzfinallyztryzfor)zforzbreak continue whilezfromzimportzglobal)zglobalznonlocal NAMESPACESzif)zifz
TRUTHVALUEzimport)zimportzMODULESzin)zinzSEQUENCEMETHODSzisz
COMPARISONzlambda)zlambdaz	FUNCTIONSznonlocal)znonlocalzglobal NAMESPACESznotzBOOLEANzorzBOOLEANzpass)zpassr   zraise)zraisez
EXCEPTIONSzreturn)zreturnz	FUNCTIONSztry)ztryz
EXCEPTIONSzwhile)zwhilezbreak continue if TRUTHVALUEzwith)zwithz CONTEXTMANAGERS EXCEPTIONS yieldzyield)zyieldr   0pydoc - the Python documentation tool

{cmd} <name> ...
    Show text documentation on something.  <name> may be the name of a
    Python keyword, topic, function, module, or package, or a dotted
    reference to a class or function within a module or module in a
    package.  If <name> contains a '{sep}', it is used as the path to a
    Python source file to document. If name is 'keywords', 'topics',
    or 'modules', a listing of these things is displayed.

{cmd} -k <keyword>
    Search for a keyword in the synopsis lines of all available modules.

{cmd} -p <port>
    Start an HTTP server on the given port on the local machine.  Port
    number 0 can be used to get an arbitrary unused port.

{cmd} -b
    Start an HTTP server on an arbitrary unused port and open a Web browser
    to interactively browse documentation.  The -p option can be used with
    the -b option to explicitly specify the server port.

{cmd} -w <name> ...
    Write out the HTML documentation for a module to a file in the current
    directory.  If <name> contains a '{sep}', it is treated as a filename; if
    it names a directory, documentation is written for all the contents.
Make a link to source file.PACKAGE CONTENTSpathdirs

The following documentation is automatically generated from the Python
source files.  It may be incomplete, incorrect or include features that
are considered implementation detail and may vary between Python
implementations.  When in doubt, consult the module reference at the
location listed above.
 (package)HTMLDoc.modpkglink26 February 2001Search results page.HTMLDoc.docroutine<a href="file:%s">%s</a>Format a section with a big heading.htmlhelpDecide whether to show documentation on a variable.normdirssplitdocHTMLRepr.__init__TextDoc.docclass.<locals>.makenameHTMLDoc.formatvalue_GoInteractive_url_handler.<locals>._HTMLDoc.filelinkHTMLDoc.docclass.<locals>.spilldata_url_handler.<locals>.html_search.<locals>.bltinlinktempfilepagerHTMLDoc.index.<locals>.<genexpr>Helper.listmodules.<locals>.onerrorDoc.document
Here is a list of the Python keywords.  Enter any keyword to get more help.

_url_handler.<locals>.html_keywords.<locals>.bltinlink
Welcome to Python {0}'s help utility!

If this is your first time using Python, you should definitely check out
the tutorial on the Internet at https://docs.python.org/{0}/tutorial/.

Enter the name of any module, keyword, or topic to get help on writing
Python programs and using Python modules.  To quit this help utility and
return to the interpreter, just type "quit".

To get a list of available modules, keywords, symbols, or topics, type
"modules", "keywords", "symbols", or "topics".  Each module also comes
with a one-line summary of what it does; to list the modules whose name
or summary contain a given string such as "spam", type "modules spam".
Subclass of TextDoc which overrides string stylingHTMLDoc.namelinkvisiblenameDisplay text documentation, given an object or a path to an object.self.<strong>%s</strong>HTMLDoc._docdescriptorModule Index page.Format a string in bold by overstriking.Data descriptors %s:
TextDoc.docclass.<locals>.HorizontalRule.__init___is_bound_methodimportfileTextRepr.repr_stringProduce html documentation for a data descriptor.Command-line interface (looks at sys.argv to decide what to do).Produce text documentation for a data descriptor.defined heresafeimport#55aa55
</font></dt>source_synopsisTextDoc.bold.<locals>.<genexpr>Helper.<lambda>TextDoc.docclass.<locals>.spilldescriptorsHTMLDoc.grey_start_server.<locals>.ServerThread.__init__plainpager at 0x[0-9a-f]{6,16}(>+)$
    Returns True if fn is a bound method, regardless of whether
    fn was implemented in Python or in C.
    C:\msys64\mingw64\lib\python3.6\pydoc_data\__init__.pyC:\msys64\mingw64\lib\python3.6\pydoc_data\topics.pyûzassertas  The "assert" statement
**********************

Assert statements are a convenient way to insert debugging assertions
into a program:

   assert_stmt ::= "assert" expression ["," expression]

The simple form, "assert expression", is equivalent to

   if __debug__:
       if not expression: raise AssertionError

The extended form, "assert expression1, expression2", is equivalent to

   if __debug__:
       if not expression1: raise AssertionError(expression2)

These equivalences assume that "__debug__" and "AssertionError" refer
to the built-in variables with those names.  In the current
implementation, the built-in variable "__debug__" is "True" under
normal circumstances, "False" when optimization is requested (command
line option -O).  The current code generator emits no code for an
assert statement when optimization is requested at compile time.  Note
that it is unnecessary to include the source code for the expression
that failed in the error message; it will be displayed as part of the
stack trace.

Assignments to "__debug__" are illegal.  The value for the built-in
variable is determined when the interpreter starts.
z
assignmenta*  Assignment statements
*********************

Assignment statements are used to (re)bind names to values and to
modify attributes or items of mutable objects:

   assignment_stmt ::= (target_list "=")+ (starred_expression | yield_expression)
   target_list     ::= target ("," target)* [","]
   target          ::= identifier
              | "(" [target_list] ")"
              | "[" [target_list] "]"
              | attributeref
              | subscription
              | slicing
              | "*" target

(See section Primaries for the syntax definitions for *attributeref*,
*subscription*, and *slicing*.)

An assignment statement evaluates the expression list (remember that
this can be a single expression or a comma-separated list, the latter
yielding a tuple) and assigns the single resulting object to each of
the target lists, from left to right.

Assignment is defined recursively depending on the form of the target
(list). When a target is part of a mutable object (an attribute
reference, subscription or slicing), the mutable object must
ultimately perform the assignment and decide about its validity, and
may raise an exception if the assignment is unacceptable.  The rules
observed by various types and the exceptions raised are given with the
definition of the object types (see section The standard type
hierarchy).

Assignment of an object to a target list, optionally enclosed in
parentheses or square brackets, is recursively defined as follows.

* If the target list is empty: The object must also be an empty
  iterable.

* If the target list is a single target in parentheses: The object
  is assigned to that target.

* If the target list is a comma-separated list of targets, or a
  single target in square brackets: The object must be an iterable
  with the same number of items as there are targets in the target
  list, and the items are assigned, from left to right, to the
  corresponding targets.

  * If the target list contains one target prefixed with an
    asterisk, called a "starred" target: The object must be an
    iterable with at least as many items as there are targets in the
    target list, minus one.  The first items of the iterable are
    assigned, from left to right, to the targets before the starred
    target.  The final items of the iterable are assigned to the
    targets after the starred target.  A list of the remaining items
    in the iterable is then assigned to the starred target (the list
    can be empty).

  * Else: The object must be an iterable with the same number of
    items as there are targets in the target list, and the items are
    assigned, from left to right, to the corresponding targets.

Assignment of an object to a single target is recursively defined as
follows.

* If the target is an identifier (name):

  * If the name does not occur in a "global" or "nonlocal" statement
    in the current code block: the name is bound to the object in the
    current local namespace.

  * Otherwise: the name is bound to the object in the global
    namespace or the outer namespace determined by "nonlocal",
    respectively.

  The name is rebound if it was already bound.  This may cause the
  reference count for the object previously bound to the name to reach
  zero, causing the object to be deallocated and its destructor (if it
  has one) to be called.

* If the target is an attribute reference: The primary expression in
  the reference is evaluated.  It should yield an object with
  assignable attributes; if this is not the case, "TypeError" is
  raised.  That object is then asked to assign the assigned object to
  the given attribute; if it cannot perform the assignment, it raises
  an exception (usually but not necessarily "AttributeError").

  Note: If the object is a class instance and the attribute reference
  occurs on both sides of the assignment operator, the RHS expression,
  "a.x" can access either an instance attribute or (if no instance
  attribute exists) a class attribute.  The LHS target "a.x" is always
  set as an instance attribute, creating it if necessary.  Thus, the
  two occurrences of "a.x" do not necessarily refer to the same
  attribute: if the RHS expression refers to a class attribute, the
  LHS creates a new instance attribute as the target of the
  assignment:

     class Cls:
         x = 3             # class variable
     inst = Cls()
     inst.x = inst.x + 1   # writes inst.x as 4 leaving Cls.x as 3

  This description does not necessarily apply to descriptor
  attributes, such as properties created with "property()".

* If the target is a subscription: The primary expression in the
  reference is evaluated.  It should yield either a mutable sequence
  object (such as a list) or a mapping object (such as a dictionary).
  Next, the subscript expression is evaluated.

  If the primary is a mutable sequence object (such as a list), the
  subscript must yield an integer.  If it is negative, the sequence's
  length is added to it.  The resulting value must be a nonnegative
  integer less than the sequence's length, and the sequence is asked
  to assign the assigned object to its item with that index.  If the
  index is out of range, "IndexError" is raised (assignment to a
  subscripted sequence cannot add new items to a list).

  If the primary is a mapping object (such as a dictionary), the
  subscript must have a type compatible with the mapping's key type,
  and the mapping is then asked to create a key/datum pair which maps
  the subscript to the assigned object.  This can either replace an
  existing key/value pair with the same key value, or insert a new
  key/value pair (if no key with the same value existed).

  For user-defined objects, the "__setitem__()" method is called with
  appropriate arguments.

* If the target is a slicing: The primary expression in the
  reference is evaluated.  It should yield a mutable sequence object
  (such as a list).  The assigned object should be a sequence object
  of the same type.  Next, the lower and upper bound expressions are
  evaluated, insofar they are present; defaults are zero and the
  sequence's length.  The bounds should evaluate to integers. If
  either bound is negative, the sequence's length is added to it.  The
  resulting bounds are clipped to lie between zero and the sequence's
  length, inclusive.  Finally, the sequence object is asked to replace
  the slice with the items of the assigned sequence.  The length of
  the slice may be different from the length of the assigned sequence,
  thus changing the length of the target sequence, if the target
  sequence allows it.

**CPython implementation detail:** In the current implementation, the
syntax for targets is taken to be the same as for expressions, and
invalid syntax is rejected during the code generation phase, causing
less detailed error messages.

Although the definition of assignment implies that overlaps between
the left-hand side and the right-hand side are 'simultaneous' (for
example "a, b = b, a" swaps two variables), overlaps *within* the
collection of assigned-to variables occur left-to-right, sometimes
resulting in confusion.  For instance, the following program prints
"[0, 2]":

   x = [0, 1]
   i = 0
   i, x[i] = 1, 2         # i is updated, then x[i] is updated
   print(x)

See also:

  **PEP 3132** - Extended Iterable Unpacking
     The specification for the "*target" feature.


Augmented assignment statements
===============================

Augmented assignment is the combination, in a single statement, of a
binary operation and an assignment statement:

   augmented_assignment_stmt ::= augtarget augop (expression_list | yield_expression)
   augtarget                 ::= identifier | attributeref | subscription | slicing
   augop                     ::= "+=" | "-=" | "*=" | "@=" | "/=" | "//=" | "%=" | "**="
             | ">>=" | "<<=" | "&=" | "^=" | "|="

(See section Primaries for the syntax definitions of the last three
symbols.)

An augmented assignment evaluates the target (which, unlike normal
assignment statements, cannot be an unpacking) and the expression
list, performs the binary operation specific to the type of assignment
on the two operands, and assigns the result to the original target.
The target is only evaluated once.

An augmented assignment expression like "x += 1" can be rewritten as
"x = x + 1" to achieve a similar, but not exactly equal effect. In the
augmented version, "x" is only evaluated once. Also, when possible,
the actual operation is performed *in-place*, meaning that rather than
creating a new object and assigning that to the target, the old object
is modified instead.

Unlike normal assignments, augmented assignments evaluate the left-
hand side *before* evaluating the right-hand side.  For example, "a[i]
+= f(x)" first looks-up "a[i]", then it evaluates "f(x)" and performs
the addition, and lastly, it writes the result back to "a[i]".

With the exception of assigning to tuples and multiple targets in a
single statement, the assignment done by augmented assignment
statements is handled the same way as normal assignments. Similarly,
with the exception of the possible *in-place* behavior, the binary
operation performed by augmented assignment is the same as the normal
binary operations.

For targets which are attribute references, the same caveat about
class and instance attributes applies as for regular assignments.


Annotated assignment statements
===============================

Annotation assignment is the combination, in a single statement, of a
variable or attribute annotation and an optional assignment statement:

   annotated_assignment_stmt ::= augtarget ":" expression ["=" expression]

The difference from normal Assignment statements is that only single
target and only single right hand side value is allowed.

For simple names as assignment targets, if in class or module scope,
the annotations are evaluated and stored in a special class or module
attribute "__annotations__" that is a dictionary mapping from variable
names (mangled if private) to evaluated annotations. This attribute is
writable and is automatically created at the start of class or module
body execution, if annotations are found statically.

For expressions as assignment targets, the annotations are evaluated
if in class or module scope, but not stored.

If a name is annotated in a function scope, then this name is local
for that scope. Annotations are never evaluated and stored in function
scopes.

If the right hand side is present, an annotated assignment performs
the actual assignment before evaluating annotations (where
applicable). If the right hand side is not present for an expression
target, then the interpreter evaluates the target except for the last
"__setitem__()" or "__setattr__()" call.

See also: **PEP 526** - Variable and attribute annotation syntax
  **PEP 484** - Type hints
zatom-identifiersaÌ  Identifiers (Names)
*******************

An identifier occurring as an atom is a name.  See section Identifiers
and keywords for lexical definition and section Naming and binding for
documentation of naming and binding.

When the name is bound to an object, evaluation of the atom yields
that object. When a name is not bound, an attempt to evaluate it
raises a "NameError" exception.

**Private name mangling:** When an identifier that textually occurs in
a class definition begins with two or more underscore characters and
does not end in two or more underscores, it is considered a *private
name* of that class. Private names are transformed to a longer form
before code is generated for them.  The transformation inserts the
class name, with leading underscores removed and a single underscore
inserted, in front of the name.  For example, the identifier "__spam"
occurring in a class named "Ham" will be transformed to "_Ham__spam".
This transformation is independent of the syntactical context in which
the identifier is used.  If the transformed name is extremely long
(longer than 255 characters), implementation defined truncation may
happen. If the class name consists only of underscores, no
transformation is done.
zatom-literalsa  Literals
********

Python supports string and bytes literals and various numeric
literals:

   literal ::= stringliteral | bytesliteral
               | integer | floatnumber | imagnumber

Evaluation of a literal yields an object of the given type (string,
bytes, integer, floating point number, complex number) with the given
value.  The value may be approximated in the case of floating point
and imaginary (complex) literals.  See section Literals for details.

All literals correspond to immutable data types, and hence the
object's identity is less important than its value.  Multiple
evaluations of literals with the same value (either the same
occurrence in the program text or a different occurrence) may obtain
the same object or a different object with the same value.
zattribute-accessa-  Customizing attribute access
****************************

The following methods can be defined to customize the meaning of
attribute access (use of, assignment to, or deletion of "x.name") for
class instances.

object.__getattr__(self, name)

   Called when the default attribute access fails with an
   "AttributeError" (either "__getattribute__()" raises an
   "AttributeError" because *name* is not an instance attribute or an
   attribute in the class tree for "self"; or "__get__()" of a *name*
   property raises "AttributeError").  This method should either
   return the (computed) attribute value or raise an "AttributeError"
   exception.

   Note that if the attribute is found through the normal mechanism,
   "__getattr__()" is not called.  (This is an intentional asymmetry
   between "__getattr__()" and "__setattr__()".) This is done both for
   efficiency reasons and because otherwise "__getattr__()" would have
   no way to access other attributes of the instance.  Note that at
   least for instance variables, you can fake total control by not
   inserting any values in the instance attribute dictionary (but
   instead inserting them in another object).  See the
   "__getattribute__()" method below for a way to actually get total
   control over attribute access.

object.__getattribute__(self, name)

   Called unconditionally to implement attribute accesses for
   instances of the class. If the class also defines "__getattr__()",
   the latter will not be called unless "__getattribute__()" either
   calls it explicitly or raises an "AttributeError". This method
   should return the (computed) attribute value or raise an
   "AttributeError" exception. In order to avoid infinite recursion in
   this method, its implementation should always call the base class
   method with the same name to access any attributes it needs, for
   example, "object.__getattribute__(self, name)".

   Note: This method may still be bypassed when looking up special
     methods as the result of implicit invocation via language syntax
     or built-in functions. See Special method lookup.

object.__setattr__(self, name, value)

   Called when an attribute assignment is attempted.  This is called
   instead of the normal mechanism (i.e. store the value in the
   instance dictionary). *name* is the attribute name, *value* is the
   value to be assigned to it.

   If "__setattr__()" wants to assign to an instance attribute, it
   should call the base class method with the same name, for example,
   "object.__setattr__(self, name, value)".

object.__delattr__(self, name)

   Like "__setattr__()" but for attribute deletion instead of
   assignment.  This should only be implemented if "del obj.name" is
   meaningful for the object.

object.__dir__(self)

   Called when "dir()" is called on the object. A sequence must be
   returned. "dir()" converts the returned sequence to a list and
   sorts it.


Customizing module attribute access
===================================

For a more fine grained customization of the module behavior (setting
attributes, properties, etc.), one can set the "__class__" attribute
of a module object to a subclass of "types.ModuleType". For example:

   import sys
   from types import ModuleType

   class VerboseModule(ModuleType):
       def __repr__(self):
           return f'Verbose {self.__name__}'

       def __setattr__(self, attr, value):
           print(f'Setting {attr}...')
           setattr(self, attr, value)

   sys.modules[__name__].__class__ = VerboseModule

Note: Setting module "__class__" only affects lookups made using the
  attribute access syntax -- directly accessing the module globals
  (whether by code within the module, or via a reference to the
  module's globals dictionary) is unaffected.

Changed in version 3.5: "__class__" module attribute is now writable.


Implementing Descriptors
========================

The following methods only apply when an instance of the class
containing the method (a so-called *descriptor* class) appears in an
*owner* class (the descriptor must be in either the owner's class
dictionary or in the class dictionary for one of its parents).  In the
examples below, "the attribute" refers to the attribute whose name is
the key of the property in the owner class' "__dict__".

object.__get__(self, instance, owner)

   Called to get the attribute of the owner class (class attribute
   access) or of an instance of that class (instance attribute
   access). *owner* is always the owner class, while *instance* is the
   instance that the attribute was accessed through, or "None" when
   the attribute is accessed through the *owner*.  This method should
   return the (computed) attribute value or raise an "AttributeError"
   exception.

object.__set__(self, instance, value)

   Called to set the attribute on an instance *instance* of the owner
   class to a new value, *value*.

object.__delete__(self, instance)

   Called to delete the attribute on an instance *instance* of the
   owner class.

object.__set_name__(self, owner, name)

   Called at the time the owning class *owner* is created. The
   descriptor has been assigned to *name*.

   New in version 3.6.

The attribute "__objclass__" is interpreted by the "inspect" module as
specifying the class where this object was defined (setting this
appropriately can assist in runtime introspection of dynamic class
attributes). For callables, it may indicate that an instance of the
given type (or a subclass) is expected or required as the first
positional argument (for example, CPython sets this attribute for
unbound methods that are implemented in C).


Invoking Descriptors
====================

In general, a descriptor is an object attribute with "binding
behavior", one whose attribute access has been overridden by methods
in the descriptor protocol:  "__get__()", "__set__()", and
"__delete__()". If any of those methods are defined for an object, it
is said to be a descriptor.

The default behavior for attribute access is to get, set, or delete
the attribute from an object's dictionary. For instance, "a.x" has a
lookup chain starting with "a.__dict__['x']", then
"type(a).__dict__['x']", and continuing through the base classes of
"type(a)" excluding metaclasses.

However, if the looked-up value is an object defining one of the
descriptor methods, then Python may override the default behavior and
invoke the descriptor method instead.  Where this occurs in the
precedence chain depends on which descriptor methods were defined and
how they were called.

The starting point for descriptor invocation is a binding, "a.x". How
the arguments are assembled depends on "a":

Direct Call
   The simplest and least common call is when user code directly
   invokes a descriptor method:    "x.__get__(a)".

Instance Binding
   If binding to an object instance, "a.x" is transformed into the
   call: "type(a).__dict__['x'].__get__(a, type(a))".

Class Binding
   If binding to a class, "A.x" is transformed into the call:
   "A.__dict__['x'].__get__(None, A)".

Super Binding
   If "a" is an instance of "super", then the binding "super(B,
   obj).m()" searches "obj.__class__.__mro__" for the base class "A"
   immediately preceding "B" and then invokes the descriptor with the
   call: "A.__dict__['m'].__get__(obj, obj.__class__)".

For instance bindings, the precedence of descriptor invocation depends
on the which descriptor methods are defined.  A descriptor can define
any combination of "__get__()", "__set__()" and "__delete__()".  If it
does not define "__get__()", then accessing the attribute will return
the descriptor object itself unless there is a value in the object's
instance dictionary.  If the descriptor defines "__set__()" and/or
"__delete__()", it is a data descriptor; if it defines neither, it is
a non-data descriptor.  Normally, data descriptors define both
"__get__()" and "__set__()", while non-data descriptors have just the
"__get__()" method.  Data descriptors with "__set__()" and "__get__()"
defined always override a redefinition in an instance dictionary.  In
contrast, non-data descriptors can be overridden by instances.

Python methods (including "staticmethod()" and "classmethod()") are
implemented as non-data descriptors.  Accordingly, instances can
redefine and override methods.  This allows individual instances to
acquire behaviors that differ from other instances of the same class.

The "property()" function is implemented as a data descriptor.
Accordingly, instances cannot override the behavior of a property.


__slots__
=========

*__slots__* allow us to explicitly declare data members (like
properties) and deny the creation of *__dict__* and *__weakref__*
(unless explicitly declared in *__slots__* or available in a parent.)

The space saved over using *__dict__* can be significant.

object.__slots__

   This class variable can be assigned a string, iterable, or sequence
   of strings with variable names used by instances.  *__slots__*
   reserves space for the declared variables and prevents the
   automatic creation of *__dict__* and *__weakref__* for each
   instance.


Notes on using *__slots__*
--------------------------

* When inheriting from a class without *__slots__*, the *__dict__*
  and *__weakref__* attribute of the instances will always be
  accessible.

* Without a *__dict__* variable, instances cannot be assigned new
  variables not listed in the *__slots__* definition.  Attempts to
  assign to an unlisted variable name raises "AttributeError". If
  dynamic assignment of new variables is desired, then add
  "'__dict__'" to the sequence of strings in the *__slots__*
  declaration.

* Without a *__weakref__* variable for each instance, classes
  defining *__slots__* do not support weak references to its
  instances. If weak reference support is needed, then add
  "'__weakref__'" to the sequence of strings in the *__slots__*
  declaration.

* *__slots__* are implemented at the class level by creating
  descriptors (Implementing Descriptors) for each variable name.  As a
  result, class attributes cannot be used to set default values for
  instance variables defined by *__slots__*; otherwise, the class
  attribute would overwrite the descriptor assignment.

* The action of a *__slots__* declaration is not limited to the
  class where it is defined.  *__slots__* declared in parents are
  available in child classes. However, child subclasses will get a
  *__dict__* and *__weakref__* unless they also define *__slots__*
  (which should only contain names of any *additional* slots).

* If a class defines a slot also defined in a base class, the
  instance variable defined by the base class slot is inaccessible
  (except by retrieving its descriptor directly from the base class).
  This renders the meaning of the program undefined.  In the future, a
  check may be added to prevent this.

* Nonempty *__slots__* does not work for classes derived from
  "variable-length" built-in types such as "int", "bytes" and "tuple".

* Any non-string iterable may be assigned to *__slots__*. Mappings
  may also be used; however, in the future, special meaning may be
  assigned to the values corresponding to each key.

* *__class__* assignment works only if both classes have the same
  *__slots__*.

* Multiple inheritance with multiple slotted parent classes can be
  used, but only one parent is allowed to have attributes created by
  slots (the other bases must have empty slot layouts) - violations
  raise "TypeError".
zattribute-referencesa  Attribute references
********************

An attribute reference is a primary followed by a period and a name:

   attributeref ::= primary "." identifier

The primary must evaluate to an object of a type that supports
attribute references, which most objects do.  This object is then
asked to produce the attribute whose name is the identifier.  This
production can be customized by overriding the "__getattr__()" method.
If this attribute is not available, the exception "AttributeError" is
raised.  Otherwise, the type and value of the object produced is
determined by the object.  Multiple evaluations of the same attribute
reference may yield different objects.
z	augassignaÛ  Augmented assignment statements
*******************************

Augmented assignment is the combination, in a single statement, of a
binary operation and an assignment statement:

   augmented_assignment_stmt ::= augtarget augop (expression_list | yield_expression)
   augtarget                 ::= identifier | attributeref | subscription | slicing
   augop                     ::= "+=" | "-=" | "*=" | "@=" | "/=" | "//=" | "%=" | "**="
             | ">>=" | "<<=" | "&=" | "^=" | "|="

(See section Primaries for the syntax definitions of the last three
symbols.)

An augmented assignment evaluates the target (which, unlike normal
assignment statements, cannot be an unpacking) and the expression
list, performs the binary operation specific to the type of assignment
on the two operands, and assigns the result to the original target.
The target is only evaluated once.

An augmented assignment expression like "x += 1" can be rewritten as
"x = x + 1" to achieve a similar, but not exactly equal effect. In the
augmented version, "x" is only evaluated once. Also, when possible,
the actual operation is performed *in-place*, meaning that rather than
creating a new object and assigning that to the target, the old object
is modified instead.

Unlike normal assignments, augmented assignments evaluate the left-
hand side *before* evaluating the right-hand side.  For example, "a[i]
+= f(x)" first looks-up "a[i]", then it evaluates "f(x)" and performs
the addition, and lastly, it writes the result back to "a[i]".

With the exception of assigning to tuples and multiple targets in a
single statement, the assignment done by augmented assignment
statements is handled the same way as normal assignments. Similarly,
with the exception of the possible *in-place* behavior, the binary
operation performed by augmented assignment is the same as the normal
binary operations.

For targets which are attribute references, the same caveat about
class and instance attributes applies as for regular assignments.
zbinaryae  Binary arithmetic operations
****************************

The binary arithmetic operations have the conventional priority
levels.  Note that some of these operations also apply to certain non-
numeric types.  Apart from the power operator, there are only two
levels, one for multiplicative operators and one for additive
operators:

   m_expr ::= u_expr | m_expr "*" u_expr | m_expr "@" m_expr |
              m_expr "//" u_expr| m_expr "/" u_expr |
              m_expr "%" u_expr
   a_expr ::= m_expr | a_expr "+" m_expr | a_expr "-" m_expr

The "*" (multiplication) operator yields the product of its arguments.
The arguments must either both be numbers, or one argument must be an
integer and the other must be a sequence. In the former case, the
numbers are converted to a common type and then multiplied together.
In the latter case, sequence repetition is performed; a negative
repetition factor yields an empty sequence.

The "@" (at) operator is intended to be used for matrix
multiplication.  No builtin Python types implement this operator.

New in version 3.5.

The "/" (division) and "//" (floor division) operators yield the
quotient of their arguments.  The numeric arguments are first
converted to a common type. Division of integers yields a float, while
floor division of integers results in an integer; the result is that
of mathematical division with the 'floor' function applied to the
result.  Division by zero raises the "ZeroDivisionError" exception.

The "%" (modulo) operator yields the remainder from the division of
the first argument by the second.  The numeric arguments are first
converted to a common type.  A zero right argument raises the
"ZeroDivisionError" exception.  The arguments may be floating point
numbers, e.g., "3.14%0.7" equals "0.34" (since "3.14" equals "4*0.7 +
0.34".)  The modulo operator always yields a result with the same sign
as its second operand (or zero); the absolute value of the result is
strictly smaller than the absolute value of the second operand [1].

The floor division and modulo operators are connected by the following
identity: "x == (x//y)*y + (x%y)".  Floor division and modulo are also
connected with the built-in function "divmod()": "divmod(x, y) ==
(x//y, x%y)". [2].

In addition to performing the modulo operation on numbers, the "%"
operator is also overloaded by string objects to perform old-style
string formatting (also known as interpolation).  The syntax for
string formatting is described in the Python Library Reference,
section printf-style String Formatting.

The floor division operator, the modulo operator, and the "divmod()"
function are not defined for complex numbers.  Instead, convert to a
floating point number using the "abs()" function if appropriate.

The "+" (addition) operator yields the sum of its arguments.  The
arguments must either both be numbers or both be sequences of the same
type.  In the former case, the numbers are converted to a common type
and then added together. In the latter case, the sequences are
concatenated.

The "-" (subtraction) operator yields the difference of its arguments.
The numeric arguments are first converted to a common type.
zbitwisea$  Binary bitwise operations
*************************

Each of the three bitwise operations has a different priority level:

   and_expr ::= shift_expr | and_expr "&" shift_expr
   xor_expr ::= and_expr | xor_expr "^" and_expr
   or_expr  ::= xor_expr | or_expr "|" xor_expr

The "&" operator yields the bitwise AND of its arguments, which must
be integers.

The "^" operator yields the bitwise XOR (exclusive OR) of its
arguments, which must be integers.

The "|" operator yields the bitwise (inclusive) OR of its arguments,
which must be integers.
zbltin-code-objectsar  Code Objects
************

Code objects are used by the implementation to represent "pseudo-
compiled" executable Python code such as a function body. They differ
from function objects because they don't contain a reference to their
global execution environment.  Code objects are returned by the built-
in "compile()" function and can be extracted from function objects
through their "__code__" attribute. See also the "code" module.

A code object can be executed or evaluated by passing it (instead of a
source string) to the "exec()" or "eval()"  built-in functions.

See The standard type hierarchy for more information.
zbltin-ellipsis-objecta.  The Ellipsis Object
*******************

This object is commonly used by slicing (see Slicings).  It supports
no special operations.  There is exactly one ellipsis object, named
"Ellipsis" (a built-in name).  "type(Ellipsis)()" produces the
"Ellipsis" singleton.

It is written as "Ellipsis" or "...".
zbltin-null-objecta  The Null Object
***************

This object is returned by functions that don't explicitly return a
value.  It supports no special operations.  There is exactly one null
object, named "None" (a built-in name).  "type(None)()" produces the
same singleton.

It is written as "None".
zbltin-type-objectsa3  Type Objects
************

Type objects represent the various object types.  An object's type is
accessed by the built-in function "type()".  There are no special
operations on types.  The standard module "types" defines names for
all standard built-in types.

Types are written like this: "<class 'int'>".
zbooleansaÂ  Boolean operations
******************

   or_test  ::= and_test | or_test "or" and_test
   and_test ::= not_test | and_test "and" not_test
   not_test ::= comparison | "not" not_test

In the context of Boolean operations, and also when expressions are
used by control flow statements, the following values are interpreted
as false: "False", "None", numeric zero of all types, and empty
strings and containers (including strings, tuples, lists,
dictionaries, sets and frozensets).  All other values are interpreted
as true.  User-defined objects can customize their truth value by
providing a "__bool__()" method.

The operator "not" yields "True" if its argument is false, "False"
otherwise.

The expression "x and y" first evaluates *x*; if *x* is false, its
value is returned; otherwise, *y* is evaluated and the resulting value
is returned.

The expression "x or y" first evaluates *x*; if *x* is true, its value
is returned; otherwise, *y* is evaluated and the resulting value is
returned.

(Note that neither "and" nor "or" restrict the value and type they
return to "False" and "True", but rather return the last evaluated
argument.  This is sometimes useful, e.g., if "s" is a string that
should be replaced by a default value if it is empty, the expression
"s or 'foo'" yields the desired value.  Because "not" has to create a
new value, it returns a boolean value regardless of the type of its
argument (for example, "not 'foo'" produces "False" rather than "''".)
zbreaka$  The "break" statement
*********************

   break_stmt ::= "break"

"break" may only occur syntactically nested in a "for" or "while"
loop, but not nested in a function or class definition within that
loop.

It terminates the nearest enclosing loop, skipping the optional "else"
clause if the loop has one.

If a "for" loop is terminated by "break", the loop control target
keeps its current value.

When "break" passes control out of a "try" statement with a "finally"
clause, that "finally" clause is executed before really leaving the
loop.
zcallable-typeszøEmulating callable objects
**************************

object.__call__(self[, args...])

   Called when the instance is "called" as a function; if this method
   is defined, "x(arg1, arg2, ...)" is a shorthand for
   "x.__call__(arg1, arg2, ...)".
zcallsa<  Calls
*****

A call calls a callable object (e.g., a *function*) with a possibly
empty series of *arguments*:

   call                 ::= primary "(" [argument_list [","] | comprehension] ")"
   argument_list        ::= positional_arguments ["," starred_and_keywords]
                       ["," keywords_arguments]
                     | starred_and_keywords ["," keywords_arguments]
                     | keywords_arguments
   positional_arguments ::= ["*"] expression ("," ["*"] expression)*
   starred_and_keywords ::= ("*" expression | keyword_item)
                            ("," "*" expression | "," keyword_item)*
   keywords_arguments   ::= (keyword_item | "**" expression)
                          ("," keyword_item | "," "**" expression)*
   keyword_item         ::= identifier "=" expression

An optional trailing comma may be present after the positional and
keyword arguments but does not affect the semantics.

The primary must evaluate to a callable object (user-defined
functions, built-in functions, methods of built-in objects, class
objects, methods of class instances, and all objects having a
"__call__()" method are callable).  All argument expressions are
evaluated before the call is attempted.  Please refer to section
Function definitions for the syntax of formal *parameter* lists.

If keyword arguments are present, they are first converted to
positional arguments, as follows.  First, a list of unfilled slots is
created for the formal parameters.  If there are N positional
arguments, they are placed in the first N slots.  Next, for each
keyword argument, the identifier is used to determine the
corresponding slot (if the identifier is the same as the first formal
parameter name, the first slot is used, and so on).  If the slot is
already filled, a "TypeError" exception is raised. Otherwise, the
value of the argument is placed in the slot, filling it (even if the
expression is "None", it fills the slot).  When all arguments have
been processed, the slots that are still unfilled are filled with the
corresponding default value from the function definition.  (Default
values are calculated, once, when the function is defined; thus, a
mutable object such as a list or dictionary used as default value will
be shared by all calls that don't specify an argument value for the
corresponding slot; this should usually be avoided.)  If there are any
unfilled slots for which no default value is specified, a "TypeError"
exception is raised.  Otherwise, the list of filled slots is used as
the argument list for the call.

**CPython implementation detail:** An implementation may provide
built-in functions whose positional parameters do not have names, even
if they are 'named' for the purpose of documentation, and which
therefore cannot be supplied by keyword.  In CPython, this is the case
for functions implemented in C that use "PyArg_ParseTuple()" to parse
their arguments.

If there are more positional arguments than there are formal parameter
slots, a "TypeError" exception is raised, unless a formal parameter
using the syntax "*identifier" is present; in this case, that formal
parameter receives a tuple containing the excess positional arguments
(or an empty tuple if there were no excess positional arguments).

If any keyword argument does not correspond to a formal parameter
name, a "TypeError" exception is raised, unless a formal parameter
using the syntax "**identifier" is present; in this case, that formal
parameter receives a dictionary containing the excess keyword
arguments (using the keywords as keys and the argument values as
corresponding values), or a (new) empty dictionary if there were no
excess keyword arguments.

If the syntax "*expression" appears in the function call, "expression"
must evaluate to an *iterable*.  Elements from these iterables are
treated as if they were additional positional arguments.  For the call
"f(x1, x2, *y, x3, x4)", if *y* evaluates to a sequence *y1*, ...,
*yM*, this is equivalent to a call with M+4 positional arguments *x1*,
*x2*, *y1*, ..., *yM*, *x3*, *x4*.

A consequence of this is that although the "*expression" syntax may
appear *after* explicit keyword arguments, it is processed *before*
the keyword arguments (and any "**expression" arguments -- see below).
So:

   >>> def f(a, b):
   ...     print(a, b)
   ...
   >>> f(b=1, *(2,))
   2 1
   >>> f(a=1, *(2,))
   Traceback (most recent call last):
     File "<stdin>", line 1, in <module>
   TypeError: f() got multiple values for keyword argument 'a'
   >>> f(1, *(2,))
   1 2

It is unusual for both keyword arguments and the "*expression" syntax
to be used in the same call, so in practice this confusion does not
arise.

If the syntax "**expression" appears in the function call,
"expression" must evaluate to a *mapping*, the contents of which are
treated as additional keyword arguments.  If a keyword is already
present (as an explicit keyword argument, or from another unpacking),
a "TypeError" exception is raised.

Formal parameters using the syntax "*identifier" or "**identifier"
cannot be used as positional argument slots or as keyword argument
names.

Changed in version 3.5: Function calls accept any number of "*" and
"**" unpackings, positional arguments may follow iterable unpackings
("*"), and keyword arguments may follow dictionary unpackings ("**").
Originally proposed by **PEP 448**.

A call always returns some value, possibly "None", unless it raises an
exception.  How this value is computed depends on the type of the
callable object.

If it is---

a user-defined function:
   The code block for the function is executed, passing it the
   argument list.  The first thing the code block will do is bind the
   formal parameters to the arguments; this is described in section
   Function definitions.  When the code block executes a "return"
   statement, this specifies the return value of the function call.

a built-in function or method:
   The result is up to the interpreter; see Built-in Functions for the
   descriptions of built-in functions and methods.

a class object:
   A new instance of that class is returned.

a class instance method:
   The corresponding user-defined function is called, with an argument
   list that is one longer than the argument list of the call: the
   instance becomes the first argument.

a class instance:
   The class must define a "__call__()" method; the effect is then the
   same as if that method was called.
zclassaÞ	  Class definitions
*****************

A class definition defines a class object (see section The standard
type hierarchy):

   classdef    ::= [decorators] "class" classname [inheritance] ":" suite
   inheritance ::= "(" [argument_list] ")"
   classname   ::= identifier

A class definition is an executable statement.  The inheritance list
usually gives a list of base classes (see Metaclasses for more
advanced uses), so each item in the list should evaluate to a class
object which allows subclassing.  Classes without an inheritance list
inherit, by default, from the base class "object"; hence,

   class Foo:
       pass

is equivalent to

   class Foo(object):
       pass

The class's suite is then executed in a new execution frame (see
Naming and binding), using a newly created local namespace and the
original global namespace. (Usually, the suite contains mostly
function definitions.)  When the class's suite finishes execution, its
execution frame is discarded but its local namespace is saved. [4] A
class object is then created using the inheritance list for the base
classes and the saved local namespace for the attribute dictionary.
The class name is bound to this class object in the original local
namespace.

The order in which attributes are defined in the class body is
preserved in the new class's "__dict__".  Note that this is reliable
only right after the class is created and only for classes that were
defined using the definition syntax.

Class creation can be customized heavily using metaclasses.

Classes can also be decorated: just like when decorating functions,

   @f1(arg)
   @f2
   class Foo: pass

is roughly equivalent to

   class Foo: pass
   Foo = f1(arg)(f2(Foo))

The evaluation rules for the decorator expressions are the same as for
function decorators.  The result is then bound to the class name.

**Programmer's note:** Variables defined in the class definition are
class attributes; they are shared by instances.  Instance attributes
can be set in a method with "self.name = value".  Both class and
instance attributes are accessible through the notation ""self.name"",
and an instance attribute hides a class attribute with the same name
when accessed in this way.  Class attributes can be used as defaults
for instance attributes, but using mutable values there can lead to
unexpected results.  Descriptors can be used to create instance
variables with different implementation details.

See also: **PEP 3115** - Metaclasses in Python 3 **PEP 3129** -
  Class Decorators
zcomparisonsa2)  Comparisons
***********

Unlike C, all comparison operations in Python have the same priority,
which is lower than that of any arithmetic, shifting or bitwise
operation.  Also unlike C, expressions like "a < b < c" have the
interpretation that is conventional in mathematics:

   comparison    ::= or_expr ( comp_operator or_expr )*
   comp_operator ::= "<" | ">" | "==" | ">=" | "<=" | "!="
                     | "is" ["not"] | ["not"] "in"

Comparisons yield boolean values: "True" or "False".

Comparisons can be chained arbitrarily, e.g., "x < y <= z" is
equivalent to "x < y and y <= z", except that "y" is evaluated only
once (but in both cases "z" is not evaluated at all when "x < y" is
found to be false).

Formally, if *a*, *b*, *c*, ..., *y*, *z* are expressions and *op1*,
*op2*, ..., *opN* are comparison operators, then "a op1 b op2 c ... y
opN z" is equivalent to "a op1 b and b op2 c and ... y opN z", except
that each expression is evaluated at most once.

Note that "a op1 b op2 c" doesn't imply any kind of comparison between
*a* and *c*, so that, e.g., "x < y > z" is perfectly legal (though
perhaps not pretty).


Value comparisons
=================

The operators "<", ">", "==", ">=", "<=", and "!=" compare the values
of two objects.  The objects do not need to have the same type.

Chapter Objects, values and types states that objects have a value (in
addition to type and identity).  The value of an object is a rather
abstract notion in Python: For example, there is no canonical access
method for an object's value.  Also, there is no requirement that the
value of an object should be constructed in a particular way, e.g.
comprised of all its data attributes. Comparison operators implement a
particular notion of what the value of an object is.  One can think of
them as defining the value of an object indirectly, by means of their
comparison implementation.

Because all types are (direct or indirect) subtypes of "object", they
inherit the default comparison behavior from "object".  Types can
customize their comparison behavior by implementing *rich comparison
methods* like "__lt__()", described in Basic customization.

The default behavior for equality comparison ("==" and "!=") is based
on the identity of the objects.  Hence, equality comparison of
instances with the same identity results in equality, and equality
comparison of instances with different identities results in
inequality.  A motivation for this default behavior is the desire that
all objects should be reflexive (i.e. "x is y" implies "x == y").

A default order comparison ("<", ">", "<=", and ">=") is not provided;
an attempt raises "TypeError".  A motivation for this default behavior
is the lack of a similar invariant as for equality.

The behavior of the default equality comparison, that instances with
different identities are always unequal, may be in contrast to what
types will need that have a sensible definition of object value and
value-based equality.  Such types will need to customize their
comparison behavior, and in fact, a number of built-in types have done
that.

The following list describes the comparison behavior of the most
important built-in types.

* Numbers of built-in numeric types (Numeric Types --- int, float,
  complex) and of the standard library types "fractions.Fraction" and
  "decimal.Decimal" can be compared within and across their types,
  with the restriction that complex numbers do not support order
  comparison.  Within the limits of the types involved, they compare
  mathematically (algorithmically) correct without loss of precision.

  The not-a-number values "float('NaN')" and "Decimal('NaN')" are
  special.  They are identical to themselves ("x is x" is true) but
  are not equal to themselves ("x == x" is false).  Additionally,
  comparing any number to a not-a-number value will return "False".
  For example, both "3 < float('NaN')" and "float('NaN') < 3" will
  return "False".

* Binary sequences (instances of "bytes" or "bytearray") can be
  compared within and across their types.  They compare
  lexicographically using the numeric values of their elements.

* Strings (instances of "str") compare lexicographically using the
  numerical Unicode code points (the result of the built-in function
  "ord()") of their characters. [3]

  Strings and binary sequences cannot be directly compared.

* Sequences (instances of "tuple", "list", or "range") can be
  compared only within each of their types, with the restriction that
  ranges do not support order comparison.  Equality comparison across
  these types results in inequality, and ordering comparison across
  these types raises "TypeError".

  Sequences compare lexicographically using comparison of
  corresponding elements, whereby reflexivity of the elements is
  enforced.

  In enforcing reflexivity of elements, the comparison of collections
  assumes that for a collection element "x", "x == x" is always true.
  Based on that assumption, element identity is compared first, and
  element comparison is performed only for distinct elements.  This
  approach yields the same result as a strict element comparison
  would, if the compared elements are reflexive.  For non-reflexive
  elements, the result is different than for strict element
  comparison, and may be surprising:  The non-reflexive not-a-number
  values for example result in the following comparison behavior when
  used in a list:

     >>> nan = float('NaN')
     >>> nan is nan
     True
     >>> nan == nan
     False                 <-- the defined non-reflexive behavior of NaN
     >>> [nan] == [nan]
     True                  <-- list enforces reflexivity and tests identity first

  Lexicographical comparison between built-in collections works as
  follows:

  * For two collections to compare equal, they must be of the same
    type, have the same length, and each pair of corresponding
    elements must compare equal (for example, "[1,2] == (1,2)" is
    false because the type is not the same).

  * Collections that support order comparison are ordered the same
    as their first unequal elements (for example, "[1,2,x] <= [1,2,y]"
    has the same value as "x <= y").  If a corresponding element does
    not exist, the shorter collection is ordered first (for example,
    "[1,2] < [1,2,3]" is true).

* Mappings (instances of "dict") compare equal if and only if they
  have equal *(key, value)* pairs. Equality comparison of the keys and
  values enforces reflexivity.

  Order comparisons ("<", ">", "<=", and ">=") raise "TypeError".

* Sets (instances of "set" or "frozenset") can be compared within
  and across their types.

  They define order comparison operators to mean subset and superset
  tests.  Those relations do not define total orderings (for example,
  the two sets "{1,2}" and "{2,3}" are not equal, nor subsets of one
  another, nor supersets of one another).  Accordingly, sets are not
  appropriate arguments for functions which depend on total ordering
  (for example, "min()", "max()", and "sorted()" produce undefined
  results given a list of sets as inputs).

  Comparison of sets enforces reflexivity of its elements.

* Most other built-in types have no comparison methods implemented,
  so they inherit the default comparison behavior.

User-defined classes that customize their comparison behavior should
follow some consistency rules, if possible:

* Equality comparison should be reflexive. In other words, identical
  objects should compare equal:

     "x is y" implies "x == y"

* Comparison should be symmetric. In other words, the following
  expressions should have the same result:

     "x == y" and "y == x"

     "x != y" and "y != x"

     "x < y" and "y > x"

     "x <= y" and "y >= x"

* Comparison should be transitive. The following (non-exhaustive)
  examples illustrate that:

     "x > y and y > z" implies "x > z"

     "x < y and y <= z" implies "x < z"

* Inverse comparison should result in the boolean negation. In other
  words, the following expressions should have the same result:

     "x == y" and "not x != y"

     "x < y" and "not x >= y" (for total ordering)

     "x > y" and "not x <= y" (for total ordering)

  The last two expressions apply to totally ordered collections (e.g.
  to sequences, but not to sets or mappings). See also the
  "total_ordering()" decorator.

* The "hash()" result should be consistent with equality. Objects
  that are equal should either have the same hash value, or be marked
  as unhashable.

Python does not enforce these consistency rules. In fact, the
not-a-number values are an example for not following these rules.


Membership test operations
==========================

The operators "in" and "not in" test for membership.  "x in s"
evaluates to "True" if *x* is a member of *s*, and "False" otherwise.
"x not in s" returns the negation of "x in s".  All built-in sequences
and set types support this as well as dictionary, for which "in" tests
whether the dictionary has a given key. For container types such as
list, tuple, set, frozenset, dict, or collections.deque, the
expression "x in y" is equivalent to "any(x is e or x == e for e in
y)".

For the string and bytes types, "x in y" is "True" if and only if *x*
is a substring of *y*.  An equivalent test is "y.find(x) != -1".
Empty strings are always considered to be a substring of any other
string, so """ in "abc"" will return "True".

For user-defined classes which define the "__contains__()" method, "x
in y" returns "True" if "y.__contains__(x)" returns a true value, and
"False" otherwise.

For user-defined classes which do not define "__contains__()" but do
define "__iter__()", "x in y" is "True" if some value "z" with "x ==
z" is produced while iterating over "y".  If an exception is raised
during the iteration, it is as if "in" raised that exception.

Lastly, the old-style iteration protocol is tried: if a class defines
"__getitem__()", "x in y" is "True" if and only if there is a non-
negative integer index *i* such that "x == y[i]", and all lower
integer indices do not raise "IndexError" exception.  (If any other
exception is raised, it is as if "in" raised that exception).

The operator "not in" is defined to have the inverse true value of
"in".


Identity comparisons
====================

The operators "is" and "is not" test for object identity: "x is y" is
true if and only if *x* and *y* are the same object.  Object identity
is determined using the "id()" function.  "x is not y" yields the
inverse truth value. [4]
zcompoundac  Compound statements
*******************

Compound statements contain (groups of) other statements; they affect
or control the execution of those other statements in some way.  In
general, compound statements span multiple lines, although in simple
incarnations a whole compound statement may be contained in one line.

The "if", "while" and "for" statements implement traditional control
flow constructs.  "try" specifies exception handlers and/or cleanup
code for a group of statements, while the "with" statement allows the
execution of initialization and finalization code around a block of
code.  Function and class definitions are also syntactically compound
statements.

A compound statement consists of one or more 'clauses.'  A clause
consists of a header and a 'suite.'  The clause headers of a
particular compound statement are all at the same indentation level.
Each clause header begins with a uniquely identifying keyword and ends
with a colon.  A suite is a group of statements controlled by a
clause.  A suite can be one or more semicolon-separated simple
statements on the same line as the header, following the header's
colon, or it can be one or more indented statements on subsequent
lines.  Only the latter form of a suite can contain nested compound
statements; the following is illegal, mostly because it wouldn't be
clear to which "if" clause a following "else" clause would belong:

   if test1: if test2: print(x)

Also note that the semicolon binds tighter than the colon in this
context, so that in the following example, either all or none of the
"print()" calls are executed:

   if x < y < z: print(x); print(y); print(z)

Summarizing:

   compound_stmt ::= if_stmt
                     | while_stmt
                     | for_stmt
                     | try_stmt
                     | with_stmt
                     | funcdef
                     | classdef
                     | async_with_stmt
                     | async_for_stmt
                     | async_funcdef
   suite         ::= stmt_list NEWLINE | NEWLINE INDENT statement+ DEDENT
   statement     ::= stmt_list NEWLINE | compound_stmt
   stmt_list     ::= simple_stmt (";" simple_stmt)* [";"]

Note that statements always end in a "NEWLINE" possibly followed by a
"DEDENT".  Also note that optional continuation clauses always begin
with a keyword that cannot start a statement, thus there are no
ambiguities (the 'dangling "else"' problem is solved in Python by
requiring nested "if" statements to be indented).

The formatting of the grammar rules in the following sections places
each clause on a separate line for clarity.


The "if" statement
==================

The "if" statement is used for conditional execution:

   if_stmt ::= "if" expression ":" suite
               ( "elif" expression ":" suite )*
               ["else" ":" suite]

It selects exactly one of the suites by evaluating the expressions one
by one until one is found to be true (see section Boolean operations
for the definition of true and false); then that suite is executed
(and no other part of the "if" statement is executed or evaluated).
If all expressions are false, the suite of the "else" clause, if
present, is executed.


The "while" statement
=====================

The "while" statement is used for repeated execution as long as an
expression is true:

   while_stmt ::= "while" expression ":" suite
                  ["else" ":" suite]

This repeatedly tests the expression and, if it is true, executes the
first suite; if the expression is false (which may be the first time
it is tested) the suite of the "else" clause, if present, is executed
and the loop terminates.

A "break" statement executed in the first suite terminates the loop
without executing the "else" clause's suite.  A "continue" statement
executed in the first suite skips the rest of the suite and goes back
to testing the expression.


The "for" statement
===================

The "for" statement is used to iterate over the elements of a sequence
(such as a string, tuple or list) or other iterable object:

   for_stmt ::= "for" target_list "in" expression_list ":" suite
                ["else" ":" suite]

The expression list is evaluated once; it should yield an iterable
object.  An iterator is created for the result of the
"expression_list".  The suite is then executed once for each item
provided by the iterator, in the order returned by the iterator.  Each
item in turn is assigned to the target list using the standard rules
for assignments (see Assignment statements), and then the suite is
executed.  When the items are exhausted (which is immediately when the
sequence is empty or an iterator raises a "StopIteration" exception),
the suite in the "else" clause, if present, is executed, and the loop
terminates.

A "break" statement executed in the first suite terminates the loop
without executing the "else" clause's suite.  A "continue" statement
executed in the first suite skips the rest of the suite and continues
with the next item, or with the "else" clause if there is no next
item.

The for-loop makes assignments to the variables(s) in the target list.
This overwrites all previous assignments to those variables including
those made in the suite of the for-loop:

   for i in range(10):
       print(i)
       i = 5             # this will not affect the for-loop
                         # because i will be overwritten with the next
                         # index in the range

Names in the target list are not deleted when the loop is finished,
but if the sequence is empty, they will not have been assigned to at
all by the loop.  Hint: the built-in function "range()" returns an
iterator of integers suitable to emulate the effect of Pascal's "for i
:= a to b do"; e.g., "list(range(3))" returns the list "[0, 1, 2]".

Note: There is a subtlety when the sequence is being modified by the
  loop (this can only occur for mutable sequences, i.e. lists).  An
  internal counter is used to keep track of which item is used next,
  and this is incremented on each iteration.  When this counter has
  reached the length of the sequence the loop terminates.  This means
  that if the suite deletes the current (or a previous) item from the
  sequence, the next item will be skipped (since it gets the index of
  the current item which has already been treated).  Likewise, if the
  suite inserts an item in the sequence before the current item, the
  current item will be treated again the next time through the loop.
  This can lead to nasty bugs that can be avoided by making a
  temporary copy using a slice of the whole sequence, e.g.,

     for x in a[:]:
         if x < 0: a.remove(x)


The "try" statement
===================

The "try" statement specifies exception handlers and/or cleanup code
for a group of statements:

   try_stmt  ::= try1_stmt | try2_stmt
   try1_stmt ::= "try" ":" suite
                 ("except" [expression ["as" identifier]] ":" suite)+
                 ["else" ":" suite]
                 ["finally" ":" suite]
   try2_stmt ::= "try" ":" suite
                 "finally" ":" suite

The "except" clause(s) specify one or more exception handlers. When no
exception occurs in the "try" clause, no exception handler is
executed. When an exception occurs in the "try" suite, a search for an
exception handler is started.  This search inspects the except clauses
in turn until one is found that matches the exception.  An expression-
less except clause, if present, must be last; it matches any
exception.  For an except clause with an expression, that expression
is evaluated, and the clause matches the exception if the resulting
object is "compatible" with the exception.  An object is compatible
with an exception if it is the class or a base class of the exception
object or a tuple containing an item compatible with the exception.

If no except clause matches the exception, the search for an exception
handler continues in the surrounding code and on the invocation stack.
[1]

If the evaluation of an expression in the header of an except clause
raises an exception, the original search for a handler is canceled and
a search starts for the new exception in the surrounding code and on
the call stack (it is treated as if the entire "try" statement raised
the exception).

When a matching except clause is found, the exception is assigned to
the target specified after the "as" keyword in that except clause, if
present, and the except clause's suite is executed.  All except
clauses must have an executable block.  When the end of this block is
reached, execution continues normally after the entire try statement.
(This means that if two nested handlers exist for the same exception,
and the exception occurs in the try clause of the inner handler, the
outer handler will not handle the exception.)

When an exception has been assigned using "as target", it is cleared
at the end of the except clause.  This is as if

   except E as N:
       foo

was translated to

   except E as N:
       try:
           foo
       finally:
           del N

This means the exception must be assigned to a different name to be
able to refer to it after the except clause.  Exceptions are cleared
because with the traceback attached to them, they form a reference
cycle with the stack frame, keeping all locals in that frame alive
until the next garbage collection occurs.

Before an except clause's suite is executed, details about the
exception are stored in the "sys" module and can be accessed via
"sys.exc_info()". "sys.exc_info()" returns a 3-tuple consisting of the
exception class, the exception instance and a traceback object (see
section The standard type hierarchy) identifying the point in the
program where the exception occurred.  "sys.exc_info()" values are
restored to their previous values (before the call) when returning
from a function that handled an exception.

The optional "else" clause is executed if and when control flows off
the end of the "try" clause. [2] Exceptions in the "else" clause are
not handled by the preceding "except" clauses.

If "finally" is present, it specifies a 'cleanup' handler.  The "try"
clause is executed, including any "except" and "else" clauses.  If an
exception occurs in any of the clauses and is not handled, the
exception is temporarily saved. The "finally" clause is executed.  If
there is a saved exception it is re-raised at the end of the "finally"
clause.  If the "finally" clause raises another exception, the saved
exception is set as the context of the new exception. If the "finally"
clause executes a "return" or "break" statement, the saved exception
is discarded:

   >>> def f():
   ...     try:
   ...         1/0
   ...     finally:
   ...         return 42
   ...
   >>> f()
   42

The exception information is not available to the program during
execution of the "finally" clause.

When a "return", "break" or "continue" statement is executed in the
"try" suite of a "try"..."finally" statement, the "finally" clause is
also executed 'on the way out.' A "continue" statement is illegal in
the "finally" clause. (The reason is a problem with the current
implementation --- this restriction may be lifted in the future).

The return value of a function is determined by the last "return"
statement executed.  Since the "finally" clause always executes, a
"return" statement executed in the "finally" clause will always be the
last one executed:

   >>> def foo():
   ...     try:
   ...         return 'try'
   ...     finally:
   ...         return 'finally'
   ...
   >>> foo()
   'finally'

Additional information on exceptions can be found in section
Exceptions, and information on using the "raise" statement to generate
exceptions may be found in section The raise statement.


The "with" statement
====================

The "with" statement is used to wrap the execution of a block with
methods defined by a context manager (see section With Statement
Context Managers). This allows common "try"..."except"..."finally"
usage patterns to be encapsulated for convenient reuse.

   with_stmt ::= "with" with_item ("," with_item)* ":" suite
   with_item ::= expression ["as" target]

The execution of the "with" statement with one "item" proceeds as
follows:

1. The context expression (the expression given in the "with_item")
   is evaluated to obtain a context manager.

2. The context manager's "__exit__()" is loaded for later use.

3. The context manager's "__enter__()" method is invoked.

4. If a target was included in the "with" statement, the return
   value from "__enter__()" is assigned to it.

   Note: The "with" statement guarantees that if the "__enter__()"
     method returns without an error, then "__exit__()" will always be
     called. Thus, if an error occurs during the assignment to the
     target list, it will be treated the same as an error occurring
     within the suite would be. See step 6 below.

5. The suite is executed.

6. The context manager's "__exit__()" method is invoked.  If an
   exception caused the suite to be exited, its type, value, and
   traceback are passed as arguments to "__exit__()". Otherwise, three
   "None" arguments are supplied.

   If the suite was exited due to an exception, and the return value
   from the "__exit__()" method was false, the exception is reraised.
   If the return value was true, the exception is suppressed, and
   execution continues with the statement following the "with"
   statement.

   If the suite was exited for any reason other than an exception, the
   return value from "__exit__()" is ignored, and execution proceeds
   at the normal location for the kind of exit that was taken.

With more than one item, the context managers are processed as if
multiple "with" statements were nested:

   with A() as a, B() as b:
       suite

is equivalent to

   with A() as a:
       with B() as b:
           suite

Changed in version 3.1: Support for multiple context expressions.

See also:

  **PEP 343** - The "with" statement
     The specification, background, and examples for the Python "with"
     statement.


Function definitions
====================

A function definition defines a user-defined function object (see
section The standard type hierarchy):

   funcdef                 ::= [decorators] "def" funcname "(" [parameter_list] ")" ["->" expression] ":" suite
   decorators              ::= decorator+
   decorator               ::= "@" dotted_name ["(" [argument_list [","]] ")"] NEWLINE
   dotted_name             ::= identifier ("." identifier)*
   parameter_list          ::= defparameter ("," defparameter)* ["," [parameter_list_starargs]]
                      | parameter_list_starargs
   parameter_list_starargs ::= "*" [parameter] ("," defparameter)* ["," ["**" parameter [","]]]
                               | "**" parameter [","]
   parameter               ::= identifier [":" expression]
   defparameter            ::= parameter ["=" expression]
   funcname                ::= identifier

A function definition is an executable statement.  Its execution binds
the function name in the current local namespace to a function object
(a wrapper around the executable code for the function).  This
function object contains a reference to the current global namespace
as the global namespace to be used when the function is called.

The function definition does not execute the function body; this gets
executed only when the function is called. [3]

A function definition may be wrapped by one or more *decorator*
expressions. Decorator expressions are evaluated when the function is
defined, in the scope that contains the function definition.  The
result must be a callable, which is invoked with the function object
as the only argument. The returned value is bound to the function name
instead of the function object.  Multiple decorators are applied in
nested fashion. For example, the following code

   @f1(arg)
   @f2
   def func(): pass

is roughly equivalent to

   def func(): pass
   func = f1(arg)(f2(func))

except that the original function is not temporarily bound to the name
"func".

When one or more *parameters* have the form *parameter* "="
*expression*, the function is said to have "default parameter values."
For a parameter with a default value, the corresponding *argument* may
be omitted from a call, in which case the parameter's default value is
substituted.  If a parameter has a default value, all following
parameters up until the ""*"" must also have a default value --- this
is a syntactic restriction that is not expressed by the grammar.

**Default parameter values are evaluated from left to right when the
function definition is executed.** This means that the expression is
evaluated once, when the function is defined, and that the same "pre-
computed" value is used for each call.  This is especially important
to understand when a default parameter is a mutable object, such as a
list or a dictionary: if the function modifies the object (e.g. by
appending an item to a list), the default value is in effect modified.
This is generally not what was intended.  A way around this is to use
"None" as the default, and explicitly test for it in the body of the
function, e.g.:

   def whats_on_the_telly(penguin=None):
       if penguin is None:
           penguin = []
       penguin.append("property of the zoo")
       return penguin

Function call semantics are described in more detail in section Calls.
A function call always assigns values to all parameters mentioned in
the parameter list, either from position arguments, from keyword
arguments, or from default values.  If the form ""*identifier"" is
present, it is initialized to a tuple receiving any excess positional
parameters, defaulting to the empty tuple. If the form
""**identifier"" is present, it is initialized to a new ordered
mapping receiving any excess keyword arguments, defaulting to a new
empty mapping of the same type.  Parameters after ""*"" or
""*identifier"" are keyword-only parameters and may only be passed
used keyword arguments.

Parameters may have annotations of the form "": expression"" following
the parameter name.  Any parameter may have an annotation even those
of the form "*identifier" or "**identifier".  Functions may have
"return" annotation of the form ""-> expression"" after the parameter
list.  These annotations can be any valid Python expression and are
evaluated when the function definition is executed.  Annotations may
be evaluated in a different order than they appear in the source code.
The presence of annotations does not change the semantics of a
function.  The annotation values are available as values of a
dictionary keyed by the parameters' names in the "__annotations__"
attribute of the function object.

It is also possible to create anonymous functions (functions not bound
to a name), for immediate use in expressions.  This uses lambda
expressions, described in section Lambdas.  Note that the lambda
expression is merely a shorthand for a simplified function definition;
a function defined in a ""def"" statement can be passed around or
assigned to another name just like a function defined by a lambda
expression.  The ""def"" form is actually more powerful since it
allows the execution of multiple statements and annotations.

**Programmer's note:** Functions are first-class objects.  A ""def""
statement executed inside a function definition defines a local
function that can be returned or passed around.  Free variables used
in the nested function can access the local variables of the function
containing the def.  See section Naming and binding for details.

See also:

  **PEP 3107** - Function Annotations
     The original specification for function annotations.


Class definitions
=================

A class definition defines a class object (see section The standard
type hierarchy):

   classdef    ::= [decorators] "class" classname [inheritance] ":" suite
   inheritance ::= "(" [argument_list] ")"
   classname   ::= identifier

A class definition is an executable statement.  The inheritance list
usually gives a list of base classes (see Metaclasses for more
advanced uses), so each item in the list should evaluate to a class
object which allows subclassing.  Classes without an inheritance list
inherit, by default, from the base class "object"; hence,

   class Foo:
       pass

is equivalent to

   class Foo(object):
       pass

The class's suite is then executed in a new execution frame (see
Naming and binding), using a newly created local namespace and the
original global namespace. (Usually, the suite contains mostly
function definitions.)  When the class's suite finishes execution, its
execution frame is discarded but its local namespace is saved. [4] A
class object is then created using the inheritance list for the base
classes and the saved local namespace for the attribute dictionary.
The class name is bound to this class object in the original local
namespace.

The order in which attributes are defined in the class body is
preserved in the new class's "__dict__".  Note that this is reliable
only right after the class is created and only for classes that were
defined using the definition syntax.

Class creation can be customized heavily using metaclasses.

Classes can also be decorated: just like when decorating functions,

   @f1(arg)
   @f2
   class Foo: pass

is roughly equivalent to

   class Foo: pass
   Foo = f1(arg)(f2(Foo))

The evaluation rules for the decorator expressions are the same as for
function decorators.  The result is then bound to the class name.

**Programmer's note:** Variables defined in the class definition are
class attributes; they are shared by instances.  Instance attributes
can be set in a method with "self.name = value".  Both class and
instance attributes are accessible through the notation ""self.name"",
and an instance attribute hides a class attribute with the same name
when accessed in this way.  Class attributes can be used as defaults
for instance attributes, but using mutable values there can lead to
unexpected results.  Descriptors can be used to create instance
variables with different implementation details.

See also: **PEP 3115** - Metaclasses in Python 3 **PEP 3129** -
  Class Decorators


Coroutines
==========

New in version 3.5.


Coroutine function definition
-----------------------------

   async_funcdef ::= [decorators] "async" "def" funcname "(" [parameter_list] ")" ["->" expression] ":" suite

Execution of Python coroutines can be suspended and resumed at many
points (see *coroutine*).  In the body of a coroutine, any "await" and
"async" identifiers become reserved keywords; "await" expressions,
"async for" and "async with" can only be used in coroutine bodies.

Functions defined with "async def" syntax are always coroutine
functions, even if they do not contain "await" or "async" keywords.

It is a "SyntaxError" to use "yield from" expressions in "async def"
coroutines.

An example of a coroutine function:

   async def func(param1, param2):
       do_stuff()
       await some_coroutine()


The "async for" statement
-------------------------

   async_for_stmt ::= "async" for_stmt

An *asynchronous iterable* is able to call asynchronous code in its
*iter* implementation, and *asynchronous iterator* can call
asynchronous code in its *next* method.

The "async for" statement allows convenient iteration over
asynchronous iterators.

The following code:

   async for TARGET in ITER:
       BLOCK
   else:
       BLOCK2

Is semantically equivalent to:

   iter = (ITER)
   iter = type(iter).__aiter__(iter)
   running = True
   while running:
       try:
           TARGET = await type(iter).__anext__(iter)
       except StopAsyncIteration:
           running = False
       else:
           BLOCK
   else:
       BLOCK2

See also "__aiter__()" and "__anext__()" for details.

It is a "SyntaxError" to use "async for" statement outside of an
"async def" function.


The "async with" statement
--------------------------

   async_with_stmt ::= "async" with_stmt

An *asynchronous context manager* is a *context manager* that is able
to suspend execution in its *enter* and *exit* methods.

The following code:

   async with EXPR as VAR:
       BLOCK

Is semantically equivalent to:

   mgr = (EXPR)
   aexit = type(mgr).__aexit__
   aenter = type(mgr).__aenter__(mgr)

   VAR = await aenter
   try:
       BLOCK
   except:
       if not await aexit(mgr, *sys.exc_info()):
           raise
   else:
       await aexit(mgr, None, None, None)

See also "__aenter__()" and "__aexit__()" for details.

It is a "SyntaxError" to use "async with" statement outside of an
"async def" function.

See also: **PEP 492** - Coroutines with async and await syntax

-[ Footnotes ]-

[1] The exception is propagated to the invocation stack unless
    there is a "finally" clause which happens to raise another
    exception. That new exception causes the old one to be lost.

[2] Currently, control "flows off the end" except in the case of
    an exception or the execution of a "return", "continue", or
    "break" statement.

[3] A string literal appearing as the first statement in the
    function body is transformed into the function's "__doc__"
    attribute and therefore the function's *docstring*.

[4] A string literal appearing as the first statement in the class
    body is transformed into the namespace's "__doc__" item and
    therefore the class's *docstring*.
zcontext-managersa  With Statement Context Managers
*******************************

A *context manager* is an object that defines the runtime context to
be established when executing a "with" statement. The context manager
handles the entry into, and the exit from, the desired runtime context
for the execution of the block of code.  Context managers are normally
invoked using the "with" statement (described in section The with
statement), but can also be used by directly invoking their methods.

Typical uses of context managers include saving and restoring various
kinds of global state, locking and unlocking resources, closing opened
files, etc.

For more information on context managers, see Context Manager Types.

object.__enter__(self)

   Enter the runtime context related to this object. The "with"
   statement will bind this method's return value to the target(s)
   specified in the "as" clause of the statement, if any.

object.__exit__(self, exc_type, exc_value, traceback)

   Exit the runtime context related to this object. The parameters
   describe the exception that caused the context to be exited. If the
   context was exited without an exception, all three arguments will
   be "None".

   If an exception is supplied, and the method wishes to suppress the
   exception (i.e., prevent it from being propagated), it should
   return a true value. Otherwise, the exception will be processed
   normally upon exit from this method.

   Note that "__exit__()" methods should not reraise the passed-in
   exception; this is the caller's responsibility.

See also:

  **PEP 343** - The "with" statement
     The specification, background, and examples for the Python "with"
     statement.
zcontinuea×  The "continue" statement
************************

   continue_stmt ::= "continue"

"continue" may only occur syntactically nested in a "for" or "while"
loop, but not nested in a function or class definition or "finally"
clause within that loop.  It continues with the next cycle of the
nearest enclosing loop.

When "continue" passes control out of a "try" statement with a
"finally" clause, that "finally" clause is executed before really
starting the next loop cycle.
zconversionsa  Arithmetic conversions
**********************

When a description of an arithmetic operator below uses the phrase
"the numeric arguments are converted to a common type," this means
that the operator implementation for built-in types works as follows:

* If either argument is a complex number, the other is converted to
  complex;

* otherwise, if either argument is a floating point number, the
  other is converted to floating point;

* otherwise, both must be integers and no conversion is necessary.

Some additional rules apply for certain operators (e.g., a string as a
left argument to the '%' operator).  Extensions must define their own
conversion behavior.
zcustomizationa¡3  Basic customization
*******************

object.__new__(cls[, ...])

   Called to create a new instance of class *cls*.  "__new__()" is a
   static method (special-cased so you need not declare it as such)
   that takes the class of which an instance was requested as its
   first argument.  The remaining arguments are those passed to the
   object constructor expression (the call to the class).  The return
   value of "__new__()" should be the new object instance (usually an
   instance of *cls*).

   Typical implementations create a new instance of the class by
   invoking the superclass's "__new__()" method using
   "super().__new__(cls[, ...])" with appropriate arguments and then
   modifying the newly-created instance as necessary before returning
   it.

   If "__new__()" returns an instance of *cls*, then the new
   instance's "__init__()" method will be invoked like
   "__init__(self[, ...])", where *self* is the new instance and the
   remaining arguments are the same as were passed to "__new__()".

   If "__new__()" does not return an instance of *cls*, then the new
   instance's "__init__()" method will not be invoked.

   "__new__()" is intended mainly to allow subclasses of immutable
   types (like int, str, or tuple) to customize instance creation.  It
   is also commonly overridden in custom metaclasses in order to
   customize class creation.

object.__init__(self[, ...])

   Called after the instance has been created (by "__new__()"), but
   before it is returned to the caller.  The arguments are those
   passed to the class constructor expression.  If a base class has an
   "__init__()" method, the derived class's "__init__()" method, if
   any, must explicitly call it to ensure proper initialization of the
   base class part of the instance; for example:
   "super().__init__([args...])".

   Because "__new__()" and "__init__()" work together in constructing
   objects ("__new__()" to create it, and "__init__()" to customize
   it), no non-"None" value may be returned by "__init__()"; doing so
   will cause a "TypeError" to be raised at runtime.

object.__del__(self)

   Called when the instance is about to be destroyed.  This is also
   called a finalizer or (improperly) a destructor.  If a base class
   has a "__del__()" method, the derived class's "__del__()" method,
   if any, must explicitly call it to ensure proper deletion of the
   base class part of the instance.

   It is possible (though not recommended!) for the "__del__()" method
   to postpone destruction of the instance by creating a new reference
   to it.  This is called object *resurrection*.  It is
   implementation-dependent whether "__del__()" is called a second
   time when a resurrected object is about to be destroyed; the
   current *CPython* implementation only calls it once.

   It is not guaranteed that "__del__()" methods are called for
   objects that still exist when the interpreter exits.

   Note: "del x" doesn't directly call "x.__del__()" --- the former
     decrements the reference count for "x" by one, and the latter is
     only called when "x"'s reference count reaches zero.

   **CPython implementation detail:** It is possible for a reference
   cycle to prevent the reference count of an object from going to
   zero.  In this case, the cycle will be later detected and deleted
   by the *cyclic garbage collector*.  A common cause of reference
   cycles is when an exception has been caught in a local variable.
   The frame's locals then reference the exception, which references
   its own traceback, which references the locals of all frames caught
   in the traceback.

   See also: Documentation for the "gc" module.

   Warning: Due to the precarious circumstances under which
     "__del__()" methods are invoked, exceptions that occur during
     their execution are ignored, and a warning is printed to
     "sys.stderr" instead. In particular:

     * "__del__()" can be invoked when arbitrary code is being
       executed, including from any arbitrary thread.  If "__del__()"
       needs to take a lock or invoke any other blocking resource, it
       may deadlock as the resource may already be taken by the code
       that gets interrupted to execute "__del__()".

     * "__del__()" can be executed during interpreter shutdown.  As
       a consequence, the global variables it needs to access
       (including other modules) may already have been deleted or set
       to "None". Python guarantees that globals whose name begins
       with a single underscore are deleted from their module before
       other globals are deleted; if no other references to such
       globals exist, this may help in assuring that imported modules
       are still available at the time when the "__del__()" method is
       called.

object.__repr__(self)

   Called by the "repr()" built-in function to compute the "official"
   string representation of an object.  If at all possible, this
   should look like a valid Python expression that could be used to
   recreate an object with the same value (given an appropriate
   environment).  If this is not possible, a string of the form
   "<...some useful description...>" should be returned. The return
   value must be a string object. If a class defines "__repr__()" but
   not "__str__()", then "__repr__()" is also used when an "informal"
   string representation of instances of that class is required.

   This is typically used for debugging, so it is important that the
   representation is information-rich and unambiguous.

object.__str__(self)

   Called by "str(object)" and the built-in functions "format()" and
   "print()" to compute the "informal" or nicely printable string
   representation of an object.  The return value must be a string
   object.

   This method differs from "object.__repr__()" in that there is no
   expectation that "__str__()" return a valid Python expression: a
   more convenient or concise representation can be used.

   The default implementation defined by the built-in type "object"
   calls "object.__repr__()".

object.__bytes__(self)

   Called by bytes to compute a byte-string representation of an
   object. This should return a "bytes" object.

object.__format__(self, format_spec)

   Called by the "format()" built-in function, and by extension,
   evaluation of formatted string literals and the "str.format()"
   method, to produce a "formatted" string representation of an
   object. The "format_spec" argument is a string that contains a
   description of the formatting options desired. The interpretation
   of the "format_spec" argument is up to the type implementing
   "__format__()", however most classes will either delegate
   formatting to one of the built-in types, or use a similar
   formatting option syntax.

   See Format Specification Mini-Language for a description of the
   standard formatting syntax.

   The return value must be a string object.

   Changed in version 3.4: The __format__ method of "object" itself
   raises a "TypeError" if passed any non-empty string.

object.__lt__(self, other)
object.__le__(self, other)
object.__eq__(self, other)
object.__ne__(self, other)
object.__gt__(self, other)
object.__ge__(self, other)

   These are the so-called "rich comparison" methods. The
   correspondence between operator symbols and method names is as
   follows: "x<y" calls "x.__lt__(y)", "x<=y" calls "x.__le__(y)",
   "x==y" calls "x.__eq__(y)", "x!=y" calls "x.__ne__(y)", "x>y" calls
   "x.__gt__(y)", and "x>=y" calls "x.__ge__(y)".

   A rich comparison method may return the singleton "NotImplemented"
   if it does not implement the operation for a given pair of
   arguments. By convention, "False" and "True" are returned for a
   successful comparison. However, these methods can return any value,
   so if the comparison operator is used in a Boolean context (e.g.,
   in the condition of an "if" statement), Python will call "bool()"
   on the value to determine if the result is true or false.

   By default, "__ne__()" delegates to "__eq__()" and inverts the
   result unless it is "NotImplemented".  There are no other implied
   relationships among the comparison operators, for example, the
   truth of "(x<y or x==y)" does not imply "x<=y". To automatically
   generate ordering operations from a single root operation, see
   "functools.total_ordering()".

   See the paragraph on "__hash__()" for some important notes on
   creating *hashable* objects which support custom comparison
   operations and are usable as dictionary keys.

   There are no swapped-argument versions of these methods (to be used
   when the left argument does not support the operation but the right
   argument does); rather, "__lt__()" and "__gt__()" are each other's
   reflection, "__le__()" and "__ge__()" are each other's reflection,
   and "__eq__()" and "__ne__()" are their own reflection. If the
   operands are of different types, and right operand's type is a
   direct or indirect subclass of the left operand's type, the
   reflected method of the right operand has priority, otherwise the
   left operand's method has priority.  Virtual subclassing is not
   considered.

object.__hash__(self)

   Called by built-in function "hash()" and for operations on members
   of hashed collections including "set", "frozenset", and "dict".
   "__hash__()" should return an integer. The only required property
   is that objects which compare equal have the same hash value; it is
   advised to mix together the hash values of the components of the
   object that also play a part in comparison of objects by packing
   them into a tuple and hashing the tuple. Example:

      def __hash__(self):
          return hash((self.name, self.nick, self.color))

   Note: "hash()" truncates the value returned from an object's
     custom "__hash__()" method to the size of a "Py_ssize_t".  This
     is typically 8 bytes on 64-bit builds and 4 bytes on 32-bit
     builds. If an object's   "__hash__()" must interoperate on builds
     of different bit sizes, be sure to check the width on all
     supported builds.  An easy way to do this is with "python -c
     "import sys; print(sys.hash_info.width)"".

   If a class does not define an "__eq__()" method it should not
   define a "__hash__()" operation either; if it defines "__eq__()"
   but not "__hash__()", its instances will not be usable as items in
   hashable collections.  If a class defines mutable objects and
   implements an "__eq__()" method, it should not implement
   "__hash__()", since the implementation of hashable collections
   requires that a key's hash value is immutable (if the object's hash
   value changes, it will be in the wrong hash bucket).

   User-defined classes have "__eq__()" and "__hash__()" methods by
   default; with them, all objects compare unequal (except with
   themselves) and "x.__hash__()" returns an appropriate value such
   that "x == y" implies both that "x is y" and "hash(x) == hash(y)".

   A class that overrides "__eq__()" and does not define "__hash__()"
   will have its "__hash__()" implicitly set to "None".  When the
   "__hash__()" method of a class is "None", instances of the class
   will raise an appropriate "TypeError" when a program attempts to
   retrieve their hash value, and will also be correctly identified as
   unhashable when checking "isinstance(obj, collections.Hashable)".

   If a class that overrides "__eq__()" needs to retain the
   implementation of "__hash__()" from a parent class, the interpreter
   must be told this explicitly by setting "__hash__ =
   <ParentClass>.__hash__".

   If a class that does not override "__eq__()" wishes to suppress
   hash support, it should include "__hash__ = None" in the class
   definition. A class which defines its own "__hash__()" that
   explicitly raises a "TypeError" would be incorrectly identified as
   hashable by an "isinstance(obj, collections.Hashable)" call.

   Note: By default, the "__hash__()" values of str, bytes and
     datetime objects are "salted" with an unpredictable random value.
     Although they remain constant within an individual Python
     process, they are not predictable between repeated invocations of
     Python.This is intended to provide protection against a denial-
     of-service caused by carefully-chosen inputs that exploit the
     worst case performance of a dict insertion, O(n^2) complexity.
     See http://www.ocert.org/advisories/ocert-2011-003.html for
     details.Changing hash values affects the iteration order of
     dicts, sets and other mappings.  Python has never made guarantees
     about this ordering (and it typically varies between 32-bit and
     64-bit builds).See also "PYTHONHASHSEED".

   Changed in version 3.3: Hash randomization is enabled by default.

object.__bool__(self)

   Called to implement truth value testing and the built-in operation
   "bool()"; should return "False" or "True".  When this method is not
   defined, "__len__()" is called, if it is defined, and the object is
   considered true if its result is nonzero.  If a class defines
   neither "__len__()" nor "__bool__()", all its instances are
   considered true.
zdebuggeruUF  "pdb" --- The Python Debugger
*****************************

**Source code:** Lib/pdb.py

======================================================================

The module "pdb" defines an interactive source code debugger for
Python programs.  It supports setting (conditional) breakpoints and
single stepping at the source line level, inspection of stack frames,
source code listing, and evaluation of arbitrary Python code in the
context of any stack frame.  It also supports post-mortem debugging
and can be called under program control.

The debugger is extensible -- it is actually defined as the class
"Pdb". This is currently undocumented but easily understood by reading
the source.  The extension interface uses the modules "bdb" and "cmd".

The debugger's prompt is "(Pdb)". Typical usage to run a program under
control of the debugger is:

   >>> import pdb
   >>> import mymodule
   >>> pdb.run('mymodule.test()')
   > <string>(0)?()
   (Pdb) continue
   > <string>(1)?()
   (Pdb) continue
   NameError: 'spam'
   > <string>(1)?()
   (Pdb)

Changed in version 3.3: Tab-completion via the "readline" module is
available for commands and command arguments, e.g. the current global
and local names are offered as arguments of the "p" command.

"pdb.py" can also be invoked as a script to debug other scripts.  For
example:

   python3 -m pdb myscript.py

When invoked as a script, pdb will automatically enter post-mortem
debugging if the program being debugged exits abnormally.  After post-
mortem debugging (or after normal exit of the program), pdb will
restart the program.  Automatic restarting preserves pdb's state (such
as breakpoints) and in most cases is more useful than quitting the
debugger upon program's exit.

New in version 3.2: "pdb.py" now accepts a "-c" option that executes
commands as if given in a ".pdbrc" file, see Debugger Commands.

The typical usage to break into the debugger from a running program is
to insert

   import pdb; pdb.set_trace()

at the location you want to break into the debugger.  You can then
step through the code following this statement, and continue running
without the debugger using the "continue" command.

The typical usage to inspect a crashed program is:

   >>> import pdb
   >>> import mymodule
   >>> mymodule.test()
   Traceback (most recent call last):
     File "<stdin>", line 1, in <module>
     File "./mymodule.py", line 4, in test
       test2()
     File "./mymodule.py", line 3, in test2
       print(spam)
   NameError: spam
   >>> pdb.pm()
   > ./mymodule.py(3)test2()
   -> print(spam)
   (Pdb)

The module defines the following functions; each enters the debugger
in a slightly different way:

pdb.run(statement, globals=None, locals=None)

   Execute the *statement* (given as a string or a code object) under
   debugger control.  The debugger prompt appears before any code is
   executed; you can set breakpoints and type "continue", or you can
   step through the statement using "step" or "next" (all these
   commands are explained below).  The optional *globals* and *locals*
   arguments specify the environment in which the code is executed; by
   default the dictionary of the module "__main__" is used.  (See the
   explanation of the built-in "exec()" or "eval()" functions.)

pdb.runeval(expression, globals=None, locals=None)

   Evaluate the *expression* (given as a string or a code object)
   under debugger control.  When "runeval()" returns, it returns the
   value of the expression.  Otherwise this function is similar to
   "run()".

pdb.runcall(function, *args, **kwds)

   Call the *function* (a function or method object, not a string)
   with the given arguments.  When "runcall()" returns, it returns
   whatever the function call returned.  The debugger prompt appears
   as soon as the function is entered.

pdb.set_trace()

   Enter the debugger at the calling stack frame.  This is useful to
   hard-code a breakpoint at a given point in a program, even if the
   code is not otherwise being debugged (e.g. when an assertion
   fails).

pdb.post_mortem(traceback=None)

   Enter post-mortem debugging of the given *traceback* object.  If no
   *traceback* is given, it uses the one of the exception that is
   currently being handled (an exception must be being handled if the
   default is to be used).

pdb.pm()

   Enter post-mortem debugging of the traceback found in
   "sys.last_traceback".

The "run*" functions and "set_trace()" are aliases for instantiating
the "Pdb" class and calling the method of the same name.  If you want
to access further features, you have to do this yourself:

class pdb.Pdb(completekey='tab', stdin=None, stdout=None, skip=None, nosigint=False, readrc=True)

   "Pdb" is the debugger class.

   The *completekey*, *stdin* and *stdout* arguments are passed to the
   underlying "cmd.Cmd" class; see the description there.

   The *skip* argument, if given, must be an iterable of glob-style
   module name patterns.  The debugger will not step into frames that
   originate in a module that matches one of these patterns. [1]

   By default, Pdb sets a handler for the SIGINT signal (which is sent
   when the user presses "Ctrl-C" on the console) when you give a
   "continue" command. This allows you to break into the debugger
   again by pressing "Ctrl-C".  If you want Pdb not to touch the
   SIGINT handler, set *nosigint* to true.

   The *readrc* argument defaults to true and controls whether Pdb
   will load .pdbrc files from the filesystem.

   Example call to enable tracing with *skip*:

      import pdb; pdb.Pdb(skip=['django.*']).set_trace()

   New in version 3.1: The *skip* argument.

   New in version 3.2: The *nosigint* argument.  Previously, a SIGINT
   handler was never set by Pdb.

   Changed in version 3.6: The *readrc* argument.

   run(statement, globals=None, locals=None)
   runeval(expression, globals=None, locals=None)
   runcall(function, *args, **kwds)
   set_trace()

      See the documentation for the functions explained above.


Debugger Commands
=================

The commands recognized by the debugger are listed below.  Most
commands can be abbreviated to one or two letters as indicated; e.g.
"h(elp)" means that either "h" or "help" can be used to enter the help
command (but not "he" or "hel", nor "H" or "Help" or "HELP").
Arguments to commands must be separated by whitespace (spaces or
tabs).  Optional arguments are enclosed in square brackets ("[]") in
the command syntax; the square brackets must not be typed.
Alternatives in the command syntax are separated by a vertical bar
("|").

Entering a blank line repeats the last command entered.  Exception: if
the last command was a "list" command, the next 11 lines are listed.

Commands that the debugger doesn't recognize are assumed to be Python
statements and are executed in the context of the program being
debugged.  Python statements can also be prefixed with an exclamation
point ("!").  This is a powerful way to inspect the program being
debugged; it is even possible to change a variable or call a function.
When an exception occurs in such a statement, the exception name is
printed but the debugger's state is not changed.

The debugger supports aliases.  Aliases can have parameters which
allows one a certain level of adaptability to the context under
examination.

Multiple commands may be entered on a single line, separated by ";;".
(A single ";" is not used as it is the separator for multiple commands
in a line that is passed to the Python parser.)  No intelligence is
applied to separating the commands; the input is split at the first
";;" pair, even if it is in the middle of a quoted string.

If a file ".pdbrc" exists in the user's home directory or in the
current directory, it is read in and executed as if it had been typed
at the debugger prompt.  This is particularly useful for aliases.  If
both files exist, the one in the home directory is read first and
aliases defined there can be overridden by the local file.

Changed in version 3.2: ".pdbrc" can now contain commands that
continue debugging, such as "continue" or "next".  Previously, these
commands had no effect.

h(elp) [command]

   Without argument, print the list of available commands.  With a
   *command* as argument, print help about that command.  "help pdb"
   displays the full documentation (the docstring of the "pdb"
   module).  Since the *command* argument must be an identifier, "help
   exec" must be entered to get help on the "!" command.

w(here)

   Print a stack trace, with the most recent frame at the bottom.  An
   arrow indicates the current frame, which determines the context of
   most commands.

d(own) [count]

   Move the current frame *count* (default one) levels down in the
   stack trace (to a newer frame).

u(p) [count]

   Move the current frame *count* (default one) levels up in the stack
   trace (to an older frame).

b(reak) [([filename:]lineno | function) [, condition]]

   With a *lineno* argument, set a break there in the current file.
   With a *function* argument, set a break at the first executable
   statement within that function.  The line number may be prefixed
   with a filename and a colon, to specify a breakpoint in another
   file (probably one that hasn't been loaded yet).  The file is
   searched on "sys.path".  Note that each breakpoint is assigned a
   number to which all the other breakpoint commands refer.

   If a second argument is present, it is an expression which must
   evaluate to true before the breakpoint is honored.

   Without argument, list all breaks, including for each breakpoint,
   the number of times that breakpoint has been hit, the current
   ignore count, and the associated condition if any.

tbreak [([filename:]lineno | function) [, condition]]

   Temporary breakpoint, which is removed automatically when it is
   first hit. The arguments are the same as for "break".

cl(ear) [filename:lineno | bpnumber [bpnumber ...]]

   With a *filename:lineno* argument, clear all the breakpoints at
   this line. With a space separated list of breakpoint numbers, clear
   those breakpoints. Without argument, clear all breaks (but first
   ask confirmation).

disable [bpnumber [bpnumber ...]]

   Disable the breakpoints given as a space separated list of
   breakpoint numbers.  Disabling a breakpoint means it cannot cause
   the program to stop execution, but unlike clearing a breakpoint, it
   remains in the list of breakpoints and can be (re-)enabled.

enable [bpnumber [bpnumber ...]]

   Enable the breakpoints specified.

ignore bpnumber [count]

   Set the ignore count for the given breakpoint number.  If count is
   omitted, the ignore count is set to 0.  A breakpoint becomes active
   when the ignore count is zero.  When non-zero, the count is
   decremented each time the breakpoint is reached and the breakpoint
   is not disabled and any associated condition evaluates to true.

condition bpnumber [condition]

   Set a new *condition* for the breakpoint, an expression which must
   evaluate to true before the breakpoint is honored.  If *condition*
   is absent, any existing condition is removed; i.e., the breakpoint
   is made unconditional.

commands [bpnumber]

   Specify a list of commands for breakpoint number *bpnumber*.  The
   commands themselves appear on the following lines.  Type a line
   containing just "end" to terminate the commands. An example:

      (Pdb) commands 1
      (com) p some_variable
      (com) end
      (Pdb)

   To remove all commands from a breakpoint, type commands and follow
   it immediately with "end"; that is, give no commands.

   With no *bpnumber* argument, commands refers to the last breakpoint
   set.

   You can use breakpoint commands to start your program up again.
   Simply use the continue command, or step, or any other command that
   resumes execution.

   Specifying any command resuming execution (currently continue,
   step, next, return, jump, quit and their abbreviations) terminates
   the command list (as if that command was immediately followed by
   end). This is because any time you resume execution (even with a
   simple next or step), you may encounter another breakpointâwhich
   could have its own command list, leading to ambiguities about which
   list to execute.

   If you use the 'silent' command in the command list, the usual
   message about stopping at a breakpoint is not printed.  This may be
   desirable for breakpoints that are to print a specific message and
   then continue.  If none of the other commands print anything, you
   see no sign that the breakpoint was reached.

s(tep)

   Execute the current line, stop at the first possible occasion
   (either in a function that is called or on the next line in the
   current function).

n(ext)

   Continue execution until the next line in the current function is
   reached or it returns.  (The difference between "next" and "step"
   is that "step" stops inside a called function, while "next"
   executes called functions at (nearly) full speed, only stopping at
   the next line in the current function.)

unt(il) [lineno]

   Without argument, continue execution until the line with a number
   greater than the current one is reached.

   With a line number, continue execution until a line with a number
   greater or equal to that is reached.  In both cases, also stop when
   the current frame returns.

   Changed in version 3.2: Allow giving an explicit line number.

r(eturn)

   Continue execution until the current function returns.

c(ont(inue))

   Continue execution, only stop when a breakpoint is encountered.

j(ump) lineno

   Set the next line that will be executed.  Only available in the
   bottom-most frame.  This lets you jump back and execute code again,
   or jump forward to skip code that you don't want to run.

   It should be noted that not all jumps are allowed -- for instance
   it is not possible to jump into the middle of a "for" loop or out
   of a "finally" clause.

l(ist) [first[, last]]

   List source code for the current file.  Without arguments, list 11
   lines around the current line or continue the previous listing.
   With "." as argument, list 11 lines around the current line.  With
   one argument, list 11 lines around at that line.  With two
   arguments, list the given range; if the second argument is less
   than the first, it is interpreted as a count.

   The current line in the current frame is indicated by "->".  If an
   exception is being debugged, the line where the exception was
   originally raised or propagated is indicated by ">>", if it differs
   from the current line.

   New in version 3.2: The ">>" marker.

ll | longlist

   List all source code for the current function or frame.
   Interesting lines are marked as for "list".

   New in version 3.2.

a(rgs)

   Print the argument list of the current function.

p expression

   Evaluate the *expression* in the current context and print its
   value.

   Note: "print()" can also be used, but is not a debugger command
     --- this executes the Python "print()" function.

pp expression

   Like the "p" command, except the value of the expression is pretty-
   printed using the "pprint" module.

whatis expression

   Print the type of the *expression*.

source expression

   Try to get source code for the given object and display it.

   New in version 3.2.

display [expression]

   Display the value of the expression if it changed, each time
   execution stops in the current frame.

   Without expression, list all display expressions for the current
   frame.

   New in version 3.2.

undisplay [expression]

   Do not display the expression any more in the current frame.
   Without expression, clear all display expressions for the current
   frame.

   New in version 3.2.

interact

   Start an interactive interpreter (using the "code" module) whose
   global namespace contains all the (global and local) names found in
   the current scope.

   New in version 3.2.

alias [name [command]]

   Create an alias called *name* that executes *command*.  The command
   must *not* be enclosed in quotes.  Replaceable parameters can be
   indicated by "%1", "%2", and so on, while "%*" is replaced by all
   the parameters. If no command is given, the current alias for
   *name* is shown. If no arguments are given, all aliases are listed.

   Aliases may be nested and can contain anything that can be legally
   typed at the pdb prompt.  Note that internal pdb commands *can* be
   overridden by aliases.  Such a command is then hidden until the
   alias is removed.  Aliasing is recursively applied to the first
   word of the command line; all other words in the line are left
   alone.

   As an example, here are two useful aliases (especially when placed
   in the ".pdbrc" file):

      # Print instance variables (usage "pi classInst")
      alias pi for k in %1.__dict__.keys(): print("%1.",k,"=",%1.__dict__[k])
      # Print instance variables in self
      alias ps pi self

unalias name

   Delete the specified alias.

! statement

   Execute the (one-line) *statement* in the context of the current
   stack frame. The exclamation point can be omitted unless the first
   word of the statement resembles a debugger command.  To set a
   global variable, you can prefix the assignment command with a
   "global" statement on the same line, e.g.:

      (Pdb) global list_options; list_options = ['-l']
      (Pdb)

run [args ...]
restart [args ...]

   Restart the debugged Python program.  If an argument is supplied,
   it is split with "shlex" and the result is used as the new
   "sys.argv". History, breakpoints, actions and debugger options are
   preserved. "restart" is an alias for "run".

q(uit)

   Quit from the debugger.  The program being executed is aborted.

-[ Footnotes ]-

[1] Whether a frame is considered to originate in a certain module
    is determined by the "__name__" in the frame globals.
zdela©  The "del" statement
*******************

   del_stmt ::= "del" target_list

Deletion is recursively defined very similar to the way assignment is
defined. Rather than spelling it out in full details, here are some
hints.

Deletion of a target list recursively deletes each target, from left
to right.

Deletion of a name removes the binding of that name from the local or
global namespace, depending on whether the name occurs in a "global"
statement in the same code block.  If the name is unbound, a
"NameError" exception will be raised.

Deletion of attribute references, subscriptions and slicings is passed
to the primary object involved; deletion of a slicing is in general
equivalent to assignment of an empty slice of the right type (but even
this is determined by the sliced object).

Changed in version 3.2: Previously it was illegal to delete a name
from the local namespace if it occurs as a free variable in a nested
block.
zdicta  Dictionary displays
*******************

A dictionary display is a possibly empty series of key/datum pairs
enclosed in curly braces:

   dict_display       ::= "{" [key_datum_list | dict_comprehension] "}"
   key_datum_list     ::= key_datum ("," key_datum)* [","]
   key_datum          ::= expression ":" expression | "**" or_expr
   dict_comprehension ::= expression ":" expression comp_for

A dictionary display yields a new dictionary object.

If a comma-separated sequence of key/datum pairs is given, they are
evaluated from left to right to define the entries of the dictionary:
each key object is used as a key into the dictionary to store the
corresponding datum.  This means that you can specify the same key
multiple times in the key/datum list, and the final dictionary's value
for that key will be the last one given.

A double asterisk "**" denotes *dictionary unpacking*. Its operand
must be a *mapping*.  Each mapping item is added to the new
dictionary.  Later values replace values already set by earlier
key/datum pairs and earlier dictionary unpackings.

New in version 3.5: Unpacking into dictionary displays, originally
proposed by **PEP 448**.

A dict comprehension, in contrast to list and set comprehensions,
needs two expressions separated with a colon followed by the usual
"for" and "if" clauses. When the comprehension is run, the resulting
key and value elements are inserted in the new dictionary in the order
they are produced.

Restrictions on the types of the key values are listed earlier in
section The standard type hierarchy.  (To summarize, the key type
should be *hashable*, which excludes all mutable objects.)  Clashes
between duplicate keys are not detected; the last datum (textually
rightmost in the display) stored for a given key value prevails.
zdynamic-featuresa°  Interaction with dynamic features
*********************************

Name resolution of free variables occurs at runtime, not at compile
time. This means that the following code will print 42:

   i = 10
   def f():
       print(i)
   i = 42
   f()

The "eval()" and "exec()" functions do not have access to the full
environment for resolving names.  Names may be resolved in the local
and global namespaces of the caller.  Free variables are not resolved
in the nearest enclosing namespace, but in the global namespace.  [1]
The "exec()" and "eval()" functions have optional arguments to
override the global and local namespace.  If only one namespace is
specified, it is used for both.
zelseaD  The "if" statement
******************

The "if" statement is used for conditional execution:

   if_stmt ::= "if" expression ":" suite
               ( "elif" expression ":" suite )*
               ["else" ":" suite]

It selects exactly one of the suites by evaluating the expressions one
by one until one is found to be true (see section Boolean operations
for the definition of true and false); then that suite is executed
(and no other part of the "if" statement is executed or evaluated).
If all expressions are false, the suite of the "else" clause, if
present, is executed.
z
exceptionsa  Exceptions
**********

Exceptions are a means of breaking out of the normal flow of control
of a code block in order to handle errors or other exceptional
conditions.  An exception is *raised* at the point where the error is
detected; it may be *handled* by the surrounding code block or by any
code block that directly or indirectly invoked the code block where
the error occurred.

The Python interpreter raises an exception when it detects a run-time
error (such as division by zero).  A Python program can also
explicitly raise an exception with the "raise" statement. Exception
handlers are specified with the "try" ... "except" statement.  The
"finally" clause of such a statement can be used to specify cleanup
code which does not handle the exception, but is executed whether an
exception occurred or not in the preceding code.

Python uses the "termination" model of error handling: an exception
handler can find out what happened and continue execution at an outer
level, but it cannot repair the cause of the error and retry the
failing operation (except by re-entering the offending piece of code
from the top).

When an exception is not handled at all, the interpreter terminates
execution of the program, or returns to its interactive main loop.  In
either case, it prints a stack backtrace, except when the exception is
"SystemExit".

Exceptions are identified by class instances.  The "except" clause is
selected depending on the class of the instance: it must reference the
class of the instance or a base class thereof.  The instance can be
received by the handler and can carry additional information about the
exceptional condition.

Note: Exception messages are not part of the Python API.  Their
  contents may change from one version of Python to the next without
  warning and should not be relied on by code which will run under
  multiple versions of the interpreter.

See also the description of the "try" statement in section The try
statement and "raise" statement in section The raise statement.

-[ Footnotes ]-

[1] This limitation occurs because the code that is executed by
    these operations is not available at the time the module is
    compiled.
z	execmodelaû#  Execution model
***************


Structure of a program
======================

A Python program is constructed from code blocks. A *block* is a piece
of Python program text that is executed as a unit. The following are
blocks: a module, a function body, and a class definition. Each
command typed interactively is a block.  A script file (a file given
as standard input to the interpreter or specified as a command line
argument to the interpreter) is a code block.  A script command (a
command specified on the interpreter command line with the '**-c**'
option) is a code block.  The string argument passed to the built-in
functions "eval()" and "exec()" is a code block.

A code block is executed in an *execution frame*.  A frame contains
some administrative information (used for debugging) and determines
where and how execution continues after the code block's execution has
completed.


Naming and binding
==================


Binding of names
----------------

*Names* refer to objects.  Names are introduced by name binding
operations.

The following constructs bind names: formal parameters to functions,
"import" statements, class and function definitions (these bind the
class or function name in the defining block), and targets that are
identifiers if occurring in an assignment, "for" loop header, or after
"as" in a "with" statement or "except" clause. The "import" statement
of the form "from ... import *" binds all names defined in the
imported module, except those beginning with an underscore.  This form
may only be used at the module level.

A target occurring in a "del" statement is also considered bound for
this purpose (though the actual semantics are to unbind the name).

Each assignment or import statement occurs within a block defined by a
class or function definition or at the module level (the top-level
code block).

If a name is bound in a block, it is a local variable of that block,
unless declared as "nonlocal" or "global".  If a name is bound at the
module level, it is a global variable.  (The variables of the module
code block are local and global.)  If a variable is used in a code
block but not defined there, it is a *free variable*.

Each occurrence of a name in the program text refers to the *binding*
of that name established by the following name resolution rules.


Resolution of names
-------------------

A *scope* defines the visibility of a name within a block.  If a local
variable is defined in a block, its scope includes that block.  If the
definition occurs in a function block, the scope extends to any blocks
contained within the defining one, unless a contained block introduces
a different binding for the name.

When a name is used in a code block, it is resolved using the nearest
enclosing scope.  The set of all such scopes visible to a code block
is called the block's *environment*.

When a name is not found at all, a "NameError" exception is raised. If
the current scope is a function scope, and the name refers to a local
variable that has not yet been bound to a value at the point where the
name is used, an "UnboundLocalError" exception is raised.
"UnboundLocalError" is a subclass of "NameError".

If a name binding operation occurs anywhere within a code block, all
uses of the name within the block are treated as references to the
current block.  This can lead to errors when a name is used within a
block before it is bound.  This rule is subtle.  Python lacks
declarations and allows name binding operations to occur anywhere
within a code block.  The local variables of a code block can be
determined by scanning the entire text of the block for name binding
operations.

If the "global" statement occurs within a block, all uses of the name
specified in the statement refer to the binding of that name in the
top-level namespace.  Names are resolved in the top-level namespace by
searching the global namespace, i.e. the namespace of the module
containing the code block, and the builtins namespace, the namespace
of the module "builtins".  The global namespace is searched first.  If
the name is not found there, the builtins namespace is searched.  The
"global" statement must precede all uses of the name.

The "global" statement has the same scope as a name binding operation
in the same block.  If the nearest enclosing scope for a free variable
contains a global statement, the free variable is treated as a global.

The "nonlocal" statement causes corresponding names to refer to
previously bound variables in the nearest enclosing function scope.
"SyntaxError" is raised at compile time if the given name does not
exist in any enclosing function scope.

The namespace for a module is automatically created the first time a
module is imported.  The main module for a script is always called
"__main__".

Class definition blocks and arguments to "exec()" and "eval()" are
special in the context of name resolution. A class definition is an
executable statement that may use and define names. These references
follow the normal rules for name resolution with an exception that
unbound local variables are looked up in the global namespace. The
namespace of the class definition becomes the attribute dictionary of
the class. The scope of names defined in a class block is limited to
the class block; it does not extend to the code blocks of methods --
this includes comprehensions and generator expressions since they are
implemented using a function scope.  This means that the following
will fail:

   class A:
       a = 42
       b = list(a + i for i in range(10))


Builtins and restricted execution
---------------------------------

**CPython implementation detail:** Users should not touch
"__builtins__"; it is strictly an implementation detail.  Users
wanting to override values in the builtins namespace should "import"
the "builtins" module and modify its attributes appropriately.

The builtins namespace associated with the execution of a code block
is actually found by looking up the name "__builtins__" in its global
namespace; this should be a dictionary or a module (in the latter case
the module's dictionary is used).  By default, when in the "__main__"
module, "__builtins__" is the built-in module "builtins"; when in any
other module, "__builtins__" is an alias for the dictionary of the
"builtins" module itself.


Interaction with dynamic features
---------------------------------

Name resolution of free variables occurs at runtime, not at compile
time. This means that the following code will print 42:

   i = 10
   def f():
       print(i)
   i = 42
   f()

The "eval()" and "exec()" functions do not have access to the full
environment for resolving names.  Names may be resolved in the local
and global namespaces of the caller.  Free variables are not resolved
in the nearest enclosing namespace, but in the global namespace.  [1]
The "exec()" and "eval()" functions have optional arguments to
override the global and local namespace.  If only one namespace is
specified, it is used for both.


Exceptions
==========

Exceptions are a means of breaking out of the normal flow of control
of a code block in order to handle errors or other exceptional
conditions.  An exception is *raised* at the point where the error is
detected; it may be *handled* by the surrounding code block or by any
code block that directly or indirectly invoked the code block where
the error occurred.

The Python interpreter raises an exception when it detects a run-time
error (such as division by zero).  A Python program can also
explicitly raise an exception with the "raise" statement. Exception
handlers are specified with the "try" ... "except" statement.  The
"finally" clause of such a statement can be used to specify cleanup
code which does not handle the exception, but is executed whether an
exception occurred or not in the preceding code.

Python uses the "termination" model of error handling: an exception
handler can find out what happened and continue execution at an outer
level, but it cannot repair the cause of the error and retry the
failing operation (except by re-entering the offending piece of code
from the top).

When an exception is not handled at all, the interpreter terminates
execution of the program, or returns to its interactive main loop.  In
either case, it prints a stack backtrace, except when the exception is
"SystemExit".

Exceptions are identified by class instances.  The "except" clause is
selected depending on the class of the instance: it must reference the
class of the instance or a base class thereof.  The instance can be
received by the handler and can carry additional information about the
exceptional condition.

Note: Exception messages are not part of the Python API.  Their
  contents may change from one version of Python to the next without
  warning and should not be relied on by code which will run under
  multiple versions of the interpreter.

See also the description of the "try" statement in section The try
statement and "raise" statement in section The raise statement.

-[ Footnotes ]-

[1] This limitation occurs because the code that is executed by
    these operations is not available at the time the module is
    compiled.
z	exprlistsas  Expression lists
****************

   expression_list    ::= expression ( "," expression )* [","]
   starred_list       ::= starred_item ( "," starred_item )* [","]
   starred_expression ::= expression | ( starred_item "," )* [starred_item]
   starred_item       ::= expression | "*" or_expr

Except when part of a list or set display, an expression list
containing at least one comma yields a tuple.  The length of the tuple
is the number of expressions in the list.  The expressions are
evaluated from left to right.

An asterisk "*" denotes *iterable unpacking*.  Its operand must be an
*iterable*.  The iterable is expanded into a sequence of items, which
are included in the new tuple, list, or set, at the site of the
unpacking.

New in version 3.5: Iterable unpacking in expression lists, originally
proposed by **PEP 448**.

The trailing comma is required only to create a single tuple (a.k.a. a
*singleton*); it is optional in all other cases.  A single expression
without a trailing comma doesn't create a tuple, but rather yields the
value of that expression. (To create an empty tuple, use an empty pair
of parentheses: "()".)
zfloatinga  Floating point literals
***********************

Floating point literals are described by the following lexical
definitions:

   floatnumber   ::= pointfloat | exponentfloat
   pointfloat    ::= [digitpart] fraction | digitpart "."
   exponentfloat ::= (digitpart | pointfloat) exponent
   digitpart     ::= digit (["_"] digit)*
   fraction      ::= "." digitpart
   exponent      ::= ("e" | "E") ["+" | "-"] digitpart

Note that the integer and exponent parts are always interpreted using
radix 10. For example, "077e010" is legal, and denotes the same number
as "77e10". The allowed range of floating point literals is
implementation-dependent.  As in integer literals, underscores are
supported for digit grouping.

Some examples of floating point literals:

   3.14    10.    .001    1e100    3.14e-10    0e0    3.14_15_93

Changed in version 3.6: Underscores are now allowed for grouping
purposes in literals.
zforaß
  The "for" statement
*******************

The "for" statement is used to iterate over the elements of a sequence
(such as a string, tuple or list) or other iterable object:

   for_stmt ::= "for" target_list "in" expression_list ":" suite
                ["else" ":" suite]

The expression list is evaluated once; it should yield an iterable
object.  An iterator is created for the result of the
"expression_list".  The suite is then executed once for each item
provided by the iterator, in the order returned by the iterator.  Each
item in turn is assigned to the target list using the standard rules
for assignments (see Assignment statements), and then the suite is
executed.  When the items are exhausted (which is immediately when the
sequence is empty or an iterator raises a "StopIteration" exception),
the suite in the "else" clause, if present, is executed, and the loop
terminates.

A "break" statement executed in the first suite terminates the loop
without executing the "else" clause's suite.  A "continue" statement
executed in the first suite skips the rest of the suite and continues
with the next item, or with the "else" clause if there is no next
item.

The for-loop makes assignments to the variables(s) in the target list.
This overwrites all previous assignments to those variables including
those made in the suite of the for-loop:

   for i in range(10):
       print(i)
       i = 5             # this will not affect the for-loop
                         # because i will be overwritten with the next
                         # index in the range

Names in the target list are not deleted when the loop is finished,
but if the sequence is empty, they will not have been assigned to at
all by the loop.  Hint: the built-in function "range()" returns an
iterator of integers suitable to emulate the effect of Pascal's "for i
:= a to b do"; e.g., "list(range(3))" returns the list "[0, 1, 2]".

Note: There is a subtlety when the sequence is being modified by the
  loop (this can only occur for mutable sequences, i.e. lists).  An
  internal counter is used to keep track of which item is used next,
  and this is incremented on each iteration.  When this counter has
  reached the length of the sequence the loop terminates.  This means
  that if the suite deletes the current (or a previous) item from the
  sequence, the next item will be skipped (since it gets the index of
  the current item which has already been treated).  Likewise, if the
  suite inserts an item in the sequence before the current item, the
  current item will be treated again the next time through the loop.
  This can lead to nasty bugs that can be avoided by making a
  temporary copy using a slice of the whole sequence, e.g.,

     for x in a[:]:
         if x < 0: a.remove(x)
zformatstringsamX  Format String Syntax
********************

The "str.format()" method and the "Formatter" class share the same
syntax for format strings (although in the case of "Formatter",
subclasses can define their own format string syntax).  The syntax is
related to that of formatted string literals, but there are
differences.

Format strings contain "replacement fields" surrounded by curly braces
"{}". Anything that is not contained in braces is considered literal
text, which is copied unchanged to the output.  If you need to include
a brace character in the literal text, it can be escaped by doubling:
"{{" and "}}".

The grammar for a replacement field is as follows:

      replacement_field ::= "{" [field_name] ["!" conversion] [":" format_spec] "}"
      field_name        ::= arg_name ("." attribute_name | "[" element_index "]")*
      arg_name          ::= [identifier | digit+]
      attribute_name    ::= identifier
      element_index     ::= digit+ | index_string
      index_string      ::= <any source character except "]"> +
      conversion        ::= "r" | "s" | "a"
      format_spec       ::= <described in the next section>

In less formal terms, the replacement field can start with a
*field_name* that specifies the object whose value is to be formatted
and inserted into the output instead of the replacement field. The
*field_name* is optionally followed by a  *conversion* field, which is
preceded by an exclamation point "'!'", and a *format_spec*, which is
preceded by a colon "':'".  These specify a non-default format for the
replacement value.

See also the Format Specification Mini-Language section.

The *field_name* itself begins with an *arg_name* that is either a
number or a keyword.  If it's a number, it refers to a positional
argument, and if it's a keyword, it refers to a named keyword
argument.  If the numerical arg_names in a format string are 0, 1, 2,
... in sequence, they can all be omitted (not just some) and the
numbers 0, 1, 2, ... will be automatically inserted in that order.
Because *arg_name* is not quote-delimited, it is not possible to
specify arbitrary dictionary keys (e.g., the strings "'10'" or
"':-]'") within a format string. The *arg_name* can be followed by any
number of index or attribute expressions. An expression of the form
"'.name'" selects the named attribute using "getattr()", while an
expression of the form "'[index]'" does an index lookup using
"__getitem__()".

Changed in version 3.1: The positional argument specifiers can be
omitted, so "'{} {}'" is equivalent to "'{0} {1}'".

Some simple format string examples:

   "First, thou shalt count to {0}"  # References first positional argument
   "Bring me a {}"                   # Implicitly references the first positional argument
   "From {} to {}"                   # Same as "From {0} to {1}"
   "My quest is {name}"              # References keyword argument 'name'
   "Weight in tons {0.weight}"       # 'weight' attribute of first positional arg
   "Units destroyed: {players[0]}"   # First element of keyword argument 'players'.

The *conversion* field causes a type coercion before formatting.
Normally, the job of formatting a value is done by the "__format__()"
method of the value itself.  However, in some cases it is desirable to
force a type to be formatted as a string, overriding its own
definition of formatting.  By converting the value to a string before
calling "__format__()", the normal formatting logic is bypassed.

Three conversion flags are currently supported: "'!s'" which calls
"str()" on the value, "'!r'" which calls "repr()" and "'!a'" which
calls "ascii()".

Some examples:

   "Harold's a clever {0!s}"        # Calls str() on the argument first
   "Bring out the holy {name!r}"    # Calls repr() on the argument first
   "More {!a}"                      # Calls ascii() on the argument first

The *format_spec* field contains a specification of how the value
should be presented, including such details as field width, alignment,
padding, decimal precision and so on.  Each value type can define its
own "formatting mini-language" or interpretation of the *format_spec*.

Most built-in types support a common formatting mini-language, which
is described in the next section.

A *format_spec* field can also include nested replacement fields
within it. These nested replacement fields may contain a field name,
conversion flag and format specification, but deeper nesting is not
allowed.  The replacement fields within the format_spec are
substituted before the *format_spec* string is interpreted. This
allows the formatting of a value to be dynamically specified.

See the Format examples section for some examples.


Format Specification Mini-Language
==================================

"Format specifications" are used within replacement fields contained
within a format string to define how individual values are presented
(see Format String Syntax and Formatted string literals). They can
also be passed directly to the built-in "format()" function.  Each
formattable type may define how the format specification is to be
interpreted.

Most built-in types implement the following options for format
specifications, although some of the formatting options are only
supported by the numeric types.

A general convention is that an empty format string ("""") produces
the same result as if you had called "str()" on the value. A non-empty
format string typically modifies the result.

The general form of a *standard format specifier* is:

   format_spec     ::= [[fill]align][sign][#][0][width][grouping_option][.precision][type]
   fill            ::= <any character>
   align           ::= "<" | ">" | "=" | "^"
   sign            ::= "+" | "-" | " "
   width           ::= digit+
   grouping_option ::= "_" | ","
   precision       ::= digit+
   type            ::= "b" | "c" | "d" | "e" | "E" | "f" | "F" | "g" | "G" | "n" | "o" | "s" | "x" | "X" | "%"

If a valid *align* value is specified, it can be preceded by a *fill*
character that can be any character and defaults to a space if
omitted. It is not possible to use a literal curly brace (""{"" or
""}"") as the *fill* character in a formatted string literal or when
using the "str.format()" method.  However, it is possible to insert a
curly brace with a nested replacement field.  This limitation doesn't
affect the "format()" function.

The meaning of the various alignment options is as follows:

   +-----------+------------------------------------------------------------+
   | Option    | Meaning                                                    |
   +===========+============================================================+
   | "'<'"     | Forces the field to be left-aligned within the available   |
   |           | space (this is the default for most objects).              |
   +-----------+------------------------------------------------------------+
   | "'>'"     | Forces the field to be right-aligned within the available  |
   |           | space (this is the default for numbers).                   |
   +-----------+------------------------------------------------------------+
   | "'='"     | Forces the padding to be placed after the sign (if any)    |
   |           | but before the digits.  This is used for printing fields   |
   |           | in the form '+000000120'. This alignment option is only    |
   |           | valid for numeric types.  It becomes the default when '0'  |
   |           | immediately precedes the field width.                      |
   +-----------+------------------------------------------------------------+
   | "'^'"     | Forces the field to be centered within the available       |
   |           | space.                                                     |
   +-----------+------------------------------------------------------------+

Note that unless a minimum field width is defined, the field width
will always be the same size as the data to fill it, so that the
alignment option has no meaning in this case.

The *sign* option is only valid for number types, and can be one of
the following:

   +-----------+------------------------------------------------------------+
   | Option    | Meaning                                                    |
   +===========+============================================================+
   | "'+'"     | indicates that a sign should be used for both positive as  |
   |           | well as negative numbers.                                  |
   +-----------+------------------------------------------------------------+
   | "'-'"     | indicates that a sign should be used only for negative     |
   |           | numbers (this is the default behavior).                    |
   +-----------+------------------------------------------------------------+
   | space     | indicates that a leading space should be used on positive  |
   |           | numbers, and a minus sign on negative numbers.             |
   +-----------+------------------------------------------------------------+

The "'#'" option causes the "alternate form" to be used for the
conversion.  The alternate form is defined differently for different
types.  This option is only valid for integer, float, complex and
Decimal types. For integers, when binary, octal, or hexadecimal output
is used, this option adds the prefix respective "'0b'", "'0o'", or
"'0x'" to the output value. For floats, complex and Decimal the
alternate form causes the result of the conversion to always contain a
decimal-point character, even if no digits follow it. Normally, a
decimal-point character appears in the result of these conversions
only if a digit follows it. In addition, for "'g'" and "'G'"
conversions, trailing zeros are not removed from the result.

The "','" option signals the use of a comma for a thousands separator.
For a locale aware separator, use the "'n'" integer presentation type
instead.

Changed in version 3.1: Added the "','" option (see also **PEP 378**).

The "'_'" option signals the use of an underscore for a thousands
separator for floating point presentation types and for integer
presentation type "'d'".  For integer presentation types "'b'", "'o'",
"'x'", and "'X'", underscores will be inserted every 4 digits.  For
other presentation types, specifying this option is an error.

Changed in version 3.6: Added the "'_'" option (see also **PEP 515**).

*width* is a decimal integer defining the minimum field width.  If not
specified, then the field width will be determined by the content.

When no explicit alignment is given, preceding the *width* field by a
zero ("'0'") character enables sign-aware zero-padding for numeric
types.  This is equivalent to a *fill* character of "'0'" with an
*alignment* type of "'='".

The *precision* is a decimal number indicating how many digits should
be displayed after the decimal point for a floating point value
formatted with "'f'" and "'F'", or before and after the decimal point
for a floating point value formatted with "'g'" or "'G'".  For non-
number types the field indicates the maximum field size - in other
words, how many characters will be used from the field content. The
*precision* is not allowed for integer values.

Finally, the *type* determines how the data should be presented.

The available string presentation types are:

   +-----------+------------------------------------------------------------+
   | Type      | Meaning                                                    |
   +===========+============================================================+
   | "'s'"     | String format. This is the default type for strings and    |
   |           | may be omitted.                                            |
   +-----------+------------------------------------------------------------+
   | None      | The same as "'s'".                                         |
   +-----------+------------------------------------------------------------+

The available integer presentation types are:

   +-----------+------------------------------------------------------------+
   | Type      | Meaning                                                    |
   +===========+============================================================+
   | "'b'"     | Binary format. Outputs the number in base 2.               |
   +-----------+------------------------------------------------------------+
   | "'c'"     | Character. Converts the integer to the corresponding       |
   |           | unicode character before printing.                         |
   +-----------+------------------------------------------------------------+
   | "'d'"     | Decimal Integer. Outputs the number in base 10.            |
   +-----------+------------------------------------------------------------+
   | "'o'"     | Octal format. Outputs the number in base 8.                |
   +-----------+------------------------------------------------------------+
   | "'x'"     | Hex format. Outputs the number in base 16, using lower-    |
   |           | case letters for the digits above 9.                       |
   +-----------+------------------------------------------------------------+
   | "'X'"     | Hex format. Outputs the number in base 16, using upper-    |
   |           | case letters for the digits above 9.                       |
   +-----------+------------------------------------------------------------+
   | "'n'"     | Number. This is the same as "'d'", except that it uses the |
   |           | current locale setting to insert the appropriate number    |
   |           | separator characters.                                      |
   +-----------+------------------------------------------------------------+
   | None      | The same as "'d'".                                         |
   +-----------+------------------------------------------------------------+

In addition to the above presentation types, integers can be formatted
with the floating point presentation types listed below (except "'n'"
and "None"). When doing so, "float()" is used to convert the integer
to a floating point number before formatting.

The available presentation types for floating point and decimal values
are:

   +-----------+------------------------------------------------------------+
   | Type      | Meaning                                                    |
   +===========+============================================================+
   | "'e'"     | Exponent notation. Prints the number in scientific         |
   |           | notation using the letter 'e' to indicate the exponent.    |
   |           | The default precision is "6".                              |
   +-----------+------------------------------------------------------------+
   | "'E'"     | Exponent notation. Same as "'e'" except it uses an upper   |
   |           | case 'E' as the separator character.                       |
   +-----------+------------------------------------------------------------+
   | "'f'"     | Fixed point. Displays the number as a fixed-point number.  |
   |           | The default precision is "6".                              |
   +-----------+------------------------------------------------------------+
   | "'F'"     | Fixed point. Same as "'f'", but converts "nan" to "NAN"    |
   |           | and "inf" to "INF".                                        |
   +-----------+------------------------------------------------------------+
   | "'g'"     | General format.  For a given precision "p >= 1", this      |
   |           | rounds the number to "p" significant digits and then       |
   |           | formats the result in either fixed-point format or in      |
   |           | scientific notation, depending on its magnitude.  The      |
   |           | precise rules are as follows: suppose that the result      |
   |           | formatted with presentation type "'e'" and precision "p-1" |
   |           | would have exponent "exp".  Then if "-4 <= exp < p", the   |
   |           | number is formatted with presentation type "'f'" and       |
   |           | precision "p-1-exp".  Otherwise, the number is formatted   |
   |           | with presentation type "'e'" and precision "p-1". In both  |
   |           | cases insignificant trailing zeros are removed from the    |
   |           | significand, and the decimal point is also removed if      |
   |           | there are no remaining digits following it.  Positive and  |
   |           | negative infinity, positive and negative zero, and nans,   |
   |           | are formatted as "inf", "-inf", "0", "-0" and "nan"        |
   |           | respectively, regardless of the precision.  A precision of |
   |           | "0" is treated as equivalent to a precision of "1". The    |
   |           | default precision is "6".                                  |
   +-----------+------------------------------------------------------------+
   | "'G'"     | General format. Same as "'g'" except switches to "'E'" if  |
   |           | the number gets too large. The representations of infinity |
   |           | and NaN are uppercased, too.                               |
   +-----------+------------------------------------------------------------+
   | "'n'"     | Number. This is the same as "'g'", except that it uses the |
   |           | current locale setting to insert the appropriate number    |
   |           | separator characters.                                      |
   +-----------+------------------------------------------------------------+
   | "'%'"     | Percentage. Multiplies the number by 100 and displays in   |
   |           | fixed ("'f'") format, followed by a percent sign.          |
   +-----------+------------------------------------------------------------+
   | None      | Similar to "'g'", except that fixed-point notation, when   |
   |           | used, has at least one digit past the decimal point. The   |
   |           | default precision is as high as needed to represent the    |
   |           | particular value. The overall effect is to match the       |
   |           | output of "str()" as altered by the other format           |
   |           | modifiers.                                                 |
   +-----------+------------------------------------------------------------+


Format examples
===============

This section contains examples of the "str.format()" syntax and
comparison with the old "%"-formatting.

In most of the cases the syntax is similar to the old "%"-formatting,
with the addition of the "{}" and with ":" used instead of "%". For
example, "'%03.2f'" can be translated to "'{:03.2f}'".

The new format syntax also supports new and different options, shown
in the follow examples.

Accessing arguments by position:

   >>> '{0}, {1}, {2}'.format('a', 'b', 'c')
   'a, b, c'
   >>> '{}, {}, {}'.format('a', 'b', 'c')  # 3.1+ only
   'a, b, c'
   >>> '{2}, {1}, {0}'.format('a', 'b', 'c')
   'c, b, a'
   >>> '{2}, {1}, {0}'.format(*'abc')      # unpacking argument sequence
   'c, b, a'
   >>> '{0}{1}{0}'.format('abra', 'cad')   # arguments' indices can be repeated
   'abracadabra'

Accessing arguments by name:

   >>> 'Coordinates: {latitude}, {longitude}'.format(latitude='37.24N', longitude='-115.81W')
   'Coordinates: 37.24N, -115.81W'
   >>> coord = {'latitude': '37.24N', 'longitude': '-115.81W'}
   >>> 'Coordinates: {latitude}, {longitude}'.format(**coord)
   'Coordinates: 37.24N, -115.81W'

Accessing arguments' attributes:

   >>> c = 3-5j
   >>> ('The complex number {0} is formed from the real part {0.real} '
   ...  'and the imaginary part {0.imag}.').format(c)
   'The complex number (3-5j) is formed from the real part 3.0 and the imaginary part -5.0.'
   >>> class Point:
   ...     def __init__(self, x, y):
   ...         self.x, self.y = x, y
   ...     def __str__(self):
   ...         return 'Point({self.x}, {self.y})'.format(self=self)
   ...
   >>> str(Point(4, 2))
   'Point(4, 2)'

Accessing arguments' items:

   >>> coord = (3, 5)
   >>> 'X: {0[0]};  Y: {0[1]}'.format(coord)
   'X: 3;  Y: 5'

Replacing "%s" and "%r":

   >>> "repr() shows quotes: {!r}; str() doesn't: {!s}".format('test1', 'test2')
   "repr() shows quotes: 'test1'; str() doesn't: test2"

Aligning the text and specifying a width:

   >>> '{:<30}'.format('left aligned')
   'left aligned                  '
   >>> '{:>30}'.format('right aligned')
   '                 right aligned'
   >>> '{:^30}'.format('centered')
   '           centered           '
   >>> '{:*^30}'.format('centered')  # use '*' as a fill char
   '***********centered***********'

Replacing "%+f", "%-f", and "% f" and specifying a sign:

   >>> '{:+f}; {:+f}'.format(3.14, -3.14)  # show it always
   '+3.140000; -3.140000'
   >>> '{: f}; {: f}'.format(3.14, -3.14)  # show a space for positive numbers
   ' 3.140000; -3.140000'
   >>> '{:-f}; {:-f}'.format(3.14, -3.14)  # show only the minus -- same as '{:f}; {:f}'
   '3.140000; -3.140000'

Replacing "%x" and "%o" and converting the value to different bases:

   >>> # format also supports binary numbers
   >>> "int: {0:d};  hex: {0:x};  oct: {0:o};  bin: {0:b}".format(42)
   'int: 42;  hex: 2a;  oct: 52;  bin: 101010'
   >>> # with 0x, 0o, or 0b as prefix:
   >>> "int: {0:d};  hex: {0:#x};  oct: {0:#o};  bin: {0:#b}".format(42)
   'int: 42;  hex: 0x2a;  oct: 0o52;  bin: 0b101010'

Using the comma as a thousands separator:

   >>> '{:,}'.format(1234567890)
   '1,234,567,890'

Expressing a percentage:

   >>> points = 19
   >>> total = 22
   >>> 'Correct answers: {:.2%}'.format(points/total)
   'Correct answers: 86.36%'

Using type-specific formatting:

   >>> import datetime
   >>> d = datetime.datetime(2010, 7, 4, 12, 15, 58)
   >>> '{:%Y-%m-%d %H:%M:%S}'.format(d)
   '2010-07-04 12:15:58'

Nesting arguments and more complex examples:

   >>> for align, text in zip('<^>', ['left', 'center', 'right']):
   ...     '{0:{fill}{align}16}'.format(text, fill=align, align=align)
   ...
   'left<<<<<<<<<<<<'
   '^^^^^center^^^^^'
   '>>>>>>>>>>>right'
   >>>
   >>> octets = [192, 168, 0, 1]
   >>> '{:02X}{:02X}{:02X}{:02X}'.format(*octets)
   'C0A80001'
   >>> int(_, 16)
   3232235521
   >>>
   >>> width = 5
   >>> for num in range(5,12): #doctest: +NORMALIZE_WHITESPACE
   ...     for base in 'dXob':
   ...         print('{0:{width}{base}}'.format(num, base=base, width=width), end=' ')
   ...     print()
   ...
       5     5     5   101
       6     6     6   110
       7     7     7   111
       8     8    10  1000
       9     9    11  1001
      10     A    12  1010
      11     B    13  1011
zfunctiona  Function definitions
********************

A function definition defines a user-defined function object (see
section The standard type hierarchy):

   funcdef                 ::= [decorators] "def" funcname "(" [parameter_list] ")" ["->" expression] ":" suite
   decorators              ::= decorator+
   decorator               ::= "@" dotted_name ["(" [argument_list [","]] ")"] NEWLINE
   dotted_name             ::= identifier ("." identifier)*
   parameter_list          ::= defparameter ("," defparameter)* ["," [parameter_list_starargs]]
                      | parameter_list_starargs
   parameter_list_starargs ::= "*" [parameter] ("," defparameter)* ["," ["**" parameter [","]]]
                               | "**" parameter [","]
   parameter               ::= identifier [":" expression]
   defparameter            ::= parameter ["=" expression]
   funcname                ::= identifier

A function definition is an executable statement.  Its execution binds
the function name in the current local namespace to a function object
(a wrapper around the executable code for the function).  This
function object contains a reference to the current global namespace
as the global namespace to be used when the function is called.

The function definition does not execute the function body; this gets
executed only when the function is called. [3]

A function definition may be wrapped by one or more *decorator*
expressions. Decorator expressions are evaluated when the function is
defined, in the scope that contains the function definition.  The
result must be a callable, which is invoked with the function object
as the only argument. The returned value is bound to the function name
instead of the function object.  Multiple decorators are applied in
nested fashion. For example, the following code

   @f1(arg)
   @f2
   def func(): pass

is roughly equivalent to

   def func(): pass
   func = f1(arg)(f2(func))

except that the original function is not temporarily bound to the name
"func".

When one or more *parameters* have the form *parameter* "="
*expression*, the function is said to have "default parameter values."
For a parameter with a default value, the corresponding *argument* may
be omitted from a call, in which case the parameter's default value is
substituted.  If a parameter has a default value, all following
parameters up until the ""*"" must also have a default value --- this
is a syntactic restriction that is not expressed by the grammar.

**Default parameter values are evaluated from left to right when the
function definition is executed.** This means that the expression is
evaluated once, when the function is defined, and that the same "pre-
computed" value is used for each call.  This is especially important
to understand when a default parameter is a mutable object, such as a
list or a dictionary: if the function modifies the object (e.g. by
appending an item to a list), the default value is in effect modified.
This is generally not what was intended.  A way around this is to use
"None" as the default, and explicitly test for it in the body of the
function, e.g.:

   def whats_on_the_telly(penguin=None):
       if penguin is None:
           penguin = []
       penguin.append("property of the zoo")
       return penguin

Function call semantics are described in more detail in section Calls.
A function call always assigns values to all parameters mentioned in
the parameter list, either from position arguments, from keyword
arguments, or from default values.  If the form ""*identifier"" is
present, it is initialized to a tuple receiving any excess positional
parameters, defaulting to the empty tuple. If the form
""**identifier"" is present, it is initialized to a new ordered
mapping receiving any excess keyword arguments, defaulting to a new
empty mapping of the same type.  Parameters after ""*"" or
""*identifier"" are keyword-only parameters and may only be passed
used keyword arguments.

Parameters may have annotations of the form "": expression"" following
the parameter name.  Any parameter may have an annotation even those
of the form "*identifier" or "**identifier".  Functions may have
"return" annotation of the form ""-> expression"" after the parameter
list.  These annotations can be any valid Python expression and are
evaluated when the function definition is executed.  Annotations may
be evaluated in a different order than they appear in the source code.
The presence of annotations does not change the semantics of a
function.  The annotation values are available as values of a
dictionary keyed by the parameters' names in the "__annotations__"
attribute of the function object.

It is also possible to create anonymous functions (functions not bound
to a name), for immediate use in expressions.  This uses lambda
expressions, described in section Lambdas.  Note that the lambda
expression is merely a shorthand for a simplified function definition;
a function defined in a ""def"" statement can be passed around or
assigned to another name just like a function defined by a lambda
expression.  The ""def"" form is actually more powerful since it
allows the execution of multiple statements and annotations.

**Programmer's note:** Functions are first-class objects.  A ""def""
statement executed inside a function definition defines a local
function that can be returned or passed around.  Free variables used
in the nested function can access the local variables of the function
containing the def.  See section Naming and binding for details.

See also:

  **PEP 3107** - Function Annotations
     The original specification for function annotations.
zglobala¿  The "global" statement
**********************

   global_stmt ::= "global" identifier ("," identifier)*

The "global" statement is a declaration which holds for the entire
current code block.  It means that the listed identifiers are to be
interpreted as globals.  It would be impossible to assign to a global
variable without "global", although free variables may refer to
globals without being declared global.

Names listed in a "global" statement must not be used in the same code
block textually preceding that "global" statement.

Names listed in a "global" statement must not be defined as formal
parameters or in a "for" loop control target, "class" definition,
function definition, "import" statement, or variable annotation.

**CPython implementation detail:** The current implementation does not
enforce some of these restrictions, but programs should not abuse this
freedom, as future implementations may enforce them or silently change
the meaning of the program.

**Programmer's note:** "global" is a directive to the parser.  It
applies only to code parsed at the same time as the "global"
statement. In particular, a "global" statement contained in a string
or code object supplied to the built-in "exec()" function does not
affect the code block *containing* the function call, and code
contained in such a string is unaffected by "global" statements in the
code containing the function call.  The same applies to the "eval()"
and "compile()" functions.
z
id-classesa  Reserved classes of identifiers
*******************************

Certain classes of identifiers (besides keywords) have special
meanings.  These classes are identified by the patterns of leading and
trailing underscore characters:

"_*"
   Not imported by "from module import *".  The special identifier "_"
   is used in the interactive interpreter to store the result of the
   last evaluation; it is stored in the "builtins" module.  When not
   in interactive mode, "_" has no special meaning and is not defined.
   See section The import statement.

   Note: The name "_" is often used in conjunction with
     internationalization; refer to the documentation for the
     "gettext" module for more information on this convention.

"__*__"
   System-defined names. These names are defined by the interpreter
   and its implementation (including the standard library).  Current
   system names are discussed in the Special method names section and
   elsewhere.  More will likely be defined in future versions of
   Python.  *Any* use of "__*__" names, in any context, that does not
   follow explicitly documented use, is subject to breakage without
   warning.

"__*"
   Class-private names.  Names in this category, when used within the
   context of a class definition, are re-written to use a mangled form
   to help avoid name clashes between "private" attributes of base and
   derived classes. See section Identifiers (Names).
zidentifiersa$  Identifiers and keywords
************************

Identifiers (also referred to as *names*) are described by the
following lexical definitions.

The syntax of identifiers in Python is based on the Unicode standard
annex UAX-31, with elaboration and changes as defined below; see also
**PEP 3131** for further details.

Within the ASCII range (U+0001..U+007F), the valid characters for
identifiers are the same as in Python 2.x: the uppercase and lowercase
letters "A" through "Z", the underscore "_" and, except for the first
character, the digits "0" through "9".

Python 3.0 introduces additional characters from outside the ASCII
range (see **PEP 3131**).  For these characters, the classification
uses the version of the Unicode Character Database as included in the
"unicodedata" module.

Identifiers are unlimited in length.  Case is significant.

   identifier   ::= xid_start xid_continue*
   id_start     ::= <all characters in general categories Lu, Ll, Lt, Lm, Lo, Nl, the underscore, and characters with the Other_ID_Start property>
   id_continue  ::= <all characters in id_start, plus characters in the categories Mn, Mc, Nd, Pc and others with the Other_ID_Continue property>
   xid_start    ::= <all characters in id_start whose NFKC normalization is in "id_start xid_continue*">
   xid_continue ::= <all characters in id_continue whose NFKC normalization is in "id_continue*">

The Unicode category codes mentioned above stand for:

* *Lu* - uppercase letters

* *Ll* - lowercase letters

* *Lt* - titlecase letters

* *Lm* - modifier letters

* *Lo* - other letters

* *Nl* - letter numbers

* *Mn* - nonspacing marks

* *Mc* - spacing combining marks

* *Nd* - decimal numbers

* *Pc* - connector punctuations

* *Other_ID_Start* - explicit list of characters in PropList.txt to
  support backwards compatibility

* *Other_ID_Continue* - likewise

All identifiers are converted into the normal form NFKC while parsing;
comparison of identifiers is based on NFKC.

A non-normative HTML file listing all valid identifier characters for
Unicode 4.1 can be found at https://www.dcl.hpi.uni-
potsdam.de/home/loewis/table-3131.html.


Keywords
========

The following identifiers are used as reserved words, or *keywords* of
the language, and cannot be used as ordinary identifiers.  They must
be spelled exactly as written here:

   False      class      finally    is         return
   None       continue   for        lambda     try
   True       def        from       nonlocal   while
   and        del        global     not        with
   as         elif       if         or         yield
   assert     else       import     pass
   break      except     in         raise


Reserved classes of identifiers
===============================

Certain classes of identifiers (besides keywords) have special
meanings.  These classes are identified by the patterns of leading and
trailing underscore characters:

"_*"
   Not imported by "from module import *".  The special identifier "_"
   is used in the interactive interpreter to store the result of the
   last evaluation; it is stored in the "builtins" module.  When not
   in interactive mode, "_" has no special meaning and is not defined.
   See section The import statement.

   Note: The name "_" is often used in conjunction with
     internationalization; refer to the documentation for the
     "gettext" module for more information on this convention.

"__*__"
   System-defined names. These names are defined by the interpreter
   and its implementation (including the standard library).  Current
   system names are discussed in the Special method names section and
   elsewhere.  More will likely be defined in future versions of
   Python.  *Any* use of "__*__" names, in any context, that does not
   follow explicitly documented use, is subject to breakage without
   warning.

"__*"
   Class-private names.  Names in this category, when used within the
   context of a class definition, are re-written to use a mangled form
   to help avoid name clashes between "private" attributes of base and
   derived classes. See section Identifiers (Names).
zifaD  The "if" statement
******************

The "if" statement is used for conditional execution:

   if_stmt ::= "if" expression ":" suite
               ( "elif" expression ":" suite )*
               ["else" ":" suite]

It selects exactly one of the suites by evaluating the expressions one
by one until one is found to be true (see section Boolean operations
for the definition of true and false); then that suite is executed
(and no other part of the "if" statement is executed or evaluated).
If all expressions are false, the suite of the "else" clause, if
present, is executed.
z	imaginarya5  Imaginary literals
******************

Imaginary literals are described by the following lexical definitions:

   imagnumber ::= (floatnumber | digitpart) ("j" | "J")

An imaginary literal yields a complex number with a real part of 0.0.
Complex numbers are represented as a pair of floating point numbers
and have the same restrictions on their range.  To create a complex
number with a nonzero real part, add a floating point number to it,
e.g., "(3+4j)".  Some examples of imaginary literals:

   3.14j   10.j    10j     .001j   1e100j   3.14e-10j   3.14_15_93j
zimporta!  The "import" statement
**********************

   import_stmt     ::= "import" module ["as" name] ( "," module ["as" name] )*
                   | "from" relative_module "import" identifier ["as" name]
                   ( "," identifier ["as" name] )*
                   | "from" relative_module "import" "(" identifier ["as" name]
                   ( "," identifier ["as" name] )* [","] ")"
                   | "from" module "import" "*"
   module          ::= (identifier ".")* identifier
   relative_module ::= "."* module | "."+
   name            ::= identifier

The basic import statement (no "from" clause) is executed in two
steps:

1. find a module, loading and initializing it if necessary

2. define a name or names in the local namespace for the scope
   where the "import" statement occurs.

When the statement contains multiple clauses (separated by commas) the
two steps are carried out separately for each clause, just as though
the clauses had been separated out into individual import statements.

The details of the first step, finding and loading modules are
described in greater detail in the section on the import system, which
also describes the various types of packages and modules that can be
imported, as well as all the hooks that can be used to customize the
import system. Note that failures in this step may indicate either
that the module could not be located, *or* that an error occurred
while initializing the module, which includes execution of the
module's code.

If the requested module is retrieved successfully, it will be made
available in the local namespace in one of three ways:

* If the module name is followed by "as", then the name following
  "as" is bound directly to the imported module.

* If no other name is specified, and the module being imported is a
  top level module, the module's name is bound in the local namespace
  as a reference to the imported module

* If the module being imported is *not* a top level module, then the
  name of the top level package that contains the module is bound in
  the local namespace as a reference to the top level package. The
  imported module must be accessed using its full qualified name
  rather than directly

The "from" form uses a slightly more complex process:

1. find the module specified in the "from" clause, loading and
   initializing it if necessary;

2. for each of the identifiers specified in the "import" clauses:

   1. check if the imported module has an attribute by that name

   2. if not, attempt to import a submodule with that name and then
      check the imported module again for that attribute

   3. if the attribute is not found, "ImportError" is raised.

   4. otherwise, a reference to that value is stored in the local
      namespace, using the name in the "as" clause if it is present,
      otherwise using the attribute name

Examples:

   import foo                 # foo imported and bound locally
   import foo.bar.baz         # foo.bar.baz imported, foo bound locally
   import foo.bar.baz as fbb  # foo.bar.baz imported and bound as fbb
   from foo.bar import baz    # foo.bar.baz imported and bound as baz
   from foo import attr       # foo imported and foo.attr bound as attr

If the list of identifiers is replaced by a star ("'*'"), all public
names defined in the module are bound in the local namespace for the
scope where the "import" statement occurs.

The *public names* defined by a module are determined by checking the
module's namespace for a variable named "__all__"; if defined, it must
be a sequence of strings which are names defined or imported by that
module.  The names given in "__all__" are all considered public and
are required to exist.  If "__all__" is not defined, the set of public
names includes all names found in the module's namespace which do not
begin with an underscore character ("'_'").  "__all__" should contain
the entire public API. It is intended to avoid accidentally exporting
items that are not part of the API (such as library modules which were
imported and used within the module).

The wild card form of import --- "from module import *" --- is only
allowed at the module level.  Attempting to use it in class or
function definitions will raise a "SyntaxError".

When specifying what module to import you do not have to specify the
absolute name of the module. When a module or package is contained
within another package it is possible to make a relative import within
the same top package without having to mention the package name. By
using leading dots in the specified module or package after "from" you
can specify how high to traverse up the current package hierarchy
without specifying exact names. One leading dot means the current
package where the module making the import exists. Two dots means up
one package level. Three dots is up two levels, etc. So if you execute
"from . import mod" from a module in the "pkg" package then you will
end up importing "pkg.mod". If you execute "from ..subpkg2 import mod"
from within "pkg.subpkg1" you will import "pkg.subpkg2.mod". The
specification for relative imports is contained within **PEP 328**.

"importlib.import_module()" is provided to support applications that
determine dynamically the modules to be loaded.


Future statements
=================

A *future statement* is a directive to the compiler that a particular
module should be compiled using syntax or semantics that will be
available in a specified future release of Python where the feature
becomes standard.

The future statement is intended to ease migration to future versions
of Python that introduce incompatible changes to the language.  It
allows use of the new features on a per-module basis before the
release in which the feature becomes standard.

   future_statement ::= "from" "__future__" "import" feature ["as" name]
                        ("," feature ["as" name])*
                        | "from" "__future__" "import" "(" feature ["as" name]
                        ("," feature ["as" name])* [","] ")"
   feature          ::= identifier
   name             ::= identifier

A future statement must appear near the top of the module.  The only
lines that can appear before a future statement are:

* the module docstring (if any),

* comments,

* blank lines, and

* other future statements.

The features recognized by Python 3.0 are "absolute_import",
"division", "generators", "unicode_literals", "print_function",
"nested_scopes" and "with_statement".  They are all redundant because
they are always enabled, and only kept for backwards compatibility.

A future statement is recognized and treated specially at compile
time: Changes to the semantics of core constructs are often
implemented by generating different code.  It may even be the case
that a new feature introduces new incompatible syntax (such as a new
reserved word), in which case the compiler may need to parse the
module differently.  Such decisions cannot be pushed off until
runtime.

For any given release, the compiler knows which feature names have
been defined, and raises a compile-time error if a future statement
contains a feature not known to it.

The direct runtime semantics are the same as for any import statement:
there is a standard module "__future__", described later, and it will
be imported in the usual way at the time the future statement is
executed.

The interesting runtime semantics depend on the specific feature
enabled by the future statement.

Note that there is nothing special about the statement:

   import __future__ [as name]

That is not a future statement; it's an ordinary import statement with
no special semantics or syntax restrictions.

Code compiled by calls to the built-in functions "exec()" and
"compile()" that occur in a module "M" containing a future statement
will, by default, use the new syntax or semantics associated with the
future statement.  This can be controlled by optional arguments to
"compile()" --- see the documentation of that function for details.

A future statement typed at an interactive interpreter prompt will
take effect for the rest of the interpreter session.  If an
interpreter is started with the "-i" option, is passed a script name
to execute, and the script includes a future statement, it will be in
effect in the interactive session started after the script is
executed.

See also:

  **PEP 236** - Back to the __future__
     The original proposal for the __future__ mechanism.
zinaO  Membership test operations
**************************

The operators "in" and "not in" test for membership.  "x in s"
evaluates to "True" if *x* is a member of *s*, and "False" otherwise.
"x not in s" returns the negation of "x in s".  All built-in sequences
and set types support this as well as dictionary, for which "in" tests
whether the dictionary has a given key. For container types such as
list, tuple, set, frozenset, dict, or collections.deque, the
expression "x in y" is equivalent to "any(x is e or x == e for e in
y)".

For the string and bytes types, "x in y" is "True" if and only if *x*
is a substring of *y*.  An equivalent test is "y.find(x) != -1".
Empty strings are always considered to be a substring of any other
string, so """ in "abc"" will return "True".

For user-defined classes which define the "__contains__()" method, "x
in y" returns "True" if "y.__contains__(x)" returns a true value, and
"False" otherwise.

For user-defined classes which do not define "__contains__()" but do
define "__iter__()", "x in y" is "True" if some value "z" with "x ==
z" is produced while iterating over "y".  If an exception is raised
during the iteration, it is as if "in" raised that exception.

Lastly, the old-style iteration protocol is tried: if a class defines
"__getitem__()", "x in y" is "True" if and only if there is a non-
negative integer index *i* such that "x == y[i]", and all lower
integer indices do not raise "IndexError" exception.  (If any other
exception is raised, it is as if "in" raised that exception).

The operator "not in" is defined to have the inverse true value of
"in".
zintegersaV  Integer literals
****************

Integer literals are described by the following lexical definitions:

   integer      ::= decinteger | bininteger | octinteger | hexinteger
   decinteger   ::= nonzerodigit (["_"] digit)* | "0"+ (["_"] "0")*
   bininteger   ::= "0" ("b" | "B") (["_"] bindigit)+
   octinteger   ::= "0" ("o" | "O") (["_"] octdigit)+
   hexinteger   ::= "0" ("x" | "X") (["_"] hexdigit)+
   nonzerodigit ::= "1"..."9"
   digit        ::= "0"..."9"
   bindigit     ::= "0" | "1"
   octdigit     ::= "0"..."7"
   hexdigit     ::= digit | "a"..."f" | "A"..."F"

There is no limit for the length of integer literals apart from what
can be stored in available memory.

Underscores are ignored for determining the numeric value of the
literal.  They can be used to group digits for enhanced readability.
One underscore can occur between digits, and after base specifiers
like "0x".

Note that leading zeros in a non-zero decimal number are not allowed.
This is for disambiguation with C-style octal literals, which Python
used before version 3.0.

Some examples of integer literals:

   7     2147483647                        0o177    0b100110111
   3     79228162514264337593543950336     0o377    0xdeadbeef
         100_000_000_000                   0b_1110_0101

Changed in version 3.6: Underscores are now allowed for grouping
purposes in literals.
zlambdaaV  Lambdas
*******

   lambda_expr        ::= "lambda" [parameter_list]: expression
   lambda_expr_nocond ::= "lambda" [parameter_list]: expression_nocond

Lambda expressions (sometimes called lambda forms) are used to create
anonymous functions. The expression "lambda arguments: expression"
yields a function object.  The unnamed object behaves like a function
object defined with:

   def <lambda>(arguments):
       return expression

See section Function definitions for the syntax of parameter lists.
Note that functions created with lambda expressions cannot contain
statements or annotations.
zlistsa/  List displays
*************

A list display is a possibly empty series of expressions enclosed in
square brackets:

   list_display ::= "[" [starred_list | comprehension] "]"

A list display yields a new list object, the contents being specified
by either a list of expressions or a comprehension.  When a comma-
separated list of expressions is supplied, its elements are evaluated
from left to right and placed into the list object in that order.
When a comprehension is supplied, the list is constructed from the
elements resulting from the comprehension.
znamingaï  Naming and binding
******************


Binding of names
================

*Names* refer to objects.  Names are introduced by name binding
operations.

The following constructs bind names: formal parameters to functions,
"import" statements, class and function definitions (these bind the
class or function name in the defining block), and targets that are
identifiers if occurring in an assignment, "for" loop header, or after
"as" in a "with" statement or "except" clause. The "import" statement
of the form "from ... import *" binds all names defined in the
imported module, except those beginning with an underscore.  This form
may only be used at the module level.

A target occurring in a "del" statement is also considered bound for
this purpose (though the actual semantics are to unbind the name).

Each assignment or import statement occurs within a block defined by a
class or function definition or at the module level (the top-level
code block).

If a name is bound in a block, it is a local variable of that block,
unless declared as "nonlocal" or "global".  If a name is bound at the
module level, it is a global variable.  (The variables of the module
code block are local and global.)  If a variable is used in a code
block but not defined there, it is a *free variable*.

Each occurrence of a name in the program text refers to the *binding*
of that name established by the following name resolution rules.


Resolution of names
===================

A *scope* defines the visibility of a name within a block.  If a local
variable is defined in a block, its scope includes that block.  If the
definition occurs in a function block, the scope extends to any blocks
contained within the defining one, unless a contained block introduces
a different binding for the name.

When a name is used in a code block, it is resolved using the nearest
enclosing scope.  The set of all such scopes visible to a code block
is called the block's *environment*.

When a name is not found at all, a "NameError" exception is raised. If
the current scope is a function scope, and the name refers to a local
variable that has not yet been bound to a value at the point where the
name is used, an "UnboundLocalError" exception is raised.
"UnboundLocalError" is a subclass of "NameError".

If a name binding operation occurs anywhere within a code block, all
uses of the name within the block are treated as references to the
current block.  This can lead to errors when a name is used within a
block before it is bound.  This rule is subtle.  Python lacks
declarations and allows name binding operations to occur anywhere
within a code block.  The local variables of a code block can be
determined by scanning the entire text of the block for name binding
operations.

If the "global" statement occurs within a block, all uses of the name
specified in the statement refer to the binding of that name in the
top-level namespace.  Names are resolved in the top-level namespace by
searching the global namespace, i.e. the namespace of the module
containing the code block, and the builtins namespace, the namespace
of the module "builtins".  The global namespace is searched first.  If
the name is not found there, the builtins namespace is searched.  The
"global" statement must precede all uses of the name.

The "global" statement has the same scope as a name binding operation
in the same block.  If the nearest enclosing scope for a free variable
contains a global statement, the free variable is treated as a global.

The "nonlocal" statement causes corresponding names to refer to
previously bound variables in the nearest enclosing function scope.
"SyntaxError" is raised at compile time if the given name does not
exist in any enclosing function scope.

The namespace for a module is automatically created the first time a
module is imported.  The main module for a script is always called
"__main__".

Class definition blocks and arguments to "exec()" and "eval()" are
special in the context of name resolution. A class definition is an
executable statement that may use and define names. These references
follow the normal rules for name resolution with an exception that
unbound local variables are looked up in the global namespace. The
namespace of the class definition becomes the attribute dictionary of
the class. The scope of names defined in a class block is limited to
the class block; it does not extend to the code blocks of methods --
this includes comprehensions and generator expressions since they are
implemented using a function scope.  This means that the following
will fail:

   class A:
       a = 42
       b = list(a + i for i in range(10))


Builtins and restricted execution
=================================

**CPython implementation detail:** Users should not touch
"__builtins__"; it is strictly an implementation detail.  Users
wanting to override values in the builtins namespace should "import"
the "builtins" module and modify its attributes appropriately.

The builtins namespace associated with the execution of a code block
is actually found by looking up the name "__builtins__" in its global
namespace; this should be a dictionary or a module (in the latter case
the module's dictionary is used).  By default, when in the "__main__"
module, "__builtins__" is the built-in module "builtins"; when in any
other module, "__builtins__" is an alias for the dictionary of the
"builtins" module itself.


Interaction with dynamic features
=================================

Name resolution of free variables occurs at runtime, not at compile
time. This means that the following code will print 42:

   i = 10
   def f():
       print(i)
   i = 42
   f()

The "eval()" and "exec()" functions do not have access to the full
environment for resolving names.  Names may be resolved in the local
and global namespaces of the caller.  Free variables are not resolved
in the nearest enclosing namespace, but in the global namespace.  [1]
The "exec()" and "eval()" functions have optional arguments to
override the global and local namespace.  If only one namespace is
specified, it is used for both.
znonlocala¢  The "nonlocal" statement
************************

   nonlocal_stmt ::= "nonlocal" identifier ("," identifier)*

The "nonlocal" statement causes the listed identifiers to refer to
previously bound variables in the nearest enclosing scope excluding
globals. This is important because the default behavior for binding is
to search the local namespace first.  The statement allows
encapsulated code to rebind variables outside of the local scope
besides the global (module) scope.

Names listed in a "nonlocal" statement, unlike those listed in a
"global" statement, must refer to pre-existing bindings in an
enclosing scope (the scope in which a new binding should be created
cannot be determined unambiguously).

Names listed in a "nonlocal" statement must not collide with pre-
existing bindings in the local scope.

See also:

  **PEP 3104** - Access to Names in Outer Scopes
     The specification for the "nonlocal" statement.
znumbersa  Numeric literals
****************

There are three types of numeric literals: integers, floating point
numbers, and imaginary numbers.  There are no complex literals
(complex numbers can be formed by adding a real number and an
imaginary number).

Note that numeric literals do not include a sign; a phrase like "-1"
is actually an expression composed of the unary operator '"-"' and the
literal "1".
znumeric-typesa¾  Emulating numeric types
***********************

The following methods can be defined to emulate numeric objects.
Methods corresponding to operations that are not supported by the
particular kind of number implemented (e.g., bitwise operations for
non-integral numbers) should be left undefined.

object.__add__(self, other)
object.__sub__(self, other)
object.__mul__(self, other)
object.__matmul__(self, other)
object.__truediv__(self, other)
object.__floordiv__(self, other)
object.__mod__(self, other)
object.__divmod__(self, other)
object.__pow__(self, other[, modulo])
object.__lshift__(self, other)
object.__rshift__(self, other)
object.__and__(self, other)
object.__xor__(self, other)
object.__or__(self, other)

   These methods are called to implement the binary arithmetic
   operations ("+", "-", "*", "@", "/", "//", "%", "divmod()",
   "pow()", "**", "<<", ">>", "&", "^", "|").  For instance, to
   evaluate the expression "x + y", where *x* is an instance of a
   class that has an "__add__()" method, "x.__add__(y)" is called.
   The "__divmod__()" method should be the equivalent to using
   "__floordiv__()" and "__mod__()"; it should not be related to
   "__truediv__()".  Note that "__pow__()" should be defined to accept
   an optional third argument if the ternary version of the built-in
   "pow()" function is to be supported.

   If one of those methods does not support the operation with the
   supplied arguments, it should return "NotImplemented".

object.__radd__(self, other)
object.__rsub__(self, other)
object.__rmul__(self, other)
object.__rmatmul__(self, other)
object.__rtruediv__(self, other)
object.__rfloordiv__(self, other)
object.__rmod__(self, other)
object.__rdivmod__(self, other)
object.__rpow__(self, other)
object.__rlshift__(self, other)
object.__rrshift__(self, other)
object.__rand__(self, other)
object.__rxor__(self, other)
object.__ror__(self, other)

   These methods are called to implement the binary arithmetic
   operations ("+", "-", "*", "@", "/", "//", "%", "divmod()",
   "pow()", "**", "<<", ">>", "&", "^", "|") with reflected (swapped)
   operands.  These functions are only called if the left operand does
   not support the corresponding operation [3] and the operands are of
   different types. [4] For instance, to evaluate the expression "x -
   y", where *y* is an instance of a class that has an "__rsub__()"
   method, "y.__rsub__(x)" is called if "x.__sub__(y)" returns
   *NotImplemented*.

   Note that ternary "pow()" will not try calling "__rpow__()" (the
   coercion rules would become too complicated).

   Note: If the right operand's type is a subclass of the left
     operand's type and that subclass provides the reflected method
     for the operation, this method will be called before the left
     operand's non-reflected method.  This behavior allows subclasses
     to override their ancestors' operations.

object.__iadd__(self, other)
object.__isub__(self, other)
object.__imul__(self, other)
object.__imatmul__(self, other)
object.__itruediv__(self, other)
object.__ifloordiv__(self, other)
object.__imod__(self, other)
object.__ipow__(self, other[, modulo])
object.__ilshift__(self, other)
object.__irshift__(self, other)
object.__iand__(self, other)
object.__ixor__(self, other)
object.__ior__(self, other)

   These methods are called to implement the augmented arithmetic
   assignments ("+=", "-=", "*=", "@=", "/=", "//=", "%=", "**=",
   "<<=", ">>=", "&=", "^=", "|=").  These methods should attempt to
   do the operation in-place (modifying *self*) and return the result
   (which could be, but does not have to be, *self*).  If a specific
   method is not defined, the augmented assignment falls back to the
   normal methods.  For instance, if *x* is an instance of a class
   with an "__iadd__()" method, "x += y" is equivalent to "x =
   x.__iadd__(y)" . Otherwise, "x.__add__(y)" and "y.__radd__(x)" are
   considered, as with the evaluation of "x + y". In certain
   situations, augmented assignment can result in unexpected errors
   (see Why does a_tuple[i] += ['item'] raise an exception when the
   addition works?), but this behavior is in fact part of the data
   model.

object.__neg__(self)
object.__pos__(self)
object.__abs__(self)
object.__invert__(self)

   Called to implement the unary arithmetic operations ("-", "+",
   "abs()" and "~").

object.__complex__(self)
object.__int__(self)
object.__float__(self)

   Called to implement the built-in functions "complex()", "int()" and
   "float()".  Should return a value of the appropriate type.

object.__index__(self)

   Called to implement "operator.index()", and whenever Python needs
   to losslessly convert the numeric object to an integer object (such
   as in slicing, or in the built-in "bin()", "hex()" and "oct()"
   functions). Presence of this method indicates that the numeric
   object is an integer type.  Must return an integer.

   Note: In order to have a coherent integer type class, when
     "__index__()" is defined "__int__()" should also be defined, and
     both should return the same value.

object.__round__(self[, ndigits])
object.__trunc__(self)
object.__floor__(self)
object.__ceil__(self)

   Called to implement the built-in function "round()" and "math"
   functions "trunc()", "floor()" and "ceil()". Unless *ndigits* is
   passed to "__round__()" all these methods should return the value
   of the object truncated to an "Integral" (typically an "int").

   If "__int__()" is not defined then the built-in function "int()"
   falls back to "__trunc__()".
zobjectsaÙ  Objects, values and types
*************************

*Objects* are Python's abstraction for data.  All data in a Python
program is represented by objects or by relations between objects. (In
a sense, and in conformance to Von Neumann's model of a "stored
program computer," code is also represented by objects.)

Every object has an identity, a type and a value.  An object's
*identity* never changes once it has been created; you may think of it
as the object's address in memory.  The '"is"' operator compares the
identity of two objects; the "id()" function returns an integer
representing its identity.

**CPython implementation detail:** For CPython, "id(x)" is the memory
address where "x" is stored.

An object's type determines the operations that the object supports
(e.g., "does it have a length?") and also defines the possible values
for objects of that type.  The "type()" function returns an object's
type (which is an object itself).  Like its identity, an object's
*type* is also unchangeable. [1]

The *value* of some objects can change.  Objects whose value can
change are said to be *mutable*; objects whose value is unchangeable
once they are created are called *immutable*. (The value of an
immutable container object that contains a reference to a mutable
object can change when the latter's value is changed; however the
container is still considered immutable, because the collection of
objects it contains cannot be changed.  So, immutability is not
strictly the same as having an unchangeable value, it is more subtle.)
An object's mutability is determined by its type; for instance,
numbers, strings and tuples are immutable, while dictionaries and
lists are mutable.

Objects are never explicitly destroyed; however, when they become
unreachable they may be garbage-collected.  An implementation is
allowed to postpone garbage collection or omit it altogether --- it is
a matter of implementation quality how garbage collection is
implemented, as long as no objects are collected that are still
reachable.

**CPython implementation detail:** CPython currently uses a reference-
counting scheme with (optional) delayed detection of cyclically linked
garbage, which collects most objects as soon as they become
unreachable, but is not guaranteed to collect garbage containing
circular references.  See the documentation of the "gc" module for
information on controlling the collection of cyclic garbage. Other
implementations act differently and CPython may change. Do not depend
on immediate finalization of objects when they become unreachable (so
you should always close files explicitly).

Note that the use of the implementation's tracing or debugging
facilities may keep objects alive that would normally be collectable.
Also note that catching an exception with a '"try"..."except"'
statement may keep objects alive.

Some objects contain references to "external" resources such as open
files or windows.  It is understood that these resources are freed
when the object is garbage-collected, but since garbage collection is
not guaranteed to happen, such objects also provide an explicit way to
release the external resource, usually a "close()" method. Programs
are strongly recommended to explicitly close such objects.  The
'"try"..."finally"' statement and the '"with"' statement provide
convenient ways to do this.

Some objects contain references to other objects; these are called
*containers*. Examples of containers are tuples, lists and
dictionaries.  The references are part of a container's value.  In
most cases, when we talk about the value of a container, we imply the
values, not the identities of the contained objects; however, when we
talk about the mutability of a container, only the identities of the
immediately contained objects are implied.  So, if an immutable
container (like a tuple) contains a reference to a mutable object, its
value changes if that mutable object is changed.

Types affect almost all aspects of object behavior.  Even the
importance of object identity is affected in some sense: for immutable
types, operations that compute new values may actually return a
reference to any existing object with the same type and value, while
for mutable objects this is not allowed.  E.g., after "a = 1; b = 1",
"a" and "b" may or may not refer to the same object with the value
one, depending on the implementation, but after "c = []; d = []", "c"
and "d" are guaranteed to refer to two different, unique, newly
created empty lists. (Note that "c = d = []" assigns the same object
to both "c" and "d".)
zoperator-summaryaÏ  Operator precedence
*******************

The following table summarizes the operator precedence in Python, from
lowest precedence (least binding) to highest precedence (most
binding).  Operators in the same box have the same precedence.  Unless
the syntax is explicitly given, operators are binary.  Operators in
the same box group left to right (except for exponentiation, which
groups from right to left).

Note that comparisons, membership tests, and identity tests, all have
the same precedence and have a left-to-right chaining feature as
described in the Comparisons section.

+-------------------------------------------------+---------------------------------------+
| Operator                                        | Description                           |
+=================================================+=======================================+
| "lambda"                                        | Lambda expression                     |
+-------------------------------------------------+---------------------------------------+
| "if" -- "else"                                  | Conditional expression                |
+-------------------------------------------------+---------------------------------------+
| "or"                                            | Boolean OR                            |
+-------------------------------------------------+---------------------------------------+
| "and"                                           | Boolean AND                           |
+-------------------------------------------------+---------------------------------------+
| "not" "x"                                       | Boolean NOT                           |
+-------------------------------------------------+---------------------------------------+
| "in", "not in", "is", "is not", "<", "<=", ">", | Comparisons, including membership     |
| ">=", "!=", "=="                                | tests and identity tests              |
+-------------------------------------------------+---------------------------------------+
| "|"                                             | Bitwise OR                            |
+-------------------------------------------------+---------------------------------------+
| "^"                                             | Bitwise XOR                           |
+-------------------------------------------------+---------------------------------------+
| "&"                                             | Bitwise AND                           |
+-------------------------------------------------+---------------------------------------+
| "<<", ">>"                                      | Shifts                                |
+-------------------------------------------------+---------------------------------------+
| "+", "-"                                        | Addition and subtraction              |
+-------------------------------------------------+---------------------------------------+
| "*", "@", "/", "//", "%"                        | Multiplication, matrix                |
|                                                 | multiplication, division, floor       |
|                                                 | division, remainder [5]               |
+-------------------------------------------------+---------------------------------------+
| "+x", "-x", "~x"                                | Positive, negative, bitwise NOT       |
+-------------------------------------------------+---------------------------------------+
| "**"                                            | Exponentiation [6]                    |
+-------------------------------------------------+---------------------------------------+
| "await" "x"                                     | Await expression                      |
+-------------------------------------------------+---------------------------------------+
| "x[index]", "x[index:index]",                   | Subscription, slicing, call,          |
| "x(arguments...)", "x.attribute"                | attribute reference                   |
+-------------------------------------------------+---------------------------------------+
| "(expressions...)", "[expressions...]", "{key:  | Binding or tuple display, list        |
| value...}", "{expressions...}"                  | display, dictionary display, set      |
|                                                 | display                               |
+-------------------------------------------------+---------------------------------------+

-[ Footnotes ]-

[1] While "abs(x%y) < abs(y)" is true mathematically, for floats
    it may not be true numerically due to roundoff.  For example, and
    assuming a platform on which a Python float is an IEEE 754 double-
    precision number, in order that "-1e-100 % 1e100" have the same
    sign as "1e100", the computed result is "-1e-100 + 1e100", which
    is numerically exactly equal to "1e100".  The function
    "math.fmod()" returns a result whose sign matches the sign of the
    first argument instead, and so returns "-1e-100" in this case.
    Which approach is more appropriate depends on the application.

[2] If x is very close to an exact integer multiple of y, it's
    possible for "x//y" to be one larger than "(x-x%y)//y" due to
    rounding.  In such cases, Python returns the latter result, in
    order to preserve that "divmod(x,y)[0] * y + x % y" be very close
    to "x".

[3] The Unicode standard distinguishes between *code points* (e.g.
    U+0041) and *abstract characters* (e.g. "LATIN CAPITAL LETTER A").
    While most abstract characters in Unicode are only represented
    using one code point, there is a number of abstract characters
    that can in addition be represented using a sequence of more than
    one code point.  For example, the abstract character "LATIN
    CAPITAL LETTER C WITH CEDILLA" can be represented as a single
    *precomposed character* at code position U+00C7, or as a sequence
    of a *base character* at code position U+0043 (LATIN CAPITAL
    LETTER C), followed by a *combining character* at code position
    U+0327 (COMBINING CEDILLA).

    The comparison operators on strings compare at the level of
    Unicode code points. This may be counter-intuitive to humans.  For
    example, ""\u00C7" == "\u0043\u0327"" is "False", even though both
    strings represent the same abstract character "LATIN CAPITAL
    LETTER C WITH CEDILLA".

    To compare strings at the level of abstract characters (that is,
    in a way intuitive to humans), use "unicodedata.normalize()".

[4] Due to automatic garbage-collection, free lists, and the
    dynamic nature of descriptors, you may notice seemingly unusual
    behaviour in certain uses of the "is" operator, like those
    involving comparisons between instance methods, or constants.
    Check their documentation for more info.

[5] The "%" operator is also used for string formatting; the same
    precedence applies.

[6] The power operator "**" binds less tightly than an arithmetic
    or bitwise unary operator on its right, that is, "2**-1" is "0.5".
zpassaw  The "pass" statement
********************

   pass_stmt ::= "pass"

"pass" is a null operation --- when it is executed, nothing happens.
It is useful as a placeholder when a statement is required
syntactically, but no code needs to be executed, for example:

   def f(arg): pass    # a function that does nothing (yet)

   class C: pass       # a class with no methods (yet)
zpowera  The power operator
******************

The power operator binds more tightly than unary operators on its
left; it binds less tightly than unary operators on its right.  The
syntax is:

   power ::= ( await_expr | primary ) ["**" u_expr]

Thus, in an unparenthesized sequence of power and unary operators, the
operators are evaluated from right to left (this does not constrain
the evaluation order for the operands): "-1**2" results in "-1".

The power operator has the same semantics as the built-in "pow()"
function, when called with two arguments: it yields its left argument
raised to the power of its right argument.  The numeric arguments are
first converted to a common type, and the result is of that type.

For int operands, the result has the same type as the operands unless
the second argument is negative; in that case, all arguments are
converted to float and a float result is delivered. For example,
"10**2" returns "100", but "10**-2" returns "0.01".

Raising "0.0" to a negative power results in a "ZeroDivisionError".
Raising a negative number to a fractional power results in a "complex"
number. (In earlier versions it raised a "ValueError".)
zraiseah  The "raise" statement
*********************

   raise_stmt ::= "raise" [expression ["from" expression]]

If no expressions are present, "raise" re-raises the last exception
that was active in the current scope.  If no exception is active in
the current scope, a "RuntimeError" exception is raised indicating
that this is an error.

Otherwise, "raise" evaluates the first expression as the exception
object.  It must be either a subclass or an instance of
"BaseException". If it is a class, the exception instance will be
obtained when needed by instantiating the class with no arguments.

The *type* of the exception is the exception instance's class, the
*value* is the instance itself.

A traceback object is normally created automatically when an exception
is raised and attached to it as the "__traceback__" attribute, which
is writable. You can create an exception and set your own traceback in
one step using the "with_traceback()" exception method (which returns
the same exception instance, with its traceback set to its argument),
like so:

   raise Exception("foo occurred").with_traceback(tracebackobj)

The "from" clause is used for exception chaining: if given, the second
*expression* must be another exception class or instance, which will
then be attached to the raised exception as the "__cause__" attribute
(which is writable).  If the raised exception is not handled, both
exceptions will be printed:

   >>> try:
   ...     print(1 / 0)
   ... except Exception as exc:
   ...     raise RuntimeError("Something bad happened") from exc
   ...
   Traceback (most recent call last):
     File "<stdin>", line 2, in <module>
   ZeroDivisionError: division by zero

   The above exception was the direct cause of the following exception:

   Traceback (most recent call last):
     File "<stdin>", line 4, in <module>
   RuntimeError: Something bad happened

A similar mechanism works implicitly if an exception is raised inside
an exception handler or a "finally" clause: the previous exception is
then attached as the new exception's "__context__" attribute:

   >>> try:
   ...     print(1 / 0)
   ... except:
   ...     raise RuntimeError("Something bad happened")
   ...
   Traceback (most recent call last):
     File "<stdin>", line 2, in <module>
   ZeroDivisionError: division by zero

   During handling of the above exception, another exception occurred:

   Traceback (most recent call last):
     File "<stdin>", line 4, in <module>
   RuntimeError: Something bad happened

Exception chaining can be explicitly suppressed by specifying "None"
in the "from" clause:

   >>> try:
   ...     print(1 / 0)
   ... except:
   ...     raise RuntimeError("Something bad happened") from None
   ...
   Traceback (most recent call last):
     File "<stdin>", line 4, in <module>
   RuntimeError: Something bad happened

Additional information on exceptions can be found in section
Exceptions, and information about handling exceptions is in section
The try statement.

Changed in version 3.3: "None" is now permitted as "Y" in "raise X
from Y".

New in version 3.3: The "__suppress_context__" attribute to suppress
automatic display of the exception context.
zreturna  The "return" statement
**********************

   return_stmt ::= "return" [expression_list]

"return" may only occur syntactically nested in a function definition,
not within a nested class definition.

If an expression list is present, it is evaluated, else "None" is
substituted.

"return" leaves the current function call with the expression list (or
"None") as return value.

When "return" passes control out of a "try" statement with a "finally"
clause, that "finally" clause is executed before really leaving the
function.

In a generator function, the "return" statement indicates that the
generator is done and will cause "StopIteration" to be raised. The
returned value (if any) is used as an argument to construct
"StopIteration" and becomes the "StopIteration.value" attribute.

In an asynchronous generator function, an empty "return" statement
indicates that the asynchronous generator is done and will cause
"StopAsyncIteration" to be raised.  A non-empty "return" statement is
a syntax error in an asynchronous generator function.
zsequence-typesaÜ  Emulating container types
*************************

The following methods can be defined to implement container objects.
Containers usually are sequences (such as lists or tuples) or mappings
(like dictionaries), but can represent other containers as well.  The
first set of methods is used either to emulate a sequence or to
emulate a mapping; the difference is that for a sequence, the
allowable keys should be the integers *k* for which "0 <= k < N" where
*N* is the length of the sequence, or slice objects, which define a
range of items.  It is also recommended that mappings provide the
methods "keys()", "values()", "items()", "get()", "clear()",
"setdefault()", "pop()", "popitem()", "copy()", and "update()"
behaving similar to those for Python's standard dictionary objects.
The "collections" module provides a "MutableMapping" abstract base
class to help create those methods from a base set of "__getitem__()",
"__setitem__()", "__delitem__()", and "keys()". Mutable sequences
should provide methods "append()", "count()", "index()", "extend()",
"insert()", "pop()", "remove()", "reverse()" and "sort()", like Python
standard list objects.  Finally, sequence types should implement
addition (meaning concatenation) and multiplication (meaning
repetition) by defining the methods "__add__()", "__radd__()",
"__iadd__()", "__mul__()", "__rmul__()" and "__imul__()" described
below; they should not define other numerical operators.  It is
recommended that both mappings and sequences implement the
"__contains__()" method to allow efficient use of the "in" operator;
for mappings, "in" should search the mapping's keys; for sequences, it
should search through the values.  It is further recommended that both
mappings and sequences implement the "__iter__()" method to allow
efficient iteration through the container; for mappings, "__iter__()"
should be the same as "keys()"; for sequences, it should iterate
through the values.

object.__len__(self)

   Called to implement the built-in function "len()".  Should return
   the length of the object, an integer ">=" 0.  Also, an object that
   doesn't define a "__bool__()" method and whose "__len__()" method
   returns zero is considered to be false in a Boolean context.

   **CPython implementation detail:** In CPython, the length is
   required to be at most "sys.maxsize". If the length is larger than
   "sys.maxsize" some features (such as "len()") may raise
   "OverflowError".  To prevent raising "OverflowError" by truth value
   testing, an object must define a "__bool__()" method.

object.__length_hint__(self)

   Called to implement "operator.length_hint()". Should return an
   estimated length for the object (which may be greater or less than
   the actual length). The length must be an integer ">=" 0. This
   method is purely an optimization and is never required for
   correctness.

   New in version 3.4.

Note: Slicing is done exclusively with the following three methods.
  A call like

     a[1:2] = b

  is translated to

     a[slice(1, 2, None)] = b

  and so forth.  Missing slice items are always filled in with "None".

object.__getitem__(self, key)

   Called to implement evaluation of "self[key]". For sequence types,
   the accepted keys should be integers and slice objects.  Note that
   the special interpretation of negative indexes (if the class wishes
   to emulate a sequence type) is up to the "__getitem__()" method. If
   *key* is of an inappropriate type, "TypeError" may be raised; if of
   a value outside the set of indexes for the sequence (after any
   special interpretation of negative values), "IndexError" should be
   raised. For mapping types, if *key* is missing (not in the
   container), "KeyError" should be raised.

   Note: "for" loops expect that an "IndexError" will be raised for
     illegal indexes to allow proper detection of the end of the
     sequence.

object.__missing__(self, key)

   Called by "dict"."__getitem__()" to implement "self[key]" for dict
   subclasses when key is not in the dictionary.

object.__setitem__(self, key, value)

   Called to implement assignment to "self[key]".  Same note as for
   "__getitem__()".  This should only be implemented for mappings if
   the objects support changes to the values for keys, or if new keys
   can be added, or for sequences if elements can be replaced.  The
   same exceptions should be raised for improper *key* values as for
   the "__getitem__()" method.

object.__delitem__(self, key)

   Called to implement deletion of "self[key]".  Same note as for
   "__getitem__()".  This should only be implemented for mappings if
   the objects support removal of keys, or for sequences if elements
   can be removed from the sequence.  The same exceptions should be
   raised for improper *key* values as for the "__getitem__()" method.

object.__iter__(self)

   This method is called when an iterator is required for a container.
   This method should return a new iterator object that can iterate
   over all the objects in the container.  For mappings, it should
   iterate over the keys of the container.

   Iterator objects also need to implement this method; they are
   required to return themselves.  For more information on iterator
   objects, see Iterator Types.

object.__reversed__(self)

   Called (if present) by the "reversed()" built-in to implement
   reverse iteration.  It should return a new iterator object that
   iterates over all the objects in the container in reverse order.

   If the "__reversed__()" method is not provided, the "reversed()"
   built-in will fall back to using the sequence protocol ("__len__()"
   and "__getitem__()").  Objects that support the sequence protocol
   should only provide "__reversed__()" if they can provide an
   implementation that is more efficient than the one provided by
   "reversed()".

The membership test operators ("in" and "not in") are normally
implemented as an iteration through a sequence.  However, container
objects can supply the following special method with a more efficient
implementation, which also does not require the object be a sequence.

object.__contains__(self, item)

   Called to implement membership test operators.  Should return true
   if *item* is in *self*, false otherwise.  For mapping objects, this
   should consider the keys of the mapping rather than the values or
   the key-item pairs.

   For objects that don't define "__contains__()", the membership test
   first tries iteration via "__iter__()", then the old sequence
   iteration protocol via "__getitem__()", see this section in the
   language reference.
zshiftinga¢  Shifting operations
*******************

The shifting operations have lower priority than the arithmetic
operations:

   shift_expr ::= a_expr | shift_expr ( "<<" | ">>" ) a_expr

These operators accept integers as arguments.  They shift the first
argument to the left or right by the number of bits given by the
second argument.

A right shift by *n* bits is defined as floor division by "pow(2,n)".
A left shift by *n* bits is defined as multiplication with "pow(2,n)".

Note: In the current implementation, the right-hand operand is
  required to be at most "sys.maxsize".  If the right-hand operand is
  larger than "sys.maxsize" an "OverflowError" exception is raised.
zslicingsa  Slicings
********

A slicing selects a range of items in a sequence object (e.g., a
string, tuple or list).  Slicings may be used as expressions or as
targets in assignment or "del" statements.  The syntax for a slicing:

   slicing      ::= primary "[" slice_list "]"
   slice_list   ::= slice_item ("," slice_item)* [","]
   slice_item   ::= expression | proper_slice
   proper_slice ::= [lower_bound] ":" [upper_bound] [ ":" [stride] ]
   lower_bound  ::= expression
   upper_bound  ::= expression
   stride       ::= expression

There is ambiguity in the formal syntax here: anything that looks like
an expression list also looks like a slice list, so any subscription
can be interpreted as a slicing.  Rather than further complicating the
syntax, this is disambiguated by defining that in this case the
interpretation as a subscription takes priority over the
interpretation as a slicing (this is the case if the slice list
contains no proper slice).

The semantics for a slicing are as follows.  The primary is indexed
(using the same "__getitem__()" method as normal subscription) with a
key that is constructed from the slice list, as follows.  If the slice
list contains at least one comma, the key is a tuple containing the
conversion of the slice items; otherwise, the conversion of the lone
slice item is the key.  The conversion of a slice item that is an
expression is that expression.  The conversion of a proper slice is a
slice object (see section The standard type hierarchy) whose "start",
"stop" and "step" attributes are the values of the expressions given
as lower bound, upper bound and stride, respectively, substituting
"None" for missing expressions.
zspecialattrsan  Special Attributes
******************

The implementation adds a few special read-only attributes to several
object types, where they are relevant.  Some of these are not reported
by the "dir()" built-in function.

object.__dict__

   A dictionary or other mapping object used to store an object's
   (writable) attributes.

instance.__class__

   The class to which a class instance belongs.

class.__bases__

   The tuple of base classes of a class object.

definition.__name__

   The name of the class, function, method, descriptor, or generator
   instance.

definition.__qualname__

   The *qualified name* of the class, function, method, descriptor, or
   generator instance.

   New in version 3.3.

class.__mro__

   This attribute is a tuple of classes that are considered when
   looking for base classes during method resolution.

class.mro()

   This method can be overridden by a metaclass to customize the
   method resolution order for its instances.  It is called at class
   instantiation, and its result is stored in "__mro__".

class.__subclasses__()

   Each class keeps a list of weak references to its immediate
   subclasses.  This method returns a list of all those references
   still alive. Example:

      >>> int.__subclasses__()
      [<class 'bool'>]

-[ Footnotes ]-

[1] Additional information on these special methods may be found
    in the Python Reference Manual (Basic customization).

[2] As a consequence, the list "[1, 2]" is considered equal to
    "[1.0, 2.0]", and similarly for tuples.

[3] They must have since the parser can't tell the type of the
    operands.

[4] Cased characters are those with general category property
    being one of "Lu" (Letter, uppercase), "Ll" (Letter, lowercase),
    or "Lt" (Letter, titlecase).

[5] To format only a tuple you should therefore provide a
    singleton tuple whose only element is the tuple to be formatted.
zspecialnamesadÎ  Special method names
********************

A class can implement certain operations that are invoked by special
syntax (such as arithmetic operations or subscripting and slicing) by
defining methods with special names. This is Python's approach to
*operator overloading*, allowing classes to define their own behavior
with respect to language operators.  For instance, if a class defines
a method named "__getitem__()", and "x" is an instance of this class,
then "x[i]" is roughly equivalent to "type(x).__getitem__(x, i)".
Except where mentioned, attempts to execute an operation raise an
exception when no appropriate method is defined (typically
"AttributeError" or "TypeError").

Setting a special method to "None" indicates that the corresponding
operation is not available.  For example, if a class sets "__iter__()"
to "None", the class is not iterable, so calling "iter()" on its
instances will raise a "TypeError" (without falling back to
"__getitem__()"). [2]

When implementing a class that emulates any built-in type, it is
important that the emulation only be implemented to the degree that it
makes sense for the object being modelled.  For example, some
sequences may work well with retrieval of individual elements, but
extracting a slice may not make sense.  (One example of this is the
"NodeList" interface in the W3C's Document Object Model.)


Basic customization
===================

object.__new__(cls[, ...])

   Called to create a new instance of class *cls*.  "__new__()" is a
   static method (special-cased so you need not declare it as such)
   that takes the class of which an instance was requested as its
   first argument.  The remaining arguments are those passed to the
   object constructor expression (the call to the class).  The return
   value of "__new__()" should be the new object instance (usually an
   instance of *cls*).

   Typical implementations create a new instance of the class by
   invoking the superclass's "__new__()" method using
   "super().__new__(cls[, ...])" with appropriate arguments and then
   modifying the newly-created instance as necessary before returning
   it.

   If "__new__()" returns an instance of *cls*, then the new
   instance's "__init__()" method will be invoked like
   "__init__(self[, ...])", where *self* is the new instance and the
   remaining arguments are the same as were passed to "__new__()".

   If "__new__()" does not return an instance of *cls*, then the new
   instance's "__init__()" method will not be invoked.

   "__new__()" is intended mainly to allow subclasses of immutable
   types (like int, str, or tuple) to customize instance creation.  It
   is also commonly overridden in custom metaclasses in order to
   customize class creation.

object.__init__(self[, ...])

   Called after the instance has been created (by "__new__()"), but
   before it is returned to the caller.  The arguments are those
   passed to the class constructor expression.  If a base class has an
   "__init__()" method, the derived class's "__init__()" method, if
   any, must explicitly call it to ensure proper initialization of the
   base class part of the instance; for example:
   "super().__init__([args...])".

   Because "__new__()" and "__init__()" work together in constructing
   objects ("__new__()" to create it, and "__init__()" to customize
   it), no non-"None" value may be returned by "__init__()"; doing so
   will cause a "TypeError" to be raised at runtime.

object.__del__(self)

   Called when the instance is about to be destroyed.  This is also
   called a finalizer or (improperly) a destructor.  If a base class
   has a "__del__()" method, the derived class's "__del__()" method,
   if any, must explicitly call it to ensure proper deletion of the
   base class part of the instance.

   It is possible (though not recommended!) for the "__del__()" method
   to postpone destruction of the instance by creating a new reference
   to it.  This is called object *resurrection*.  It is
   implementation-dependent whether "__del__()" is called a second
   time when a resurrected object is about to be destroyed; the
   current *CPython* implementation only calls it once.

   It is not guaranteed that "__del__()" methods are called for
   objects that still exist when the interpreter exits.

   Note: "del x" doesn't directly call "x.__del__()" --- the former
     decrements the reference count for "x" by one, and the latter is
     only called when "x"'s reference count reaches zero.

   **CPython implementation detail:** It is possible for a reference
   cycle to prevent the reference count of an object from going to
   zero.  In this case, the cycle will be later detected and deleted
   by the *cyclic garbage collector*.  A common cause of reference
   cycles is when an exception has been caught in a local variable.
   The frame's locals then reference the exception, which references
   its own traceback, which references the locals of all frames caught
   in the traceback.

   See also: Documentation for the "gc" module.

   Warning: Due to the precarious circumstances under which
     "__del__()" methods are invoked, exceptions that occur during
     their execution are ignored, and a warning is printed to
     "sys.stderr" instead. In particular:

     * "__del__()" can be invoked when arbitrary code is being
       executed, including from any arbitrary thread.  If "__del__()"
       needs to take a lock or invoke any other blocking resource, it
       may deadlock as the resource may already be taken by the code
       that gets interrupted to execute "__del__()".

     * "__del__()" can be executed during interpreter shutdown.  As
       a consequence, the global variables it needs to access
       (including other modules) may already have been deleted or set
       to "None". Python guarantees that globals whose name begins
       with a single underscore are deleted from their module before
       other globals are deleted; if no other references to such
       globals exist, this may help in assuring that imported modules
       are still available at the time when the "__del__()" method is
       called.

object.__repr__(self)

   Called by the "repr()" built-in function to compute the "official"
   string representation of an object.  If at all possible, this
   should look like a valid Python expression that could be used to
   recreate an object with the same value (given an appropriate
   environment).  If this is not possible, a string of the form
   "<...some useful description...>" should be returned. The return
   value must be a string object. If a class defines "__repr__()" but
   not "__str__()", then "__repr__()" is also used when an "informal"
   string representation of instances of that class is required.

   This is typically used for debugging, so it is important that the
   representation is information-rich and unambiguous.

object.__str__(self)

   Called by "str(object)" and the built-in functions "format()" and
   "print()" to compute the "informal" or nicely printable string
   representation of an object.  The return value must be a string
   object.

   This method differs from "object.__repr__()" in that there is no
   expectation that "__str__()" return a valid Python expression: a
   more convenient or concise representation can be used.

   The default implementation defined by the built-in type "object"
   calls "object.__repr__()".

object.__bytes__(self)

   Called by bytes to compute a byte-string representation of an
   object. This should return a "bytes" object.

object.__format__(self, format_spec)

   Called by the "format()" built-in function, and by extension,
   evaluation of formatted string literals and the "str.format()"
   method, to produce a "formatted" string representation of an
   object. The "format_spec" argument is a string that contains a
   description of the formatting options desired. The interpretation
   of the "format_spec" argument is up to the type implementing
   "__format__()", however most classes will either delegate
   formatting to one of the built-in types, or use a similar
   formatting option syntax.

   See Format Specification Mini-Language for a description of the
   standard formatting syntax.

   The return value must be a string object.

   Changed in version 3.4: The __format__ method of "object" itself
   raises a "TypeError" if passed any non-empty string.

object.__lt__(self, other)
object.__le__(self, other)
object.__eq__(self, other)
object.__ne__(self, other)
object.__gt__(self, other)
object.__ge__(self, other)

   These are the so-called "rich comparison" methods. The
   correspondence between operator symbols and method names is as
   follows: "x<y" calls "x.__lt__(y)", "x<=y" calls "x.__le__(y)",
   "x==y" calls "x.__eq__(y)", "x!=y" calls "x.__ne__(y)", "x>y" calls
   "x.__gt__(y)", and "x>=y" calls "x.__ge__(y)".

   A rich comparison method may return the singleton "NotImplemented"
   if it does not implement the operation for a given pair of
   arguments. By convention, "False" and "True" are returned for a
   successful comparison. However, these methods can return any value,
   so if the comparison operator is used in a Boolean context (e.g.,
   in the condition of an "if" statement), Python will call "bool()"
   on the value to determine if the result is true or false.

   By default, "__ne__()" delegates to "__eq__()" and inverts the
   result unless it is "NotImplemented".  There are no other implied
   relationships among the comparison operators, for example, the
   truth of "(x<y or x==y)" does not imply "x<=y". To automatically
   generate ordering operations from a single root operation, see
   "functools.total_ordering()".

   See the paragraph on "__hash__()" for some important notes on
   creating *hashable* objects which support custom comparison
   operations and are usable as dictionary keys.

   There are no swapped-argument versions of these methods (to be used
   when the left argument does not support the operation but the right
   argument does); rather, "__lt__()" and "__gt__()" are each other's
   reflection, "__le__()" and "__ge__()" are each other's reflection,
   and "__eq__()" and "__ne__()" are their own reflection. If the
   operands are of different types, and right operand's type is a
   direct or indirect subclass of the left operand's type, the
   reflected method of the right operand has priority, otherwise the
   left operand's method has priority.  Virtual subclassing is not
   considered.

object.__hash__(self)

   Called by built-in function "hash()" and for operations on members
   of hashed collections including "set", "frozenset", and "dict".
   "__hash__()" should return an integer. The only required property
   is that objects which compare equal have the same hash value; it is
   advised to mix together the hash values of the components of the
   object that also play a part in comparison of objects by packing
   them into a tuple and hashing the tuple. Example:

      def __hash__(self):
          return hash((self.name, self.nick, self.color))

   Note: "hash()" truncates the value returned from an object's
     custom "__hash__()" method to the size of a "Py_ssize_t".  This
     is typically 8 bytes on 64-bit builds and 4 bytes on 32-bit
     builds. If an object's   "__hash__()" must interoperate on builds
     of different bit sizes, be sure to check the width on all
     supported builds.  An easy way to do this is with "python -c
     "import sys; print(sys.hash_info.width)"".

   If a class does not define an "__eq__()" method it should not
   define a "__hash__()" operation either; if it defines "__eq__()"
   but not "__hash__()", its instances will not be usable as items in
   hashable collections.  If a class defines mutable objects and
   implements an "__eq__()" method, it should not implement
   "__hash__()", since the implementation of hashable collections
   requires that a key's hash value is immutable (if the object's hash
   value changes, it will be in the wrong hash bucket).

   User-defined classes have "__eq__()" and "__hash__()" methods by
   default; with them, all objects compare unequal (except with
   themselves) and "x.__hash__()" returns an appropriate value such
   that "x == y" implies both that "x is y" and "hash(x) == hash(y)".

   A class that overrides "__eq__()" and does not define "__hash__()"
   will have its "__hash__()" implicitly set to "None".  When the
   "__hash__()" method of a class is "None", instances of the class
   will raise an appropriate "TypeError" when a program attempts to
   retrieve their hash value, and will also be correctly identified as
   unhashable when checking "isinstance(obj, collections.Hashable)".

   If a class that overrides "__eq__()" needs to retain the
   implementation of "__hash__()" from a parent class, the interpreter
   must be told this explicitly by setting "__hash__ =
   <ParentClass>.__hash__".

   If a class that does not override "__eq__()" wishes to suppress
   hash support, it should include "__hash__ = None" in the class
   definition. A class which defines its own "__hash__()" that
   explicitly raises a "TypeError" would be incorrectly identified as
   hashable by an "isinstance(obj, collections.Hashable)" call.

   Note: By default, the "__hash__()" values of str, bytes and
     datetime objects are "salted" with an unpredictable random value.
     Although they remain constant within an individual Python
     process, they are not predictable between repeated invocations of
     Python.This is intended to provide protection against a denial-
     of-service caused by carefully-chosen inputs that exploit the
     worst case performance of a dict insertion, O(n^2) complexity.
     See http://www.ocert.org/advisories/ocert-2011-003.html for
     details.Changing hash values affects the iteration order of
     dicts, sets and other mappings.  Python has never made guarantees
     about this ordering (and it typically varies between 32-bit and
     64-bit builds).See also "PYTHONHASHSEED".

   Changed in version 3.3: Hash randomization is enabled by default.

object.__bool__(self)

   Called to implement truth value testing and the built-in operation
   "bool()"; should return "False" or "True".  When this method is not
   defined, "__len__()" is called, if it is defined, and the object is
   considered true if its result is nonzero.  If a class defines
   neither "__len__()" nor "__bool__()", all its instances are
   considered true.


Customizing attribute access
============================

The following methods can be defined to customize the meaning of
attribute access (use of, assignment to, or deletion of "x.name") for
class instances.

object.__getattr__(self, name)

   Called when the default attribute access fails with an
   "AttributeError" (either "__getattribute__()" raises an
   "AttributeError" because *name* is not an instance attribute or an
   attribute in the class tree for "self"; or "__get__()" of a *name*
   property raises "AttributeError").  This method should either
   return the (computed) attribute value or raise an "AttributeError"
   exception.

   Note that if the attribute is found through the normal mechanism,
   "__getattr__()" is not called.  (This is an intentional asymmetry
   between "__getattr__()" and "__setattr__()".) This is done both for
   efficiency reasons and because otherwise "__getattr__()" would have
   no way to access other attributes of the instance.  Note that at
   least for instance variables, you can fake total control by not
   inserting any values in the instance attribute dictionary (but
   instead inserting them in another object).  See the
   "__getattribute__()" method below for a way to actually get total
   control over attribute access.

object.__getattribute__(self, name)

   Called unconditionally to implement attribute accesses for
   instances of the class. If the class also defines "__getattr__()",
   the latter will not be called unless "__getattribute__()" either
   calls it explicitly or raises an "AttributeError". This method
   should return the (computed) attribute value or raise an
   "AttributeError" exception. In order to avoid infinite recursion in
   this method, its implementation should always call the base class
   method with the same name to access any attributes it needs, for
   example, "object.__getattribute__(self, name)".

   Note: This method may still be bypassed when looking up special
     methods as the result of implicit invocation via language syntax
     or built-in functions. See Special method lookup.

object.__setattr__(self, name, value)

   Called when an attribute assignment is attempted.  This is called
   instead of the normal mechanism (i.e. store the value in the
   instance dictionary). *name* is the attribute name, *value* is the
   value to be assigned to it.

   If "__setattr__()" wants to assign to an instance attribute, it
   should call the base class method with the same name, for example,
   "object.__setattr__(self, name, value)".

object.__delattr__(self, name)

   Like "__setattr__()" but for attribute deletion instead of
   assignment.  This should only be implemented if "del obj.name" is
   meaningful for the object.

object.__dir__(self)

   Called when "dir()" is called on the object. A sequence must be
   returned. "dir()" converts the returned sequence to a list and
   sorts it.


Customizing module attribute access
-----------------------------------

For a more fine grained customization of the module behavior (setting
attributes, properties, etc.), one can set the "__class__" attribute
of a module object to a subclass of "types.ModuleType". For example:

   import sys
   from types import ModuleType

   class VerboseModule(ModuleType):
       def __repr__(self):
           return f'Verbose {self.__name__}'

       def __setattr__(self, attr, value):
           print(f'Setting {attr}...')
           setattr(self, attr, value)

   sys.modules[__name__].__class__ = VerboseModule

Note: Setting module "__class__" only affects lookups made using the
  attribute access syntax -- directly accessing the module globals
  (whether by code within the module, or via a reference to the
  module's globals dictionary) is unaffected.

Changed in version 3.5: "__class__" module attribute is now writable.


Implementing Descriptors
------------------------

The following methods only apply when an instance of the class
containing the method (a so-called *descriptor* class) appears in an
*owner* class (the descriptor must be in either the owner's class
dictionary or in the class dictionary for one of its parents).  In the
examples below, "the attribute" refers to the attribute whose name is
the key of the property in the owner class' "__dict__".

object.__get__(self, instance, owner)

   Called to get the attribute of the owner class (class attribute
   access) or of an instance of that class (instance attribute
   access). *owner* is always the owner class, while *instance* is the
   instance that the attribute was accessed through, or "None" when
   the attribute is accessed through the *owner*.  This method should
   return the (computed) attribute value or raise an "AttributeError"
   exception.

object.__set__(self, instance, value)

   Called to set the attribute on an instance *instance* of the owner
   class to a new value, *value*.

object.__delete__(self, instance)

   Called to delete the attribute on an instance *instance* of the
   owner class.

object.__set_name__(self, owner, name)

   Called at the time the owning class *owner* is created. The
   descriptor has been assigned to *name*.

   New in version 3.6.

The attribute "__objclass__" is interpreted by the "inspect" module as
specifying the class where this object was defined (setting this
appropriately can assist in runtime introspection of dynamic class
attributes). For callables, it may indicate that an instance of the
given type (or a subclass) is expected or required as the first
positional argument (for example, CPython sets this attribute for
unbound methods that are implemented in C).


Invoking Descriptors
--------------------

In general, a descriptor is an object attribute with "binding
behavior", one whose attribute access has been overridden by methods
in the descriptor protocol:  "__get__()", "__set__()", and
"__delete__()". If any of those methods are defined for an object, it
is said to be a descriptor.

The default behavior for attribute access is to get, set, or delete
the attribute from an object's dictionary. For instance, "a.x" has a
lookup chain starting with "a.__dict__['x']", then
"type(a).__dict__['x']", and continuing through the base classes of
"type(a)" excluding metaclasses.

However, if the looked-up value is an object defining one of the
descriptor methods, then Python may override the default behavior and
invoke the descriptor method instead.  Where this occurs in the
precedence chain depends on which descriptor methods were defined and
how they were called.

The starting point for descriptor invocation is a binding, "a.x". How
the arguments are assembled depends on "a":

Direct Call
   The simplest and least common call is when user code directly
   invokes a descriptor method:    "x.__get__(a)".

Instance Binding
   If binding to an object instance, "a.x" is transformed into the
   call: "type(a).__dict__['x'].__get__(a, type(a))".

Class Binding
   If binding to a class, "A.x" is transformed into the call:
   "A.__dict__['x'].__get__(None, A)".

Super Binding
   If "a" is an instance of "super", then the binding "super(B,
   obj).m()" searches "obj.__class__.__mro__" for the base class "A"
   immediately preceding "B" and then invokes the descriptor with the
   call: "A.__dict__['m'].__get__(obj, obj.__class__)".

For instance bindings, the precedence of descriptor invocation depends
on the which descriptor methods are defined.  A descriptor can define
any combination of "__get__()", "__set__()" and "__delete__()".  If it
does not define "__get__()", then accessing the attribute will return
the descriptor object itself unless there is a value in the object's
instance dictionary.  If the descriptor defines "__set__()" and/or
"__delete__()", it is a data descriptor; if it defines neither, it is
a non-data descriptor.  Normally, data descriptors define both
"__get__()" and "__set__()", while non-data descriptors have just the
"__get__()" method.  Data descriptors with "__set__()" and "__get__()"
defined always override a redefinition in an instance dictionary.  In
contrast, non-data descriptors can be overridden by instances.

Python methods (including "staticmethod()" and "classmethod()") are
implemented as non-data descriptors.  Accordingly, instances can
redefine and override methods.  This allows individual instances to
acquire behaviors that differ from other instances of the same class.

The "property()" function is implemented as a data descriptor.
Accordingly, instances cannot override the behavior of a property.


__slots__
---------

*__slots__* allow us to explicitly declare data members (like
properties) and deny the creation of *__dict__* and *__weakref__*
(unless explicitly declared in *__slots__* or available in a parent.)

The space saved over using *__dict__* can be significant.

object.__slots__

   This class variable can be assigned a string, iterable, or sequence
   of strings with variable names used by instances.  *__slots__*
   reserves space for the declared variables and prevents the
   automatic creation of *__dict__* and *__weakref__* for each
   instance.


Notes on using *__slots__*
~~~~~~~~~~~~~~~~~~~~~~~~~~

* When inheriting from a class without *__slots__*, the *__dict__*
  and *__weakref__* attribute of the instances will always be
  accessible.

* Without a *__dict__* variable, instances cannot be assigned new
  variables not listed in the *__slots__* definition.  Attempts to
  assign to an unlisted variable name raises "AttributeError". If
  dynamic assignment of new variables is desired, then add
  "'__dict__'" to the sequence of strings in the *__slots__*
  declaration.

* Without a *__weakref__* variable for each instance, classes
  defining *__slots__* do not support weak references to its
  instances. If weak reference support is needed, then add
  "'__weakref__'" to the sequence of strings in the *__slots__*
  declaration.

* *__slots__* are implemented at the class level by creating
  descriptors (Implementing Descriptors) for each variable name.  As a
  result, class attributes cannot be used to set default values for
  instance variables defined by *__slots__*; otherwise, the class
  attribute would overwrite the descriptor assignment.

* The action of a *__slots__* declaration is not limited to the
  class where it is defined.  *__slots__* declared in parents are
  available in child classes. However, child subclasses will get a
  *__dict__* and *__weakref__* unless they also define *__slots__*
  (which should only contain names of any *additional* slots).

* If a class defines a slot also defined in a base class, the
  instance variable defined by the base class slot is inaccessible
  (except by retrieving its descriptor directly from the base class).
  This renders the meaning of the program undefined.  In the future, a
  check may be added to prevent this.

* Nonempty *__slots__* does not work for classes derived from
  "variable-length" built-in types such as "int", "bytes" and "tuple".

* Any non-string iterable may be assigned to *__slots__*. Mappings
  may also be used; however, in the future, special meaning may be
  assigned to the values corresponding to each key.

* *__class__* assignment works only if both classes have the same
  *__slots__*.

* Multiple inheritance with multiple slotted parent classes can be
  used, but only one parent is allowed to have attributes created by
  slots (the other bases must have empty slot layouts) - violations
  raise "TypeError".


Customizing class creation
==========================

Whenever a class inherits from another class, *__init_subclass__* is
called on that class. This way, it is possible to write classes which
change the behavior of subclasses. This is closely related to class
decorators, but where class decorators only affect the specific class
they're applied to, "__init_subclass__" solely applies to future
subclasses of the class defining the method.

classmethod object.__init_subclass__(cls)

   This method is called whenever the containing class is subclassed.
   *cls* is then the new subclass. If defined as a normal instance
   method, this method is implicitly converted to a class method.

   Keyword arguments which are given to a new class are passed to the
   parent's class "__init_subclass__". For compatibility with other
   classes using "__init_subclass__", one should take out the needed
   keyword arguments and pass the others over to the base class, as
   in:

      class Philosopher:
          def __init_subclass__(cls, default_name, **kwargs):
              super().__init_subclass__(**kwargs)
              cls.default_name = default_name

      class AustralianPhilosopher(Philosopher, default_name="Bruce"):
          pass

   The default implementation "object.__init_subclass__" does nothing,
   but raises an error if it is called with any arguments.

   Note: The metaclass hint "metaclass" is consumed by the rest of
     the type machinery, and is never passed to "__init_subclass__"
     implementations. The actual metaclass (rather than the explicit
     hint) can be accessed as "type(cls)".

   New in version 3.6.


Metaclasses
-----------

By default, classes are constructed using "type()". The class body is
executed in a new namespace and the class name is bound locally to the
result of "type(name, bases, namespace)".

The class creation process can be customized by passing the
"metaclass" keyword argument in the class definition line, or by
inheriting from an existing class that included such an argument. In
the following example, both "MyClass" and "MySubclass" are instances
of "Meta":

   class Meta(type):
       pass

   class MyClass(metaclass=Meta):
       pass

   class MySubclass(MyClass):
       pass

Any other keyword arguments that are specified in the class definition
are passed through to all metaclass operations described below.

When a class definition is executed, the following steps occur:

* the appropriate metaclass is determined

* the class namespace is prepared

* the class body is executed

* the class object is created


Determining the appropriate metaclass
-------------------------------------

The appropriate metaclass for a class definition is determined as
follows:

* if no bases and no explicit metaclass are given, then "type()" is
  used

* if an explicit metaclass is given and it is *not* an instance of
  "type()", then it is used directly as the metaclass

* if an instance of "type()" is given as the explicit metaclass, or
  bases are defined, then the most derived metaclass is used

The most derived metaclass is selected from the explicitly specified
metaclass (if any) and the metaclasses (i.e. "type(cls)") of all
specified base classes. The most derived metaclass is one which is a
subtype of *all* of these candidate metaclasses. If none of the
candidate metaclasses meets that criterion, then the class definition
will fail with "TypeError".


Preparing the class namespace
-----------------------------

Once the appropriate metaclass has been identified, then the class
namespace is prepared. If the metaclass has a "__prepare__" attribute,
it is called as "namespace = metaclass.__prepare__(name, bases,
**kwds)" (where the additional keyword arguments, if any, come from
the class definition).

If the metaclass has no "__prepare__" attribute, then the class
namespace is initialised as an empty ordered mapping.

See also:

  **PEP 3115** - Metaclasses in Python 3000
     Introduced the "__prepare__" namespace hook


Executing the class body
------------------------

The class body is executed (approximately) as "exec(body, globals(),
namespace)". The key difference from a normal call to "exec()" is that
lexical scoping allows the class body (including any methods) to
reference names from the current and outer scopes when the class
definition occurs inside a function.

However, even when the class definition occurs inside the function,
methods defined inside the class still cannot see names defined at the
class scope. Class variables must be accessed through the first
parameter of instance or class methods, or through the implicit
lexically scoped "__class__" reference described in the next section.


Creating the class object
-------------------------

Once the class namespace has been populated by executing the class
body, the class object is created by calling "metaclass(name, bases,
namespace, **kwds)" (the additional keywords passed here are the same
as those passed to "__prepare__").

This class object is the one that will be referenced by the zero-
argument form of "super()". "__class__" is an implicit closure
reference created by the compiler if any methods in a class body refer
to either "__class__" or "super". This allows the zero argument form
of "super()" to correctly identify the class being defined based on
lexical scoping, while the class or instance that was used to make the
current call is identified based on the first argument passed to the
method.

**CPython implementation detail:** In CPython 3.6 and later, the
"__class__" cell is passed to the metaclass as a "__classcell__" entry
in the class namespace. If present, this must be propagated up to the
"type.__new__" call in order for the class to be initialised
correctly. Failing to do so will result in a "DeprecationWarning" in
Python 3.6, and a "RuntimeWarning" in the future.

When using the default metaclass "type", or any metaclass that
ultimately calls "type.__new__", the following additional
customisation steps are invoked after creating the class object:

* first, "type.__new__" collects all of the descriptors in the class
  namespace that define a "__set_name__()" method;

* second, all of these "__set_name__" methods are called with the
  class being defined and the assigned name of that particular
  descriptor; and

* finally, the "__init_subclass__()" hook is called on the immediate
  parent of the new class in its method resolution order.

After the class object is created, it is passed to the class
decorators included in the class definition (if any) and the resulting
object is bound in the local namespace as the defined class.

When a new class is created by "type.__new__", the object provided as
the namespace parameter is copied to a new ordered mapping and the
original object is discarded. The new copy is wrapped in a read-only
proxy, which becomes the "__dict__" attribute of the class object.

See also:

  **PEP 3135** - New super
     Describes the implicit "__class__" closure reference


Metaclass example
-----------------

The potential uses for metaclasses are boundless. Some ideas that have
been explored include enum, logging, interface checking, automatic
delegation, automatic property creation, proxies, frameworks, and
automatic resource locking/synchronization.

Here is an example of a metaclass that uses an
"collections.OrderedDict" to remember the order that class variables
are defined:

   class OrderedClass(type):

       @classmethod
       def __prepare__(metacls, name, bases, **kwds):
           return collections.OrderedDict()

       def __new__(cls, name, bases, namespace, **kwds):
           result = type.__new__(cls, name, bases, dict(namespace))
           result.members = tuple(namespace)
           return result

   class A(metaclass=OrderedClass):
       def one(self): pass
       def two(self): pass
       def three(self): pass
       def four(self): pass

   >>> A.members
   ('__module__', 'one', 'two', 'three', 'four')

When the class definition for *A* gets executed, the process begins
with calling the metaclass's "__prepare__()" method which returns an
empty "collections.OrderedDict".  That mapping records the methods and
attributes of *A* as they are defined within the body of the class
statement. Once those definitions are executed, the ordered dictionary
is fully populated and the metaclass's "__new__()" method gets
invoked.  That method builds the new type and it saves the ordered
dictionary keys in an attribute called "members".


Customizing instance and subclass checks
========================================

The following methods are used to override the default behavior of the
"isinstance()" and "issubclass()" built-in functions.

In particular, the metaclass "abc.ABCMeta" implements these methods in
order to allow the addition of Abstract Base Classes (ABCs) as
"virtual base classes" to any class or type (including built-in
types), including other ABCs.

class.__instancecheck__(self, instance)

   Return true if *instance* should be considered a (direct or
   indirect) instance of *class*. If defined, called to implement
   "isinstance(instance, class)".

class.__subclasscheck__(self, subclass)

   Return true if *subclass* should be considered a (direct or
   indirect) subclass of *class*.  If defined, called to implement
   "issubclass(subclass, class)".

Note that these methods are looked up on the type (metaclass) of a
class.  They cannot be defined as class methods in the actual class.
This is consistent with the lookup of special methods that are called
on instances, only in this case the instance is itself a class.

See also:

  **PEP 3119** - Introducing Abstract Base Classes
     Includes the specification for customizing "isinstance()" and
     "issubclass()" behavior through "__instancecheck__()" and
     "__subclasscheck__()", with motivation for this functionality in
     the context of adding Abstract Base Classes (see the "abc"
     module) to the language.


Emulating callable objects
==========================

object.__call__(self[, args...])

   Called when the instance is "called" as a function; if this method
   is defined, "x(arg1, arg2, ...)" is a shorthand for
   "x.__call__(arg1, arg2, ...)".


Emulating container types
=========================

The following methods can be defined to implement container objects.
Containers usually are sequences (such as lists or tuples) or mappings
(like dictionaries), but can represent other containers as well.  The
first set of methods is used either to emulate a sequence or to
emulate a mapping; the difference is that for a sequence, the
allowable keys should be the integers *k* for which "0 <= k < N" where
*N* is the length of the sequence, or slice objects, which define a
range of items.  It is also recommended that mappings provide the
methods "keys()", "values()", "items()", "get()", "clear()",
"setdefault()", "pop()", "popitem()", "copy()", and "update()"
behaving similar to those for Python's standard dictionary objects.
The "collections" module provides a "MutableMapping" abstract base
class to help create those methods from a base set of "__getitem__()",
"__setitem__()", "__delitem__()", and "keys()". Mutable sequences
should provide methods "append()", "count()", "index()", "extend()",
"insert()", "pop()", "remove()", "reverse()" and "sort()", like Python
standard list objects.  Finally, sequence types should implement
addition (meaning concatenation) and multiplication (meaning
repetition) by defining the methods "__add__()", "__radd__()",
"__iadd__()", "__mul__()", "__rmul__()" and "__imul__()" described
below; they should not define other numerical operators.  It is
recommended that both mappings and sequences implement the
"__contains__()" method to allow efficient use of the "in" operator;
for mappings, "in" should search the mapping's keys; for sequences, it
should search through the values.  It is further recommended that both
mappings and sequences implement the "__iter__()" method to allow
efficient iteration through the container; for mappings, "__iter__()"
should be the same as "keys()"; for sequences, it should iterate
through the values.

object.__len__(self)

   Called to implement the built-in function "len()".  Should return
   the length of the object, an integer ">=" 0.  Also, an object that
   doesn't define a "__bool__()" method and whose "__len__()" method
   returns zero is considered to be false in a Boolean context.

   **CPython implementation detail:** In CPython, the length is
   required to be at most "sys.maxsize". If the length is larger than
   "sys.maxsize" some features (such as "len()") may raise
   "OverflowError".  To prevent raising "OverflowError" by truth value
   testing, an object must define a "__bool__()" method.

object.__length_hint__(self)

   Called to implement "operator.length_hint()". Should return an
   estimated length for the object (which may be greater or less than
   the actual length). The length must be an integer ">=" 0. This
   method is purely an optimization and is never required for
   correctness.

   New in version 3.4.

Note: Slicing is done exclusively with the following three methods.
  A call like

     a[1:2] = b

  is translated to

     a[slice(1, 2, None)] = b

  and so forth.  Missing slice items are always filled in with "None".

object.__getitem__(self, key)

   Called to implement evaluation of "self[key]". For sequence types,
   the accepted keys should be integers and slice objects.  Note that
   the special interpretation of negative indexes (if the class wishes
   to emulate a sequence type) is up to the "__getitem__()" method. If
   *key* is of an inappropriate type, "TypeError" may be raised; if of
   a value outside the set of indexes for the sequence (after any
   special interpretation of negative values), "IndexError" should be
   raised. For mapping types, if *key* is missing (not in the
   container), "KeyError" should be raised.

   Note: "for" loops expect that an "IndexError" will be raised for
     illegal indexes to allow proper detection of the end of the
     sequence.

object.__missing__(self, key)

   Called by "dict"."__getitem__()" to implement "self[key]" for dict
   subclasses when key is not in the dictionary.

object.__setitem__(self, key, value)

   Called to implement assignment to "self[key]".  Same note as for
   "__getitem__()".  This should only be implemented for mappings if
   the objects support changes to the values for keys, or if new keys
   can be added, or for sequences if elements can be replaced.  The
   same exceptions should be raised for improper *key* values as for
   the "__getitem__()" method.

object.__delitem__(self, key)

   Called to implement deletion of "self[key]".  Same note as for
   "__getitem__()".  This should only be implemented for mappings if
   the objects support removal of keys, or for sequences if elements
   can be removed from the sequence.  The same exceptions should be
   raised for improper *key* values as for the "__getitem__()" method.

object.__iter__(self)

   This method is called when an iterator is required for a container.
   This method should return a new iterator object that can iterate
   over all the objects in the container.  For mappings, it should
   iterate over the keys of the container.

   Iterator objects also need to implement this method; they are
   required to return themselves.  For more information on iterator
   objects, see Iterator Types.

object.__reversed__(self)

   Called (if present) by the "reversed()" built-in to implement
   reverse iteration.  It should return a new iterator object that
   iterates over all the objects in the container in reverse order.

   If the "__reversed__()" method is not provided, the "reversed()"
   built-in will fall back to using the sequence protocol ("__len__()"
   and "__getitem__()").  Objects that support the sequence protocol
   should only provide "__reversed__()" if they can provide an
   implementation that is more efficient than the one provided by
   "reversed()".

The membership test operators ("in" and "not in") are normally
implemented as an iteration through a sequence.  However, container
objects can supply the following special method with a more efficient
implementation, which also does not require the object be a sequence.

object.__contains__(self, item)

   Called to implement membership test operators.  Should return true
   if *item* is in *self*, false otherwise.  For mapping objects, this
   should consider the keys of the mapping rather than the values or
   the key-item pairs.

   For objects that don't define "__contains__()", the membership test
   first tries iteration via "__iter__()", then the old sequence
   iteration protocol via "__getitem__()", see this section in the
   language reference.


Emulating numeric types
=======================

The following methods can be defined to emulate numeric objects.
Methods corresponding to operations that are not supported by the
particular kind of number implemented (e.g., bitwise operations for
non-integral numbers) should be left undefined.

object.__add__(self, other)
object.__sub__(self, other)
object.__mul__(self, other)
object.__matmul__(self, other)
object.__truediv__(self, other)
object.__floordiv__(self, other)
object.__mod__(self, other)
object.__divmod__(self, other)
object.__pow__(self, other[, modulo])
object.__lshift__(self, other)
object.__rshift__(self, other)
object.__and__(self, other)
object.__xor__(self, other)
object.__or__(self, other)

   These methods are called to implement the binary arithmetic
   operations ("+", "-", "*", "@", "/", "//", "%", "divmod()",
   "pow()", "**", "<<", ">>", "&", "^", "|").  For instance, to
   evaluate the expression "x + y", where *x* is an instance of a
   class that has an "__add__()" method, "x.__add__(y)" is called.
   The "__divmod__()" method should be the equivalent to using
   "__floordiv__()" and "__mod__()"; it should not be related to
   "__truediv__()".  Note that "__pow__()" should be defined to accept
   an optional third argument if the ternary version of the built-in
   "pow()" function is to be supported.

   If one of those methods does not support the operation with the
   supplied arguments, it should return "NotImplemented".

object.__radd__(self, other)
object.__rsub__(self, other)
object.__rmul__(self, other)
object.__rmatmul__(self, other)
object.__rtruediv__(self, other)
object.__rfloordiv__(self, other)
object.__rmod__(self, other)
object.__rdivmod__(self, other)
object.__rpow__(self, other)
object.__rlshift__(self, other)
object.__rrshift__(self, other)
object.__rand__(self, other)
object.__rxor__(self, other)
object.__ror__(self, other)

   These methods are called to implement the binary arithmetic
   operations ("+", "-", "*", "@", "/", "//", "%", "divmod()",
   "pow()", "**", "<<", ">>", "&", "^", "|") with reflected (swapped)
   operands.  These functions are only called if the left operand does
   not support the corresponding operation [3] and the operands are of
   different types. [4] For instance, to evaluate the expression "x -
   y", where *y* is an instance of a class that has an "__rsub__()"
   method, "y.__rsub__(x)" is called if "x.__sub__(y)" returns
   *NotImplemented*.

   Note that ternary "pow()" will not try calling "__rpow__()" (the
   coercion rules would become too complicated).

   Note: If the right operand's type is a subclass of the left
     operand's type and that subclass provides the reflected method
     for the operation, this method will be called before the left
     operand's non-reflected method.  This behavior allows subclasses
     to override their ancestors' operations.

object.__iadd__(self, other)
object.__isub__(self, other)
object.__imul__(self, other)
object.__imatmul__(self, other)
object.__itruediv__(self, other)
object.__ifloordiv__(self, other)
object.__imod__(self, other)
object.__ipow__(self, other[, modulo])
object.__ilshift__(self, other)
object.__irshift__(self, other)
object.__iand__(self, other)
object.__ixor__(self, other)
object.__ior__(self, other)

   These methods are called to implement the augmented arithmetic
   assignments ("+=", "-=", "*=", "@=", "/=", "//=", "%=", "**=",
   "<<=", ">>=", "&=", "^=", "|=").  These methods should attempt to
   do the operation in-place (modifying *self*) and return the result
   (which could be, but does not have to be, *self*).  If a specific
   method is not defined, the augmented assignment falls back to the
   normal methods.  For instance, if *x* is an instance of a class
   with an "__iadd__()" method, "x += y" is equivalent to "x =
   x.__iadd__(y)" . Otherwise, "x.__add__(y)" and "y.__radd__(x)" are
   considered, as with the evaluation of "x + y". In certain
   situations, augmented assignment can result in unexpected errors
   (see Why does a_tuple[i] += ['item'] raise an exception when the
   addition works?), but this behavior is in fact part of the data
   model.

object.__neg__(self)
object.__pos__(self)
object.__abs__(self)
object.__invert__(self)

   Called to implement the unary arithmetic operations ("-", "+",
   "abs()" and "~").

object.__complex__(self)
object.__int__(self)
object.__float__(self)

   Called to implement the built-in functions "complex()", "int()" and
   "float()".  Should return a value of the appropriate type.

object.__index__(self)

   Called to implement "operator.index()", and whenever Python needs
   to losslessly convert the numeric object to an integer object (such
   as in slicing, or in the built-in "bin()", "hex()" and "oct()"
   functions). Presence of this method indicates that the numeric
   object is an integer type.  Must return an integer.

   Note: In order to have a coherent integer type class, when
     "__index__()" is defined "__int__()" should also be defined, and
     both should return the same value.

object.__round__(self[, ndigits])
object.__trunc__(self)
object.__floor__(self)
object.__ceil__(self)

   Called to implement the built-in function "round()" and "math"
   functions "trunc()", "floor()" and "ceil()". Unless *ndigits* is
   passed to "__round__()" all these methods should return the value
   of the object truncated to an "Integral" (typically an "int").

   If "__int__()" is not defined then the built-in function "int()"
   falls back to "__trunc__()".


With Statement Context Managers
===============================

A *context manager* is an object that defines the runtime context to
be established when executing a "with" statement. The context manager
handles the entry into, and the exit from, the desired runtime context
for the execution of the block of code.  Context managers are normally
invoked using the "with" statement (described in section The with
statement), but can also be used by directly invoking their methods.

Typical uses of context managers include saving and restoring various
kinds of global state, locking and unlocking resources, closing opened
files, etc.

For more information on context managers, see Context Manager Types.

object.__enter__(self)

   Enter the runtime context related to this object. The "with"
   statement will bind this method's return value to the target(s)
   specified in the "as" clause of the statement, if any.

object.__exit__(self, exc_type, exc_value, traceback)

   Exit the runtime context related to this object. The parameters
   describe the exception that caused the context to be exited. If the
   context was exited without an exception, all three arguments will
   be "None".

   If an exception is supplied, and the method wishes to suppress the
   exception (i.e., prevent it from being propagated), it should
   return a true value. Otherwise, the exception will be processed
   normally upon exit from this method.

   Note that "__exit__()" methods should not reraise the passed-in
   exception; this is the caller's responsibility.

See also:

  **PEP 343** - The "with" statement
     The specification, background, and examples for the Python "with"
     statement.


Special method lookup
=====================

For custom classes, implicit invocations of special methods are only
guaranteed to work correctly if defined on an object's type, not in
the object's instance dictionary.  That behaviour is the reason why
the following code raises an exception:

   >>> class C:
   ...     pass
   ...
   >>> c = C()
   >>> c.__len__ = lambda: 5
   >>> len(c)
   Traceback (most recent call last):
     File "<stdin>", line 1, in <module>
   TypeError: object of type 'C' has no len()

The rationale behind this behaviour lies with a number of special
methods such as "__hash__()" and "__repr__()" that are implemented by
all objects, including type objects. If the implicit lookup of these
methods used the conventional lookup process, they would fail when
invoked on the type object itself:

   >>> 1 .__hash__() == hash(1)
   True
   >>> int.__hash__() == hash(int)
   Traceback (most recent call last):
     File "<stdin>", line 1, in <module>
   TypeError: descriptor '__hash__' of 'int' object needs an argument

Incorrectly attempting to invoke an unbound method of a class in this
way is sometimes referred to as 'metaclass confusion', and is avoided
by bypassing the instance when looking up special methods:

   >>> type(1).__hash__(1) == hash(1)
   True
   >>> type(int).__hash__(int) == hash(int)
   True

In addition to bypassing any instance attributes in the interest of
correctness, implicit special method lookup generally also bypasses
the "__getattribute__()" method even of the object's metaclass:

   >>> class Meta(type):
   ...     def __getattribute__(*args):
   ...         print("Metaclass getattribute invoked")
   ...         return type.__getattribute__(*args)
   ...
   >>> class C(object, metaclass=Meta):
   ...     def __len__(self):
   ...         return 10
   ...     def __getattribute__(*args):
   ...         print("Class getattribute invoked")
   ...         return object.__getattribute__(*args)
   ...
   >>> c = C()
   >>> c.__len__()                 # Explicit lookup via instance
   Class getattribute invoked
   10
   >>> type(c).__len__(c)          # Explicit lookup via type
   Metaclass getattribute invoked
   10
   >>> len(c)                      # Implicit lookup
   10

Bypassing the "__getattribute__()" machinery in this fashion provides
significant scope for speed optimisations within the interpreter, at
the cost of some flexibility in the handling of special methods (the
special method *must* be set on the class object itself in order to be
consistently invoked by the interpreter).
zstring-methodsuàV  String Methods
**************

Strings implement all of the common sequence operations, along with
the additional methods described below.

Strings also support two styles of string formatting, one providing a
large degree of flexibility and customization (see "str.format()",
Format String Syntax and Custom String Formatting) and the other based
on C "printf" style formatting that handles a narrower range of types
and is slightly harder to use correctly, but is often faster for the
cases it can handle (printf-style String Formatting).

The Text Processing Services section of the standard library covers a
number of other modules that provide various text related utilities
(including regular expression support in the "re" module).

str.capitalize()

   Return a copy of the string with its first character capitalized
   and the rest lowercased.

str.casefold()

   Return a casefolded copy of the string. Casefolded strings may be
   used for caseless matching.

   Casefolding is similar to lowercasing but more aggressive because
   it is intended to remove all case distinctions in a string. For
   example, the German lowercase letter "'Ã'" is equivalent to ""ss"".
   Since it is already lowercase, "lower()" would do nothing to "'Ã'";
   "casefold()" converts it to ""ss"".

   The casefolding algorithm is described in section 3.13 of the
   Unicode Standard.

   New in version 3.3.

str.center(width[, fillchar])

   Return centered in a string of length *width*. Padding is done
   using the specified *fillchar* (default is an ASCII space). The
   original string is returned if *width* is less than or equal to
   "len(s)".

str.count(sub[, start[, end]])

   Return the number of non-overlapping occurrences of substring *sub*
   in the range [*start*, *end*].  Optional arguments *start* and
   *end* are interpreted as in slice notation.

str.encode(encoding="utf-8", errors="strict")

   Return an encoded version of the string as a bytes object. Default
   encoding is "'utf-8'". *errors* may be given to set a different
   error handling scheme. The default for *errors* is "'strict'",
   meaning that encoding errors raise a "UnicodeError". Other possible
   values are "'ignore'", "'replace'", "'xmlcharrefreplace'",
   "'backslashreplace'" and any other name registered via
   "codecs.register_error()", see section Error Handlers. For a list
   of possible encodings, see section Standard Encodings.

   Changed in version 3.1: Support for keyword arguments added.

str.endswith(suffix[, start[, end]])

   Return "True" if the string ends with the specified *suffix*,
   otherwise return "False".  *suffix* can also be a tuple of suffixes
   to look for.  With optional *start*, test beginning at that
   position.  With optional *end*, stop comparing at that position.

str.expandtabs(tabsize=8)

   Return a copy of the string where all tab characters are replaced
   by one or more spaces, depending on the current column and the
   given tab size.  Tab positions occur every *tabsize* characters
   (default is 8, giving tab positions at columns 0, 8, 16 and so on).
   To expand the string, the current column is set to zero and the
   string is examined character by character.  If the character is a
   tab ("\t"), one or more space characters are inserted in the result
   until the current column is equal to the next tab position. (The
   tab character itself is not copied.)  If the character is a newline
   ("\n") or return ("\r"), it is copied and the current column is
   reset to zero.  Any other character is copied unchanged and the
   current column is incremented by one regardless of how the
   character is represented when printed.

   >>> '01\t012\t0123\t01234'.expandtabs()
   '01      012     0123    01234'
   >>> '01\t012\t0123\t01234'.expandtabs(4)
   '01  012 0123    01234'

str.find(sub[, start[, end]])

   Return the lowest index in the string where substring *sub* is
   found within the slice "s[start:end]".  Optional arguments *start*
   and *end* are interpreted as in slice notation.  Return "-1" if
   *sub* is not found.

   Note: The "find()" method should be used only if you need to know
     the position of *sub*.  To check if *sub* is a substring or not,
     use the "in" operator:

        >>> 'Py' in 'Python'
        True

str.format(*args, **kwargs)

   Perform a string formatting operation.  The string on which this
   method is called can contain literal text or replacement fields
   delimited by braces "{}".  Each replacement field contains either
   the numeric index of a positional argument, or the name of a
   keyword argument.  Returns a copy of the string where each
   replacement field is replaced with the string value of the
   corresponding argument.

   >>> "The sum of 1 + 2 is {0}".format(1+2)
   'The sum of 1 + 2 is 3'

   See Format String Syntax for a description of the various
   formatting options that can be specified in format strings.

   Note: When formatting a number ("int", "float", "float" and
     subclasses) with the "n" type (ex: "'{:n}'.format(1234)"), the
     function sets temporarily the "LC_CTYPE" locale to the
     "LC_NUMERIC" locale to decode "decimal_point" and "thousands_sep"
     fields of "localeconv()" if they are non-ASCII or longer than 1
     byte, and the "LC_NUMERIC" locale is different than the
     "LC_CTYPE" locale. This temporary change affects other threads.

   Changed in version 3.6.5: When formatting a number with the "n"
   type, the function sets temporarily the "LC_CTYPE" locale to the
   "LC_NUMERIC" locale in some cases.

str.format_map(mapping)

   Similar to "str.format(**mapping)", except that "mapping" is used
   directly and not copied to a "dict".  This is useful if for example
   "mapping" is a dict subclass:

   >>> class Default(dict):
   ...     def __missing__(self, key):
   ...         return key
   ...
   >>> '{name} was born in {country}'.format_map(Default(name='Guido'))
   'Guido was born in country'

   New in version 3.2.

str.index(sub[, start[, end]])

   Like "find()", but raise "ValueError" when the substring is not
   found.

str.isalnum()

   Return true if all characters in the string are alphanumeric and
   there is at least one character, false otherwise.  A character "c"
   is alphanumeric if one of the following returns "True":
   "c.isalpha()", "c.isdecimal()", "c.isdigit()", or "c.isnumeric()".

str.isalpha()

   Return true if all characters in the string are alphabetic and
   there is at least one character, false otherwise.  Alphabetic
   characters are those characters defined in the Unicode character
   database as "Letter", i.e., those with general category property
   being one of "Lm", "Lt", "Lu", "Ll", or "Lo".  Note that this is
   different from the "Alphabetic" property defined in the Unicode
   Standard.

str.isdecimal()

   Return true if all characters in the string are decimal characters
   and there is at least one character, false otherwise. Decimal
   characters are those that can be used to form numbers in base 10,
   e.g. U+0660, ARABIC-INDIC DIGIT ZERO.  Formally a decimal character
   is a character in the Unicode General Category "Nd".

str.isdigit()

   Return true if all characters in the string are digits and there is
   at least one character, false otherwise.  Digits include decimal
   characters and digits that need special handling, such as the
   compatibility superscript digits. This covers digits which cannot
   be used to form numbers in base 10, like the Kharosthi numbers.
   Formally, a digit is a character that has the property value
   Numeric_Type=Digit or Numeric_Type=Decimal.

str.isidentifier()

   Return true if the string is a valid identifier according to the
   language definition, section Identifiers and keywords.

   Use "keyword.iskeyword()" to test for reserved identifiers such as
   "def" and "class".

str.islower()

   Return true if all cased characters [4] in the string are lowercase
   and there is at least one cased character, false otherwise.

str.isnumeric()

   Return true if all characters in the string are numeric characters,
   and there is at least one character, false otherwise. Numeric
   characters include digit characters, and all characters that have
   the Unicode numeric value property, e.g. U+2155, VULGAR FRACTION
   ONE FIFTH.  Formally, numeric characters are those with the
   property value Numeric_Type=Digit, Numeric_Type=Decimal or
   Numeric_Type=Numeric.

str.isprintable()

   Return true if all characters in the string are printable or the
   string is empty, false otherwise.  Nonprintable characters are
   those characters defined in the Unicode character database as
   "Other" or "Separator", excepting the ASCII space (0x20) which is
   considered printable.  (Note that printable characters in this
   context are those which should not be escaped when "repr()" is
   invoked on a string.  It has no bearing on the handling of strings
   written to "sys.stdout" or "sys.stderr".)

str.isspace()

   Return true if there are only whitespace characters in the string
   and there is at least one character, false otherwise.  Whitespace
   characters  are those characters defined in the Unicode character
   database as "Other" or "Separator" and those with bidirectional
   property being one of "WS", "B", or "S".

str.istitle()

   Return true if the string is a titlecased string and there is at
   least one character, for example uppercase characters may only
   follow uncased characters and lowercase characters only cased ones.
   Return false otherwise.

str.isupper()

   Return true if all cased characters [4] in the string are uppercase
   and there is at least one cased character, false otherwise.

str.join(iterable)

   Return a string which is the concatenation of the strings in
   *iterable*. A "TypeError" will be raised if there are any non-
   string values in *iterable*, including "bytes" objects.  The
   separator between elements is the string providing this method.

str.ljust(width[, fillchar])

   Return the string left justified in a string of length *width*.
   Padding is done using the specified *fillchar* (default is an ASCII
   space). The original string is returned if *width* is less than or
   equal to "len(s)".

str.lower()

   Return a copy of the string with all the cased characters [4]
   converted to lowercase.

   The lowercasing algorithm used is described in section 3.13 of the
   Unicode Standard.

str.lstrip([chars])

   Return a copy of the string with leading characters removed.  The
   *chars* argument is a string specifying the set of characters to be
   removed.  If omitted or "None", the *chars* argument defaults to
   removing whitespace.  The *chars* argument is not a prefix; rather,
   all combinations of its values are stripped:

      >>> '   spacious   '.lstrip()
      'spacious   '
      >>> 'www.example.com'.lstrip('cmowz.')
      'example.com'

static str.maketrans(x[, y[, z]])

   This static method returns a translation table usable for
   "str.translate()".

   If there is only one argument, it must be a dictionary mapping
   Unicode ordinals (integers) or characters (strings of length 1) to
   Unicode ordinals, strings (of arbitrary lengths) or "None".
   Character keys will then be converted to ordinals.

   If there are two arguments, they must be strings of equal length,
   and in the resulting dictionary, each character in x will be mapped
   to the character at the same position in y.  If there is a third
   argument, it must be a string, whose characters will be mapped to
   "None" in the result.

str.partition(sep)

   Split the string at the first occurrence of *sep*, and return a
   3-tuple containing the part before the separator, the separator
   itself, and the part after the separator.  If the separator is not
   found, return a 3-tuple containing the string itself, followed by
   two empty strings.

str.replace(old, new[, count])

   Return a copy of the string with all occurrences of substring *old*
   replaced by *new*.  If the optional argument *count* is given, only
   the first *count* occurrences are replaced.

str.rfind(sub[, start[, end]])

   Return the highest index in the string where substring *sub* is
   found, such that *sub* is contained within "s[start:end]".
   Optional arguments *start* and *end* are interpreted as in slice
   notation.  Return "-1" on failure.

str.rindex(sub[, start[, end]])

   Like "rfind()" but raises "ValueError" when the substring *sub* is
   not found.

str.rjust(width[, fillchar])

   Return the string right justified in a string of length *width*.
   Padding is done using the specified *fillchar* (default is an ASCII
   space). The original string is returned if *width* is less than or
   equal to "len(s)".

str.rpartition(sep)

   Split the string at the last occurrence of *sep*, and return a
   3-tuple containing the part before the separator, the separator
   itself, and the part after the separator.  If the separator is not
   found, return a 3-tuple containing two empty strings, followed by
   the string itself.

str.rsplit(sep=None, maxsplit=-1)

   Return a list of the words in the string, using *sep* as the
   delimiter string. If *maxsplit* is given, at most *maxsplit* splits
   are done, the *rightmost* ones.  If *sep* is not specified or
   "None", any whitespace string is a separator.  Except for splitting
   from the right, "rsplit()" behaves like "split()" which is
   described in detail below.

str.rstrip([chars])

   Return a copy of the string with trailing characters removed.  The
   *chars* argument is a string specifying the set of characters to be
   removed.  If omitted or "None", the *chars* argument defaults to
   removing whitespace.  The *chars* argument is not a suffix; rather,
   all combinations of its values are stripped:

      >>> '   spacious   '.rstrip()
      '   spacious'
      >>> 'mississippi'.rstrip('ipz')
      'mississ'

str.split(sep=None, maxsplit=-1)

   Return a list of the words in the string, using *sep* as the
   delimiter string.  If *maxsplit* is given, at most *maxsplit*
   splits are done (thus, the list will have at most "maxsplit+1"
   elements).  If *maxsplit* is not specified or "-1", then there is
   no limit on the number of splits (all possible splits are made).

   If *sep* is given, consecutive delimiters are not grouped together
   and are deemed to delimit empty strings (for example,
   "'1,,2'.split(',')" returns "['1', '', '2']").  The *sep* argument
   may consist of multiple characters (for example,
   "'1<>2<>3'.split('<>')" returns "['1', '2', '3']"). Splitting an
   empty string with a specified separator returns "['']".

   For example:

      >>> '1,2,3'.split(',')
      ['1', '2', '3']
      >>> '1,2,3'.split(',', maxsplit=1)
      ['1', '2,3']
      >>> '1,2,,3,'.split(',')
      ['1', '2', '', '3', '']

   If *sep* is not specified or is "None", a different splitting
   algorithm is applied: runs of consecutive whitespace are regarded
   as a single separator, and the result will contain no empty strings
   at the start or end if the string has leading or trailing
   whitespace.  Consequently, splitting an empty string or a string
   consisting of just whitespace with a "None" separator returns "[]".

   For example:

      >>> '1 2 3'.split()
      ['1', '2', '3']
      >>> '1 2 3'.split(maxsplit=1)
      ['1', '2 3']
      >>> '   1   2   3   '.split()
      ['1', '2', '3']

str.splitlines([keepends])

   Return a list of the lines in the string, breaking at line
   boundaries.  Line breaks are not included in the resulting list
   unless *keepends* is given and true.

   This method splits on the following line boundaries.  In
   particular, the boundaries are a superset of *universal newlines*.

   +-------------------------+-------------------------------+
   | Representation          | Description                   |
   +=========================+===============================+
   | "\n"                    | Line Feed                     |
   +-------------------------+-------------------------------+
   | "\r"                    | Carriage Return               |
   +-------------------------+-------------------------------+
   | "\r\n"                  | Carriage Return + Line Feed   |
   +-------------------------+-------------------------------+
   | "\v" or "\x0b"          | Line Tabulation               |
   +-------------------------+-------------------------------+
   | "\f" or "\x0c"          | Form Feed                     |
   +-------------------------+-------------------------------+
   | "\x1c"                  | File Separator                |
   +-------------------------+-------------------------------+
   | "\x1d"                  | Group Separator               |
   +-------------------------+-------------------------------+
   | "\x1e"                  | Record Separator              |
   +-------------------------+-------------------------------+
   | "\x85"                  | Next Line (C1 Control Code)   |
   +-------------------------+-------------------------------+
   | "\u2028"                | Line Separator                |
   +-------------------------+-------------------------------+
   | "\u2029"                | Paragraph Separator           |
   +-------------------------+-------------------------------+

   Changed in version 3.2: "\v" and "\f" added to list of line
   boundaries.

   For example:

      >>> 'ab c\n\nde fg\rkl\r\n'.splitlines()
      ['ab c', '', 'de fg', 'kl']
      >>> 'ab c\n\nde fg\rkl\r\n'.splitlines(keepends=True)
      ['ab c\n', '\n', 'de fg\r', 'kl\r\n']

   Unlike "split()" when a delimiter string *sep* is given, this
   method returns an empty list for the empty string, and a terminal
   line break does not result in an extra line:

      >>> "".splitlines()
      []
      >>> "One line\n".splitlines()
      ['One line']

   For comparison, "split('\n')" gives:

      >>> ''.split('\n')
      ['']
      >>> 'Two lines\n'.split('\n')
      ['Two lines', '']

str.startswith(prefix[, start[, end]])

   Return "True" if string starts with the *prefix*, otherwise return
   "False". *prefix* can also be a tuple of prefixes to look for.
   With optional *start*, test string beginning at that position.
   With optional *end*, stop comparing string at that position.

str.strip([chars])

   Return a copy of the string with the leading and trailing
   characters removed. The *chars* argument is a string specifying the
   set of characters to be removed. If omitted or "None", the *chars*
   argument defaults to removing whitespace. The *chars* argument is
   not a prefix or suffix; rather, all combinations of its values are
   stripped:

      >>> '   spacious   '.strip()
      'spacious'
      >>> 'www.example.com'.strip('cmowz.')
      'example'

   The outermost leading and trailing *chars* argument values are
   stripped from the string. Characters are removed from the leading
   end until reaching a string character that is not contained in the
   set of characters in *chars*. A similar action takes place on the
   trailing end. For example:

      >>> comment_string = '#....... Section 3.2.1 Issue #32 .......'
      >>> comment_string.strip('.#! ')
      'Section 3.2.1 Issue #32'

str.swapcase()

   Return a copy of the string with uppercase characters converted to
   lowercase and vice versa. Note that it is not necessarily true that
   "s.swapcase().swapcase() == s".

str.title()

   Return a titlecased version of the string where words start with an
   uppercase character and the remaining characters are lowercase.

   For example:

      >>> 'Hello world'.title()
      'Hello World'

   The algorithm uses a simple language-independent definition of a
   word as groups of consecutive letters.  The definition works in
   many contexts but it means that apostrophes in contractions and
   possessives form word boundaries, which may not be the desired
   result:

      >>> "they're bill's friends from the UK".title()
      "They'Re Bill'S Friends From The Uk"

   A workaround for apostrophes can be constructed using regular
   expressions:

      >>> import re
      >>> def titlecase(s):
      ...     return re.sub(r"[A-Za-z]+('[A-Za-z]+)?",
      ...                   lambda mo: mo.group(0)[0].upper() +
      ...                              mo.group(0)[1:].lower(),
      ...                   s)
      ...
      >>> titlecase("they're bill's friends.")
      "They're Bill's Friends."

str.translate(table)

   Return a copy of the string in which each character has been mapped
   through the given translation table.  The table must be an object
   that implements indexing via "__getitem__()", typically a *mapping*
   or *sequence*.  When indexed by a Unicode ordinal (an integer), the
   table object can do any of the following: return a Unicode ordinal
   or a string, to map the character to one or more other characters;
   return "None", to delete the character from the return string; or
   raise a "LookupError" exception, to map the character to itself.

   You can use "str.maketrans()" to create a translation map from
   character-to-character mappings in different formats.

   See also the "codecs" module for a more flexible approach to custom
   character mappings.

str.upper()

   Return a copy of the string with all the cased characters [4]
   converted to uppercase.  Note that "str.upper().isupper()" might be
   "False" if "s" contains uncased characters or if the Unicode
   category of the resulting character(s) is not "Lu" (Letter,
   uppercase), but e.g. "Lt" (Letter, titlecase).

   The uppercasing algorithm used is described in section 3.13 of the
   Unicode Standard.

str.zfill(width)

   Return a copy of the string left filled with ASCII "'0'" digits to
   make a string of length *width*. A leading sign prefix
   ("'+'"/"'-'") is handled by inserting the padding *after* the sign
   character rather than before. The original string is returned if
   *width* is less than or equal to "len(s)".

   For example:

      >>> "42".zfill(5)
      '00042'
      >>> "-42".zfill(5)
      '-0042'
zstringsao   String and Bytes literals
*************************

String literals are described by the following lexical definitions:

   stringliteral   ::= [stringprefix](shortstring | longstring)
   stringprefix    ::= "r" | "u" | "R" | "U" | "f" | "F"
                    | "fr" | "Fr" | "fR" | "FR" | "rf" | "rF" | "Rf" | "RF"
   shortstring     ::= "'" shortstringitem* "'" | '"' shortstringitem* '"'
   longstring      ::= "'''" longstringitem* "'''" | '"""' longstringitem* '"""'
   shortstringitem ::= shortstringchar | stringescapeseq
   longstringitem  ::= longstringchar | stringescapeseq
   shortstringchar ::= <any source character except "\" or newline or the quote>
   longstringchar  ::= <any source character except "\">
   stringescapeseq ::= "\" <any source character>

   bytesliteral   ::= bytesprefix(shortbytes | longbytes)
   bytesprefix    ::= "b" | "B" | "br" | "Br" | "bR" | "BR" | "rb" | "rB" | "Rb" | "RB"
   shortbytes     ::= "'" shortbytesitem* "'" | '"' shortbytesitem* '"'
   longbytes      ::= "'''" longbytesitem* "'''" | '"""' longbytesitem* '"""'
   shortbytesitem ::= shortbyteschar | bytesescapeseq
   longbytesitem  ::= longbyteschar | bytesescapeseq
   shortbyteschar ::= <any ASCII character except "\" or newline or the quote>
   longbyteschar  ::= <any ASCII character except "\">
   bytesescapeseq ::= "\" <any ASCII character>

One syntactic restriction not indicated by these productions is that
whitespace is not allowed between the "stringprefix" or "bytesprefix"
and the rest of the literal. The source character set is defined by
the encoding declaration; it is UTF-8 if no encoding declaration is
given in the source file; see section Encoding declarations.

In plain English: Both types of literals can be enclosed in matching
single quotes ("'") or double quotes (""").  They can also be enclosed
in matching groups of three single or double quotes (these are
generally referred to as *triple-quoted strings*).  The backslash
("\") character is used to escape characters that otherwise have a
special meaning, such as newline, backslash itself, or the quote
character.

Bytes literals are always prefixed with "'b'" or "'B'"; they produce
an instance of the "bytes" type instead of the "str" type.  They may
only contain ASCII characters; bytes with a numeric value of 128 or
greater must be expressed with escapes.

Both string and bytes literals may optionally be prefixed with a
letter "'r'" or "'R'"; such strings are called *raw strings* and treat
backslashes as literal characters.  As a result, in string literals,
"'\U'" and "'\u'" escapes in raw strings are not treated specially.
Given that Python 2.x's raw unicode literals behave differently than
Python 3.x's the "'ur'" syntax is not supported.

New in version 3.3: The "'rb'" prefix of raw bytes literals has been
added as a synonym of "'br'".

New in version 3.3: Support for the unicode legacy literal
("u'value'") was reintroduced to simplify the maintenance of dual
Python 2.x and 3.x codebases. See **PEP 414** for more information.

A string literal with "'f'" or "'F'" in its prefix is a *formatted
string literal*; see Formatted string literals.  The "'f'" may be
combined with "'r'", but not with "'b'" or "'u'", therefore raw
formatted strings are possible, but formatted bytes literals are not.

In triple-quoted literals, unescaped newlines and quotes are allowed
(and are retained), except that three unescaped quotes in a row
terminate the literal.  (A "quote" is the character used to open the
literal, i.e. either "'" or """.)

Unless an "'r'" or "'R'" prefix is present, escape sequences in string
and bytes literals are interpreted according to rules similar to those
used by Standard C.  The recognized escape sequences are:

+-------------------+-----------------------------------+---------+
| Escape Sequence   | Meaning                           | Notes   |
+===================+===================================+=========+
| "\newline"        | Backslash and newline ignored     |         |
+-------------------+-----------------------------------+---------+
| "\\"              | Backslash ("\")                   |         |
+-------------------+-----------------------------------+---------+
| "\'"              | Single quote ("'")                |         |
+-------------------+-----------------------------------+---------+
| "\""              | Double quote (""")                |         |
+-------------------+-----------------------------------+---------+
| "\a"              | ASCII Bell (BEL)                  |         |
+-------------------+-----------------------------------+---------+
| "\b"              | ASCII Backspace (BS)              |         |
+-------------------+-----------------------------------+---------+
| "\f"              | ASCII Formfeed (FF)               |         |
+-------------------+-----------------------------------+---------+
| "\n"              | ASCII Linefeed (LF)               |         |
+-------------------+-----------------------------------+---------+
| "\r"              | ASCII Carriage Return (CR)        |         |
+-------------------+-----------------------------------+---------+
| "\t"              | ASCII Horizontal Tab (TAB)        |         |
+-------------------+-----------------------------------+---------+
| "\v"              | ASCII Vertical Tab (VT)           |         |
+-------------------+-----------------------------------+---------+
| "\ooo"            | Character with octal value *ooo*  | (1,3)   |
+-------------------+-----------------------------------+---------+
| "\xhh"            | Character with hex value *hh*     | (2,3)   |
+-------------------+-----------------------------------+---------+

Escape sequences only recognized in string literals are:

+-------------------+-----------------------------------+---------+
| Escape Sequence   | Meaning                           | Notes   |
+===================+===================================+=========+
| "\N{name}"        | Character named *name* in the     | (4)     |
|                   | Unicode database                  |         |
+-------------------+-----------------------------------+---------+
| "\uxxxx"          | Character with 16-bit hex value   | (5)     |
|                   | *xxxx*                            |         |
+-------------------+-----------------------------------+---------+
| "\Uxxxxxxxx"      | Character with 32-bit hex value   | (6)     |
|                   | *xxxxxxxx*                        |         |
+-------------------+-----------------------------------+---------+

Notes:

1. As in Standard C, up to three octal digits are accepted.

2. Unlike in Standard C, exactly two hex digits are required.

3. In a bytes literal, hexadecimal and octal escapes denote the
   byte with the given value. In a string literal, these escapes
   denote a Unicode character with the given value.

4. Changed in version 3.3: Support for name aliases [1] has been
   added.

5. Exactly four hex digits are required.

6. Any Unicode character can be encoded this way.  Exactly eight
   hex digits are required.

Unlike Standard C, all unrecognized escape sequences are left in the
string unchanged, i.e., *the backslash is left in the result*.  (This
behavior is useful when debugging: if an escape sequence is mistyped,
the resulting output is more easily recognized as broken.)  It is also
important to note that the escape sequences only recognized in string
literals fall into the category of unrecognized escapes for bytes
literals.

   Changed in version 3.6: Unrecognized escape sequences produce a
   DeprecationWarning.  In some future version of Python they will be
   a SyntaxError.

Even in a raw literal, quotes can be escaped with a backslash, but the
backslash remains in the result; for example, "r"\""" is a valid
string literal consisting of two characters: a backslash and a double
quote; "r"\"" is not a valid string literal (even a raw string cannot
end in an odd number of backslashes).  Specifically, *a raw literal
cannot end in a single backslash* (since the backslash would escape
the following quote character).  Note also that a single backslash
followed by a newline is interpreted as those two characters as part
of the literal, *not* as a line continuation.
zsubscriptionsaK  Subscriptions
*************

A subscription selects an item of a sequence (string, tuple or list)
or mapping (dictionary) object:

   subscription ::= primary "[" expression_list "]"

The primary must evaluate to an object that supports subscription
(lists or dictionaries for example).  User-defined objects can support
subscription by defining a "__getitem__()" method.

For built-in objects, there are two types of objects that support
subscription:

If the primary is a mapping, the expression list must evaluate to an
object whose value is one of the keys of the mapping, and the
subscription selects the value in the mapping that corresponds to that
key.  (The expression list is a tuple except if it has exactly one
item.)

If the primary is a sequence, the expression (list) must evaluate to
an integer or a slice (as discussed in the following section).

The formal syntax makes no special provision for negative indices in
sequences; however, built-in sequences all provide a "__getitem__()"
method that interprets negative indices by adding the length of the
sequence to the index (so that "x[-1]" selects the last item of "x").
The resulting value must be a nonnegative integer less than the number
of items in the sequence, and the subscription selects the item whose
index is that value (counting from zero). Since the support for
negative indices and slicing occurs in the object's "__getitem__()"
method, subclasses overriding this method will need to explicitly add
that support.

A string's items are characters.  A character is not a separate data
type but a string of exactly one character.
ztruthax  Truth Value Testing
*******************

Any object can be tested for truth value, for use in an "if" or
"while" condition or as operand of the Boolean operations below.

By default, an object is considered true unless its class defines
either a "__bool__()" method that returns "False" or a "__len__()"
method that returns zero, when called with the object. [1]  Here are
most of the built-in objects considered false:

* constants defined to be false: "None" and "False".

* zero of any numeric type: "0", "0.0", "0j", "Decimal(0)",
  "Fraction(0, 1)"

* empty sequences and collections: "''", "()", "[]", "{}", "set()",
  "range(0)"

Operations and built-in functions that have a Boolean result always
return "0" or "False" for false and "1" or "True" for true, unless
otherwise stated. (Important exception: the Boolean operations "or"
and "and" always return one of their operands.)
ztryaæ  The "try" statement
*******************

The "try" statement specifies exception handlers and/or cleanup code
for a group of statements:

   try_stmt  ::= try1_stmt | try2_stmt
   try1_stmt ::= "try" ":" suite
                 ("except" [expression ["as" identifier]] ":" suite)+
                 ["else" ":" suite]
                 ["finally" ":" suite]
   try2_stmt ::= "try" ":" suite
                 "finally" ":" suite

The "except" clause(s) specify one or more exception handlers. When no
exception occurs in the "try" clause, no exception handler is
executed. When an exception occurs in the "try" suite, a search for an
exception handler is started.  This search inspects the except clauses
in turn until one is found that matches the exception.  An expression-
less except clause, if present, must be last; it matches any
exception.  For an except clause with an expression, that expression
is evaluated, and the clause matches the exception if the resulting
object is "compatible" with the exception.  An object is compatible
with an exception if it is the class or a base class of the exception
object or a tuple containing an item compatible with the exception.

If no except clause matches the exception, the search for an exception
handler continues in the surrounding code and on the invocation stack.
[1]

If the evaluation of an expression in the header of an except clause
raises an exception, the original search for a handler is canceled and
a search starts for the new exception in the surrounding code and on
the call stack (it is treated as if the entire "try" statement raised
the exception).

When a matching except clause is found, the exception is assigned to
the target specified after the "as" keyword in that except clause, if
present, and the except clause's suite is executed.  All except
clauses must have an executable block.  When the end of this block is
reached, execution continues normally after the entire try statement.
(This means that if two nested handlers exist for the same exception,
and the exception occurs in the try clause of the inner handler, the
outer handler will not handle the exception.)

When an exception has been assigned using "as target", it is cleared
at the end of the except clause.  This is as if

   except E as N:
       foo

was translated to

   except E as N:
       try:
           foo
       finally:
           del N

This means the exception must be assigned to a different name to be
able to refer to it after the except clause.  Exceptions are cleared
because with the traceback attached to them, they form a reference
cycle with the stack frame, keeping all locals in that frame alive
until the next garbage collection occurs.

Before an except clause's suite is executed, details about the
exception are stored in the "sys" module and can be accessed via
"sys.exc_info()". "sys.exc_info()" returns a 3-tuple consisting of the
exception class, the exception instance and a traceback object (see
section The standard type hierarchy) identifying the point in the
program where the exception occurred.  "sys.exc_info()" values are
restored to their previous values (before the call) when returning
from a function that handled an exception.

The optional "else" clause is executed if and when control flows off
the end of the "try" clause. [2] Exceptions in the "else" clause are
not handled by the preceding "except" clauses.

If "finally" is present, it specifies a 'cleanup' handler.  The "try"
clause is executed, including any "except" and "else" clauses.  If an
exception occurs in any of the clauses and is not handled, the
exception is temporarily saved. The "finally" clause is executed.  If
there is a saved exception it is re-raised at the end of the "finally"
clause.  If the "finally" clause raises another exception, the saved
exception is set as the context of the new exception. If the "finally"
clause executes a "return" or "break" statement, the saved exception
is discarded:

   >>> def f():
   ...     try:
   ...         1/0
   ...     finally:
   ...         return 42
   ...
   >>> f()
   42

The exception information is not available to the program during
execution of the "finally" clause.

When a "return", "break" or "continue" statement is executed in the
"try" suite of a "try"..."finally" statement, the "finally" clause is
also executed 'on the way out.' A "continue" statement is illegal in
the "finally" clause. (The reason is a problem with the current
implementation --- this restriction may be lifted in the future).

The return value of a function is determined by the last "return"
statement executed.  Since the "finally" clause always executes, a
"return" statement executed in the "finally" clause will always be the
last one executed:

   >>> def foo():
   ...     try:
   ...         return 'try'
   ...     finally:
   ...         return 'finally'
   ...
   >>> foo()
   'finally'

Additional information on exceptions can be found in section
Exceptions, and information on using the "raise" statement to generate
exceptions may be found in section The raise statement.
ztypesa@  The standard type hierarchy
***************************

Below is a list of the types that are built into Python.  Extension
modules (written in C, Java, or other languages, depending on the
implementation) can define additional types.  Future versions of
Python may add types to the type hierarchy (e.g., rational numbers,
efficiently stored arrays of integers, etc.), although such additions
will often be provided via the standard library instead.

Some of the type descriptions below contain a paragraph listing
'special attributes.'  These are attributes that provide access to the
implementation and are not intended for general use.  Their definition
may change in the future.

None
   This type has a single value.  There is a single object with this
   value. This object is accessed through the built-in name "None". It
   is used to signify the absence of a value in many situations, e.g.,
   it is returned from functions that don't explicitly return
   anything. Its truth value is false.

NotImplemented
   This type has a single value.  There is a single object with this
   value. This object is accessed through the built-in name
   "NotImplemented". Numeric methods and rich comparison methods
   should return this value if they do not implement the operation for
   the operands provided.  (The interpreter will then try the
   reflected operation, or some other fallback, depending on the
   operator.)  Its truth value is true.

   See Implementing the arithmetic operations for more details.

Ellipsis
   This type has a single value.  There is a single object with this
   value. This object is accessed through the literal "..." or the
   built-in name "Ellipsis".  Its truth value is true.

"numbers.Number"
   These are created by numeric literals and returned as results by
   arithmetic operators and arithmetic built-in functions.  Numeric
   objects are immutable; once created their value never changes.
   Python numbers are of course strongly related to mathematical
   numbers, but subject to the limitations of numerical representation
   in computers.

   Python distinguishes between integers, floating point numbers, and
   complex numbers:

   "numbers.Integral"
      These represent elements from the mathematical set of integers
      (positive and negative).

      There are two types of integers:

      Integers ("int")

         These represent numbers in an unlimited range, subject to
         available (virtual) memory only.  For the purpose of shift
         and mask operations, a binary representation is assumed, and
         negative numbers are represented in a variant of 2's
         complement which gives the illusion of an infinite string of
         sign bits extending to the left.

      Booleans ("bool")
         These represent the truth values False and True.  The two
         objects representing the values "False" and "True" are the
         only Boolean objects. The Boolean type is a subtype of the
         integer type, and Boolean values behave like the values 0 and
         1, respectively, in almost all contexts, the exception being
         that when converted to a string, the strings ""False"" or
         ""True"" are returned, respectively.

      The rules for integer representation are intended to give the
      most meaningful interpretation of shift and mask operations
      involving negative integers.

   "numbers.Real" ("float")
      These represent machine-level double precision floating point
      numbers. You are at the mercy of the underlying machine
      architecture (and C or Java implementation) for the accepted
      range and handling of overflow. Python does not support single-
      precision floating point numbers; the savings in processor and
      memory usage that are usually the reason for using these are
      dwarfed by the overhead of using objects in Python, so there is
      no reason to complicate the language with two kinds of floating
      point numbers.

   "numbers.Complex" ("complex")
      These represent complex numbers as a pair of machine-level
      double precision floating point numbers.  The same caveats apply
      as for floating point numbers. The real and imaginary parts of a
      complex number "z" can be retrieved through the read-only
      attributes "z.real" and "z.imag".

Sequences
   These represent finite ordered sets indexed by non-negative
   numbers. The built-in function "len()" returns the number of items
   of a sequence. When the length of a sequence is *n*, the index set
   contains the numbers 0, 1, ..., *n*-1.  Item *i* of sequence *a* is
   selected by "a[i]".

   Sequences also support slicing: "a[i:j]" selects all items with
   index *k* such that *i* "<=" *k* "<" *j*.  When used as an
   expression, a slice is a sequence of the same type.  This implies
   that the index set is renumbered so that it starts at 0.

   Some sequences also support "extended slicing" with a third "step"
   parameter: "a[i:j:k]" selects all items of *a* with index *x* where
   "x = i + n*k", *n* ">=" "0" and *i* "<=" *x* "<" *j*.

   Sequences are distinguished according to their mutability:

   Immutable sequences
      An object of an immutable sequence type cannot change once it is
      created.  (If the object contains references to other objects,
      these other objects may be mutable and may be changed; however,
      the collection of objects directly referenced by an immutable
      object cannot change.)

      The following types are immutable sequences:

      Strings
         A string is a sequence of values that represent Unicode code
         points. All the code points in the range "U+0000 - U+10FFFF"
         can be represented in a string.  Python doesn't have a "char"
         type; instead, every code point in the string is represented
         as a string object with length "1".  The built-in function
         "ord()" converts a code point from its string form to an
         integer in the range "0 - 10FFFF"; "chr()" converts an
         integer in the range "0 - 10FFFF" to the corresponding length
         "1" string object. "str.encode()" can be used to convert a
         "str" to "bytes" using the given text encoding, and
         "bytes.decode()" can be used to achieve the opposite.

      Tuples
         The items of a tuple are arbitrary Python objects. Tuples of
         two or more items are formed by comma-separated lists of
         expressions.  A tuple of one item (a 'singleton') can be
         formed by affixing a comma to an expression (an expression by
         itself does not create a tuple, since parentheses must be
         usable for grouping of expressions).  An empty tuple can be
         formed by an empty pair of parentheses.

      Bytes
         A bytes object is an immutable array.  The items are 8-bit
         bytes, represented by integers in the range 0 <= x < 256.
         Bytes literals (like "b'abc'") and the built-in "bytes()"
         constructor can be used to create bytes objects.  Also, bytes
         objects can be decoded to strings via the "decode()" method.

   Mutable sequences
      Mutable sequences can be changed after they are created.  The
      subscription and slicing notations can be used as the target of
      assignment and "del" (delete) statements.

      There are currently two intrinsic mutable sequence types:

      Lists
         The items of a list are arbitrary Python objects.  Lists are
         formed by placing a comma-separated list of expressions in
         square brackets. (Note that there are no special cases needed
         to form lists of length 0 or 1.)

      Byte Arrays
         A bytearray object is a mutable array. They are created by
         the built-in "bytearray()" constructor.  Aside from being
         mutable (and hence unhashable), byte arrays otherwise provide
         the same interface and functionality as immutable "bytes"
         objects.

      The extension module "array" provides an additional example of a
      mutable sequence type, as does the "collections" module.

Set types
   These represent unordered, finite sets of unique, immutable
   objects. As such, they cannot be indexed by any subscript. However,
   they can be iterated over, and the built-in function "len()"
   returns the number of items in a set. Common uses for sets are fast
   membership testing, removing duplicates from a sequence, and
   computing mathematical operations such as intersection, union,
   difference, and symmetric difference.

   For set elements, the same immutability rules apply as for
   dictionary keys. Note that numeric types obey the normal rules for
   numeric comparison: if two numbers compare equal (e.g., "1" and
   "1.0"), only one of them can be contained in a set.

   There are currently two intrinsic set types:

   Sets
      These represent a mutable set. They are created by the built-in
      "set()" constructor and can be modified afterwards by several
      methods, such as "add()".

   Frozen sets
      These represent an immutable set.  They are created by the
      built-in "frozenset()" constructor.  As a frozenset is immutable
      and *hashable*, it can be used again as an element of another
      set, or as a dictionary key.

Mappings
   These represent finite sets of objects indexed by arbitrary index
   sets. The subscript notation "a[k]" selects the item indexed by "k"
   from the mapping "a"; this can be used in expressions and as the
   target of assignments or "del" statements. The built-in function
   "len()" returns the number of items in a mapping.

   There is currently a single intrinsic mapping type:

   Dictionaries
      These represent finite sets of objects indexed by nearly
      arbitrary values.  The only types of values not acceptable as
      keys are values containing lists or dictionaries or other
      mutable types that are compared by value rather than by object
      identity, the reason being that the efficient implementation of
      dictionaries requires a key's hash value to remain constant.
      Numeric types used for keys obey the normal rules for numeric
      comparison: if two numbers compare equal (e.g., "1" and "1.0")
      then they can be used interchangeably to index the same
      dictionary entry.

      Dictionaries are mutable; they can be created by the "{...}"
      notation (see section Dictionary displays).

      The extension modules "dbm.ndbm" and "dbm.gnu" provide
      additional examples of mapping types, as does the "collections"
      module.

Callable types
   These are the types to which the function call operation (see
   section Calls) can be applied:

   User-defined functions
      A user-defined function object is created by a function
      definition (see section Function definitions).  It should be
      called with an argument list containing the same number of items
      as the function's formal parameter list.

      Special attributes:

      +---------------------------+---------------------------------+-------------+
      | Attribute                 | Meaning                         |             |
      +===========================+=================================+=============+
      | "__doc__"                 | The function's documentation    | Writable    |
      |                           | string, or "None" if            |             |
      |                           | unavailable; not inherited by   |             |
      |                           | subclasses                      |             |
      +---------------------------+---------------------------------+-------------+
      | "__name__"                | The function's name             | Writable    |
      +---------------------------+---------------------------------+-------------+
      | "__qualname__"            | The function's *qualified name* | Writable    |
      |                           | New in version 3.3.             |             |
      +---------------------------+---------------------------------+-------------+
      | "__module__"              | The name of the module the      | Writable    |
      |                           | function was defined in, or     |             |
      |                           | "None" if unavailable.          |             |
      +---------------------------+---------------------------------+-------------+
      | "__defaults__"            | A tuple containing default      | Writable    |
      |                           | argument values for those       |             |
      |                           | arguments that have defaults,   |             |
      |                           | or "None" if no arguments have  |             |
      |                           | a default value                 |             |
      +---------------------------+---------------------------------+-------------+
      | "__code__"                | The code object representing    | Writable    |
      |                           | the compiled function body.     |             |
      +---------------------------+---------------------------------+-------------+
      | "__globals__"             | A reference to the dictionary   | Read-only   |
      |                           | that holds the function's       |             |
      |                           | global variables --- the global |             |
      |                           | namespace of the module in      |             |
      |                           | which the function was defined. |             |
      +---------------------------+---------------------------------+-------------+
      | "__dict__"                | The namespace supporting        | Writable    |
      |                           | arbitrary function attributes.  |             |
      +---------------------------+---------------------------------+-------------+
      | "__closure__"             | "None" or a tuple of cells that | Read-only   |
      |                           | contain bindings for the        |             |
      |                           | function's free variables.      |             |
      +---------------------------+---------------------------------+-------------+
      | "__annotations__"         | A dict containing annotations   | Writable    |
      |                           | of parameters.  The keys of the |             |
      |                           | dict are the parameter names,   |             |
      |                           | and "'return'" for the return   |             |
      |                           | annotation, if provided.        |             |
      +---------------------------+---------------------------------+-------------+
      | "__kwdefaults__"          | A dict containing defaults for  | Writable    |
      |                           | keyword-only parameters.        |             |
      +---------------------------+---------------------------------+-------------+

      Most of the attributes labelled "Writable" check the type of the
      assigned value.

      Function objects also support getting and setting arbitrary
      attributes, which can be used, for example, to attach metadata
      to functions.  Regular attribute dot-notation is used to get and
      set such attributes. *Note that the current implementation only
      supports function attributes on user-defined functions. Function
      attributes on built-in functions may be supported in the
      future.*

      Additional information about a function's definition can be
      retrieved from its code object; see the description of internal
      types below.

   Instance methods
      An instance method object combines a class, a class instance and
      any callable object (normally a user-defined function).

      Special read-only attributes: "__self__" is the class instance
      object, "__func__" is the function object; "__doc__" is the
      method's documentation (same as "__func__.__doc__"); "__name__"
      is the method name (same as "__func__.__name__"); "__module__"
      is the name of the module the method was defined in, or "None"
      if unavailable.

      Methods also support accessing (but not setting) the arbitrary
      function attributes on the underlying function object.

      User-defined method objects may be created when getting an
      attribute of a class (perhaps via an instance of that class), if
      that attribute is a user-defined function object or a class
      method object.

      When an instance method object is created by retrieving a user-
      defined function object from a class via one of its instances,
      its "__self__" attribute is the instance, and the method object
      is said to be bound.  The new method's "__func__" attribute is
      the original function object.

      When a user-defined method object is created by retrieving
      another method object from a class or instance, the behaviour is
      the same as for a function object, except that the "__func__"
      attribute of the new instance is not the original method object
      but its "__func__" attribute.

      When an instance method object is created by retrieving a class
      method object from a class or instance, its "__self__" attribute
      is the class itself, and its "__func__" attribute is the
      function object underlying the class method.

      When an instance method object is called, the underlying
      function ("__func__") is called, inserting the class instance
      ("__self__") in front of the argument list.  For instance, when
      "C" is a class which contains a definition for a function "f()",
      and "x" is an instance of "C", calling "x.f(1)" is equivalent to
      calling "C.f(x, 1)".

      When an instance method object is derived from a class method
      object, the "class instance" stored in "__self__" will actually
      be the class itself, so that calling either "x.f(1)" or "C.f(1)"
      is equivalent to calling "f(C,1)" where "f" is the underlying
      function.

      Note that the transformation from function object to instance
      method object happens each time the attribute is retrieved from
      the instance.  In some cases, a fruitful optimization is to
      assign the attribute to a local variable and call that local
      variable. Also notice that this transformation only happens for
      user-defined functions; other callable objects (and all non-
      callable objects) are retrieved without transformation.  It is
      also important to note that user-defined functions which are
      attributes of a class instance are not converted to bound
      methods; this *only* happens when the function is an attribute
      of the class.

   Generator functions
      A function or method which uses the "yield" statement (see
      section The yield statement) is called a *generator function*.
      Such a function, when called, always returns an iterator object
      which can be used to execute the body of the function:  calling
      the iterator's "iterator.__next__()" method will cause the
      function to execute until it provides a value using the "yield"
      statement.  When the function executes a "return" statement or
      falls off the end, a "StopIteration" exception is raised and the
      iterator will have reached the end of the set of values to be
      returned.

   Coroutine functions
      A function or method which is defined using "async def" is
      called a *coroutine function*.  Such a function, when called,
      returns a *coroutine* object.  It may contain "await"
      expressions, as well as "async with" and "async for" statements.
      See also the Coroutine Objects section.

   Asynchronous generator functions
      A function or method which is defined using "async def" and
      which uses the "yield" statement is called a *asynchronous
      generator function*.  Such a function, when called, returns an
      asynchronous iterator object which can be used in an "async for"
      statement to execute the body of the function.

      Calling the asynchronous iterator's "aiterator.__anext__()"
      method will return an *awaitable* which when awaited will
      execute until it provides a value using the "yield" expression.
      When the function executes an empty "return" statement or falls
      off the end, a "StopAsyncIteration" exception is raised and the
      asynchronous iterator will have reached the end of the set of
      values to be yielded.

   Built-in functions
      A built-in function object is a wrapper around a C function.
      Examples of built-in functions are "len()" and "math.sin()"
      ("math" is a standard built-in module). The number and type of
      the arguments are determined by the C function. Special read-
      only attributes: "__doc__" is the function's documentation
      string, or "None" if unavailable; "__name__" is the function's
      name; "__self__" is set to "None" (but see the next item);
      "__module__" is the name of the module the function was defined
      in or "None" if unavailable.

   Built-in methods
      This is really a different disguise of a built-in function, this
      time containing an object passed to the C function as an
      implicit extra argument.  An example of a built-in method is
      "alist.append()", assuming *alist* is a list object. In this
      case, the special read-only attribute "__self__" is set to the
      object denoted by *alist*.

   Classes
      Classes are callable.  These objects normally act as factories
      for new instances of themselves, but variations are possible for
      class types that override "__new__()".  The arguments of the
      call are passed to "__new__()" and, in the typical case, to
      "__init__()" to initialize the new instance.

   Class Instances
      Instances of arbitrary classes can be made callable by defining
      a "__call__()" method in their class.

Modules
   Modules are a basic organizational unit of Python code, and are
   created by the import system as invoked either by the "import"
   statement (see "import"), or by calling functions such as
   "importlib.import_module()" and built-in "__import__()".  A module
   object has a namespace implemented by a dictionary object (this is
   the dictionary referenced by the "__globals__" attribute of
   functions defined in the module).  Attribute references are
   translated to lookups in this dictionary, e.g., "m.x" is equivalent
   to "m.__dict__["x"]". A module object does not contain the code
   object used to initialize the module (since it isn't needed once
   the initialization is done).

   Attribute assignment updates the module's namespace dictionary,
   e.g., "m.x = 1" is equivalent to "m.__dict__["x"] = 1".

   Predefined (writable) attributes: "__name__" is the module's name;
   "__doc__" is the module's documentation string, or "None" if
   unavailable; "__annotations__" (optional) is a dictionary
   containing *variable annotations* collected during module body
   execution; "__file__" is the pathname of the file from which the
   module was loaded, if it was loaded from a file. The "__file__"
   attribute may be missing for certain types of modules, such as C
   modules that are statically linked into the interpreter; for
   extension modules loaded dynamically from a shared library, it is
   the pathname of the shared library file.

   Special read-only attribute: "__dict__" is the module's namespace
   as a dictionary object.

   **CPython implementation detail:** Because of the way CPython
   clears module dictionaries, the module dictionary will be cleared
   when the module falls out of scope even if the dictionary still has
   live references.  To avoid this, copy the dictionary or keep the
   module around while using its dictionary directly.

Custom classes
   Custom class types are typically created by class definitions (see
   section Class definitions).  A class has a namespace implemented by
   a dictionary object. Class attribute references are translated to
   lookups in this dictionary, e.g., "C.x" is translated to
   "C.__dict__["x"]" (although there are a number of hooks which allow
   for other means of locating attributes). When the attribute name is
   not found there, the attribute search continues in the base
   classes. This search of the base classes uses the C3 method
   resolution order which behaves correctly even in the presence of
   'diamond' inheritance structures where there are multiple
   inheritance paths leading back to a common ancestor. Additional
   details on the C3 MRO used by Python can be found in the
   documentation accompanying the 2.3 release at
   https://www.python.org/download/releases/2.3/mro/.

   When a class attribute reference (for class "C", say) would yield a
   class method object, it is transformed into an instance method
   object whose "__self__" attributes is "C".  When it would yield a
   static method object, it is transformed into the object wrapped by
   the static method object. See section Implementing Descriptors for
   another way in which attributes retrieved from a class may differ
   from those actually contained in its "__dict__".

   Class attribute assignments update the class's dictionary, never
   the dictionary of a base class.

   A class object can be called (see above) to yield a class instance
   (see below).

   Special attributes: "__name__" is the class name; "__module__" is
   the module name in which the class was defined; "__dict__" is the
   dictionary containing the class's namespace; "__bases__" is a tuple
   containing the base classes, in the order of their occurrence in
   the base class list; "__doc__" is the class's documentation string,
   or "None" if undefined; "__annotations__" (optional) is a
   dictionary containing *variable annotations* collected during class
   body execution.

Class instances
   A class instance is created by calling a class object (see above).
   A class instance has a namespace implemented as a dictionary which
   is the first place in which attribute references are searched.
   When an attribute is not found there, and the instance's class has
   an attribute by that name, the search continues with the class
   attributes.  If a class attribute is found that is a user-defined
   function object, it is transformed into an instance method object
   whose "__self__" attribute is the instance.  Static method and
   class method objects are also transformed; see above under
   "Classes".  See section Implementing Descriptors for another way in
   which attributes of a class retrieved via its instances may differ
   from the objects actually stored in the class's "__dict__".  If no
   class attribute is found, and the object's class has a
   "__getattr__()" method, that is called to satisfy the lookup.

   Attribute assignments and deletions update the instance's
   dictionary, never a class's dictionary.  If the class has a
   "__setattr__()" or "__delattr__()" method, this is called instead
   of updating the instance dictionary directly.

   Class instances can pretend to be numbers, sequences, or mappings
   if they have methods with certain special names.  See section
   Special method names.

   Special attributes: "__dict__" is the attribute dictionary;
   "__class__" is the instance's class.

I/O objects (also known as file objects)
   A *file object* represents an open file.  Various shortcuts are
   available to create file objects: the "open()" built-in function,
   and also "os.popen()", "os.fdopen()", and the "makefile()" method
   of socket objects (and perhaps by other functions or methods
   provided by extension modules).

   The objects "sys.stdin", "sys.stdout" and "sys.stderr" are
   initialized to file objects corresponding to the interpreter's
   standard input, output and error streams; they are all open in text
   mode and therefore follow the interface defined by the
   "io.TextIOBase" abstract class.

Internal types
   A few types used internally by the interpreter are exposed to the
   user. Their definitions may change with future versions of the
   interpreter, but they are mentioned here for completeness.

   Code objects
      Code objects represent *byte-compiled* executable Python code,
      or *bytecode*. The difference between a code object and a
      function object is that the function object contains an explicit
      reference to the function's globals (the module in which it was
      defined), while a code object contains no context; also the
      default argument values are stored in the function object, not
      in the code object (because they represent values calculated at
      run-time).  Unlike function objects, code objects are immutable
      and contain no references (directly or indirectly) to mutable
      objects.

      Special read-only attributes: "co_name" gives the function name;
      "co_argcount" is the number of positional arguments (including
      arguments with default values); "co_nlocals" is the number of
      local variables used by the function (including arguments);
      "co_varnames" is a tuple containing the names of the local
      variables (starting with the argument names); "co_cellvars" is a
      tuple containing the names of local variables that are
      referenced by nested functions; "co_freevars" is a tuple
      containing the names of free variables; "co_code" is a string
      representing the sequence of bytecode instructions; "co_consts"
      is a tuple containing the literals used by the bytecode;
      "co_names" is a tuple containing the names used by the bytecode;
      "co_filename" is the filename from which the code was compiled;
      "co_firstlineno" is the first line number of the function;
      "co_lnotab" is a string encoding the mapping from bytecode
      offsets to line numbers (for details see the source code of the
      interpreter); "co_stacksize" is the required stack size
      (including local variables); "co_flags" is an integer encoding a
      number of flags for the interpreter.

      The following flag bits are defined for "co_flags": bit "0x04"
      is set if the function uses the "*arguments" syntax to accept an
      arbitrary number of positional arguments; bit "0x08" is set if
      the function uses the "**keywords" syntax to accept arbitrary
      keyword arguments; bit "0x20" is set if the function is a
      generator.

      Future feature declarations ("from __future__ import division")
      also use bits in "co_flags" to indicate whether a code object
      was compiled with a particular feature enabled: bit "0x2000" is
      set if the function was compiled with future division enabled;
      bits "0x10" and "0x1000" were used in earlier versions of
      Python.

      Other bits in "co_flags" are reserved for internal use.

      If a code object represents a function, the first item in
      "co_consts" is the documentation string of the function, or
      "None" if undefined.

   Frame objects
      Frame objects represent execution frames.  They may occur in
      traceback objects (see below).

      Special read-only attributes: "f_back" is to the previous stack
      frame (towards the caller), or "None" if this is the bottom
      stack frame; "f_code" is the code object being executed in this
      frame; "f_locals" is the dictionary used to look up local
      variables; "f_globals" is used for global variables;
      "f_builtins" is used for built-in (intrinsic) names; "f_lasti"
      gives the precise instruction (this is an index into the
      bytecode string of the code object).

      Special writable attributes: "f_trace", if not "None", is a
      function called at the start of each source code line (this is
      used by the debugger); "f_lineno" is the current line number of
      the frame --- writing to this from within a trace function jumps
      to the given line (only for the bottom-most frame).  A debugger
      can implement a Jump command (aka Set Next Statement) by writing
      to f_lineno.

      Frame objects support one method:

      frame.clear()

         This method clears all references to local variables held by
         the frame.  Also, if the frame belonged to a generator, the
         generator is finalized.  This helps break reference cycles
         involving frame objects (for example when catching an
         exception and storing its traceback for later use).

         "RuntimeError" is raised if the frame is currently executing.

         New in version 3.4.

   Traceback objects
      Traceback objects represent a stack trace of an exception.  A
      traceback object is created when an exception occurs.  When the
      search for an exception handler unwinds the execution stack, at
      each unwound level a traceback object is inserted in front of
      the current traceback.  When an exception handler is entered,
      the stack trace is made available to the program. (See section
      The try statement.) It is accessible as the third item of the
      tuple returned by "sys.exc_info()". When the program contains no
      suitable handler, the stack trace is written (nicely formatted)
      to the standard error stream; if the interpreter is interactive,
      it is also made available to the user as "sys.last_traceback".

      Special read-only attributes: "tb_next" is the next level in the
      stack trace (towards the frame where the exception occurred), or
      "None" if there is no next level; "tb_frame" points to the
      execution frame of the current level; "tb_lineno" gives the line
      number where the exception occurred; "tb_lasti" indicates the
      precise instruction.  The line number and last instruction in
      the traceback may differ from the line number of its frame
      object if the exception occurred in a "try" statement with no
      matching except clause or with a finally clause.

   Slice objects
      Slice objects are used to represent slices for "__getitem__()"
      methods.  They are also created by the built-in "slice()"
      function.

      Special read-only attributes: "start" is the lower bound; "stop"
      is the upper bound; "step" is the step value; each is "None" if
      omitted.  These attributes can have any type.

      Slice objects support one method:

      slice.indices(self, length)

         This method takes a single integer argument *length* and
         computes information about the slice that the slice object
         would describe if applied to a sequence of *length* items.
         It returns a tuple of three integers; respectively these are
         the *start* and *stop* indices and the *step* or stride
         length of the slice. Missing or out-of-bounds indices are
         handled in a manner consistent with regular slices.

   Static method objects
      Static method objects provide a way of defeating the
      transformation of function objects to method objects described
      above. A static method object is a wrapper around any other
      object, usually a user-defined method object. When a static
      method object is retrieved from a class or a class instance, the
      object actually returned is the wrapped object, which is not
      subject to any further transformation. Static method objects are
      not themselves callable, although the objects they wrap usually
      are. Static method objects are created by the built-in
      "staticmethod()" constructor.

   Class method objects
      A class method object, like a static method object, is a wrapper
      around another object that alters the way in which that object
      is retrieved from classes and class instances. The behaviour of
      class method objects upon such retrieval is described above,
      under "User-defined methods". Class method objects are created
      by the built-in "classmethod()" constructor.
ztypesfunctionsa¬  Functions
*********

Function objects are created by function definitions.  The only
operation on a function object is to call it: "func(argument-list)".

There are really two flavors of function objects: built-in functions
and user-defined functions.  Both support the same operation (to call
the function), but the implementation is different, hence the
different object types.

See Function definitions for more information.
ztypesmappinga$  Mapping Types --- "dict"
************************

A *mapping* object maps *hashable* values to arbitrary objects.
Mappings are mutable objects.  There is currently only one standard
mapping type, the *dictionary*.  (For other containers see the built-
in "list", "set", and "tuple" classes, and the "collections" module.)

A dictionary's keys are *almost* arbitrary values.  Values that are
not *hashable*, that is, values containing lists, dictionaries or
other mutable types (that are compared by value rather than by object
identity) may not be used as keys.  Numeric types used for keys obey
the normal rules for numeric comparison: if two numbers compare equal
(such as "1" and "1.0") then they can be used interchangeably to index
the same dictionary entry.  (Note however, that since computers store
floating-point numbers as approximations it is usually unwise to use
them as dictionary keys.)

Dictionaries can be created by placing a comma-separated list of "key:
value" pairs within braces, for example: "{'jack': 4098, 'sjoerd':
4127}" or "{4098: 'jack', 4127: 'sjoerd'}", or by the "dict"
constructor.

class dict(**kwarg)
class dict(mapping, **kwarg)
class dict(iterable, **kwarg)

   Return a new dictionary initialized from an optional positional
   argument and a possibly empty set of keyword arguments.

   If no positional argument is given, an empty dictionary is created.
   If a positional argument is given and it is a mapping object, a
   dictionary is created with the same key-value pairs as the mapping
   object.  Otherwise, the positional argument must be an *iterable*
   object.  Each item in the iterable must itself be an iterable with
   exactly two objects.  The first object of each item becomes a key
   in the new dictionary, and the second object the corresponding
   value.  If a key occurs more than once, the last value for that key
   becomes the corresponding value in the new dictionary.

   If keyword arguments are given, the keyword arguments and their
   values are added to the dictionary created from the positional
   argument.  If a key being added is already present, the value from
   the keyword argument replaces the value from the positional
   argument.

   To illustrate, the following examples all return a dictionary equal
   to "{"one": 1, "two": 2, "three": 3}":

      >>> a = dict(one=1, two=2, three=3)
      >>> b = {'one': 1, 'two': 2, 'three': 3}
      >>> c = dict(zip(['one', 'two', 'three'], [1, 2, 3]))
      >>> d = dict([('two', 2), ('one', 1), ('three', 3)])
      >>> e = dict({'three': 3, 'one': 1, 'two': 2})
      >>> a == b == c == d == e
      True

   Providing keyword arguments as in the first example only works for
   keys that are valid Python identifiers.  Otherwise, any valid keys
   can be used.

   These are the operations that dictionaries support (and therefore,
   custom mapping types should support too):

   len(d)

      Return the number of items in the dictionary *d*.

   d[key]

      Return the item of *d* with key *key*.  Raises a "KeyError" if
      *key* is not in the map.

      If a subclass of dict defines a method "__missing__()" and *key*
      is not present, the "d[key]" operation calls that method with
      the key *key* as argument.  The "d[key]" operation then returns
      or raises whatever is returned or raised by the
      "__missing__(key)" call. No other operations or methods invoke
      "__missing__()". If "__missing__()" is not defined, "KeyError"
      is raised. "__missing__()" must be a method; it cannot be an
      instance variable:

         >>> class Counter(dict):
         ...     def __missing__(self, key):
         ...         return 0
         >>> c = Counter()
         >>> c['red']
         0
         >>> c['red'] += 1
         >>> c['red']
         1

      The example above shows part of the implementation of
      "collections.Counter".  A different "__missing__" method is used
      by "collections.defaultdict".

   d[key] = value

      Set "d[key]" to *value*.

   del d[key]

      Remove "d[key]" from *d*.  Raises a "KeyError" if *key* is not
      in the map.

   key in d

      Return "True" if *d* has a key *key*, else "False".

   key not in d

      Equivalent to "not key in d".

   iter(d)

      Return an iterator over the keys of the dictionary.  This is a
      shortcut for "iter(d.keys())".

   clear()

      Remove all items from the dictionary.

   copy()

      Return a shallow copy of the dictionary.

   classmethod fromkeys(seq[, value])

      Create a new dictionary with keys from *seq* and values set to
      *value*.

      "fromkeys()" is a class method that returns a new dictionary.
      *value* defaults to "None".

   get(key[, default])

      Return the value for *key* if *key* is in the dictionary, else
      *default*. If *default* is not given, it defaults to "None", so
      that this method never raises a "KeyError".

   items()

      Return a new view of the dictionary's items ("(key, value)"
      pairs). See the documentation of view objects.

   keys()

      Return a new view of the dictionary's keys.  See the
      documentation of view objects.

   pop(key[, default])

      If *key* is in the dictionary, remove it and return its value,
      else return *default*.  If *default* is not given and *key* is
      not in the dictionary, a "KeyError" is raised.

   popitem()

      Remove and return an arbitrary "(key, value)" pair from the
      dictionary.

      "popitem()" is useful to destructively iterate over a
      dictionary, as often used in set algorithms.  If the dictionary
      is empty, calling "popitem()" raises a "KeyError".

   setdefault(key[, default])

      If *key* is in the dictionary, return its value.  If not, insert
      *key* with a value of *default* and return *default*.  *default*
      defaults to "None".

   update([other])

      Update the dictionary with the key/value pairs from *other*,
      overwriting existing keys.  Return "None".

      "update()" accepts either another dictionary object or an
      iterable of key/value pairs (as tuples or other iterables of
      length two).  If keyword arguments are specified, the dictionary
      is then updated with those key/value pairs: "d.update(red=1,
      blue=2)".

   values()

      Return a new view of the dictionary's values.  See the
      documentation of view objects.

   Dictionaries compare equal if and only if they have the same "(key,
   value)" pairs. Order comparisons ('<', '<=', '>=', '>') raise
   "TypeError".

See also: "types.MappingProxyType" can be used to create a read-only
  view of a "dict".


Dictionary view objects
=======================

The objects returned by "dict.keys()", "dict.values()" and
"dict.items()" are *view objects*.  They provide a dynamic view on the
dictionary's entries, which means that when the dictionary changes,
the view reflects these changes.

Dictionary views can be iterated over to yield their respective data,
and support membership tests:

len(dictview)

   Return the number of entries in the dictionary.

iter(dictview)

   Return an iterator over the keys, values or items (represented as
   tuples of "(key, value)") in the dictionary.

   Keys and values are iterated over in an arbitrary order which is
   non-random, varies across Python implementations, and depends on
   the dictionary's history of insertions and deletions. If keys,
   values and items views are iterated over with no intervening
   modifications to the dictionary, the order of items will directly
   correspond.  This allows the creation of "(value, key)" pairs using
   "zip()": "pairs = zip(d.values(), d.keys())".  Another way to
   create the same list is "pairs = [(v, k) for (k, v) in d.items()]".

   Iterating views while adding or deleting entries in the dictionary
   may raise a "RuntimeError" or fail to iterate over all entries.

x in dictview

   Return "True" if *x* is in the underlying dictionary's keys, values
   or items (in the latter case, *x* should be a "(key, value)"
   tuple).

Keys views are set-like since their entries are unique and hashable.
If all values are hashable, so that "(key, value)" pairs are unique
and hashable, then the items view is also set-like.  (Values views are
not treated as set-like since the entries are generally not unique.)
For set-like views, all of the operations defined for the abstract
base class "collections.abc.Set" are available (for example, "==",
"<", or "^").

An example of dictionary view usage:

   >>> dishes = {'eggs': 2, 'sausage': 1, 'bacon': 1, 'spam': 500}
   >>> keys = dishes.keys()
   >>> values = dishes.values()

   >>> # iteration
   >>> n = 0
   >>> for val in values:
   ...     n += val
   >>> print(n)
   504

   >>> # keys and values are iterated over in the same order
   >>> list(keys)
   ['eggs', 'bacon', 'sausage', 'spam']
   >>> list(values)
   [2, 1, 1, 500]

   >>> # view objects are dynamic and reflect dict changes
   >>> del dishes['eggs']
   >>> del dishes['sausage']
   >>> list(keys)
   ['spam', 'bacon']

   >>> # set operations
   >>> keys & {'eggs', 'bacon', 'salad'}
   {'bacon'}
   >>> keys ^ {'sausage', 'juice'}
   {'juice', 'sausage', 'bacon', 'spam'}
ztypesmethodsa  Methods
*******

Methods are functions that are called using the attribute notation.
There are two flavors: built-in methods (such as "append()" on lists)
and class instance methods.  Built-in methods are described with the
types that support them.

If you access a method (a function defined in a class namespace)
through an instance, you get a special object: a *bound method* (also
called *instance method*) object. When called, it will add the "self"
argument to the argument list.  Bound methods have two special read-
only attributes: "m.__self__" is the object on which the method
operates, and "m.__func__" is the function implementing the method.
Calling "m(arg-1, arg-2, ..., arg-n)" is completely equivalent to
calling "m.__func__(m.__self__, arg-1, arg-2, ..., arg-n)".

Like function objects, bound method objects support getting arbitrary
attributes.  However, since method attributes are actually stored on
the underlying function object ("meth.__func__"), setting method
attributes on bound methods is disallowed.  Attempting to set an
attribute on a method results in an "AttributeError" being raised.  In
order to set a method attribute, you need to explicitly set it on the
underlying function object:

   >>> class C:
   ...     def method(self):
   ...         pass
   ...
   >>> c = C()
   >>> c.method.whoami = 'my name is method'  # can't set on the method
   Traceback (most recent call last):
     File "<stdin>", line 1, in <module>
   AttributeError: 'method' object has no attribute 'whoami'
   >>> c.method.__func__.whoami = 'my name is method'
   >>> c.method.whoami
   'my name is method'

See The standard type hierarchy for more information.
ztypesmodulesa  Modules
*******

The only special operation on a module is attribute access: "m.name",
where *m* is a module and *name* accesses a name defined in *m*'s
symbol table. Module attributes can be assigned to.  (Note that the
"import" statement is not, strictly speaking, an operation on a module
object; "import foo" does not require a module object named *foo* to
exist, rather it requires an (external) *definition* for a module
named *foo* somewhere.)

A special attribute of every module is "__dict__". This is the
dictionary containing the module's symbol table. Modifying this
dictionary will actually change the module's symbol table, but direct
assignment to the "__dict__" attribute is not possible (you can write
"m.__dict__['a'] = 1", which defines "m.a" to be "1", but you can't
write "m.__dict__ = {}").  Modifying "__dict__" directly is not
recommended.

Modules built into the interpreter are written like this: "<module
'sys' (built-in)>".  If loaded from a file, they are written as
"<module 'os' from '/usr/local/lib/pythonX.Y/os.pyc'>".
ztypesseqa¿Y  Sequence Types --- "list", "tuple", "range"
*******************************************

There are three basic sequence types: lists, tuples, and range
objects. Additional sequence types tailored for processing of binary
data and text strings are described in dedicated sections.


Common Sequence Operations
==========================

The operations in the following table are supported by most sequence
types, both mutable and immutable. The "collections.abc.Sequence" ABC
is provided to make it easier to correctly implement these operations
on custom sequence types.

This table lists the sequence operations sorted in ascending priority.
In the table, *s* and *t* are sequences of the same type, *n*, *i*,
*j* and *k* are integers and *x* is an arbitrary object that meets any
type and value restrictions imposed by *s*.

The "in" and "not in" operations have the same priorities as the
comparison operations. The "+" (concatenation) and "*" (repetition)
operations have the same priority as the corresponding numeric
operations. [3]

+----------------------------+----------------------------------+------------+
| Operation                  | Result                           | Notes      |
+============================+==================================+============+
| "x in s"                   | "True" if an item of *s* is      | (1)        |
|                            | equal to *x*, else "False"       |            |
+----------------------------+----------------------------------+------------+
| "x not in s"               | "False" if an item of *s* is     | (1)        |
|                            | equal to *x*, else "True"        |            |
+----------------------------+----------------------------------+------------+
| "s + t"                    | the concatenation of *s* and *t* | (6)(7)     |
+----------------------------+----------------------------------+------------+
| "s * n" or "n * s"         | equivalent to adding *s* to      | (2)(7)     |
|                            | itself *n* times                 |            |
+----------------------------+----------------------------------+------------+
| "s[i]"                     | *i*th item of *s*, origin 0      | (3)        |
+----------------------------+----------------------------------+------------+
| "s[i:j]"                   | slice of *s* from *i* to *j*     | (3)(4)     |
+----------------------------+----------------------------------+------------+
| "s[i:j:k]"                 | slice of *s* from *i* to *j*     | (3)(5)     |
|                            | with step *k*                    |            |
+----------------------------+----------------------------------+------------+
| "len(s)"                   | length of *s*                    |            |
+----------------------------+----------------------------------+------------+
| "min(s)"                   | smallest item of *s*             |            |
+----------------------------+----------------------------------+------------+
| "max(s)"                   | largest item of *s*              |            |
+----------------------------+----------------------------------+------------+
| "s.index(x[, i[, j]])"     | index of the first occurrence of | (8)        |
|                            | *x* in *s* (at or after index    |            |
|                            | *i* and before index *j*)        |            |
+----------------------------+----------------------------------+------------+
| "s.count(x)"               | total number of occurrences of   |            |
|                            | *x* in *s*                       |            |
+----------------------------+----------------------------------+------------+

Sequences of the same type also support comparisons.  In particular,
tuples and lists are compared lexicographically by comparing
corresponding elements. This means that to compare equal, every
element must compare equal and the two sequences must be of the same
type and have the same length.  (For full details see Comparisons in
the language reference.)

Notes:

1. While the "in" and "not in" operations are used only for simple
   containment testing in the general case, some specialised sequences
   (such as "str", "bytes" and "bytearray") also use them for
   subsequence testing:

      >>> "gg" in "eggs"
      True

2. Values of *n* less than "0" are treated as "0" (which yields an
   empty sequence of the same type as *s*).  Note that items in the
   sequence *s* are not copied; they are referenced multiple times.
   This often haunts new Python programmers; consider:

      >>> lists = [[]] * 3
      >>> lists
      [[], [], []]
      >>> lists[0].append(3)
      >>> lists
      [[3], [3], [3]]

   What has happened is that "[[]]" is a one-element list containing
   an empty list, so all three elements of "[[]] * 3" are references
   to this single empty list.  Modifying any of the elements of
   "lists" modifies this single list. You can create a list of
   different lists this way:

      >>> lists = [[] for i in range(3)]
      >>> lists[0].append(3)
      >>> lists[1].append(5)
      >>> lists[2].append(7)
      >>> lists
      [[3], [5], [7]]

   Further explanation is available in the FAQ entry How do I create a
   multidimensional list?.

3. If *i* or *j* is negative, the index is relative to the end of
   sequence *s*: "len(s) + i" or "len(s) + j" is substituted.  But
   note that "-0" is still "0".

4. The slice of *s* from *i* to *j* is defined as the sequence of
   items with index *k* such that "i <= k < j".  If *i* or *j* is
   greater than "len(s)", use "len(s)".  If *i* is omitted or "None",
   use "0".  If *j* is omitted or "None", use "len(s)".  If *i* is
   greater than or equal to *j*, the slice is empty.

5. The slice of *s* from *i* to *j* with step *k* is defined as the
   sequence of items with index  "x = i + n*k" such that "0 <= n <
   (j-i)/k".  In other words, the indices are "i", "i+k", "i+2*k",
   "i+3*k" and so on, stopping when *j* is reached (but never
   including *j*).  When *k* is positive, *i* and *j* are reduced to
   "len(s)" if they are greater. When *k* is negative, *i* and *j* are
   reduced to "len(s) - 1" if they are greater.  If *i* or *j* are
   omitted or "None", they become "end" values (which end depends on
   the sign of *k*).  Note, *k* cannot be zero. If *k* is "None", it
   is treated like "1".

6. Concatenating immutable sequences always results in a new
   object. This means that building up a sequence by repeated
   concatenation will have a quadratic runtime cost in the total
   sequence length. To get a linear runtime cost, you must switch to
   one of the alternatives below:

   * if concatenating "str" objects, you can build a list and use
     "str.join()" at the end or else write to an "io.StringIO"
     instance and retrieve its value when complete

   * if concatenating "bytes" objects, you can similarly use
     "bytes.join()" or "io.BytesIO", or you can do in-place
     concatenation with a "bytearray" object.  "bytearray" objects are
     mutable and have an efficient overallocation mechanism

   * if concatenating "tuple" objects, extend a "list" instead

   * for other types, investigate the relevant class documentation

7. Some sequence types (such as "range") only support item
   sequences that follow specific patterns, and hence don't support
   sequence concatenation or repetition.

8. "index" raises "ValueError" when *x* is not found in *s*. Not
   all implementations support passing the additional arguments *i*
   and *j*. These arguments allow efficient searching of subsections
   of the sequence. Passing the extra arguments is roughly equivalent
   to using "s[i:j].index(x)", only without copying any data and with
   the returned index being relative to the start of the sequence
   rather than the start of the slice.


Immutable Sequence Types
========================

The only operation that immutable sequence types generally implement
that is not also implemented by mutable sequence types is support for
the "hash()" built-in.

This support allows immutable sequences, such as "tuple" instances, to
be used as "dict" keys and stored in "set" and "frozenset" instances.

Attempting to hash an immutable sequence that contains unhashable
values will result in "TypeError".


Mutable Sequence Types
======================

The operations in the following table are defined on mutable sequence
types. The "collections.abc.MutableSequence" ABC is provided to make
it easier to correctly implement these operations on custom sequence
types.

In the table *s* is an instance of a mutable sequence type, *t* is any
iterable object and *x* is an arbitrary object that meets any type and
value restrictions imposed by *s* (for example, "bytearray" only
accepts integers that meet the value restriction "0 <= x <= 255").

+--------------------------------+----------------------------------+-----------------------+
| Operation                      | Result                           | Notes                 |
+================================+==================================+=======================+
| "s[i] = x"                     | item *i* of *s* is replaced by   |                       |
|                                | *x*                              |                       |
+--------------------------------+----------------------------------+-----------------------+
| "s[i:j] = t"                   | slice of *s* from *i* to *j* is  |                       |
|                                | replaced by the contents of the  |                       |
|                                | iterable *t*                     |                       |
+--------------------------------+----------------------------------+-----------------------+
| "del s[i:j]"                   | same as "s[i:j] = []"            |                       |
+--------------------------------+----------------------------------+-----------------------+
| "s[i:j:k] = t"                 | the elements of "s[i:j:k]" are   | (1)                   |
|                                | replaced by those of *t*         |                       |
+--------------------------------+----------------------------------+-----------------------+
| "del s[i:j:k]"                 | removes the elements of          |                       |
|                                | "s[i:j:k]" from the list         |                       |
+--------------------------------+----------------------------------+-----------------------+
| "s.append(x)"                  | appends *x* to the end of the    |                       |
|                                | sequence (same as                |                       |
|                                | "s[len(s):len(s)] = [x]")        |                       |
+--------------------------------+----------------------------------+-----------------------+
| "s.clear()"                    | removes all items from "s" (same | (5)                   |
|                                | as "del s[:]")                   |                       |
+--------------------------------+----------------------------------+-----------------------+
| "s.copy()"                     | creates a shallow copy of "s"    | (5)                   |
|                                | (same as "s[:]")                 |                       |
+--------------------------------+----------------------------------+-----------------------+
| "s.extend(t)" or "s += t"      | extends *s* with the contents of |                       |
|                                | *t* (for the most part the same  |                       |
|                                | as "s[len(s):len(s)] = t")       |                       |
+--------------------------------+----------------------------------+-----------------------+
| "s *= n"                       | updates *s* with its contents    | (6)                   |
|                                | repeated *n* times               |                       |
+--------------------------------+----------------------------------+-----------------------+
| "s.insert(i, x)"               | inserts *x* into *s* at the      |                       |
|                                | index given by *i* (same as      |                       |
|                                | "s[i:i] = [x]")                  |                       |
+--------------------------------+----------------------------------+-----------------------+
| "s.pop([i])"                   | retrieves the item at *i* and    | (2)                   |
|                                | also removes it from *s*         |                       |
+--------------------------------+----------------------------------+-----------------------+
| "s.remove(x)"                  | remove the first item from *s*   | (3)                   |
|                                | where "s[i] == x"                |                       |
+--------------------------------+----------------------------------+-----------------------+
| "s.reverse()"                  | reverses the items of *s* in     | (4)                   |
|                                | place                            |                       |
+--------------------------------+----------------------------------+-----------------------+

Notes:

1. *t* must have the same length as the slice it is replacing.

2. The optional argument *i* defaults to "-1", so that by default
   the last item is removed and returned.

3. "remove" raises "ValueError" when *x* is not found in *s*.

4. The "reverse()" method modifies the sequence in place for
   economy of space when reversing a large sequence.  To remind users
   that it operates by side effect, it does not return the reversed
   sequence.

5. "clear()" and "copy()" are included for consistency with the
   interfaces of mutable containers that don't support slicing
   operations (such as "dict" and "set")

   New in version 3.3: "clear()" and "copy()" methods.

6. The value *n* is an integer, or an object implementing
   "__index__()".  Zero and negative values of *n* clear the sequence.
   Items in the sequence are not copied; they are referenced multiple
   times, as explained for "s * n" under Common Sequence Operations.


Lists
=====

Lists are mutable sequences, typically used to store collections of
homogeneous items (where the precise degree of similarity will vary by
application).

class list([iterable])

   Lists may be constructed in several ways:

   * Using a pair of square brackets to denote the empty list: "[]"

   * Using square brackets, separating items with commas: "[a]",
     "[a, b, c]"

   * Using a list comprehension: "[x for x in iterable]"

   * Using the type constructor: "list()" or "list(iterable)"

   The constructor builds a list whose items are the same and in the
   same order as *iterable*'s items.  *iterable* may be either a
   sequence, a container that supports iteration, or an iterator
   object.  If *iterable* is already a list, a copy is made and
   returned, similar to "iterable[:]". For example, "list('abc')"
   returns "['a', 'b', 'c']" and "list( (1, 2, 3) )" returns "[1, 2,
   3]". If no argument is given, the constructor creates a new empty
   list, "[]".

   Many other operations also produce lists, including the "sorted()"
   built-in.

   Lists implement all of the common and mutable sequence operations.
   Lists also provide the following additional method:

   sort(*, key=None, reverse=False)

      This method sorts the list in place, using only "<" comparisons
      between items. Exceptions are not suppressed - if any comparison
      operations fail, the entire sort operation will fail (and the
      list will likely be left in a partially modified state).

      "sort()" accepts two arguments that can only be passed by
      keyword (keyword-only arguments):

      *key* specifies a function of one argument that is used to
      extract a comparison key from each list element (for example,
      "key=str.lower"). The key corresponding to each item in the list
      is calculated once and then used for the entire sorting process.
      The default value of "None" means that list items are sorted
      directly without calculating a separate key value.

      The "functools.cmp_to_key()" utility is available to convert a
      2.x style *cmp* function to a *key* function.

      *reverse* is a boolean value.  If set to "True", then the list
      elements are sorted as if each comparison were reversed.

      This method modifies the sequence in place for economy of space
      when sorting a large sequence.  To remind users that it operates
      by side effect, it does not return the sorted sequence (use
      "sorted()" to explicitly request a new sorted list instance).

      The "sort()" method is guaranteed to be stable.  A sort is
      stable if it guarantees not to change the relative order of
      elements that compare equal --- this is helpful for sorting in
      multiple passes (for example, sort by department, then by salary
      grade).

      **CPython implementation detail:** While a list is being sorted,
      the effect of attempting to mutate, or even inspect, the list is
      undefined.  The C implementation of Python makes the list appear
      empty for the duration, and raises "ValueError" if it can detect
      that the list has been mutated during a sort.


Tuples
======

Tuples are immutable sequences, typically used to store collections of
heterogeneous data (such as the 2-tuples produced by the "enumerate()"
built-in). Tuples are also used for cases where an immutable sequence
of homogeneous data is needed (such as allowing storage in a "set" or
"dict" instance).

class tuple([iterable])

   Tuples may be constructed in a number of ways:

   * Using a pair of parentheses to denote the empty tuple: "()"

   * Using a trailing comma for a singleton tuple: "a," or "(a,)"

   * Separating items with commas: "a, b, c" or "(a, b, c)"

   * Using the "tuple()" built-in: "tuple()" or "tuple(iterable)"

   The constructor builds a tuple whose items are the same and in the
   same order as *iterable*'s items.  *iterable* may be either a
   sequence, a container that supports iteration, or an iterator
   object.  If *iterable* is already a tuple, it is returned
   unchanged. For example, "tuple('abc')" returns "('a', 'b', 'c')"
   and "tuple( [1, 2, 3] )" returns "(1, 2, 3)". If no argument is
   given, the constructor creates a new empty tuple, "()".

   Note that it is actually the comma which makes a tuple, not the
   parentheses. The parentheses are optional, except in the empty
   tuple case, or when they are needed to avoid syntactic ambiguity.
   For example, "f(a, b, c)" is a function call with three arguments,
   while "f((a, b, c))" is a function call with a 3-tuple as the sole
   argument.

   Tuples implement all of the common sequence operations.

For heterogeneous collections of data where access by name is clearer
than access by index, "collections.namedtuple()" may be a more
appropriate choice than a simple tuple object.


Ranges
======

The "range" type represents an immutable sequence of numbers and is
commonly used for looping a specific number of times in "for" loops.

class range(stop)
class range(start, stop[, step])

   The arguments to the range constructor must be integers (either
   built-in "int" or any object that implements the "__index__"
   special method).  If the *step* argument is omitted, it defaults to
   "1". If the *start* argument is omitted, it defaults to "0". If
   *step* is zero, "ValueError" is raised.

   For a positive *step*, the contents of a range "r" are determined
   by the formula "r[i] = start + step*i" where "i >= 0" and "r[i] <
   stop".

   For a negative *step*, the contents of the range are still
   determined by the formula "r[i] = start + step*i", but the
   constraints are "i >= 0" and "r[i] > stop".

   A range object will be empty if "r[0]" does not meet the value
   constraint. Ranges do support negative indices, but these are
   interpreted as indexing from the end of the sequence determined by
   the positive indices.

   Ranges containing absolute values larger than "sys.maxsize" are
   permitted but some features (such as "len()") may raise
   "OverflowError".

   Range examples:

      >>> list(range(10))
      [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
      >>> list(range(1, 11))
      [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
      >>> list(range(0, 30, 5))
      [0, 5, 10, 15, 20, 25]
      >>> list(range(0, 10, 3))
      [0, 3, 6, 9]
      >>> list(range(0, -10, -1))
      [0, -1, -2, -3, -4, -5, -6, -7, -8, -9]
      >>> list(range(0))
      []
      >>> list(range(1, 0))
      []

   Ranges implement all of the common sequence operations except
   concatenation and repetition (due to the fact that range objects
   can only represent sequences that follow a strict pattern and
   repetition and concatenation will usually violate that pattern).

   start

      The value of the *start* parameter (or "0" if the parameter was
      not supplied)

   stop

      The value of the *stop* parameter

   step

      The value of the *step* parameter (or "1" if the parameter was
      not supplied)

The advantage of the "range" type over a regular "list" or "tuple" is
that a "range" object will always take the same (small) amount of
memory, no matter the size of the range it represents (as it only
stores the "start", "stop" and "step" values, calculating individual
items and subranges as needed).

Range objects implement the "collections.abc.Sequence" ABC, and
provide features such as containment tests, element index lookup,
slicing and support for negative indices (see Sequence Types --- list,
tuple, range):

>>> r = range(0, 20, 2)
>>> r
range(0, 20, 2)
>>> 11 in r
False
>>> 10 in r
True
>>> r.index(10)
5
>>> r[5]
10
>>> r[:5]
range(0, 10, 2)
>>> r[-1]
18

Testing range objects for equality with "==" and "!=" compares them as
sequences.  That is, two range objects are considered equal if they
represent the same sequence of values.  (Note that two range objects
that compare equal might have different "start", "stop" and "step"
attributes, for example "range(0) == range(2, 1, 3)" or "range(0, 3,
2) == range(0, 4, 2)".)

Changed in version 3.2: Implement the Sequence ABC. Support slicing
and negative indices. Test "int" objects for membership in constant
time instead of iterating through all items.

Changed in version 3.3: Define '==' and '!=' to compare range objects
based on the sequence of values they define (instead of comparing
based on object identity).

New in version 3.3: The "start", "stop" and "step" attributes.

See also:

  * The linspace recipe shows how to implement a lazy version of
    range that suitable for floating point applications.
ztypesseq-mutableaq  Mutable Sequence Types
**********************

The operations in the following table are defined on mutable sequence
types. The "collections.abc.MutableSequence" ABC is provided to make
it easier to correctly implement these operations on custom sequence
types.

In the table *s* is an instance of a mutable sequence type, *t* is any
iterable object and *x* is an arbitrary object that meets any type and
value restrictions imposed by *s* (for example, "bytearray" only
accepts integers that meet the value restriction "0 <= x <= 255").

+--------------------------------+----------------------------------+-----------------------+
| Operation                      | Result                           | Notes                 |
+================================+==================================+=======================+
| "s[i] = x"                     | item *i* of *s* is replaced by   |                       |
|                                | *x*                              |                       |
+--------------------------------+----------------------------------+-----------------------+
| "s[i:j] = t"                   | slice of *s* from *i* to *j* is  |                       |
|                                | replaced by the contents of the  |                       |
|                                | iterable *t*                     |                       |
+--------------------------------+----------------------------------+-----------------------+
| "del s[i:j]"                   | same as "s[i:j] = []"            |                       |
+--------------------------------+----------------------------------+-----------------------+
| "s[i:j:k] = t"                 | the elements of "s[i:j:k]" are   | (1)                   |
|                                | replaced by those of *t*         |                       |
+--------------------------------+----------------------------------+-----------------------+
| "del s[i:j:k]"                 | removes the elements of          |                       |
|                                | "s[i:j:k]" from the list         |                       |
+--------------------------------+----------------------------------+-----------------------+
| "s.append(x)"                  | appends *x* to the end of the    |                       |
|                                | sequence (same as                |                       |
|                                | "s[len(s):len(s)] = [x]")        |                       |
+--------------------------------+----------------------------------+-----------------------+
| "s.clear()"                    | removes all items from "s" (same | (5)                   |
|                                | as "del s[:]")                   |                       |
+--------------------------------+----------------------------------+-----------------------+
| "s.copy()"                     | creates a shallow copy of "s"    | (5)                   |
|                                | (same as "s[:]")                 |                       |
+--------------------------------+----------------------------------+-----------------------+
| "s.extend(t)" or "s += t"      | extends *s* with the contents of |                       |
|                                | *t* (for the most part the same  |                       |
|                                | as "s[len(s):len(s)] = t")       |                       |
+--------------------------------+----------------------------------+-----------------------+
| "s *= n"                       | updates *s* with its contents    | (6)                   |
|                                | repeated *n* times               |                       |
+--------------------------------+----------------------------------+-----------------------+
| "s.insert(i, x)"               | inserts *x* into *s* at the      |                       |
|                                | index given by *i* (same as      |                       |
|                                | "s[i:i] = [x]")                  |                       |
+--------------------------------+----------------------------------+-----------------------+
| "s.pop([i])"                   | retrieves the item at *i* and    | (2)                   |
|                                | also removes it from *s*         |                       |
+--------------------------------+----------------------------------+-----------------------+
| "s.remove(x)"                  | remove the first item from *s*   | (3)                   |
|                                | where "s[i] == x"                |                       |
+--------------------------------+----------------------------------+-----------------------+
| "s.reverse()"                  | reverses the items of *s* in     | (4)                   |
|                                | place                            |                       |
+--------------------------------+----------------------------------+-----------------------+

Notes:

1. *t* must have the same length as the slice it is replacing.

2. The optional argument *i* defaults to "-1", so that by default
   the last item is removed and returned.

3. "remove" raises "ValueError" when *x* is not found in *s*.

4. The "reverse()" method modifies the sequence in place for
   economy of space when reversing a large sequence.  To remind users
   that it operates by side effect, it does not return the reversed
   sequence.

5. "clear()" and "copy()" are included for consistency with the
   interfaces of mutable containers that don't support slicing
   operations (such as "dict" and "set")

   New in version 3.3: "clear()" and "copy()" methods.

6. The value *n* is an integer, or an object implementing
   "__index__()".  Zero and negative values of *n* clear the sequence.
   Items in the sequence are not copied; they are referenced multiple
   times, as explained for "s * n" under Common Sequence Operations.
zunarya~  Unary arithmetic and bitwise operations
***************************************

All unary arithmetic and bitwise operations have the same priority:

   u_expr ::= power | "-" u_expr | "+" u_expr | "~" u_expr

The unary "-" (minus) operator yields the negation of its numeric
argument.

The unary "+" (plus) operator yields its numeric argument unchanged.

The unary "~" (invert) operator yields the bitwise inversion of its
integer argument.  The bitwise inversion of "x" is defined as
"-(x+1)".  It only applies to integral numbers.

In all three cases, if the argument does not have the proper type, a
"TypeError" exception is raised.
zwhilea¯  The "while" statement
*********************

The "while" statement is used for repeated execution as long as an
expression is true:

   while_stmt ::= "while" expression ":" suite
                  ["else" ":" suite]

This repeatedly tests the expression and, if it is true, executes the
first suite; if the expression is false (which may be the first time
it is tested) the suite of the "else" clause, if present, is executed
and the loop terminates.

A "break" statement executed in the first suite terminates the loop
without executing the "else" clause's suite.  A "continue" statement
executed in the first suite skips the rest of the suite and goes back
to testing the expression.
zwitha	  The "with" statement
********************

The "with" statement is used to wrap the execution of a block with
methods defined by a context manager (see section With Statement
Context Managers). This allows common "try"..."except"..."finally"
usage patterns to be encapsulated for convenient reuse.

   with_stmt ::= "with" with_item ("," with_item)* ":" suite
   with_item ::= expression ["as" target]

The execution of the "with" statement with one "item" proceeds as
follows:

1. The context expression (the expression given in the "with_item")
   is evaluated to obtain a context manager.

2. The context manager's "__exit__()" is loaded for later use.

3. The context manager's "__enter__()" method is invoked.

4. If a target was included in the "with" statement, the return
   value from "__enter__()" is assigned to it.

   Note: The "with" statement guarantees that if the "__enter__()"
     method returns without an error, then "__exit__()" will always be
     called. Thus, if an error occurs during the assignment to the
     target list, it will be treated the same as an error occurring
     within the suite would be. See step 6 below.

5. The suite is executed.

6. The context manager's "__exit__()" method is invoked.  If an
   exception caused the suite to be exited, its type, value, and
   traceback are passed as arguments to "__exit__()". Otherwise, three
   "None" arguments are supplied.

   If the suite was exited due to an exception, and the return value
   from the "__exit__()" method was false, the exception is reraised.
   If the return value was true, the exception is suppressed, and
   execution continues with the statement following the "with"
   statement.

   If the suite was exited for any reason other than an exception, the
   return value from "__exit__()" is ignored, and execution proceeds
   at the normal location for the kind of exit that was taken.

With more than one item, the context managers are processed as if
multiple "with" statements were nested:

   with A() as a, B() as b:
       suite

is equivalent to

   with A() as a:
       with B() as b:
           suite

Changed in version 3.1: Support for multiple context expressions.

See also:

  **PEP 343** - The "with" statement
     The specification, background, and examples for the Python "with"
     statement.
zyielda,  The "yield" statement
*********************

   yield_stmt ::= yield_expression

A "yield" statement is semantically equivalent to a yield expression.
The yield statement can be used to omit the parentheses that would
otherwise be required in the equivalent yield expression statement.
For example, the yield statements

   yield <expr>
   yield from <expr>

are equivalent to the yield expression statements

   (yield <expr>)
   (yield from <expr>)

Yield expressions and statements are only used when defining a
*generator* function, and are only used in the body of the generator
function.  Using yield in a function definition is sufficient to cause
that definition to create a generator function instead of a normal
function.

For full details of "yield" semantics, refer to the Yield expressions
section.
0C:\msys64\mingw64\lib\python3.6\site-packages\pygtkcompat\__init__.py<module pygtkcompat>citerGenericTreeModel.on_get_flagsfrom_addressdefault_returnon_iter_has_childOverridable.

        :Returns:
            The first child of parent or None if parent has no children.
            If parent is None, return the first node of the model.
        on_iter_n_childrenOverridable.

        :Returns:
            The number of children for the given node. If node is None,
            return the number of top level nodes.
        GenericTreeModel.do_iter_childrenGenericTreeModel.on_get_iterdo_iter_nextGenericTreeModel.on_get_column_typeGenericTreeModel.iter_depth_firston_iter_parent_CTreeIterGenericTreeModel.on_iter_nextGenericTreeModel.do_get_column_typedo_ref_nodeGenericTreeModel._create_tree_iterGenericTreeModel.get_user_dataleak_referencesC:\msys64\mingw64\lib\python3.6\site-packages\pygtkcompat\generictreemodel.pydo_get_pathnext_datanode_idGenericTreeModel.on_ref_nodeset_user_dataOverridable.

        :Returns:
            A TreePath for the given node.
        GenericTreeModel.do_unref_nodeGenericTreeModel.do_get_iterdo_iter_n_childrenOverridable.

        :Returns:
            A python object (node) for the given TreePath.
        GenericTreeModel.on_iter_childrenGenericTreeModel.on_iter_parentInternal method.Overridable.

        :Parameters:
            node : object
                Node at current level.

        :Returns:
            A python object (node) following the given node at the current level.
        wrapped_funcInternal creation of a (bool, TreeIter) pair for returning directly
        back to the view interfacing with this model.GenericTreeModel.do_iter_has_childOverridable.

        :Parameters:
            node : object
            column : int
                Column index to get the value from.

        :Returns:
            The value of the column for the given node.on_iter_nth_childon_get_pathOverridable.

        :Returns:
            The parent node of child or None if child is a top level node.do_iter_nth_childGenericTreeModel.create_tree_iterCreate a Gtk.TreeIter instance with the given user_data specific for this model.

        Use this method to create Gtk.TreeIter instance instead of directly calling
        Gtk.Treeiter(), this will ensure proper reference managment of wrapped used_data.
        user_data3on_unref_noderow_deletedInitialize. Make sure to call this from derived classes if overridden.GenericTreeModel.iter_is_validGenericTreeModel.on_iter_has_child<module pygtkcompat.generictreemodel>on_get_n_columnshandle_exception.<locals>.decorator.<locals>.wrapped_funcGenericTreeModel.row_deletedReturns a function which can act as a decorator for wrapping exceptions and
    returning "default_return" upon an exception being thrown.

    This is used to wrap Gtk.TreeModel "do_" method implementations so we can return
    a proper value from the override upon an exception occurring with client code
    implemented by the "on_" methods.
    do_get_valueGenericTreeModel.invalidate_iterextendleftGenericTreeModel.on_iter_n_childrenGenericTreeModel.do_get_n_columnsOverridable.

        :Returns:
            The number of columns for this model.
        GenericTreeModel.set_user_dataGenericTreeModel.do_ref_nodeGenericTreeModel.on_get_value_CTreeIter.from_iterGenericTreeModel.do_iter_parentClear user data and its reference from the iter and this model.GenericTreeModel.do_get_value_held_refsDepth-first iteration of the entire TreeModel yielding the python nodes.GenericTreeModel.do_iter_nth_childuser_data2_get_user_data_as_pyobjectGenericTreeModel.do_get_flags
        This method invalidates all TreeIter objects associated with this custom tree model
        and frees their locally pooled references.
        Applies user_data and stamp to the given iter.

        If the models "leak_references" property is set, a reference to the
        user_data is stored with the model to ensure we don't run into bad
        memory problems with the TreeIter.
        GenericTreeModel.do_iter_next
        :Returns:
            True if the gtk.TreeIter specified by iter is valid for the custom tree model.
        GenericTreeModel.do_iter_n_childrenGenericTreeModel.on_unref_nodeGenericTreeModel.on_get_n_columnsGenericTreeModel.on_iter_nth_childGenericTreeModel.do_get_pathGenericTreeModel.__init__A base implementation of a Gtk.TreeModel for python.

    The GenericTreeModel eases implementing the Gtk.TreeModel interface in Python.
    The class can be subclassed to provide a TreeModel implementation which works
    directly with Python objects instead of iterators.

    All of the on_* methods should be overridden by subclasses to provide the
    underlying implementation a way to access custom model data. For the purposes of
    this API, all custom model data supplied or handed back through the overridable
    API will use the argument names: node, parent, and child in regards to user data
    python objects.

    The create_tree_iter, set_user_data, invalidate_iters, iter_is_valid methods are
    available to help manage Gtk.TreeIter objects and their Python object references.

    GenericTreeModel manages a pool of user data nodes that have been used with iters.
    This pool stores a references to user data nodes as a dictionary value with the
    key being the integer id of the data. This id is what the Gtk.TreeIter objects
    use to reference data in the pool.
    References will be removed from the pool when the model is deleted or explicitly
    by using the optional "node" argument to the "row_deleted" method when notifying
    the model of row deletion.
    Notify the model a row has been deleted.

        Use the node parameter to ensure the user_data reference associated
        with the path is properly freed by this model.

        :Parameters:
            path : Gtk.TreePath
                Path to the row that has been deleted.
            node : object
                Python object used as the node returned from "on_get_iter". This is
                optional but ensures the model will not leak references to this object.
        GenericTreeModel.on_get_pathOverridable.

        :Returns:
            True if the given node has children.
        GenericTreeModel.invalidate_itersGet the user_data associated with the given TreeIter.

        GenericTreeModel stores arbitrary Python objects mapped to instances of Gtk.TreeIter.
        This method allows to retrieve the Python object held by the given iterator.
        Overridable.

        :Returns Gtk.TreeModelFlags:
            The flags for this model. See: Gtk.TreeModelFlags
        Overridable.

        :Returns:
            The column type for the given index.
        If True, strong references to user data attached to iters are stored in a dictionary pool (default). Otherwise the user data is stored as a raw pointer to a python object without a reference.Overridable.

        :Parameters:
            parent : object
            n : int
                Index of child within parent.

        :Returns:
            The child for the given parent index starting at 0. If parent None,
            return the top level node corresponding to "n".
            If "n" is larger then available nodes, return None.
        min_aspectBaseGettertext_columnenable_gtk.<locals>.BaseGetter.__getitem__install_child_property() is not supportedorig_cell_pack_endexpander_new_with_mnemonicorig_VScaleenable_gtk.<locals>.set_tool_item_typeimage_new_from_pixbufpixbuf_new_from_inlineVteBASE_SIZEorig_tree_view_column_pack_startCanvasImageGUdevPangoCairoRectgst.videoenable_gtk.<locals>.size_request.<locals>.SizeRequest.__init__orig_get_frame_extentsorig_HScalegst.basegeom_maskscroll_to_markget_extensionsGstBaseclipboard_getset_default_icon_nameGstVideoenable_gtk.<locals>.VScaleUnixPrintpygtkcompat.pygtkcompatpypoppler_versionget_geometrycombo_box_entry_newASPECTpixbuf_new_from_stream_at_scaleenable_gtk.<locals>.ComboBoxEntry.get_text_columnGOO_CANVAS_GooCanvaswithin_marginenable_gtk.<locals>.cell_pack_endwidget_get_default_directionGstAudioregistry_get_defaultappend_textversion 4.0 not supportedorig_gdk_window_get_geometryenable_gtk.<locals>.UnixPrintget_gst_versionenable_gtk.<locals>.HScale.__init__menuactionReturns True in case it is already enabledenable_gtk.<locals>.combo_row_separator_func.<locals>.callbackget_formatsAtkset_entry_text_columnget_mime_types_2BUTTON_PRESSenable_gtk.<locals>.StyleDescriptorenable_gtk.<locals>.StyleDescriptor.__get__RESIZE_INCStylesxscaleenable_gtk.<locals>.combo_box_entry_new_with_modelgst.pbutilsorig_Alignmentget_web_inspectorenable_gtk.<locals>.GenericCellRendererbase_heightorig_pack_startWebViewElementFactorycombo_box_new_textenable_gtk.<locals>.ComboBoxEntry.__init__set_row_separator_funcstatus_icon_position_menuClipboardenabled_versionscreen_get_defaultenable_gtk.<locals>.pack_startorig_pack_endorig_combo_row_separator_functree_view_column_pack_endget_inspectorC:\msys64\mingw64\lib\python3.6\site-packages\pygtkcompat\pygtkcompat.pyset_modelScreenwindow_set_default_icon_patchesenable_gtk.<locals>.Styles.__init__has_entryPixbufLoadertext_view_scroll_to_markenable_gtk.<locals>.get_formats.<locals>.make_dictorig_set_geometry_hintsaspect ratios must be positivepixbuf_new_from_xpm_datapixbuf_new_from_fileorig_set_cell_data_funcset_tool_item_type() is not supportedelement_registerBaseSinkWindowHintsscreen_widthenable_gst.<locals>.<lambda>get_windoworig_size_requestenable_gtk.<locals>.<lambda>PopplerGstPbutilsgudevuse_alignget_file_infoGstInterfacesGstControllerheight_incconnect_groupenable_gtk.<locals>.new_textgobject.propertyhelperenable_gtk.<locals>.install_child_propertyCellLayoutgoocanvas_check_enabledCanvasItemimage_new_from_animationimage_new_from_file0.18settings_get_defaultwidth_incget_pygst_versiongtk.keysymspygtk_versionMIN_SIZEnew_from_datapixbuf_get_file_infowindow_set_default_icon_nameenable_gtk.<locals>.set_cell_data_funcgst.controllerorig_get_formatsorig_get_originGeometry_module_patchesenable_gtk.<locals>.tree_view_column_pack_endpixbuf_new_from_dataRectangleCanvasGroupenable_gtk.<locals>.VScale.__init__gst.audiocell_pack_startwebkit      ð¿_patch_modulewindow_list_toplevelsget_visualorig_tree_view_column_pack_endenable_gtk.<locals>.pack_endenable_gtk.<locals>.append_textenable_gtk.<locals>.cell_pack_startAccelGroupenable_gtk.<locals>.tree_view_column_pack_startBaseTransformmax_aspectgst.interfaces%r already enabled with different version (%r)setdefaultencodingorig_text_view_scroll_to_mark__flags_values__pixbuf_new_from_file_at_scalestock_add_enabled_registrynew_from_stockset_tooltipget_style_contextenable_gtk.<locals>.BaseGetter.__init__©:ÚversionÚAtkÚPangoÚ
PangoCairoÚGdkÚ	GdkPixbufÚorig_get_formatsÚget_formatsÚorig_get_frame_extentsÚget_frame_extentsÚorig_get_originÚ
get_originÚorig_gdk_window_get_geometryÚgdk_window_get_geometryÚGtkÚset_tool_item_typeÚorig_AlignmentÚ	AlignmentÚorig_pack_endÚpack_endÚorig_pack_startÚ
pack_startÚorig_tree_view_column_pack_endÚtree_view_column_pack_endÚ orig_tree_view_column_pack_startÚtree_view_column_pack_startÚorig_cell_pack_endÚcell_pack_endÚorig_cell_pack_startÚcell_pack_startÚorig_set_cell_data_funcÚset_cell_data_funcÚGenericCellRendererÚorig_combo_row_separator_funcÚcombo_row_separator_funcÚComboBoxEntryÚcombo_box_entry_newÚcombo_box_entry_new_with_modelÚinstall_child_propertyÚnew_textÚappend_textÚorig_HScaleÚorig_VScaleÚHScaleÚVScaleÚorig_size_requestÚsize_requestÚ
BaseGetterÚStylesÚStyleDescriptorÚorig_text_view_scroll_to_markÚtext_view_scroll_to_markÚorig_set_geometry_hintsÚset_geometry_hintsÚ	UnixPrintÚ	unixprintÚkeysymsÚgenerictreemodel_install_enumsmin_height<module pygtkcompat.pygtkcompat>base_widthget_background_colorimage_new_from_icon_setnew_with_typeimage_new_from_stockenable_gtk.<locals>.ComboBoxEntry.set_text_columngeometry_widgetget_best_depthenable_gtk.<locals>.set_cell_data_func.<locals>.callbackenable_gtk.<locals>.gdk_window_get_geometryenable_gtk.<locals>.AlignmentReverse all effects of the enable_xxx() calls except for
    require_version() calls and imports.
    enable_gtk.<locals>.get_frame_extentsenable_gtk.<locals>.text_view_scroll_to_markStatusIconCanvasRectelement_factory_make__enum_values__new_anyicon_theme_get_defaultenable_gtk.<locals>.set_geometry_hintsenable_gtk.<locals>.get_originIconThemecaps_new_anyCanvasItemSimpleget_entry_text_columnpixbuf_new_from_file_at_sizeset_tooltip_textpixbuf_get_formatsenable_gtk.<locals>.Alignment.__init__
PyGTK compatibility layer.

This modules goes a little bit longer to maintain PyGTK compatibility than
the normal overrides system.

It is recommended to not depend on this layer, but only use it as an
intermediate step when porting your application to PyGI.

Compatibility might never be 100%, but the aim is to make it possible to run
a well behaved PyGTK application mostly unmodified on top of PyGI.

_disable_allscreen_heightQuestionMarkView.draw_ailmentQuestionMarkView.draw_guardingC:\msys64\home\cbper\questionmarkview.pyfeedback_enabledQuestionMarkView.enable_feedback<module questionmarkview>QuestionMarkView.disable_feedbackQuestionMarkView.__init__html/dummy_imitation_question.svgQuestionMarkView.draw_palpation_locationquestmaster checked_tasks_completequest_datarepeatabletask_dataQuestMaster.begin_questdata_setQuestMaster.quest_listQuest.__init__QuestMaster.begin_new_questQuestMaster.update_questTaskquest_data_listQuest.new_dataquest_idend_quest_data_indexes
            {
                'name': '',
                'id': '',
                'case': '',
                'description': '',
                'completion_text': '',
                'tasks': [
                    {
                        'description':      '',
                        'type':             'any', # Can be any or all
                        'data_source:       'pressure', #Can be ailment or pressure
                        'data_indexes':     [200, 201, 215, 216],
                        'required_value':   'down', # Any valid data type of the requested data above
                    },
                ],
            },
        
            {
                'name': '',
                'id': '',
                'case': '',
                'description': '',
                'completion_text': '',
                'tasks': [
                    {
                        'description':      '',
                        'type':             'any', # Can be any or all
                        'data_source:       'pressure', #Can be ailment or pressure
                        'data_indexes':     [200, 201, 215],
                                            # indexes 0-215 are points on the pressure pad
                        'required_value':   'down', # Any valid data type of the requested data above
                    },
                ],
            },
        Task.__init__QuestMaster.__init__QuestMaster.end_questThis class holds the text that will create Quests. Eventually it'll get them from data files, but I am too busy.Task.new_data<module questmaster>C:\msys64\home\cbper\questmaster.pyRemove and return an item from the queue without blocking.

        Only get an item if one is immediately available. Otherwise
        raise the Empty exception.
        not_fullPriorityQueue._qsize<module queue>LifoQueueQueue._getQueue._initLifoQueue._qsizeVariant of Queue that retrieves open entries in priority order (lowest first).

    Entries are typically tuples of the form:  (priority number, data).
    A multi-producer, multi-consumer queue.PriorityQueue._initReturn the approximate size of the queue (not reliable!).Put an item into the queue.

        If optional args 'block' is true and 'timeout' is None (the default),
        block if necessary until a free slot is available. If 'timeout' is
        a non-negative number, it blocks at most 'timeout' seconds and raises
        the Full exception if no free slot was available within that time.
        Otherwise ('block' is false), put an item on the queue if a free slot
        is immediately available, else raise the Full exception ('timeout'
        is ignored in that case).
        'timeout' must be a non-negative numberVariant of Queue that retrieves most recently added entries first.Queue._putLifoQueue._initPut an item into the queue without blocking.

        Only enqueue the item if a free slot is immediately available.
        Otherwise raise the Full exception.
        Return True if the queue is full, False otherwise (not reliable!).

        This method is likely to be removed at some point.  Use qsize() >= n
        as a direct substitute, but be aware that either approach risks a race
        condition where a queue can shrink before the result of full() or
        qsize() can be used.
        Blocks until all items in the Queue have been gotten and processed.

        The count of unfinished tasks goes up whenever an item is added to the
        queue. The count goes down whenever a consumer thread calls task_done()
        to indicate the item was retrieved and all work on it is complete.

        When the count of unfinished tasks drops to zero, join() unblocks.
        Exception raised by Queue.put(block=0)/put_nowait().Indicate that a formerly enqueued task is complete.

        Used by Queue consumer threads.  For each get() used to fetch a task,
        a subsequent call to task_done() tells the queue that the processing
        on the task is complete.

        If a join() is currently blocking, it will resume when all items
        have been processed (meaning that a task_done() call was received
        for every item that had been put() into the queue).

        Raises a ValueError if called more times than there were items
        placed in the queue.
        Exception raised by Queue.get(block=0)/get_nowait().LifoQueue._getLifoQueue._putCreate a queue object with a given maximum size.

    If maxsize is <= 0, the queue size is infinite.
    PriorityQueue._putC:\msys64\mingw64\lib\python3.6\queue.pyPriorityQueue._getall_tasks_doneReturn True if the queue is empty, False otherwise (not reliable!).

        This method is likely to be removed at some point.  Use qsize() == 0
        as a direct substitute, but be aware that either approach risks a race
        condition where a queue can grow before the result of empty() or
        qsize() can be used.

        To create code that needs to wait for all queued tasks to be
        completed, the preferred technique is to use the join() method.
        Remove and return an item from the queue.

        If optional args 'block' is true and 'timeout' is None (the default),
        block if necessary until an item is available. If 'timeout' is
        a non-negative number, it blocks at most 'timeout' seconds and raises
        the Empty exception if no item was available within that time.
        Otherwise ('block' is false), return an item if one is immediately
        available, else raise the Empty exception ('timeout' is ignored
        in that case).
        usage: quopri [-t | -d] [file] ...ishex 	lineEndRead 'input', apply quoted-printable encoding, and write to 'output'.

    'input' and 'output' are binary file objects. The 'quotetabs' flag
    indicates whether embedded tabs and spaces should be quoted. Note that
    line-ending tabs and spaces are always encoded, as per RFC 1521.
    The 'header' flag indicates whether we are encoding spaces as _ as per RFC
    1522.a2b_qpencode.<locals>.writeGet the integer value of a hexadecimal number.prevlineinfp-t: quote tabsnon-hex digit Quote a single character.Conversions to/from quoted-printable transport encoding as per RFC 1521.Return true if the byte ordinal 'c' is a hexadecimal digit in ASCII.%s: can't open (%s)
-t and -d are mutually exclusiveneedsquoting-d: decode; default encodeRead 'input', apply quoted-printable decoding, and write to 'output'.
    'input' and 'output' are binary file objects.
    If 'header' is true, decode underscore as space (per RFC 1522).<module quopri>C:\msys64\mingw64\lib\python3.6\quopri.pyDecide whether a particular byte ordinal needs to be quoted.

    The 'quotetabs' flag indicates whether embedded tabs and spaces should be
    quoted.  Note that line-ending tabs and spaces are always encoded, as per
    RFC 1521.
    populationrandbelowsetsizeselected_addNormal distribution.

        mu is the mean, and sigma is the standard deviation.

        _BuiltinMethodTypeUUUUUUÕ?Initialize an instance.

        Optional argument x controls seeding, as for Random.seed().
        Random.triangulargauss_urandomavgRandom.weibullvariateBPFRECIP_BPFThe number of weights does not match the populationsqsumnumber of bits must be greater than zeroShuffle list x in place, and return None.

        Optional argument random is a 0-argument function returning a
        random float in [0.0, 1.0); if it is the default None, the
        standard random.random will be used.

        Circular data distribution.

        mu is the mean angle, expressed in radians between 0 and 2*pi, and
        kappa is the concentration parameter, which must be greater than or
        equal to zero.  If kappa is equal to zero, this distribution reduces
        to a uniform random angle over the range 0 to 2*pi.

        Underlying random() generator does not supply 
enough bits to choose from a population range this large.
To remove the range limitation, add a getrandbits() method.      @internalstateRandom.samplegammavariate: alpha and beta must be > 0.0Exponential distribution.

        lambd is 1.0 divided by the desired mean.  It should be
        nonzero.  (The parameter would be called "lambda", but that is
        a reserved word in Python.)  Returned values range from 0 to
        positive infinity if lambd is positive, and from negative
        infinity to 0 if lambd is negative.

        Random.randrangeSystemRandom.seedRandom.expovariateGamma distribution.  Not the gamma function!

        Conditions on the parameters are alpha > 0 and beta > 0.

        The probability distribution function is:

                    x ** (alpha - 1) * math.exp(-x / beta)
          pdf(x) =  --------------------------------------
                      math.gamma(alpha) * beta ** alpha

        _acosRandom.setstatenon-integer stop for randrange()non-integer step for randrange()SystemRandom.getrandbitsMethod should not be called for a system random number generator.       ÀRandom.__getstate__LOG4Cannot choose from an empty sequenceRestore internal state from object returned by getstate().Stub method.  Not used for a system random number generator.Return internal state; can be passed to setstate() later.Pareto distribution.  alpha is the shape parameter.Get the next random number in the range [0.0, 1.0).Random.uniformnormalvariateRandom.shuffleWeibull distribution.

        alpha is the scale parameter and beta is the shape parameter.

        avg %g, stddev %g, min %g, max %g
getrandbits(k) -> x.  Generates an int with k random bits.Random.choiceRandom.__init__Get a random number in the range [a, b) or [a, b] depending on rounding.SystemRandom.random      à¿      @Return a random int in the range [0,n).  Raises ValueError if n==0._MethodTypeRandom variable generators.

    integers
    --------
           uniform within range

    sequences
    ---------
           pick random element
           pick random sample
           pick weighted random sample
           generate random permutation

    distributions on the real line:
    ------------------------------
           uniform
           triangular
           normal (Gaussian)
           lognormal
           negative exponential
           gamma
           beta
           pareto
           Weibull

    distributions on the circle (angles 0 to 2pi)
    ---------------------------------------------
           circular uniform
           von Mises

General notes on the underlying Mersenne Twister core generator:

* The period is 2**19937-1.
* It is one of the most extensively tested generators in existence.
* The random() method is implemented in C, executes in a single Python step,
  and is, therefore, threadsafe.

NV_MAGICCONSTgauss_nextSG_MAGICCONSTempty range for randrange()    _ BistepRandom.__setstate__Û   zRandomzseedzrandomzuniformzrandintzchoicezsamplez	randrangezshuffleznormalvariatezlognormvariatezexpovariatezvonmisesvariatezgammavariatez
triangularzgausszbetavariatezparetovariatezweibullvariatezgetstatezsetstatezgetrandbitszchoiceszSystemRandomainvg2radRandom.vonmisesvariateTriangular distribution.

        Continuous distribution bounded by given lower and upper limits,
        and having a given mode value in-between.

        http://en.wikipedia.org/wiki/Triangular_distribution

        Random.gammavariateReturn random integer in range [a, b], including both end points.
        Cannot specify both weights and cumulative weightsC:\msys64\mingw64\lib\python3.6\random.pyistartistopRandom.randintRandom number generator base class used by bound module functions.

    Used to instantiate instances of Random to get generators that don't
    share state.

    Class Random can also be subclassed if you want to use a different basic
    generator of your own devising: in that case, override the following
    methods:  random(), seed(), getstate(), and setstate().
    Optionally, implement a getrandbits() method so that randrange()
    can cover arbitrarily large ranges.

    Random.gausszero step for randrange()non-integer arg 1 for randrange()Random.getstatecum_weights    _ ÂRandom.setstate.<locals>.<genexpr>Choose a random item from range(start, stop[, step]).

        This fixes the problem with randint() which includes the
        endpoint; in Python this is usually not what you want.

        System entropy source does not have state.TWOPISystemRandom._notimplementedRandom._randbelowËPÊÿÿï?Random.normalvariateRandom.lognormvariateRandom.betavariateRandom.__reduce__x2piRandom.paretovariatestate with version %s passed to Random.setstate() of version %s      i@Log normal distribution.

        If you take the natural logarithm of this distribution, you'll get a
        normal distribution with mean mu and standard deviation sigma.
        mu can have any value, and sigma must be greater than zero.

        empty range for randrange() (%d,%d, %d)Random.choicesíµ ÷Æ°>sec,Initialize internal state from hashable object.

        None or no argument seeds from current time or from an operating
        system specific randomness source if available.

        If *a* is an int, all bits are used.

        For version 2 (the default), all of the bits are used if *a* is a str,
        bytes, or bytearray.  For version 1 (provided for reproducing random
        sequences from older versions of Python), the algorithm for str and
        bytes generates a narrower range of seeds.

        Beta distribution.

        Conditions on the parameters are alpha > 0 and beta > 0.
        Returned values range between 0 and 1.

        Return a k sized list of population elements chosen with replacement.

        If the relative weights or cumulative weights are not specified,
        the selections are made with equal probability.

        _test_generatorSample larger than population or is negativeAlternate random number generator using sources provided
    by the operating system (such as /dev/urandom on Unix or
    CryptGenRandom on Windows).

     Not available on all systems (see os.urandom() for details).
    Chooses k unique random elements from a population sequence or set.

        Returns a new list containing elements from the population while
        leaving the original population unchanged.  The resulting list is
        in selection order so that all sub-slices will also be valid random
        samples.  This allows raffle winners (the sample) to be partitioned
        into grand prize and second place winners (the subslices).

        Members of the population need not be hashable or unique.  If the
        population contains repeats, then each occurrence is a possible
        selection in the sample.

        To choose a sample in a range of integers, use range as an argument.
        This is especially fast and space efficient for sampling from a
        large population:   sample(range(10000000), 60)
        number of bits should be an integer_cosPopulation must be a sequence or set.  For dicts, use list(d).ÍÌÌÌÌÌì?<module random>Choose a random element from a non-empty sequence.H¯¼ò×z>Gaussian distribution.

        mu is the mean, and sigma is the standard deviation.  This is
        slightly faster than the normalvariate() function.

        Not thread-safe without a lock around calls.

        first argument must be string or compiled pattern_MAXCACHElexiconRegexFlagpurge_alphanum_str
    Escape all the characters in pattern except ASCII letters, numbers and '_'.
    <module re>_subx.<locals>.filterlastindexScanner.__init__C:\msys64\mingw64\lib\python3.6\re.py_pattern_typeReturn a list of all non-overlapping matches in the string.

    If one or more capturing groups are present in the pattern, return
    a list of groups; this will be a list of tuples if the pattern
    has more than one group.

    Empty matches are included in the result.Compile a regular expression pattern, returning a pattern object.cannot process flags argument with a compiled patternTry to apply the pattern to all of the string, returning
    a match object, or None if no match was found.¾?   é0   é1   é2   é3   é4   é5   é6   é7   é8   é9   éA   éB   éC   éD   éE   éF   éG   éH   éI   éJ   éK   éL   éM   éN   éO   éP   éQ   éR   éS   éT   éU   éV   éW   éX   éY   éZ   é_   éa   éb   éc   éd   ée   éf   ég   éh   éi   éj   ék   él   ém   én   éo   ép   éq   ér   és   ét   éu   év   éw   éx   éy   éz   Split the source string by the occurrences of the pattern,
    returning a list containing the resulting substrings.  If
    capturing parentheses are used in pattern, then the text of all
    groups in the pattern are also returned as part of the resulting
    list.  If maxsplit is nonzero, at most maxsplit splits occur,
    and the remainder of the string is returned as the final element
    of the list.Try to apply the pattern at the start of the string, returning
    a match object, or None if no match was found.TEMPLATE\000Scanner.scan¾?   ÚxúFÚMÚiÚrúYú2ÚpÚdú8ÚXÚcÚKÚQÚDÚlÚyÚEÚSÚOú3ÚhÚmÚHÚPÚBÚUúJÚzúVÚAú6ÚkÚIÚLú5ÚoÚaÚ0ÚZú7Ú_ÚgÚ1ÚTÚfÚuÚeúGúWÚwÚRÚnÚbÚqÚjÚtÚsÚNú4ú9ÚvÚCReturn a 2-tuple containing (new_string, number).
    new_string is the string obtained by replacing the leftmost
    non-overlapping occurrences of the pattern in the source
    string by the replacement repl.  number is the number of
    substitutions that were made. repl can be either a string or a
    callable; if a string, backslash escapes in it are processed.
    If it is a callable, it's passed the match object and must
    return a replacement string to be used._alphanum_bytesReturn an iterator over all non-overlapping matches in the
    string.  For each match, the iterator returns a match object.

    Empty matches are included in the result.Support for regular expressions (RE).

This module provides regular expression matching operations similar to
those found in Perl.  It supports both 8-bit and Unicode strings; both
the pattern and the strings being processed can contain null bytes and
characters outside the US ASCII range.

Regular expressions can contain both special and ordinary characters.
Most ordinary characters, like "A", "a", or "0", are the simplest
regular expressions; they simply match themselves.  You can
concatenate ordinary characters, so last matches the string 'last'.

The special characters are:
    "."      Matches any character except a newline.
    "^"      Matches the start of the string.
    "$"      Matches the end of the string or just before the newline at
             the end of the string.
    "*"      Matches 0 or more (greedy) repetitions of the preceding RE.
             Greedy means that it will match as many repetitions as possible.
    "+"      Matches 1 or more (greedy) repetitions of the preceding RE.
    "?"      Matches 0 or 1 (greedy) of the preceding RE.
    *?,+?,?? Non-greedy versions of the previous three special characters.
    {m,n}    Matches from m to n repetitions of the preceding RE.
    {m,n}?   Non-greedy version of the above.
    "\\"     Either escapes special characters or signals a special sequence.
    []       Indicates a set of characters.
             A "^" as the first character indicates a complementing set.
    "|"      A|B, creates an RE that will match either A or B.
    (...)    Matches the RE inside the parentheses.
             The contents can be retrieved or matched later in the string.
    (?aiLmsux) Set the A, I, L, M, S, U, or X flag for the RE (see below).
    (?:...)  Non-grouping version of regular parentheses.
    (?P<name>...) The substring matched by the group is accessible by name.
    (?P=name)     Matches the text matched earlier by the group named name.
    (?#...)  A comment; ignored.
    (?=...)  Matches if ... matches next, but doesn't consume the string.
    (?!...)  Matches if ... doesn't match next.
    (?<=...) Matches if preceded by ... (must be fixed length).
    (?<!...) Matches if not preceded by ... (must be fixed length).
    (?(id/name)yes|no) Matches yes pattern if the group with id/name matched,
                       the (optional) no pattern otherwise.

The special sequences consist of "\\" and a character from the list
below.  If the ordinary character is not on the list, then the
resulting RE will match the second character.
    \number  Matches the contents of the group of the same number.
    \A       Matches only at the start of the string.
    \Z       Matches only at the end of the string.
    \b       Matches the empty string, but only at the start or end of a word.
    \B       Matches the empty string, but not at the start or end of a word.
    \d       Matches any decimal digit; equivalent to the set [0-9] in
             bytes patterns or string patterns with the ASCII flag.
             In string patterns without the ASCII flag, it will match the whole
             range of Unicode digits.
    \D       Matches any non-digit character; equivalent to [^\d].
    \s       Matches any whitespace character; equivalent to [ \t\n\r\f\v] in
             bytes patterns or string patterns with the ASCII flag.
             In string patterns without the ASCII flag, it will match the whole
             range of Unicode whitespace characters.
    \S       Matches any non-whitespace character; equivalent to [^\s].
    \w       Matches any alphanumeric character; equivalent to [a-zA-Z0-9_]
             in bytes patterns or string patterns with the ASCII flag.
             In string patterns without the ASCII flag, it will match the
             range of Unicode alphanumeric characters (letters plus digits
             plus underscore).
             With LOCALE, it will match the set [0-9_] plus characters defined
             as letters for the current locale.
    \W       Matches the complement of \w.
    \\       Matches a literal backslash.

This module exports the following functions:
    match     Match a regular expression pattern to the beginning of a string.
    fullmatch Match a regular expression pattern to all of a string.
    search    Search a string for the presence of a pattern.
    sub       Substitute occurrences of a pattern found in a string.
    subn      Same as sub, but also return the number of substitutions made.
    split     Split a string by the occurrences of a pattern.
    findall   Find all occurrences of a pattern in a string.
    finditer  Return an iterator yielding a match object for each match.
    compile   Compile a pattern into a RegexObject.
    purge     Clear the regular expression cache.
    escape    Backslash all non-alphanumerics in a string.

Some of the functions in this module takes flags as optional parameters:
    A  ASCII       For string patterns, make \w, \W, \b, \B, \d, \D
                   match the corresponding ASCII character categories
                   (rather than the whole Unicode categories, which is the
                   default).
                   For bytes patterns, this flag is the only available
                   behaviour and needn't be specified.
    I  IGNORECASE  Perform case-insensitive matching.
    L  LOCALE      Make \w, \W, \b, \B, dependent on the current locale.
    M  MULTILINE   "^" matches the beginning of lines (after a newline)
                   as well as the string.
                   "$" matches the end of lines (before a newline) as well
                   as the end of the string.
    S  DOTALL      "." matches any character at all, including the newline.
    X  VERBOSE     Ignore whitespace and comments for nicer looking RE's.
    U  UNICODE     For compatibility only. Ignored for string patterns (it
                   is the default), and forbidden for bytes patterns.

This module also defines an exception 'error'.

2.2.1Scan through string looking for a match to the pattern, returning
    a match object, or None if no match was found._compile_replReturn the string obtained by replacing the leftmost
    non-overlapping occurrences of the pattern in string by the
    replacement repl.  repl can be either a string or a callable;
    if a string, backslash escapes in it are processed.  If it is
    a callable, it's passed the match object and must return
    a replacement string to be used.Compile a template pattern, returning a pattern objectClear the regular expression cachesÛ   zmatchz	fullmatchzsearchzsubzsubnzsplitzfindallzfinditerzcompilezpurgeztemplatezescapezerrorÚAÚIÚLÚMÚSÚXÚUzASCIIz
IGNORECASEzLOCALEz	MULTILINEzDOTALLzVERBOSEzUNICODERedo the builtin repr() (representation) but with limits on most sizes.repr_dictvalreprRepr.repr_dequearray('%s', [Repr.repr_setrecursive_repr.<locals>.decorating_function.<locals>.wrapper<module reprlib>Repr.repr_frozensetRepr._repr_iterablenewlevelRepr.repr_arraymaxfrozensetrepr_runningRepr.repr_listRepr.repr_dictmaxiterkeyrepraReprarray('%s')maxlongfrozenset({deque([repr_tupleRepr.repr_int<%s instance at %#x>maxarray_possibly_sortedmaxdequeDecorator to make a repr function return fillvalue for a recursive callmaxsetRepr.repr_tupleC:\msys64\mingw64\lib\python3.6\reprlib.pyRuns the designated module in the __main__ namespace

       Note that the executed module will have full access to the
       __main__ namespace. If this is not desirable, the run_module()
       function should be used to run the module code in a fresh namespace.

       At the very least, these variables in __main__ will be overwritten:
           __name__
           __file__
           __cached__
           __loader__
           __package__
    init_globalsis_NullImportermod_spectemp_modulemod_globalsalter_argv_ModifiedArgv0_TempModule.__init__%s; %r is a package and cannot be directly executedRelative module names not supported_ModifiedArgv0.__exit__can't find %r module in %rError while finding module specification for {!r} ({}: {})Already preserving saved value_ErrorCannot use package as __main__ modulerun_globals_saved_modulepkg_main_name_TempModule.__enter___get_module_detailsExecute a module's code without importing it

       Returns the resulting top level namespace dictionary
    C:\msys64\mingw64\lib\python3.6\runpy.pymain_globalsError that _run_module_as_main() should report without a traceback_ModifiedArgv0.__init___get_main_module_details_ModifiedArgv0.__enter__<module runpy>_run_codeExecute code located at the specified filesystem location

       Returns the resulting top level namespace dictionary

       The file path may refer directly to a Python script (i.e.
       one that could be directly executed with execfile) or else
       it may refer to a zipfile or directory containing a top
       level __main__.py script.
    Temporarily replace a module in sys.modules with an empty namespace{mod_name!r} found in sys.modules after import of package {pkg_name!r}, but prior to execution of {mod_name!r}; this may result in unpredictable behaviour_get_code_from_fileHelper to run code in nominated namespaceHelper to run code in new namespace with sys modifiedrunpy.py - locating and running Python code using the module namespace

Provides support for locating and running Python scripts using the Python
module namespace instead of the native filesystem.

This allows Python code to play nicely with non-filesystem based PEP 302
importers when locating support scripts as well as when importing modules.
<run_path>saved_mainNo module named %sNo code object available for %s_TempModule.__exit__%r is a namespace package and cannot be executed_run_module_code_saved_value_fd_to_keyKQ_EV_ADDBaseSelector.modifySolaris /dev/poll selector.poll_eventsBaseSelector.get_keymax_evKqueue-based selector.kev_listReturn a file descriptor from a file object.

        This wraps _fileobj_to_fd() to do an exhaustive search in case
        the object is invalid but we still have it in our map.  This
        is used by unregister() so we can unregister an object that
        was previously registered even if it is closed.  It is also
        used by _SelectorMapping.
        DevpollSelector.unregisterü©ñÒMbP?_BaseSelectorImpl._fileobj_lookupkeventReturn the key associated to a given file descriptor.

        Parameters:
        fd -- file descriptor

        Returns:
        corresponding key, or None if not found
        C:\msys64\mingw64\lib\python3.6\selectors.pyFile object registered.Events that must be waited for on this file object.DevpollSelector.registerBaseSelector.__enter__Change a registered file object monitored events or attached data.

        Parameters:
        fileobj -- file object or file descriptor
        events  -- events to monitor (bitwise mask of EVENT_READ|EVENT_WRITE)
        data    -- attached data

        Returns:
        SelectorKey instance

        Raises:
        Anything that unregister() or register() raises
        KqueueSelector.__init__KqueueSelector.closeBaseSelector.get_map<module selectors>epoll_eventsPollSelector.selectSelectSelector.registerInvalid file object: {!r}_epoll_BaseSelectorImpl.register_devpollEpollSelector.filenoInvalid events: {!r}SelectSelector._selectEpoll-based selector.Unregister a file object.

        Parameters:
        fileobj -- file object or file descriptor

        Returns:
        SelectorKey instance

        Raises:
        KeyError if fileobj is not registered

        Note:
        If fileobj is registered but has since been closed this does
        *not* raise OSError (even if the wrapped syscall does)
        DevpollSelector.closeDevpollSelector.__init__SelectorKey(fileobj, fd, events, data)

    Object used to associate a file object to its backing
    file descriptor, selected event mask, and attached data.
EPOLLOUTEpollSelector.selectRegister a file object.

        Parameters:
        fileobj -- file object or file descriptor
        events  -- events to monitor (bitwise mask of EVENT_READ|EVENT_WRITE)
        data    -- attached data

        Returns:
        SelectorKey instance

        Raises:
        ValueError if events is invalid
        KeyError if fileobj is already registered
        OSError if fileobj is closed or otherwise is unacceptable to
                the underlying system call (if a system call is made)

        Note:
        OSError may or may not be raised
        BaseSelector.__exit___BaseSelectorImpl.closeBaseSelector.selectBaseSelector.closePoll-based selector._kqueueDevpollSelector.select_SelectorMapping.__iter__PollSelector.__init__KqueueSelector.filenoPerform the actual selection, until some monitored file objects are
        ready or a timeout expires.

        Parameters:
        timeout -- if timeout > 0, this specifies the maximum wait time, in
                   seconds
                   if timeout <= 0, the select() call won't block, and will
                   report the currently ready file objects
                   if timeout is None, select() will block until a monitored
                   file object becomes ready

        Returns:
        list of (key, events) for ready file objects
        `events` is a bitwise mask of EVENT_READ|EVENT_WRITE
        Return the key associated to a registered file object.

        Returns:
        SelectorKey for this file object
        _SelectorMapping.__getitem__Select-based selector.DevpollSelector.filenoKqueueSelector.register_readersBaseSelector.registerMapping of file objects to selector keys._BaseSelectorImpl.modify_BaseSelectorImpl.unregisterEPOLLIN{!r} is not registeredUnderlying file descriptor.BaseSelector.unregisterBase selector implementation.KQ_EV_DELETEEpollSelector.__init__Optional opaque data associated to this file object.
    For example, this could be used to store a per-client session ID.SelectSelector.selectfd_event_listInvalid file descriptor: {}_SelectorMapping.__len__KQ_FILTER_READEpollSelector.closeSelector is closedEpollSelector.unregister_BaseSelectorImpl._key_from_fdSelectSelector.unregisterSelectSelector.__init__KqueueSelector.unregisterKQ_FILTER_WRITEReturn a mapping of file objects to selector keys.PollSelector.unregister_BaseSelectorImpl.get_mapKqueueSelector.select{!r} (FD {}) is already registered_writersSelectors module.

This module allows high-level and efficient I/O multiplexing, built upon the
`select` module primitives.
Selector abstract base class.

    A selector supports registering file objects to be monitored for specific
    I/O events.

    A file object is a file descriptor or any object with a `fileno()` method.
    An arbitrary object can be attached to the file object, which can be used
    for example to store context information, a callback, etc.

    A selector can use various implementations (select(), poll(), epoll()...)
    depending on the platform. The default `Selector` class uses the most
    efficient implementation on the current platform.
    Close the selector.

        This must be called to make sure that any underlying resource is freed.
        _BaseSelectorImpl.__init__PollSelector.registerEpollSelector.register_SelectorMapping.__init__Return a file descriptor from a file object.

    Parameters:
    fileobj -- file object or file descriptor

    Returns:
    corresponding file descriptor

    Raises:
    ValueError if the object is invalid
    label_markupbuild_chooser<span font='14'>Ovary, Right</span><span font='20' fgcolor='#1E9D1C'><b>Correct</b></span><span font='16'><b>Unremarkable Abdomen</b></span><span font='14'>Pancreas</span>SelfPractice.ddx_chosenSelfPractice.new_selected_case<span font='23'>No abnormal ultrasound available.</span>build_frameSelfPracticeWithUltrasound.__init__show_feedback_imagesSelfPractice.on_next_case_button<span font='14'>Gallbladder Tenderness</span>Normal Ultrasound<span font='14'>Gastric</span><span font='16'><b>Tenderness</b></span>SelfPracticeWithUltrasound.hide_feedbackget_translation_domain<span font='16'><b>Organ Enlargement</b></span>SelfPractice.build_chooser<span font='16'>For this milestone, you will report the findings by feel and sound only.

When you select a finding, you will receive feedback and have a second chance to palpate.

When you are confident in eliciting findings, we will integrate patient history and non-palpitory physical findings.</span><span font='14'>Colon Tenderness + Guarding</span><span font='14'>Ovary, Right + Guarding</span><span font='14'>Colon</span><span font='28'>You selected:
{given_ddx}          

Correct selection:
 {current_case} </span><span font='23'>No normal ultrasound available.</span>expander_label<span font='16'>In this experimental training session, you will report the findings by feel and sound only, like in Milestone 4.

When you select a finding, you will view a normal and abnormal ultrasound image of the correct selection.

Familiarize yourself with normal and abnormal image findings.</span><span font='14'>Gastric Tenderness</span>SelfPractice.__init__normal_ultrasound<span font='14'>No Abnormalities</span>SelfPracticeWithUltrasound.assemble_interfacebutton_nameSelfPractice.set_correctness_text<span font='14'>Appendix Tenderness</span>expanders_to_close<span font='14'>Gallbladder Tenderness + Guarding</span>SelfPractice.build_case_text_view<span font='14'>Bladder</span><span font='20' fgcolor='#FF3333'><b>Incorrect</b></span><span font='14'>Appendix Tenderness + Rebound Tenderness</span>SelfPractice.reset_pageselfpractice:109: LANG=%sexpander_vbox<span font='14'>Colon Tenderness</span>Abnormal UltrasoundSelfPractice.build_prototype_text_view<span font='14'>Ovary, Left</span>normal_ultrasound_image_unavailable_label<span font='14'>Appendix Tenderness + Guarding</span>      @<span font='14'>Organs</span>frame_vboxframe_specframe_labelselfpractice:112: translation_domain=%sSelfPractice.assemble_interfaceSHADOW_NONESelfPractice.hide_feedback<span font="14">Unremarkable Abdomen</span>us_vbox<span font='14'>Splenomegaly</span>SelfPractice.show_feedback_imagesC:\msys64\home\cbper\selfpractice.py<span font='14'>Enlarged Urinary Bladder</span><span font='14'>Appendix Tenderness + Guarding + Rebound Tenderness</span><span font='14'>Gallbladder</span>SelfPracticeWithUltrasound.show_feedback_imagesabnormal_ultrasound_image<span font='16'>Before moving on, re-familiarize yourself with how this condition feels.</span>queue_draw_areaabnormal_ultrasound_image_unavailable_labelbuild_megaframe<span font='14'>Hepatomegaly</span>SelfPracticeWithUltrasound.new_selected_case<span font='14'>Bladder Tenderness</span>SelfPractice.build_frame<span font='14'>Appendix</span><span font='14'>Ovary, Left + Guarding</span>SelfPractice.create_ddx_chosen_buttonSelfPractice.build_glade_filesSelfPractice.build_interface_partsquestion_mark_view<module selfpractice>SelfPractice.build_megaframeset_label_widget    Get an instance of the Serial class, depending on port/url. The port is not
    opened when the keyword parameter 'do_not_open' is true, by default it
    is. All other parameters are directly passed to the __init__ method when
    the port is instantiated.

    The list of package names that is searched for protocol handlers is kept in
    ``protocol_handler_packages``.

    e.g. we want to support a URL ``foobar://``. A module
    ``my_handlers.protocol_foobar`` is provided by the user. Then
    ``protocol_handler_packages.append("my_handlers")`` would extend the search
    path so that ``serial_for_url("foobar://"))`` would work.
    serial_class_for_url<module serial>C:\msys64\mingw64\lib\python3.6\site-packages\serialhandler_moduleinvalid URL, protocol {!r} not knownserial.urlhandler.protocol_{}C:\msys64\mingw64\lib\python3.6\site-packages\serial\__init__.pyurl_lowercaseSorry: no implementation for your platform ('{}') availableRtsEnableUnsupported parity mode: %rReadTimeout
        Set break: Controls TXD. When active, to transmitting is possible.
        Serial port implementation for .NET/Mono.PortsDiscardOutBufferRequestToSendC:\msys64\mingw64\lib\python3.6\site-packages\serial\serialcli.pyDtrEnableDataBitsRequestToSendXOnXOffWriteTimeout<module serial.serialcli>InfiniteTimeoutTimeoutExceptionOnePointFiveUnsupported number of stop bits: %rCDHoldingcould not open port %s: %sCtsHoldingSystem.IO.PortsDsrHoldingUnsupported number of data bits: %rHandshakeInvalidOperationExceptionas_byte_arrayBytesToReadDiscardInBufferReadByteunsupported number of stopbits: %rpython serial moduleCould not open port: %sgetPortIdentifiergetOutputStreamsetSerialPortParamsenableReceiveTimeoutThe _update_break_state function is not implemented in java.portIdjstopbitsisRIDATABITS_6javax.commgnu.ioPORT_SERIALdetect_java_comm    Serial port class, implemented with Java Communications API and
    thus usable with jython and the appropriate java extension.
    CommPortIdentifierNo Java Communications API implementation foundSTOPBITS_2FLOWCONTROL_RTSCTS_OUTgetPortIdentifiersjflowoutSTOPBITS_1_5DATABITS_7portnumbergetInputStreamunsupported parity type: %rjparity_outstreamjdatabitsjflowinexpected %s or bytearray, got %sSend break condition. Timed, returns to idle state after given duration.nextElementDATABITS_8Turn a port number into a device namedisableReceiveTimeoutFLOWCONTROL_XONXOFF_IN_instreamFLOWCONTROL_XONXOFF_OUTSerial._reconfigurePorttry given list of modules and return that importsC:\msys64\mingw64\lib\python3.6\site-packages\serial\serialjava.pymy_importisCDunsupported bytesize: %r<module serial.serialjava>DATABITS_5isDSRgetPortTypeisCTShasMoreElementssetFlowControlModeFLOWCONTROL_RTSCTS_INCSTOPBIXOFFCRTSCTSCS7tcsendbreakEALREADYSER_RS485_ENABLEDnetbsdVTIMESerial.readSerial.nonblockingSER_RS485_RTS_ON_SENDCan only operate on a valid file descriptoriflaglflagPosixPollSerial.readIOSSIOSPEEDSerial.set_input_flow_controlPlatformSpecificBaseSerial.filenoB38400ECHOCTLRS485 not supported on this platformECHOKE        For easier use of the serial port instance with select.
        WARNING: this function is not portable to different platforms!
        O_NONBLOCKforce_updateCBAUDReturnBaudrateTCSANOWûi ô i  i è i  i ¡ i  i Ê i  i  i	  i@B i
  i  i  i`ã i  i i  i %& i  iÀÆ- i  0    Implement timeout using vtime of tty device instead of using select.
    This means that no inter character timeout can be specified and that
    the error handling is degraded.

    Overall timeout is disabled when inter-character timeout is used.
    pipe_abort_write_rorig_attrispeedospeedSER_RS485_RX_DURING_TXtcdrainReturnBaudrate.__getitem__TIOCCBRKwrite failed: {}IUCLCTIOCOUTQEINPROGRESSPARMRKTIOCM_RTSCS6TIOCGRS485IXANYwrite failed (select)TIOCM_DTR_strECHONLINLCRTIOCSRS485TCSETS2PlatformSpecificBase._set_rs485_modeInvalid char len: {!r}device reports readiness to read but returned no data (device disconnected or multiple access on port?)TCIONTIOCSBRKSER_RS485_RTS_AFTER_SENDcustom_baudInvalid stop bit specification: {!r}TIOCMGETTIOCM_CTSTIOCMSETTIOCM_RNGnonblocking() has no effect, already nonblockingTIOCM_RTS_strBAUDRATE_CONSTANTSflockC:\msys64\mingw64\lib\python3.6\site-packages\serial\serialposix.pydevice reports error (poll)Failed to set custom baud rate ({}): {}TCIFLUSHCould not exclusively lock port {}: {}_set_special_baudrateTIOCM_RITIOCMBISPlatformSpecific._set_rs485_modeTCOOFF        Set break: Controls TXD. When active, no transmitting is possible.
        tx_lenPlatformSpecificBase._set_special_baudrateLOCK_UNTCOFLUSHECHOEB{}Could not configure port: {}CREAD        Manually control flow of outgoing data - when hardware or software flow
        control is enabled.
        WARNING: this function is not portable to different platforms!
        pipe_abort_write_wTIOCM_zero_str        Manually control flow - when software flow control is enabled.
        This will send XON (true) or XOFF (false) to the other device.
        WARNING: this function is not portable to different platforms!
        Invalid baud rate: {!r}TIOCINQVTIMESerial._reconfigure_portioctl<module serial.serialposix>could not open port {}: {}POLLHUPûé    r   é2   é   éK   é   én   é   é   é   é   é   éÈ   é   i,  é   iX  é   i°  é	   i  é
   i`	  é   iÀ  é   i%  é   i K  é   i   é   i á  i  i Â i  i  i  i  i  i ¡ i  i Ê i  i  i  i@B i  i  i	  i`ã i
  i i  i %& i  iÀÆ- i  iàg5 i  i 	= i  0pipe_abort_read_rF_SETFLIGNBRKIGNCRInvalid vmin: {!r}TCGETS2TCOONInvalid parity: {!r}    Poll based read implementation. Not all systems support poll properly.
    However this one has better handling of errors, such as a device
    disconnecting while it's in use (e.g. USB-serial unplugged).
    Failed to set RS485 mode: {}TIOCMBICÛ@   é    r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   OCRNLread failed: {}tcflowDEPRECATED - has no useCNEW_RTSCTSTCIOFFInvalid vtime: {!r}TIOCM_CARCLOCALENOTTYPlatformSpecific._set_special_baudrate        Open port with current settings. This may throw a SerialException
        if the port cannot be opened.POLLERRpipe_abort_read_wTIOCM_CDtcflush    Serial port class POSIX implementation. Serial port configuration is
    done with termios and fcntl. Runs on Linux and many other Un*x like
    systems.
    EINTRPOLLNVALTIOCM_DSRReturn the number of bytes currently in the output buffer.LOCK_EXCMSPARPARODDONLCRBOTHERnon-standard baudrates are not supported on this platformLOCK_NBFIONREADSerialBase.__exit__SerialBase.__enter__"port" must be None or a string, not {}SerialBase.writeTimeoutwrite_timeout_SAVED_SETTINGS{name}<id=0x{id:x}, open={p.is_open}>(port={p.portstr!r}, baudrate={p.baudrate!r}, bytesize={p.bytesize!r}, parity={p.parity!r}, stopbits={p.stopbits!r}, timeout={p.timeout!r}, xonxoff={p.xonxoff!r}, rtscts={p.rtscts!r}, dsrdtr={p.dsrdtr!r})        Initialize comm port object. If a "port" is given, then the port will be
        opened immediately. Otherwise a Serial port object in closed state
        is returned.
        lentermSerialBase.writableSerialBase.getDSRinWaitingSerialBase.sendBreakSerialBase.__repr__PARITIESGet the current inter-character timeout setting.Not a valid stop bit size: {!r}SerialBase.read_allSerialBase.flushOutput        Get the current port setting. The value that was passed on init or using
        setPort() is passed back.
        getRISerialBase.inWaitingAttempting to use a port that is not openSerialBase.rtsString representation of the current port settings and its state.SerialBase.baudrateSerialBase.read_until        Restart a timeout, only supported if a timeout was already set up
        before.
        C:\msys64\mingw64\lib\python3.6\site-packages\serial\serialutil.pySerialBase.dsrdtrChange byte size.Get the current exclusive access setting.        Get current port settings as a dictionary. For use with
        apply_settings().
        Change timeout setting.Timeout.expiredChange parity setting.SerialBase.readintointer_byte_timeoutSerialBase.applySettingsDictget_settingsSerialBase.setDTRSerialBase.iread_untilbreak_conditionSerialBase.bytesizeTimeout.restartSerialBase.paritySerialBase.setPortInitialize a timeout with given durationChange XON/XOFF setting.Change DsrDtr flow control setting.SerialBase.__init__        Apply stored settings from a dictionary returned from
        get_settings(). It's allowed to delete keys from the dictionary. These
        values will simply left unchanged.
        SerialBase.inter_byte_timeout        Read until a termination sequence is found ('
' by default), the size
        is exceeded or until timeout occurs.
            Serial port base class. Provides __init__ function and properties to
    get/set port settings.
    SerialBase.rs485_modegetCTSiterbytesSerialBase.getCD<module serial.serialutil>SerialBase.timeoutReturn a boolean, telling if the timeout has expiredinterCharTimeoutBase class for serial port related exceptions.SerialBase.interCharTimeoutSerialBase.getCTS        Change baud rate. It raises a ValueError if the port is open and the
        baud rate is not possible. If the port is closed, then the value is
        accepted and the exception is raised when the port is opened.
        Change inter-byte timeout setting.ic_timeout        Read all bytes currently available in the buffer of the OS.
        Not a valid byte size: {!r}PARITY_NAMESwas_openSerialBase.stopbitsWrite timeouts give an exceptionChange RTS/CTS flow control setting.        Enable RS485 mode and apply new settings, set to None to disable.
        See serial.rs485.RS485Settings for more info about the value.
        Get the current stop bits setting.SerialBase.getRIGet the current RTS/CTS flow control setting.SerialBase.rtsctsSerialBase.setRTSGet the current XON/XOFF setting.SerialBase.break_conditionReturn how many seconds are left until the timeout expiresconvert a sequence to a bytes typeSerialBase.dtrGet the current DSR/DTR flow control setting.Not a valid parity: {!r}SerialBase.portNot a valid baudrate: {!r}SerialTimeoutExceptionGet the current parity setting.SerialBase.seekableSerialBase.xonxoffSerialBase.write_timeoutSerialBase.get_settingsunicode strings are not supported, please encode to bytes: {!r}Get the current byte size setting.Not a valid timeout: {!r}Change stop bits size.SerialBase.readableunexpected keyword arguments: {!r}Timeout.__init__target_timeBYTESIZESSerialBase.getSettingsDictisOpenSerialBase.apply_settings        Read lines, implemented as generator. It will raise StopIteration on
        timeout (empty read).
        Get the current baud rate setting.SerialBase.send_breakSerialBase.exclusiveSerialBase.flushInputIterate over bytes, returning bytes instead of ints (python3)SerialBase.isOpen        Change the port.
        Timeout.time_left    Abstraction for timeout operations. Using time.monotonic() if available
    or time.time() in all other cases.

    The class can also be initialized with 0 or None, in order to support
    non-blocking and fully blocking I/O operations. The attributes
    is_non_blocking and is_infinite are set accordingly.
    Get the current timeout setting.©é2   éK   én   é   é   éÈ   i,  iX  i°  i  i`	  iÀ  i%  i K  i   i á  i Â i  i  i ¡ i Ê i  i@B i  i`ã i i %& iÀÆ- iàg5 i 	= _overlapped_writeSerial.__init__Unsupported number of data bits: {!r}Serial.set_buffer_sizeSerial._closeUnsupported value for RS485Settings.rts_level_for_rx: {!r}Return how many bytes the in the outgoing buffercomstatUnsupported value for RS485Settings.delay_before_tx: {!r}GetOverlappedResult failed ({!r})errorcoderesult_okinternal close port helperCancel a blocking write operation, may be called from other threadUnsupported value for RS485Settings.rts_level_for_tx: {!r}Unsupported parity mode: {!r}Cancel a blocking read operation, may be called from other threadSerial._cancel_overlapped_iocomDCBCannot configure port, something went wrong. Original message: {!r}ReadFile failed ({!r})tx_sizeClearCommError failed ({!r})WriteFile failed ({!r})win32 only supports exclusive access (not: {})Serial._GetCommModemStatuscould not open port {!r}: {!r}Unsupported value for RS485Settings.delay_before_rx: {!r}Unsupported number of stop bits: {!r}rx_size        Manually control flow - when software flow control is enabled.
        This will do the same as if XON (true) or XOFF (false) are received
        from the other device and control the transmission accordingly.
        WARNING: this function is not portable to different platforms!
        _orgTimeoutsSerial.exclusive<module serial.serialwin32>        Recommend a buffer size to the driver (device driver can ignore this
        value). Must be called before the port is opened.
        _overlapped_readC:\msys64\mingw64\lib\python3.6\site-packages\serial\serialwin32.pySerial port implementation for Win32 based on ctypes.read_okUnsupported value for RS485Settings.loopback: {!r}CreateFileWWriteTotalTimeoutMultiplierÛR   zGetLastErrorz	MS_CTS_ONzFILE_ATTRIBUTE_NORMALzDTR_CONTROL_ENABLEz_COMSTATz
MS_RLSD_ONzGetOverlappedResultzSETXONzPURGE_TXABORTz	PurgeCommzN11_OVERLAPPED4DOLLAR_48EzEV_RINGz
ONESTOPBITzSETXOFFzPURGE_RXABORTzGetCommStatezRTS_CONTROL_ENABLEz_DCBzCreateEventz_COMMTIMEOUTSz_SECURITY_ATTRIBUTESzEV_DSRzEV_PERRz	EV_RXFLAGzOPEN_EXISTINGzDCBzFILE_FLAG_OVERLAPPEDzEV_CTSz	SetupCommzLPOVERLAPPEDz
EV_TXEMPTYzClearCommBreakzLPSECURITY_ATTRIBUTESzSetCommBreakzSetCommTimeoutszCOMMTIMEOUTSz	ODDPARITYzEV_RLSDzGetCommModemStatusz	EV_EVENT2zPURGE_TXCLEARzEV_BREAKz
EVENPARITYzLPCVOIDzCOMSTATzReadFilezPVOIDz_OVERLAPPEDz	WriteFilezGetCommTimeoutsz
ResetEventz	EV_RXCHARz	LPCOMSTATzClearCommErrorzERROR_IO_PENDINGzEscapeCommFunctionzGENERIC_READzRTS_CONTROL_HANDSHAKEz
OVERLAPPEDzDTR_CONTROL_HANDSHAKEzPURGE_RXCLEARzGENERIC_WRITEzLPDCBzCreateEventWzSetCommMaskz	EV_EVENT1zSetCommStatezLPVOIDzCreateFileWzLPDWORDzEV_RX80FULLzTWOSTOPBITSzLPCOMMTIMEOUTSzMAXDWORDz	MS_DSR_ONz
MS_RING_ONz#N11_OVERLAPPED4DOLLAR_484DOLLAR_49EzEV_ERRz	ULONG_PTRz
CreateFilezNOPARITYzCloseHandle<module serial.win32>C:\msys64\mingw64\lib\python3.6\site-packages\serial\win32.pyErrorChar_stdcall_librariesfXoffSentfCtsHoldfRlsdHoldfXoffHoldDCBlengthfDummy2fTximlpSecurityDescriptorfReservedis_64bitfDsrSensitivityfDsrHoldXoffLim_anonymous_fTXContinueOnXoffReturns true when running on a 64 bit systemReadTotalTimeoutMultiplierCreateFileAbInheritHandlefEofEvtCharCreateEventAXonLimOffsetHighInternalHighEofChar<module serialbladder>serialbladder: is connection dead?SerialBladder.reconnectserialbladder::reconnect exception: adding command to remembered_commands: bladder has no ports to closeserialbladder::send_command: LUQconnection_is_deadJust began the serialbladder run function. Let's do this.home_stop called from bladder!memorable_commandsreconnected to serialbladderdeflating and disconnecting bladdernot finding port on this pass for bladder, encoded as at the start of the outer serialbladder loopC:\msys64\home\cbper\serialbladder.pyreconnection exception for bladderûzwho_are_youzR
zpushbackzP
zclearz0
zRUQz1
zRLQz2
zLUQz3
zLLQz4
zhepatomegalyz5
zsplenomegalyz6
zenlarged_bladderz7
0SerialBladder.bladder_home_stopserialbladder::connection_is_dead: update_memorized_commands_since_clearSerialBladder.disconnectSerialBladder.__init__SerialBladder.send_commandSerialBladder.runremembered_commands_since_clearSerialBladder.connection_is_deadSending command to bladder controller: SerialBladder.update_memorized_commands_since_clearnow remembered_commands is  not workingloopeddata_buffergottimeC:\msys64\home\cbper\serialport.pydevice_id<module serialport>Bladdersno pressure pad command, 0Sensors.runTimed out trying to find pressure pad frame beginning.pressure pad has a command, and we will send ittrying to get new pressure pad command?re_list_serial_portsno port. We are not connectedno connection returnedtrying to reconnect other devicess_connectioninitial_readSensors.stoppedpressure pad has/had no port; trying to reconnectserialException overridere_list_serial_ports_othersSensors.send_commandCouldn't connect to sensors on Sensors.process_data/dev/tty[A-Za-z]*closing pressure pad portSensors.serial_home_stopûzclearÚ0zRUQnÚ1zRLQnú2zLUQnú3zLLQnú4zhepatomegalyú5zsplenomegalyú6zenlarged_bladderú7zUGInú8zRUQpÚAzRLQpÚBzLUQpÚCzLLQpÚDzUGIpÚEzbladder_pushbackúF0look_for_deviceSensors.disconnectserial home_stop called!/dev/tty.*Sensors.reconnects_connection_listSensors.find_frame_beginningSensors.connectTimed out trying to read data.trashed_framesedge_finderhave port; we are connectedSensors.reconnect_othersSensors.__init__Grbltrying to read Pressure pad from portLooping way too much to find frame beginning. Problem.Sensors.frame_ending_is_therebuild_platform_port_listread_from_portUnsupported platformin_bytetrail_byteLists serial ports

    :raises EnvironmentError:
        On unsupported or unknown platforms
    :returns:
        A list of available serial ports
    Sensors.read_from_portpressure_pad_connectionshlex: I see whitespace in word stateshlex: token=EOFshlex.__init__shlex.__next__shlex.push_tokenPush a token onto the stack popped by the get_token methodPush an input source onto the lexer's input source stack.shlex: popping to %s, line %derror_leadershlex.get_tokenReturn a shell-escaped version of the string *s*.();<>|&shlex: I see EOF in quotes stateread_tokenescapedstatenewstreamshlex: I see EOF in escape statePop the input source stack._print_tokenspush_sourceshlex.read_tokenpunctuation_charsshlex: I see whitespace in whitespace stateNo closing quotationabcdfeghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789_shlex: pushing token shlex: I see punctuation in word state[^\w@%+=:,./-]Get a token from the input stream (or from stack if it's nonempty)shlex.error_leaderA lexical analyzer class for simple shell-like syntaxes.pop_sourcefilestackshlex: in state %r I see character: %rsourcehookC:\msys64\mingw64\lib\python3.6\shlex.pyshlex.push_sourceshlex: pushing to file %sshlex: pushing to stream %sshlex: raw token=shlex: popping token <module shlex>whitespace_splitToken: _pushback_charsEmit a C-compiler-like, Emacs-friendly error-message leader.shlex.pop_sourceshlex: raw token=EOFHook called on a filename to be sourced.shlex.sourcehookNo escaped charactershlex.__iter__ÃÃ Ã¡Ã¢Ã£Ã¤Ã¥Ã¦Ã§Ã¨Ã©ÃªÃ«Ã¬Ã­Ã®Ã¯Ã°Ã±Ã²Ã³Ã´ÃµÃ¶Ã¸Ã¹ÃºÃ»Ã¼Ã½Ã¾Ã¿ÃÃÃÃÃÃÃÃÃÃÃÃÃÃÃÃÃÃÃÃÃÃÃÃÃÃÃÃÃÃ~-./*?=_find_unsafeescapedquotes"%s", line %d: Registers an archive format.

    name is the name of the format. function is the callable that will be
    used to create archives. If provided, extra_args is a sequence of
    (name, value) tuples that will be passed as arguments to the callable.
    description can be provided to describe the format, and will be returned
    by the get_archive_formats() function.
    _LZMA_SUPPORTED_set_uid_gidroot_dirlistxattrENOTSUPExecError<module shutil>_rmtree_safe_fdignored_namesextract_dirformat_infof_bavailCannot move a directory '%s' into itself '%s'.Destination path '%s' already existssrcnamepathextst_mtime_nsst_flagsfsrc_access_checkthefile_samefileTotal space in bytes_destinsrcRecursively copy a directory tree.

    The destination directory must not already exist.
    If exception(s) occur, an Error is raised with a list of reasons.

    If the optional symlinks flag is true, symbolic links in the
    source tree result in symbolic links in the destination tree; if
    it is false, the contents of the files pointed to by symbolic
    links are copied. If the file pointed by the symlink doesn't
    exist, an exception will be added in the list of errors raised in
    an Error exception at the end of the copy process.

    You can set the optional ignore_dangling_symlinks flag to true if you
    want to silence this exception. Notice that this has no effect on
    platforms that don't support os.symlink.

    The optional ignore argument is a callable. If given, it
    is called with the `src` parameter, which is the directory
    being visited by copytree(), and `names` which is the list of
    `src` contents, as returned by os.listdir():

        callable(src, names) -> ignored_names

    Since copytree() is called recursively, the callable will be
    called once for each directory that is copied. It returns a
    list of names relative to the `src` directory that should
    not be copied.

    The optional copy_function argument is a callable that will be used
    to copy each file. It will be called with the source path and the
    destination path as arguments. By default, copy2() is used, but any
    function that supports the same signature (like copy()) can be used.

    SameFileError_make_tarball.<locals>._set_uid_gidCopy mode bits from src to dst.

    If follow_symlinks is not set, symlinks aren't followed if and only
    if both `src` and `dst` are symlinks.  If `lchmod` isn't available
    (e.g. Linux) this method does nothing.

    Raised when trying to do a kind of operation (e.g. copying) which is
    not supported on a special file (e.g. a named pipe)save_cwdgztarCopy data from src to dst.

    If follow_symlinks is not set and src is a symbolic link, a new
    symlink will be created instead of copying the file it points to.

    Copy extended filesystem attributes from `src` to `dst`.

        Overwrite existing attributes.

        If `follow_symlinks` is false, symlinks won't be followed.

        Create an archive file (eg. zip or tar).

    'base_name' is the name of the file to create, minus any format-specific
    extension; 'format' is the archive format: one of "zip", "tar", "gztar",
    "bztar", or "xztar".  Or any other registered format.

    'root_dir' is a directory that will be the root directory of the
    archive; ie. we typically chdir into 'root_dir' before creating the
    archive.  'base_dir' is the directory where we start archiving from;
    ie. 'base_dir' will be the common prefix of all files and
    directories in the archive.  'root_dir' and 'base_dir' both default
    to the current directory.  Returns the name of the archive file.

    'owner' and 'group' are used when creating a tar archive. By default,
    uses the current owner and group.
    _use_fd_functionsSpecialFileError_check_unpack_optionsignore_patterns.<locals>._ignore_patternsunpack_archivedisk_usage_get_gidEPERMCannot call rmtree on a symbolic linkregister_archive_format_make_zipfiledstnameEOPNOTSUPPENODATA_nopuser and/or group must be setterminal_sizearchive_dirtar_compressionzip_filenamechmod_func%s is already registered for "%s"ZIP fileunregister_unpack_formatRecursively move a file or directory to another location. This is
    similar to the Unix "mv" command. Return the file or directory's
    destination.

    If the destination is a directory or a symlink to a directory, the source
    is moved inside the directory. The destination path must not already
    exist.

    If the destination already exists but is not a directory, it may be
    overwritten depending on os.rename() semantics.

    If the destination is on our current filesystem, then rename() is used.
    Otherwise, src is copied to the destination and then removed. Symlinks are
    recreated under the new name if os.rename() fails because of cross
    filesystem renames.

    The optional `copy_function` argument is a callable that will be used
    to copy the source or it will be delegated to `copytree`.
    By default, copy2() is used, but any function that supports the same
    signature (like copy()) can be used.

    A lot more could be done here...  A look at a mv.c shows a lot of
    the issues this implementation glosses over.

    Unpack zip `filename` to `extract_dir`
    unregister_archive_formattotal used freeRemoves the pack format from the registry.Unknown unpack format '{0}'Change owner user and group of the given path.

    user and group can be the uid/gid or the user/group names, and in that case,
    they are converted to their respective uid/gid.
    dry_rungzip'ed tar-filebzip2'ed tar-file_copyxattr_ntuple_diskusagecompress_extarchive_nameRecursively delete a directory tree.

    If ignore_errors is set, errors are ignored; otherwise, if onerror
    is set, it is called to handle the error with arguments (func,
    path, exc_info) where func is platform and implementation dependent;
    path is the argument to that function that caused it to fail; and
    exc_info is a tuple returned by sys.exc_info().  If ignore_errors
    is false and onerror is None, an exception is raised.

    creating '%s' and adding '%s' to itcopymodeReturn disk usage statistics about the given path.

        Returned value is a named tuple with attributes 'total', 'used' and
        'free', which are the amount of total, used and free space, in bytes.
        which.<locals>.<genexpr>get_terminal_sizecopy data from file-like object fsrc to file-like object fdstCopy data and mode bits ("cp src dst"). Return the file's destination.

    The destination may be a directory.

    If follow_symlinks is false, symlinks won't be followed. This
    resembles GNU's "cp -P src dst".

    If source and destination are the same file, a SameFileError will be
    raised.

    Returns a list of supported formats for unpacking.

    Each element of the returned sequence is a tuple
    (name, extensions, description)
    tarobjEnsure that the parent directory of `path` existsC:\msys64\mingw64\lib\python3.6\shutil.pyxz'ed tar-filegetxattrreal_dstlinktomake_archive`%s` is a named pipe_rmtree_unsafeFree space in bytesCreating tar archivef_blocksuncompressed tar filebad value for 'compress', or compression format not supported : {0}_ARCHIVE_FORMATScopystatUnknown archive format '{0}'copystat.<locals>._nopThe %s object is not callableexisting_extensions_ZLIB_SUPPORTEDextra_args elements are : (arg_name, value)Raised when a command could not be executedget_unpack_formatsChecks what gets registered as an unpacker._basenamesetxattr_find_unpack_format_get_uidCreate a zip file from all the files under 'base_dir'.

    The output zip file will be named 'base_name' + ".zip".  Returns the
    name of the output zip file.
    Create a (possibly compressed) tar file from all the files under
    'base_dir'.

    'compress' must be "gzip" (the default), "bzip2", "xz", or None.

    'owner' and 'group' can be used to define an owner and a group for the
    archive that is being built. If not provided, the current owner and group
    will be used.

    The output tar file will be named 'base_name' +  ".tar", possibly plus
    the appropriate compression extension (".gz", ".bz2", or ".xz").

    Returns the output filename.
    _unpack_tarfile{!r} and {!r} are the same file_BZ2_SUPPORTEDPATHEXTcreating %sno such user: {!r}stat_funcUnpack an archive.

    `filename` is the name of the archive.

    `extract_dir` is the name of the target directory, where the archive
    is unpacked. If not provided, the current working directory is used.

    `format` is the archive format: one of "zip", "tar", "gztar", "bztar",
    or "xztar".  Or any other registered format.  If not provided,
    unpack_archive will use the filename extension and see if an unpacker
    was registered for that extension.

    In case none is found, a ValueError is raised.
    Get the size of the terminal window.

    For each of the two dimensions, the environment variable, COLUMNS
    and LINES respectively, is checked. If the variable is defined and
    the value is a positive integer, it is used.

    When COLUMNS or LINES is not defined, which is the common case,
    the terminal connected to sys.__stdout__ is queried
    by invoking os.get_terminal_size.

    If the terminal size cannot be successfully queried, either because
    the system doesn't support querying, or because we are not
    connected to a terminal, the value given in fallback parameter
    is used. Fallback defaults to (80, 24) which is the default
    size used by many terminal emulators.

    The value returned is a named tuple of type os.terminal_size.
    Copy data and all stat info ("cp -p src dst"). Return the file's
    destination."

    The destination may be a directory.

    If follow_symlinks is false, symlinks won't be followed. This
    resembles GNU's "cp -P src dst".

    %s is not a zip fileRegisters an unpack format.

    `name` is the name of the format. `extensions` is a list of extensions
    corresponding to the format.

    `function` is the callable that will be
    used to unpack archives. The callable will receive archives to unpack.
    If it's unable to handle an archive, it needs to raise a ReadError
    exception.

    If provided, `extra_args` is a sequence of
    (name, value) tuples that will be passed as arguments to the callable.
    description can be provided to describe the format, and will be returned
    by the get_unpack_formats() function.
    changing into '%s'Returns a gid, given a group name.f_frsizeGiven a command, mode, and a PATH string, return the path which
    conforms to the given mode on the PATH, or None if there is no such
    file.

    `mode` defaults to os.F_OK | os.X_OK. `path` defaults to the result
    of os.environ.get("PATH"), or can be overridden with a custom search
    path.

    Return disk usage statistics about the given path.

        Returned values is a named tuple with attributes 'total', 'used' and
        'free', which are the amount of total, used and free space, in bytes.
        Returns a list of supported formats for archiving and unarchiving.

    Each element of the returned sequence is a tuple (name, description)
    extra_args needs to be a sequenceRaised when source and destination are the same file.w|%s_getdiskusagest_atime_nschanging back to '%s'%s is not a compressed or uncompressed tar file_UNPACK_FORMATSFunction that can be used as copytree() ignore parameter.

    Patterns is a sequence of glob-style patterns
    that are used to exclude filesrmtree.<locals>.onerrorunknown archive format '%s'no such group: {!r}Utility functions for copying and archiving files and directory trees.

XXX The functions here don't copy the resource fork or other metadata on Mac.

avoids_symlink_attacksRaised when a registry operation with the archiving
    and unpacking registries failsÛ   zcopyfileobjzcopyfilezcopymodezcopystatzcopyzcopy2zcopytreezmovezrmtreezErrorzSpecialFileErrorz	ExecErrorzmake_archivezget_archive_formatszregister_archive_formatzunregister_archive_formatzget_unpack_formatszregister_unpack_formatzunregister_unpack_formatzunpack_archivezignore_patternszchownzwhichzget_terminal_sizezSameFileErrorThe registered function must be a callablewhich.<locals>._access_check_unpack_zipfileReturns an uid, given a user name.Unpack tar/tar.gz/tar.bz2/tar.xz `filename` to `extract_dir`
    Copy all stat info (mode bits, atime, mtime, flags) from src to dst.

    If the optional flag `follow_symlinks` is not set, symlinks aren't followed if and
    only if both `src` and `dst` are symlinks.

    _ensure_directoryf_bfreecopystat.<locals>.lookupUsed space in bytesRaised when an archive cannot be readConvert a numeric value to an IntEnum member.
    If it's not a known member, return the numeric value itself.
    SIG_UNBLOCKSIG_SETMASKsigssigpendingSigmaskssignalnumsigs_setsigwaitsigpending.<locals>.<genexpr>CTRL_Convert an IntEnum member to a numeric value.
    If it's not an IntEnum member return the value itself.
    _int_to_enum_wrapssigsetretsigC:\msys64\mingw64\lib\python3.6\signal.py_enum_to_intpthread_sigmask.<locals>.<genexpr><module signal><module sim>SimLogging.remove_fileSimLogging.__init__SimLogging.on_quit_closeC:\msys64\home\cbper\simLogging.py<module simLogging>SimLogging.gatherlogsgeneric gallbladderWay too hard in gallbladder zoneûzdescriptionzMain coverage of the pancreasztypezanyzdata_indexes[   éi   éj   ét   éu   év   é   é   zrequired_valuezdownzseverity[   zmoderatezallowed_cry_types[   zgaspzgroanzwail0Main coverage of the ovary_leftgeneric hepatomegalyyelp when pressed too hard anywhere on the padMain coverage of the hepatomegaly zoneûzdescriptionzovary_left curtilageztypezanyzdata_indexes[   é   é   é   é   é   é   é   é   zrequired_valuezdownzseverity[   zmildzmoderatezallowed_cry_types[   zgaspzgroan0Way too hard in ovary_left zoneenlarged_bladder curtilagesplenomegaly curtilagetoo hard in hepatomegaly zoneWay too hard in pancreas zoneugi curtilageMain coverage of the splenomegaly zoneûzdescriptionzpancreas curtilageztypezanyzdata_indexes[   é]   é^   é_   éh   ék   és   éw   é   é   é   é   é   é   é   zrequired_valuezdownzseverity[   zmildzmoderatezallowed_cry_types[   zgaspzgroan0Main coverage of the ugiWay too hard in ugi zoneWay too hard in ovary_right zonegeneric ovary_leftgeneric completionhepatomegaly tgeneric ovary_rightMain coverage of the ovary_rightovary_right curtilagegeneric colonûzdescriptionzMain coverage of the colonztypezanyzdata_indexes[   é   é   é   é   é   é   é   é   zrequired_valuezdownzseverity[   zmoderatezallowed_cry_types[   zgaspzgroanzwail0ûzdescriptionzColon curtilageztypezanyzdata_indexes[   é   é   é   é   é   é   é   zrequired_valuezdownzseverity[   zmildzmoderatezallowed_cry_types[   zgaspzgroan0ûzdescriptionzWay too hard in colon zoneztypezanyzdata_indexes[   é   é   é   é   é   é   é   é   zrequired_valueztoo_hardzseverity[   zseverezallowed_cry_types[   zgroanzwail0hepatomegaly curtilageûzappendix[   é0   é1   é<   é=   éH   éI   zcolon[   é   é   é   é   é   é   é   é   zgallbladder[   ér   és   é~   é   zugi[   é   é   é   é   z
ovary_left[   é   é   é   é   zovary_right[   é   é   é   é$   é%   é&   zpancreas[   éi   éj   ét   éu   év   é   é   zbladder[   é    é   r   é   é   r   zhepatomegaly[   éq   r   r   r#   r$   r%   é{   é|   é}   r   r   r'   r&   r   é   é   é   é   é   é   é   r   zsplenomegaly[   é.   é/   é:   é;   éE   éF   éG   éQ   éR   éS   é^   é_   r"   ék   éw   zenlarged_bladder[   r(   r)   r   r   r*   r+   r   r   r   r   r   r   r   0ûzdescriptionzAppendix curtilageztypezanyzdata_indexes[   é$   é%   é2   é>   éJ   éT   éU   zrequired_valuezdownzseverity[   zmildzmoderatezallowed_cry_types[   zgaspzgroan0way too hard in appendix zonegeneric pancreasno ailment activeûznone{zdescriptionzno ailment activezcompletion_textzgeneric completionzfemale_voice_requiredFzcaseznone tztasksÛ    0zhepatomegaly{zdescriptionzgeneric hepatomegalyzcompletion_textzgeneric completionzfemale_voice_requiredFzcasezhepatomegaly tztasks[   {zdescriptionz&Main coverage of the hepatomegaly zoneztypezanyzdata_indexes[   éq   ér   és   ét   éu   év   é{   é|   é}   é~   é   é   é   é   é   é   é   é   é   é   é   é   zrequired_valuezdownzseverity[   zmoderatezallowed_cry_types[   zgaspzgroanzwail00zsplenomegaly{zdescriptionzgeneric splenomegalyzcompletion_textzgeneric completionzfemale_voice_requiredFzcasezsplenomegaly tztasks[   {zdescriptionz&Main coverage of the splenomegaly zoneztypezanyzdata_indexes[   é.   é/   é:   é;   éE   éF   éG   éQ   éR   éS   é^   é_   éj   ék   éw   zrequired_valuezdownzseverity[   zmoderatezallowed_cry_types[   zgaspzgroanzwail00zenlarged_bladder{zdescriptionzgeneric enlarged_bladderzcompletion_textzgeneric completionzfemale_voice_requiredFzcasezenlarged_bladder tztasks[   {zdescriptionz*Main coverage of the enlarged_bladder zoneztypezanyzdata_indexes[   é    é   é   é   é   é   é   é   é   é   é   é$   é%   zrequired_valuezdownzseverity[   zmoderatezallowed_cry_types[   zgaspzgroanzwail00zappendix{zdescriptionzgeneric appendixzcompletion_textzgeneric completionzfemale_voice_requiredFzcasez
appendix tztasks[   {zdescriptionz"Main coverage of the appendix zoneztypezanyzdata_indexes[   é0   é1   é<   é=   éH   éI   zrequired_valuezdownzseverity[   zmoderatezallowed_cry_types[   zgaspzgroanzwail00zcolon{zdescriptionzgeneric colonzcompletion_textzgeneric completionzfemale_voice_requiredFzcasezcolon tztasks[   {zdescriptionzMain coverage of the colonztypezanyzdata_indexes[   é   é   é   é   é   é   é   é   zrequired_valuezdownzseverity[   zmoderatezallowed_cry_types[   zgaspzgroanzwail00zgallbladder{zdescriptionzgeneric gallbladderzcompletion_textzgeneric completionzfemale_voice_requiredFzcasezgallbladder tztasks[   {zdescriptionz Main coverage of the gallbladderztypezanyzdata_indexes[   r   r   r   r   zrequired_valuezdownzseverity[   zmoderatezallowed_cry_types[   zgaspzgroanzwail00zugi{zdescriptionzgeneric ugizcompletion_textzgeneric completionzfemale_voice_requiredFzcasezugi tztasks[   {zdescriptionzMain coverage of the ugiztypezanyzdata_indexes[   r   é   r   é   zrequired_valuezdownzseverity[   zmoderatezallowed_cry_types[   zgaspzgroanzwail00z
ovary_left{zdescriptionzgeneric ovary_leftzcompletion_textzgeneric completionzfemale_voice_requiredTzcasezovary_left tztasks[   {zdescriptionzMain coverage of the ovary_leftztypezanyzdata_indexes[   r)   r*   r-   r.   zrequired_valuezdownzseverity[   zmoderatezallowed_cry_types[   zgaspzgroanzwail00zovary_right{zdescriptionzgeneric ovary_rightzcompletion_textzgeneric completionzfemale_voice_requiredTzcasezovary_right tztasks[   {zdescriptionz Main coverage of the ovary_rightztypezanyzdata_indexes[   r/   r0   r1   r2   r3   é&   zrequired_valuezdownzseverity[   zmoderatezallowed_cry_types[   zgaspzgroanzwail00zpancreas{zdescriptionzgeneric pancreaszcompletion_textzgeneric completionzfemale_voice_requiredFzcasez
pancreas tztasks[   {zdescriptionzMain coverage of the pancreasztypezanyzdata_indexes[   éi   r$   r   r   r   r   r   zrequired_valuezdownzseverity[   zmoderatezallowed_cry_types[   zgaspzgroanzwail00zbladder{zdescriptionzgeneric bladderzcompletion_textzgeneric completionzfemale_voice_requiredFzcasez	bladder tztasks[   {zdescriptionzMain coverage of the bladderztypezanyzdata_indexes[   r'   r(   r)   r+   r,   r-   zrequired_valuezdownzseverity[   zmoderatezallowed_cry_types[   zgaspzgroanzwail000way too hard in splenomegaly zoneWay too hard in bladder zoneûzdescriptionz*Main coverage of the enlarged_bladder zoneztypezanyzdata_indexes[   é    é   é   é   é   é   é   é   é   é   é   é$   é%   zrequired_valuezdownzseverity[   zmoderatezallowed_cry_types[   zgaspzgroanzwail0ûzdescriptionz%way too hard in enlarged_bladder zoneztypezanyzdata_indexes[   é    é   é   é   é   é   é   é   é   é   é   é$   é%   zrequired_valueztoo_hardzseverity[   zseverezallowed_cry_types[   zgroanzwail0gallbladder curtilagerebound tenderness opposite appendixpushback_questsC:\msys64\home\cbper\sim_constants.pyerrorTabcount must be a positive integer (got {!r})<%s.%s%s fd=%i, family=%s, type=%s, proto=%iTrue if the SocketIO is open for writing.
        Only SOCK_STREAM socket type is supportedRead-only access to the address family for this socket.
        socket.__init__The network has been shut down., laddr=%sThe operation was interrupted.Read up to len(b) bytes into the writable buffer *b* and return
        the number of bytes read.  If the socket is non-blocking and no bytes
        are available, None is returned.

        If *b* is non-empty, a 0 return value indicates that the connection
        was shutdown at the other end.
        accept() -> (socket object, address info)

        Wait for an incoming connection.  Return a new socket
        representing the connection, and the address of the client.
        For IP sockets, the address info is a pair (hostaddr, port).
        SocketIO.readintoThe host is down.SocketIO.readablegetdefaulttimeoutSocketIO.__init__, raddr=%s_blocking_errnossocketpair([family[, type[, proto]]]) -> (socket object, socket object)
Create a pair of socket objects from the sockets returned by the platform
socketpair() function.
The arguments are the same as for socket() except the default family is AF_UNIX
if defined on the platform; otherwise, the default is AF_INET.
SocketIO.modeSOCK_NONBLOCKA bad file handle was passed.Set the inheritable flag of the socketset_inheritablenfdsocket.makefilesocket.get_inheritableReturn the file descriptor of the underlying socket.
        _sendfile_use_sendfileos_sendfilePermission denied.Resolve host and port into list of address info entries.

    Translate the host/port argument into a sequence of 5-tuples that contain
    all the necessary arguments for creating a socket connected to that service.
    host is a domain name, a string representation of an IPv4/v6 address or
    None. port is a string service name such as 'http', a numeric port number or
    None. By passing None as the value of host and port, you can pass NULL to
    the underlying C API.

    The family, type and proto arguments can be optionally specified in order to
    narrow the list of addresses returned. Passing zero as a value for each of
    these arguments selects the full range of results.
    cannot read from timed out objectTrue if the SocketIO is open for seeking.
        _realsocketunbuffered streams must be binarydetach() -> file descriptor

        Close the socket object without closing the underlying file descriptor.
        The object cannot be used after this call, but the file descriptor
        can be reused for other purposes.  The file descriptor is returned.
        rawmodesocket.dupsocketpair([family[, type[, proto]]]) -> (socket object, socket object)

        Create a pair of socket objects from the sockets returned by the platform
        socketpair() function.
        The arguments are the same as for socket() except the default family is
        AF_UNIX if defined on the platform; otherwise, the default is AF_INET.
        socket._decref_socketios fromshare(info) -> socket object

        Create a socket object from the bytes object returned by
        socket.share(pid).
        socket.__repr__socket.__enter__The socket operation would blocksocknototal_sentselector_selectOnly AF_INET and AF_INET6 socket address families are supportedClose the SocketIO object.  This doesn't close the underlying
        socket, except if all references to it have disappeared.
        SocketIO.seekablesocket.typesocket.acceptConnection refused._io_refs<module socket>AddressFamilySocketKindThe host is unreachable._intenum_convertersocket.closeThe network address is in use.A fault occurred on the network??Write the given bytes or bytearray object *b* to the socket
        and return the number of bytes written.  This can be less than
        len(b) if not all data could be written.  If the socket is
        non-blocking and no bytes could be written None is returned.
        I/O operation on closed socket. fromfd(fd, family, type[, proto]) -> socket object

    Create a socket object from a duplicate of the given file
    descriptor.  The remaining arguments are the same as for socket().
    invalid mode %r (only r, w, b allowed)sock_sendThe name is too long.This module provides socket operations and some related functions.
On Unix, it supports IP (Internet Protocol) and Unix domain sockets.
On other systems, it only supports IP. Functions specific for a
socket are available as methods of the socket object.

Functions:

socket() -- create a new socket object
socketpair() -- create a pair of new socket objects [*]
fromfd() -- create a socket object from an open file descriptor [*]
fromshare() -- create a socket object from data received from socket.share() [*]
gethostname() -- return the current hostname
gethostbyname() -- map a hostname to its IP number
gethostbyaddr() -- map an IP number or hostname to DNS info
getservbyname() -- map a service name and a protocol name to a port number
getprotobyname() -- map a protocol name (e.g. 'tcp') to a number
ntohs(), ntohl() -- convert 16, 32 bit int from network to host byte order
htons(), htonl() -- convert 16, 32 bit int from host to network byte order
inet_aton() -- convert IP addr string (123.45.67.89) to 32-bit packed format
inet_ntoa() -- convert 32-bit packed format IP to string (123.45.67.89)
socket.getdefaulttimeout() -- get the default timeout value
socket.setdefaulttimeout() -- set the default timeout value
create_connection() -- connects to an address, with an optional timeout and
                       optional source address.

 [*] not available on all platforms!

Special objects:

SocketType -- type object for socket objects
error -- exception raised for I/O errors
has_ipv6 -- boolean value indicating if IPv6 is supported

IntEnum constants:

AF_INET, AF_UNIX -- socket domains (first argument to socket() call)
SOCK_STREAM, SOCK_DGRAM, SOCK_RAW -- socket types (second argument)

Integer constants:

Many other constants may be defined; these may be used in calls to
the setsockopt() and getsockopt() methods.
Wrap __repr__() to reveal the real class name and socket
        address(es).
        C:\msys64\mingw64\lib\python3.6\socket.py_GiveupOnSendfilesocket._check_sendfile_paramsrwbA blocking operation is already in progress.only SOCK_STREAM type sockets are supportedsocket._sendfile_use_sendfile_checkWritable_checkReadableRaw I/O implementation for stream sockets.

    This class supports the makefile() method on sockets.  It provides
    the raw I/O interface on top of a socket object.
    file should be opened in binary mode_LOCALHOST_V6SocketIO.filenosocket.sendfileget_handle_inheritableGet the inheritable flag of the socketos.sendfile() not available on this platforminvalid mode: %rsendfile(file[, offset[, count]]) -> sent

        Send a file until EOF is reached by using high-performance
        os.sendfile() and return the total number of bytes which
        were sent.
        *file* must be a regular file object opened in binary mode.
        If os.sendfile() is not available (e.g. Windows) or file is
        not a regular file socket.send() will be used instead.
        *offset* tells from where to start reading the file.
        If specified, *count* is the total number of bytes to transmit
        as opposed to sending the file until EOF is reached.
        File position is updated on return or also in case of error in
        which case file.tell() can be used to figure out the number of
        bytes which were sent.
        The socket must be of SOCK_STREAM type.
        Non-blocking sockets are not supported.
        SocketIO.writecsockSocketIO.closeset_handle_inheritableAddressInfosocket.__exit__Connect to *address* and return the socket object.

    Convenience function.  Connect to *address* (a 2-tuple ``(host,
    port)``) and return the socket object.  Passing the optional
    *timeout* parameter will set the timeout on the socket instance
    before attempting to connect.  If no *timeout* is supplied, the
    global default timeout setting returned by :func:`getdefaulttimeout`
    is used.  If *source_address* is set it must be a tuple of (host, port)
    for the socket to bind as a source address before making the connection.
    A host of '' or port 0 tells the OS to use the default.
    SocketIO.writable_readingAn invalid operation was attempted.A subclass of _socket.socket adding the makefile() method.Only protocol zero is supportedTrue if the SocketIO is open for reading.
        The operation timed out.socket._real_closesocket.__getstate__ipaddrs_timeout_occurredRead-only access to the socket type.
        Cannot serialize socket objectsocket.familySocketIO.namesocket.set_inheritableConvert a numeric family value to an IntEnum member.

    If it's not a known member, return the numeric value itself.
    MsgFlagsocket.detachThe connection has been reset.makefile(...) -> an I/O stream connected to the socket

        The arguments are as for io.open() after the filename, except the only
        supported mode values are 'r' (default), 'w' and 'b'.
        non-blocking sockets are not supportedGet fully qualified domain name from name.

    An empty argument is interpreted as meaning the local host.

    First the hostname returned by gethostbyaddr() is checked, then
    possibly existing aliases. In case no FQDN is available, hostname
    from gethostname() is returned.
    dup() -> socket object

        Duplicate the socket. Return a new socket object connected to the same
        system resource. The new socket is non-inheritable.
        Called by constructor to activate the server.

        May be overridden.

        Base class for various socket-based server classes.

    Defaults to synchronous IP stream (i.e., TCP).

    Methods for the caller:

    - __init__(server_address, RequestHandlerClass, bind_and_activate=True)
    - serve_forever(poll_interval=0.5)
    - shutdown()
    - handle_request()  # if you don't use serve_forever()
    - fileno() -> int   # for selector

    Methods that may be overridden:

    - server_bind()
    - server_activate()
    - get_request() -> request, client_address
    - handle_timeout()
    - verify_request(request, client_address)
    - process_request(request, client_address)
    - shutdown_request(request)
    - close_request(request)
    - handle_error()

    Methods for derived classes:

    - finish_request(request, client_address)

    Class variables that may be overridden by derived classes or
    instances:

    - timeout
    - address_family
    - socket_type
    - request_queue_size (only for stream sockets)
    - allow_reuse_address

    Instance variables:

    - server_address
    - RequestHandlerClass
    - socket

    BaseServer.server_closeprocess_request_thread_SocketWriter.writableStart a new thread to process the request.Verify the request.  May be overridden.

        Return True if we should proceed with this request.

        Handle an error gracefully.  May be overridden.

        The default is to print a traceback and continue.

        ThreadingUnixStreamServerBaseServer.serve_foreverGet the request and client address from the socket.

        May be overridden.

        ThreadingMixIn.process_requestUDPServerTCPServer.shutdown_requestCall finish_request.

        Overridden by ForkingMixIn and ThreadingMixIn.

        ThreadingUDPServerBaseServer.__init__Collect the zombie child processes regularly in the ForkingMixIn.

            service_actions is called in the BaseServer's serve_forver loop.
            BaseServer._handle_request_noblockBaseServer.close_request_SocketWriter.filenoUDP server class.BaseServer.shutdown_requestDefine self.rfile and self.wfile for stream sockets.BaseServer.handle_timeoutCalled to clean-up the server.

        May be overridden.

        _BaseServer__is_shut_downCalled to clean up an individual request.BaseRequestHandler.setupUDPServer.shutdown_requestBaseRequestHandler.finishUnixDatagramServerThreadingUnixDatagramServerThreadingTCPServerpacketDatagramRequestHandler.setupForkingTCPServermax_childrenBaseServer.verify_requestBaseServer.__enter__SHUT_WRTCPServer.server_bind_ServerSelectorSimple writable BufferedIOBase implementation for a socket

    Does not hold data in a buffer, avoiding any need to call flush().ForkingMixIn.collect_childrenSame as in BaseServer but as a thread.

        In addition, exception handling is done here.

        BaseServer.service_actionsBaseServer.__exit__Generic socket server classes.

This module tries to capture the various aspects of defining a server:

For socket-based servers:

- address family:
        - AF_INET{,6}: IP (Internet Protocol) sockets (default)
        - AF_UNIX: Unix domain sockets
        - others, e.g. AF_DECNET are conceivable (see <socket.h>
- socket type:
        - SOCK_STREAM (reliable stream, e.g. TCP)
        - SOCK_DGRAM (datagrams, e.g. UDP)

For request-based servers (including socket-based):

- client address verification before further looking at the request
        (This is actually a hook for any processing that needs to look
         at the request before anything else, e.g. logging)
- how to handle multiple requests:
        - synchronous (one request is handled at a time)
        - forking (each request is handled by a new process)
        - threading (each request is handled by a new thread)

The classes in this module favor the server type that is simplest to
write: a synchronous TCP/IP server.  This is bad class design, but
save some typing.  (There's also the issue that a deep class hierarchy
slows down method lookups.)

There are five classes in an inheritance diagram, four of which represent
synchronous servers of four types:

        +------------+
        | BaseServer |
        +------------+
              |
              v
        +-----------+        +------------------+
        | TCPServer |------->| UnixStreamServer |
        +-----------+        +------------------+
              |
              v
        +-----------+        +--------------------+
        | UDPServer |------->| UnixDatagramServer |
        +-----------+        +--------------------+

Note that UnixDatagramServer derives from UDPServer, not from
UnixStreamServer -- the only difference between an IP and a Unix
stream server is the address family, which is simply repeated in both
unix server classes.

Forking and threading versions of each type of server can be created
using the ForkingMixIn and ThreadingMixIn mix-in classes.  For
instance, a threading UDP server class is created as follows:

        class ThreadingUDPServer(ThreadingMixIn, UDPServer): pass

The Mix-in class must come first, since it overrides a method defined
in UDPServer! Setting the various member variables also changes
the behavior of the underlying server mechanism.

To implement a service, you must derive a class from
BaseRequestHandler and redefine its handle() method.  You can then run
various versions of the service by combining one of the server classes
with your request handler class.

The request handler class must be different for datagram or stream
services.  This can be hidden by using the request handler
subclasses StreamRequestHandler or DatagramRequestHandler.

Of course, you still have to use your head!

For instance, it makes no sense to use a forking server if the service
contains state in memory that can be modified by requests (since the
modifications in the child process would never reach the initial state
kept in the parent process and passed to each child).  In this case,
you can use a threading server, but you will probably have to use
locks to avoid two requests that come in nearly simultaneous to apply
conflicting changes to the server state.

On the other hand, if you are building e.g. an HTTP server, where all
data is stored externally (e.g. in the file system), a synchronous
class will essentially render the service "deaf" while one request is
being handled -- which may be for a very long time if a client is slow
to read all the data it has requested.  Here a threading or forking
server is appropriate.

In some cases, it may be appropriate to process part of a request
synchronously, but to finish processing in a forked child depending on
the request data.  This can be implemented by using a synchronous
server and doing an explicit fork in the request handler class
handle() method.

Another approach to handling multiple simultaneous requests in an
environment that supports neither threads nor fork (or where these are
too expensive or inappropriate for the service) is to maintain an
explicit table of partially finished requests and to use a selector to
decide which request to work on next (or whether to handle a new
incoming request).  This is particularly important for stream services
where each client can potentially be connected for a long time (if
threads or subprocesses cannot be used).

Future work:
- Standard classes for Sun RPC (which uses either UDP or TCP)
- Standard mix-in classes to implement various authentication
  and encryption schemes

XXX Open problems:
- What to do with out-of-band data?

BaseServer:
- split generic "request" functionality out into BaseServer class.
  Copyright (C) 2000  Luke Kenneth Casson Leighton <lkcl@samba.org>

  example: read entries from a SQL database (requires overriding
  get_request() to return a table entry from the database).
  entry is processed by a RequestHandlerClass.

C:\msys64\mingw64\lib\python3.6\socketserver.pyStreamRequestHandler.finishForkingMixIn.service_actionswbufsizeFinish one request by instantiating RequestHandlerClass.BaseServer.server_activateForkingUDPServerTCPServer.__init___SocketWriter.writeBaseRequestHandler.__init__Called if no new request arrives within self.timeout.

        Overridden by ForkingMixIn.
        Constructor.  May be extended, do not override.max_packet_sizeInternal routine to wait for children that have exited.BaseServer.handle_requestException happened during processing of request from0.4ThreadingMixIn.process_request_threadDefine self.rfile and self.wfile for datagram sockets.Called to shutdown and close an individual request.TCPServer.server_close_BaseServer__shutdown_requestHandle one request, possibly blocking.

        Respects self.timeout.
        _SocketWriter.__init__Return socket file number.

        Interface required by selector.

        Mix-in class to handle each request in a new process.Handle one request, without blocking.

        I assume that selector.select() has returned that the socket is
        readable before this function was called, so there should be no risk of
        blocking in get_request().
        TCPServer.filenodaemon_threadsDatagramRequestHandler.finishMix-in class to handle each request in a new thread.BaseServer.handle_errorCalled by the serve_forever() loop.

        May be overridden by a subclass / Mixin to implement any code that
        needs to be run during the loop.
        UDPServer.get_requestHandle one request at a time until shutdown.

        Polls for shutdown every poll_interval seconds. Ignores
        self.timeout. If you need to do periodic tasks, do them in
        another thread.
        BaseServer.finish_requestTCPServer.server_activateFork a new subprocess to process the request.Called by constructor to bind the socket.

        May be overridden.

        Base class for request handler classes.

    This class is instantiated for each request to be handled.  The
    constructor sets the instance variables request, client_address
    and server, and then calls the handle() method.  To implement a
    specific service, all you need to do is to derive a class which
    defines a handle() method.

    The handle() method can find the request as self.request, the
    client address as self.client_address, and the server (in case it
    needs access to per-server information) as self.server.  Since a
    separate instance is created for each request, the handle() method
    can define other arbitrary instance variables.

    ForkingMixIn.handle_timeoutTCPServer.close_requestUDPServer.server_activateUDPServer.close_requestStreamRequestHandler.setupTCPServer.get_requestdisable_nagle_algorithmStops the serve_forever loop.

        Blocks until the loop has finished. This must be called while
        serve_forever() is running in another thread, or it will
        deadlock.
        Wait for zombies after self.timeout seconds of inactivity.

            May be extended, do not override.
            ForkingMixIn.process_request<module socketserver>BaseServer.process_requestBase class for server classes.

    Methods for the caller:

    - __init__(server_address, RequestHandlerClass)
    - serve_forever(poll_interval=0.5)
    - shutdown()
    - handle_request()  # if you do not use serve_forever()
    - fileno() -> int   # for selector

    Methods that may be overridden:

    - server_bind()
    - server_activate()
    - get_request() -> request, client_address
    - handle_timeout()
    - verify_request(request, client_address)
    - server_close()
    - process_request(request, client_address)
    - shutdown_request(request)
    - close_request(request)
    - service_actions()
    - handle_error()

    Methods for derived classes:

    - finish_request(request, client_address)

    Class variables that may be overridden by derived classes or
    instances:

    - timeout
    - address_family
    - socket_type
    - allow_reuse_address

    Instance variables:

    - RequestHandlerClass
    - socket

    BaseRequestHandler.handleC:\msys64\home\cbper\sounds.py<module sounds>no sound profile for case SoundPlayertask_completedsound_file_queuevoicesSoundPlayer.runtime_since_last_played_soundSoundPlayer.stopvoices_availablenew_soundvoices/donotpalpate.wavSounds.build_sound_questsSounds.do_not_palpatetouchalerterSounds.check_genderdeleting previous voiceûzmale{zruffin{zgasp{zmildé   zmoderater   zsevereé   0zgroan{zmildr   zmoderater   zseverer   0zwail{zmildr   zmoderateé   zsevereé   000zfemale{zjamie{zgasp{zmildr   zmoderater   zseverer   0zgroan{zmildr   zmoderater   zseverer   0zwail{zmoderater   zseverer   0000time_of_last_played_soundSoundPlayer.play_soundvoice_nameSounds.select_sound_filedisabling soundswinsoundsound_queuecry_type_nameSND_FILENAMErequest_soundsetting up sound for pressurelistgender block failedpath_seqSounds.stop_sound_playerSounds.new_generic_casechosen_cry_typesounds::new_generic_case: case %s, case_block %sSounds.OnStateChangeSND_PURGESoundPlayer.stoppedno voiceSounds.request_soundcase_partsPlaySound, disabling soundSoundPlayer.__init__enable_soundSounds.__init__C:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\specsC:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\specs\__init__.pydo not like a tuple %sBuiltinParameterSpecExceptionsbuiltin_reversed_specarg_dictFatal error: builtin_sorted_specBuiltinBytearraySpec<module specs.BuiltinParameterSpecs>given_list_star_argBuiltinParameterSpecNoKeywordsBuiltinParameterSpecNoKeywords.simulateCallbuiltin_exec_specbuiltin_enumerate_specgiven_dict_star_argsgetCallableNamedict_argsBuiltinParameterSpecPosArgs.__init__BuiltinRangeSpecgiven_normal_argsBuiltinParameterSpec.simulateCallBuiltinParameterSpec.__repr__BuiltinParameterSpec.isCompileTimeComputablerefuse_moregiven_value<BuiltinParameterSpec %s>BuiltinParameterSpec.getNamegiven_list_star_args Optimizations of built-ins to built-in calls.

BuiltinBytearraySpec.isCompileTimeComputableBuiltinParameterSpec.simulateCall.<locals>.<genexpr>args_listBuiltinParameterSpecExceptions.__init__C:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\specs\BuiltinParameterSpecs.pyexceptions.%s does not take keyword argumentslist_argsBuiltinParameterSpecExceptions.getKeywordRefusalTextBuiltinRangeSpec.isCompileTimeComputableFatal problem: %rBuiltinParameterSpecExceptions.getCallableNameBuiltinParameterSpecExceptions.allowsKeywordsBuiltinParameterSpecPosArgs.getPositionalOnlyCountdo not like tuple %sBuiltinParameterSpec.__init__BuiltinParameterSpecNoKeywords.allowsKeywordsParameterSpec.checkParametersValidParameterSpec.getArgumentCount%s() takes %s %s (%d given)ParameterSpec.getKwOnlyVariablesneed more than %d %s to unpackParameterSpec.makeClonegetTopLevelVariableslist_star_variablereal_exception'%s' is an invalid keyword argument for this function This module maintains the parameter specification classes.

These are used for function, lambdas, generators. They are also a factory
for the respective variable objects. One of the difficulty of Python and
its parameter parsing is that they are allowed to be nested like this:

(a,b), c

Much like in assignments, which are very similar to parameters, except
that parameters may also be assigned from a dictionary, they are no less
flexible.

duplicate argument '%s' in function definitionParameterSpec.setOwnerParameterSpec.getListStarArgVariablegetDictStarArgVariableParameterSpec.getPositionalOnlyCount%s() got an unexpected keyword argument '%s'<ParameterSpec '%s'>ParameterSpec.allowsKeywordsC:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\specs\ParameterSpecs.pyParameterSpec.getTopLevelVariablesParameterSpec.getArgumentNameskw_only_argsisAssigned%s() takes exactly 0 arguments (%d given)%s() takes at most %d %s (%d given)ParameterSpec.hasDefaultParametersParameterSpec.getAllVariablesParameterSpec.getKwOnlyParameterNames%s() takes no arguments (%d given)ParameterSpec.getDictStarArgVariable'%s' is an invalid keyword argument for %s()ParameterSpec.getKeywordRefusalText%d argumentsParameterSpec.getDefaultCountParameterSpec.getParameterNames%s() takes no keyword argumentsmatchCall.<locals>.assigndict_star_variablenormal_variableskw_only_variables%s expected %d arguments, got %dParameterSpec.getStarListArgumentNamematchCall.<locals>.isAssignedTooManyArguments.getRealException©Ú	func_nameÚargsÚstar_list_argÚstar_dict_argÚnum_defaultsÚnum_posonlyÚ
positionalÚpairsÚimprovedÚresultÚassigned_tuple_paramsÚassignÚ
isAssignedÚnum_posÚ	num_totalÚnum_argsÚargÚvalueÚpairÚ	arg_indexÚmessageÚnamed_argument_namesÚ	new_pairsÚ
unexpectedÚ
unassignedÚnum_requiredÚarg_descsubarg%s() takes exactly one argument (%d given)%s() got multiple values for keyword argument '%s'<NoParameters>ParameterSpec.getDetailsTooManyArguments.__init__ParameterSpec.getStarDictArgumentNameParameterSpec.getKwOnlyParameterCount%s expected %s%s, got %d<module specs.ParameterSpecs><span font='20'>AbSim is loading...</span>
<span font='12'>(this might take 30 seconds)</span>splash_label<module splashscreen>C:\msys64\home\cbper\splashscreen.pySplashScreen.__init__C:\msys64\mingw64\lib\python3.6\sqlite3<module sqlite3>C:\msys64\mingw64\lib\python3.6\sqlite3\__init__.pyTimeFromTickssqlite_versionregister_adapters_and_converters.<locals>.convert_dateadapt_dateticksdatepartregister_converterparamstyleadapt_datetimeconvert_timestamp_sqlite3{:0<6.6}<module sqlite3.dbapi2>apilevelTimestampregister_adapters_and_converters.<locals>.adapt_dateqmarkTimestampFromTicksC:\msys64\mingw64\lib\python3.6\sqlite3\dbapi2.pyregister_adapters_and_converters.<locals>.convert_timestampregister_adapters_and_converters.<locals>.adapt_datetimetimeparttimepart_fullsqlite_version_infoDateFromTicksthreadsafetyRowprefix_skipgot_all_CODEBITS_REPEATING_CODESBIGCHARSETinternal: unsupported operand type %r_BITS_TRANSC:\msys64\mingw64\lib\python3.6\sre_compile.pycappend_SUCCESS_CODES_ignorecase_fixes_get_literal_prefixprefixappend_get_charset_prefix_generate_overlap_tableMIN_REPEAT_ONE_mk_bitmapSRE module mismatch_bytes_to_codesprefix_skip1©ÚcharsetÚfixupÚfixesÚoutÚtailÚcharmapÚopÚavÚloÚkÚrÚiÚrunsÚqÚpÚdataÚcompsÚmappingÚblockÚchunk_compile.<locals>.fixup<module sre_compile>dictcontraction.<locals>.<genexpr>0111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111look-behind requires fixed-width pattern_LITERAL_CODES
    Generate an overlap table for the following prefix.
    An overlap table is a table of the same size as the prefix which
    informs about the potential self-overlap for each index in the prefix:
    - if overlap[i] == 0, prefix[i:] can't overlap prefix[0:...]
    - if overlap[i] == k with 0 < k <= i, prefix[i-k+1:i+1] overlaps with
      prefix[0:k]
    ©)éi   i1  )és   i  )éµ   i¼  )iE  i¹  i¾  )i  iÓ  )i°  iã  )i²  iÐ  )iµ  iõ  )i¸  iÑ  )iº  ið  )iÀ  iÖ  )iÁ  iñ  )iÂ  iÃ  )iÆ  iÕ  )ia  i  )iû  iû  ANY_ALLCODESIZE_compile_charsetinternal: unsupported template operator %rindexgroup_compile_infointernal: unsupported set operator %r_ASSERT_CODESMIN_UNTIL©ÚcodeÚpatternÚflagsÚemitÚ_lenÚLITERAL_CODESÚREPEATING_CODESÚSUCCESS_CODESÚASSERT_CODESÚfixesÚopÚavÚloÚskipÚkÚfixupÚgroupÚ	add_flagsÚ	del_flagsÚpÚhiÚtailÚ
tailappendÚskipyesÚskipnoprefix1_optimize_charsetgetlower_equivalencesMAXCODEMAX_UNTILCATEGORY_UNI_SPACE
    CATEGORY_DIGIT CATEGORY_NOT_DIGIT
    CATEGORY_SPACE CATEGORY_NOT_SPACE
    CATEGORY_WORD CATEGORY_NOT_WORD
    CATEGORY_LINEBREAK CATEGORY_NOT_LINEBREAK
    CATEGORY_LOC_WORD CATEGORY_LOC_NOT_WORD
    CATEGORY_UNI_DIGIT CATEGORY_UNI_NOT_DIGIT
    CATEGORY_UNI_SPACE CATEGORY_UNI_NOT_SPACE
    CATEGORY_UNI_WORD CATEGORY_UNI_NOT_WORD
    CATEGORY_UNI_LINEBREAK CATEGORY_UNI_NOT_LINEBREAK
C:\msys64\mingw64\lib\python3.6\sre_constants.py_NamedIntConstant.__new__ATCODES%s at position %d_NamedIntConstant.__str__AT_LOC_NON_BOUNDARYCHCODESLITERAL_IGNORENOT_LITERAL_IGNOREAT_UNI_NON_BOUNDARYException raised for invalid regular expressions.

    Attributes:

        msg: The unformatted error message
        pattern: The regular expression pattern
        pos: The index in the pattern where compilation failed (may be None)
        lineno: The line corresponding to pos (may be None)
        colno: The column corresponding to pos (may be None)
    
    FAILURE SUCCESS

    ANY ANY_ALL
    ASSERT ASSERT_NOT
    AT
    BRANCH
    CALL
    CATEGORY
    CHARSET BIGCHARSET
    GROUPREF GROUPREF_EXISTS GROUPREF_IGNORE
    IN IN_IGNORE
    INFO
    JUMP
    LITERAL LITERAL_IGNORE
    MARK
    MAX_UNTIL
    MIN_UNTIL
    NOT_LITERAL NOT_LITERAL_IGNORE
    NEGATE
    RANGE
    REPEAT
    REPEAT_ONE
    SUBPATTERN
    MIN_REPEAT_ONE
    RANGE_IGNORE

    MIN_REPEAT MAX_REPEAT
<module sre_constants>%s (line %d, column %d)
    AT_BEGINNING AT_BEGINNING_LINE AT_BEGINNING_STRING
    AT_BOUNDARY AT_NON_BOUNDARY
    AT_END AT_END_LINE AT_END_STRING
    AT_LOC_BOUNDARY AT_LOC_NON_BOUNDARY
    AT_UNI_BOUNDARY AT_UNI_NON_BOUNDARY
OPCODESerror.__init___makecodesmissing -, : or )incomplete escape %sTokenizer.posPattern.__init__missing %s, unterminated nameconditional backref with more than two branchesTokenizer.tellCATEGORIESgetuntilmin repeat greater than max repeatunsupported special character %rsourcegetbad character range %s-%stoo many groupsbad escape (end of pattern)seqtypescondgroupitem_yesitem_no_parse_flagscannot refer to an open groupunterminated character setbad inline flags: cannot turn off global flagESCAPESlookbehindgroupsisoctalPattern.checklookbehindgroupmissing ), unterminated subpatternTokenizer.getuntilmultiple repeatcannot refer to group defined in the same lookbehind subpatternSubPattern.__setitem__missing ), unterminated comment¾4   ÚxúFÚMÚiÚrúYÚpÚdÚXÚcÚKÚQÚDÚlÚyÚEÚSÚOÚhÚmÚHÚPÚBÚUúJÚzúVÚAÚkÚIÚLÚoÚaÚZÚgÚTÚfÚuÚeúGúWÚwÚRÚnÚbÚqÚjÚtÚsÚNÚvÚC<module sre_parse>ASCII and UNICODE flags are incompatibleaddgroupogiditemsappendsourcematchsubpatternappendbad escape %smissing flagASCII and LOCALE flags are incompatible*+?{SubPattern.__delitem___REPEATCODESTokenizer.matchSubPattern.appendSubPattern.insertcannot use LOCALE flag with a str pattern=!bad inline flags: cannot turn on global flagSubPattern.__init__Tokenizer.__init__unexpected end of patternFlags not at the start of the expression %r%sbad group numberSubPattern.getwidthELSEfix_flagsREPEAT_CHARSredefinition of group name %r as group %d; was group %dSubPattern.__len__the repetition number is too largeTokenizer.seekASCIILETTERSOCTDIGITS.\[{()*+?^$|SPECIAL_CHARS_parse_subbad character in group name %rparse_template.<locals>.addgroupTokenizer.__nextunknown extension ?Pinvalid group reference %d (truncated))-:getwhileC:\msys64\mingw64\lib\python3.6\sre_parse.pymissing <unknown group name %rmissing group nameunknown extension ?<=!<missing :_parse_sub_condSubPattern.__repr__unknown flagoctal escape value %s outside of range 0-0o377Tokenizer.getwhile_UNITCODESGLOBAL_FLAGSnothing to repeatPattern.checkgroupcannot use UNICODE flag with a bytes patternTokenizer.errorHEXDIGITSbad inline flags: flag turned on and offPattern.closegroupSubPattern.dump_class_escapegroupwidthsPattern.groups©)ÚsourceÚstateÚverboseÚnestedÚfirstÚ
subpatternÚsubpatternappendÚ	sourcegetÚsourcematchÚ_lenÚ_ordÚthisÚcodeÚhereÚsetÚ	setappendÚstartÚcode1ÚthatÚcode2ÚmsgÚloÚhiÚminÚmaxÚitemÚgroupÚnameÚ	condgroupÚ	add_flagsÚ	del_flagsÚcharÚgidÚdirÚlookbehindgroupsÚpÚcondnameÚflagsÚwarningsÚerrÚsub_verboseSubPattern.__getitem__unsupported quantifier %rPattern.opengroup_Tokenizer__next_set_npn_protocolsSSLSocket.getpeercertsuppress_ragged_eofsOPENSSL_VERSION_NUMBEROPENSSL_VERSION_INFOReturn the currently selected NPN protocol as a string, or ``None``
        if a next protocol was not negotiated or if NPN is not supported by one
        of the peers.DefaultVerifyPathshost_ipdnsnamescommonNameSSLSocket.session_reusedserver_sidecert_reqsca_certsdo_handshake_on_connectcipherssslsock_ASN1Objectload_default_certsSSLContext.verify_mode_wrap_socketmax_wildcardspatsVerify that *cert* (in decoded format as returned by
    SSLSocket.getpeercert()) matches the *hostname*.  RFC 2818 and RFC 6125
    rules are followed, but IP addresses are not accepted for *hostname*.

    CertificateError is raised on failure. On success, the function
    returns nothing.
    fromnidSSLWantReadErrorbinary_formSSLContext.wrap_bioReturn the currently selected ALPN protocol as a string, or ``None``
        if a next protocol was not negotiated or if ALPN is not supported by one
        of the peers._ASN1Object.fromnameHAS_NPNUnsupported channel binding typeload_verify_locationsNPN protocols must be 1 to 255 in lengthsocket_errorrecvmsg_intoMatching according to RFC 6125, section 6.4.3

    http://tools.ietf.org/html/rfc6125#section-6.4.3
    attempt to connect already-connected SSLSocket!SSLObject.shared_ciphersPROTOCOL_SSLv2unable to enumerate Windows certificate storeGet channel binding data for current connection.  Raise ValueError
        if the requested `cb_type` is not supported.  Return bytes of the data
        or None if the data is not available (e.g. before the handshake).Get channel binding data for current connection.  Raise ValueError
        if the requested `cb_type` is not supported.  Return bytes of the data
        or None if the data is not available (e.g. before the handshake).
        MemoryBIOWrite DATA to the underlying SSL channel.  Returns
        number of bytes of DATA actually transmitted.pem_cert_stringcadatacheck_hostname requires server_hostnameconnect_exsslobjSSLSocket.get_channel_bindingDER_cert_to_PEM_certSSLSocket.sendmsg %d %H:%M:%S %Y GMTnon-zero flags not allowed in calls to recv_into() on %sverify_flagsSSLSocket.contextCreate a SSLContext object for Python stdlib modules

    All Python stdlib modules shall use this function to create SSLContext
    objects in order to keep common settings in one place. The configuration
    is less restrict than create_default_context()'s to increase backward
    compatibility.
    This module provides some more Pythonic support for SSL.

Object types:

  SSLSocket -- subtype of socket.socket which does SSL over the socket

Exceptions:

  SSLError -- exception raised for I/O errors

Functions:

  cert_time_to_seconds -- convert time string used for certificate
                          notBefore and notAfter functions to integer
                          seconds past the Epoch (the time values
                          returned from time.time())

  fetch_server_certificate (HOST, PORT) -- fetch the certificate provided
                          by the server running on HOST at port PORT.  No
                          validation of the certificate is performed.

Integer constants:

SSL_ERROR_ZERO_RETURN
SSL_ERROR_WANT_READ
SSL_ERROR_WANT_WRITE
SSL_ERROR_WANT_X509_LOOKUP
SSL_ERROR_SYSCALL
SSL_ERROR_SSL
SSL_ERROR_WANT_CONNECT

SSL_ERROR_EOF
SSL_ERROR_INVALID_ERROR_CODE

The following group define certificate requirements that one side is
allowing/requiring from the other side:

CERT_NONE - no certificates from the other side are required (or will
            be looked at if provided)
CERT_OPTIONAL - certificates are not required, but if provided will be
                validated, and if validation fails, the connection will
                also fail
CERT_REQUIRED - certificates are required, and will be validated, and
                if validation fails, the connection will also fail

The following constants identify various SSL protocol variants:

PROTOCOL_SSLv2
PROTOCOL_SSLv3
PROTOCOL_SSLv23
PROTOCOL_TLS
PROTOCOL_TLS_CLIENT
PROTOCOL_TLS_SERVER
PROTOCOL_TLSv1
PROTOCOL_TLSv1_1
PROTOCOL_TLSv1_2

The following constants identify various SSL alert message descriptions as per
http://www.iana.org/assignments/tls-parameters/tls-parameters.xml#tls-parameters-6

ALERT_DESCRIPTION_CLOSE_NOTIFY
ALERT_DESCRIPTION_UNEXPECTED_MESSAGE
ALERT_DESCRIPTION_BAD_RECORD_MAC
ALERT_DESCRIPTION_RECORD_OVERFLOW
ALERT_DESCRIPTION_DECOMPRESSION_FAILURE
ALERT_DESCRIPTION_HANDSHAKE_FAILURE
ALERT_DESCRIPTION_BAD_CERTIFICATE
ALERT_DESCRIPTION_UNSUPPORTED_CERTIFICATE
ALERT_DESCRIPTION_CERTIFICATE_REVOKED
ALERT_DESCRIPTION_CERTIFICATE_EXPIRED
ALERT_DESCRIPTION_CERTIFICATE_UNKNOWN
ALERT_DESCRIPTION_ILLEGAL_PARAMETER
ALERT_DESCRIPTION_UNKNOWN_CA
ALERT_DESCRIPTION_ACCESS_DENIED
ALERT_DESCRIPTION_DECODE_ERROR
ALERT_DESCRIPTION_DECRYPT_ERROR
ALERT_DESCRIPTION_PROTOCOL_VERSION
ALERT_DESCRIPTION_INSUFFICIENT_SECURITY
ALERT_DESCRIPTION_INTERNAL_ERROR
ALERT_DESCRIPTION_USER_CANCELLED
ALERT_DESCRIPTION_NO_RENEGOTIATION
ALERT_DESCRIPTION_UNSUPPORTED_EXTENSION
ALERT_DESCRIPTION_CERTIFICATE_UNOBTAINABLE
ALERT_DESCRIPTION_UNRECOGNIZED_NAME
ALERT_DESCRIPTION_BAD_CERTIFICATE_STATUS_RESPONSE
ALERT_DESCRIPTION_BAD_CERTIFICATE_HASH_VALUE
ALERT_DESCRIPTION_UNKNOWN_PSK_IDENTITY
Returns a formatted version of the data in the
        certificate provided by the other end of the SSL channel.
        Return None if no certificate was provided, {} if a
        certificate was provided, but not validated.1.3.6.1.5.5.7.3.1_real_connectselected_npn_protocolSSLSocket._check_connectedipnameSSLSocket.selected_npn_protocolxn--HAS_TLS_UNIQUEsubjectAltNameSSLContext.__new__Accepts a new connection from a remote client, and returns
        a tuple containing that new connection wrapped with a server-side
        SSL channel, and the address of the remote client.SSLObject.writeSSLSession_txt2obj<module ssl>Send a file, possibly by using os.sendfile() if this is a
        clear-text socket.  Return the total number of bytes sent.
        Start the SSL shutdown handshake.VERIFY_alpn_protocolsprotosflags_or_addrenum_crlsSSLSocket.sendallenum_certificates_sslobjcan't connect in server-side modeInvalid PEM encoding; must start with %sstorename{0} channel binding type not implemented_set_alpn_protocolsSSLObject.get_channel_bindingSSLSocket.sendfiletime data %r does not match format "%%b%s"_OPENSSL_API_VERSION©ÚselfÚsockÚkeyfileÚcertfileÚserver_sideÚ	cert_reqsÚssl_versionÚca_certsÚdo_handshake_on_connectÚfamilyÚtypeÚprotoÚfilenoÚsuppress_ragged_eofsÚnpn_protocolsÚciphersÚserver_hostnameÚ_contextÚ_sessionÚeÚ	connectedÚsslobjÚtimeoutsendmsg not allowed on instances of %sSSLContext.verify_flagsget_server_certificateSSLContext.wrap_socket_SSLv2_IF_EXISTSSSLObject.compressionCHANNEL_BINDING_TYPESReturn a list of ciphers shared by the client during the handshake or
        None if this is not a valid server connection.
        VerifyModenid shortname longname oidStart the SSL/TLS handshake.SSLObject.version_ipaddress_matchNo SSL wrapper around recvfrom_into not allowed on instances of %sSSLSocket.recvfromsendto not allowed on instances of %sWas the client session reused during handshakeSSLContext.optionsSSLSocket.connect_dnsname_matchSSLSocket.cipherSSLSocket.recvmsgTakes a certificate in binary DER format and returns the
    PEM version of it as a string.certfile must be specified for server-side operationsrecvmsg not allowed on instances of %s_ASN1Object.fromnidcheck_hostname needs server_hostname argumentdercertno appropriate commonName or subjectAltName fields were foundnon-zero flags not allowed in calls to send() on %ssession can only be specified in client mode_DEFAULT_CIPHERSPerform a TLS/SSL handshake.hostname %r doesn't match either of %sTLS13-AES-256-GCM-SHA384:TLS13-CHACHA20-POLY1305-SHA256:TLS13-AES-128-GCM-SHA256:ECDH+AESGCM:ECDH+CHACHA20:DH+AESGCM:DH+CHACHA20:ECDH+AES256:DH+AES256:ECDH+AES128:DH+AES:ECDH+HIGH:DH+HIGH:RSA+AESGCM:RSA+AES:RSA+HIGH:!aNULL:!eNULL:!MD5:!DSS:!RC4:!3DESENOTCONNRetrieve the certificate from the server at the specified address,
    and return it as a PEM-encoded string.
    If 'ca_certs' is specified, validate the server cert against it.
    If 'ssl_version' is specified, use it in the connection attempt.SSLSocket.connect_exExact matching of IP addresses.

    RFC 6125 explicitly doesn't define an algorithm for this
    (section 1.7.2 - "Out of Scope").
    HAS_TLSv1_3SSLContext._load_windows_store_certsSSLObject.contextSSLSocket.do_handshakeSSLSocket.shared_ciphersSSLObject.selected_npn_protocoltoo many wildcards in certificate DNS name: SSLSocket.write_RESTRICTED_SERVER_CIPHERSPEM_FOOTERnid2obj_SSLContextThis class implements an interface on top of a low-level SSL object as
    implemented by OpenSSL. This object captures the state of an SSL connection
    but does not provide any network IO itself. IO needs to be performed
    through separate "BIO" objects which are OpenSSL's IO abstraction layer.

    This class does not have a public constructor. Instances are returned by
    ``SSLContext.wrap_bio``. This class is typically used by framework authors
    that want to implement asynchronous IO for SSL through memory buffers.

    When compared to ``SSLSocket``, this object lacks the following features:

     * Any form of network IO incluging methods such as ``recv`` and ``send``.
     * The ``do_handshake_on_connect`` and ``suppress_ragged_eofs`` machinery.
    hostname %r doesn't match %r_PROTOCOL_NAMESReturn paths to default cafile and capath.
    SSLObject.session_reusedSSLContext.set_npn_protocolsSSLZeroReturnErrorSSLWantWriteErrorSSLSyscallErrorSSLEOFErrorset_default_verify_pathsThis class implements a subtype of socket.socket that wraps
    the underlying OS socket in an SSL context when necessary, and
    provides read and write methods over that channel.SSLSocket.selected_alpn_protocolRead up to 'len' bytes from the SSL object and return them.

        If 'buffer' is provided, read into this buffer and return the number of
        bytes read.
        SSLSocket.__init___nid2objTakes a certificate in ASCII PEM format and returns the
    DER-encoded version of it as a byte sequence_wrap_bio1.3.6.1.5.5.7.3.2tls-unique[^.]+Return the current compression algorithm in use, or ``None`` if
        compression was not negotiated or not supported by one of the peers.Return a string identifying the protocol version used by the
        current SSL channel. empty or no certificate, match_hostname needs a SSL socket or SSL context with either CERT_OPTIONAL or CERT_REQUIREDset_ciphersCreate _ASN1Object from OpenSSL numeric ID
        SSLObject.unwrapSSLErrorNumber_ASN1Object.__new__An SSLContext holds various SSL-related configuration options and
    data, such as certificates and possibly a private key.RAND_bytesRAND_egdAlertDescriptionSSLObject.do_handshakePEM_HEADER-----END CERTIFICATE-----do_handshake_on_connect should not be specified for non-blocking socketsCan't dup() %s instances_create_unverified_contextReturn the time in seconds since the Epoch, given the timestring
    representing the "notBefore" or "notAfter" date from a certificate
    in ``"%b %d %H:%M:%S %Y %Z"`` strptime format (C locale).

    "notBefore" or "notAfter" dates must use UTC (RFC 5280).

    Month is one of: Jan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec
    UTC should be specified as GMT (see ASN1_TIME_print())
    SSLSocket.sendtoSSLSocket.readpeer_certificateget_protocol_nameSSLSocket._real_connectcafile capath openssl_cafile_env openssl_cafile openssl_capath_env openssl_capathALPN protocols must be 1 to 255 in length-----BEGIN CERTIFICATE-----_SSLMethodSSLObject.selected_alpn_protocolSSLSocket.dupprotocol_codeRead up to LEN bytes and return them.
        Return zero-length string on EOF.x509_asnnewsock_windows_cert_storesRAND_addSSLSocket.unwrapSO_TYPEPEM_cert_to_DER_certCLIENT_AUTHSSLObject.server_hostnameC:\msys64\mingw64\lib\python3.6\ssl.pyHAS_SNIWrite 'data' to the SSL object and return the number of bytes
        written.

        The 'data' argument must support the buffer interface.
        SSLSocket.compressionSSLSocket.recvmsg_intoRead on closed or unwrapped SSL socket.Invalid PEM encoding; must end with %sSSLObject.getpeercertWrite on closed or unwrapped SSL socket.month_numberget_default_verify_pathsVerifyFlagsCreate _ASN1Object from short name, long name or OID
        SSLSocket.recvfrom_intonon-zero flags not allowed in calls to sendall() on %sSSLSocket.shutdownReturn the number of bytes that can be read immediately.SSLSocket.acceptrecvfrom not allowed on instances of %sThe SSLContext that is currently in use.Connects to remote ADDR, and then wraps the connection in
        an SSL channel.HAS_ECDHserver_hostname can only be specified in client modeSSLObject.cipherder_cert_bytesSSLObject.server_sideASN.1 object identifier lookup
    SSLSocket.pendingReturns a formatted version of the data in the certificate provided
        by the other end of the SSL channel.

        Return None if no certificate was provided, {} if a certificate was
        provided, but not validated.
        HAS_ALPNSSLSocket.versiononly stream sockets are supportedSSLContext.set_alpn_protocolsSSLContext.__init__recvmsg_into not allowed on instances of %sTLS13-AES-256-GCM-SHA384:TLS13-CHACHA20-POLY1305-SHA256:TLS13-AES-128-GCM-SHA256:ECDH+AESGCM:ECDH+CHACHA20:DH+AESGCM:DH+CHACHA20:ECDH+AES256:DH+AES256:ECDH+AES128:DH+AES:ECDH+HIGH:DH+HIGH:RSA+AESGCM:RSA+AES:RSA+HIGH:!aNULL:!eNULL:!MD5:!3DESSSLObject.readSSLObject.pending
        Return a string identifying the protocol version used by the
        current SSL channel, or None if there is no established channel.
        SSLContext.load_default_certsSSLSocket._real_closeRAND_statusnon-zero flags not allowed in calls to recv() on %sWhether this is a server-side socket.SSLSocket._checkClosedRAND_pseudo_bytesReturn the currently selected cipher as a 3-tuple ``(name,
        ssl_version, secret_bits)``.SSLObject.__init__tls_unique_cbCreate a SSLContext object with default settings.

    NOTE: The protocol and settings may change anytime without prior
          deprecation. The values represent a fair balance between maximum
          compatibility and security.
    SSLSocket.recv_intoThe SSLSession for client socket.IP AddressSSLContext purpose flags with X509v3 Extended Key Usage objects
    The currently set server hostname (for SNI), or ``None`` if no
        server hostame is set.S_IWGRPS_IXOTHUF_COMPRESSEDS_ISGID<module stat>ST_INOSF_ARCHIVEDST_NLINKFILE_ATTRIBUTE_INTEGRITY_STREAMS_IWUSRReturn True if mode is from a character special device file.UF_OPAQUES_IFDIRFILE_ATTRIBUTE_REPARSE_POINTS_ENFMTS_IREADS_IXUSRSF_IMMUTABLES_IWOTHFILE_ATTRIBUTE_SYSTEMFILE_ATTRIBUTE_NO_SCRUB_DATAFILE_ATTRIBUTE_HIDDENS_IRGRPS_IWRITEST_MTIMEUF_IMMUTABLEReturn True if mode is from a regular file.FILE_ATTRIBUTE_OFFLINEFILE_ATTRIBUTE_READONLYS_IROTHUF_HIDDENFILE_ATTRIBUTE_TEMPORARYST_UIDSF_APPENDUF_NODUMPFILE_ATTRIBUTE_DEVICEReturn True if mode is from a socket.S_IFSOCKReturn True if mode is from a symbolic link.S_IFIFOFILE_ATTRIBUTE_COMPRESSEDFILE_ATTRIBUTE_SPARSE_FILES_IFLNKS_IRWXUST_MODEFILE_ATTRIBUTE_ENCRYPTEDUF_APPENDReturn True if mode is from a FIFO (named pipe).FILE_ATTRIBUTE_ARCHIVEConstants/functions for interpreting results of os.stat() and os.lstat().

Suggested usage: from stat import *
Convert a file's mode to a string of the form '-rwxrwxrwx'.FILE_ATTRIBUTE_VIRTUALSF_SNAPSHOTST_DEVFILE_ATTRIBUTE_NOT_CONTENT_INDEXEDST_SIZES_ISUIDReturn the portion of the file's mode that describes the
    file type.
    FILE_ATTRIBUTE_DIRECTORYReturn True if mode is from a block special device file.S_IRUSRS_IEXECUF_NOUNLINKS_ISVTX_filemode_tableST_GIDC:\msys64\mingw64\lib\python3.6\stat.pySF_NOUNLINKST_CTIMEReturn True if mode is from a directory.Return the portion of the file's mode that can be set by
    os.chmod().
    ST_ATIMES_IXGRPS_ISSOCKStateWatcher.cnc_is_idlealert_if_all_devices_are_idle has been called. need_tensioner_idle %s need_cnc_idle %sEmitting cnc_disconnected signal!
tensioner_is_connectedPARAM_READABLEEmitting tensioner_disconnected signal!
no tensioner_device_is_idlepressure_changedailment or pressure alerttensioner_ready: Emitting tensioner_connected signal!
StateWatcher.new_pressure_dataalert_if_all_devices_are_idle has been called. need_tensioner_idle need_cnc_idleStateWatcher.tensioner_disconnectedalerting that tensioner is idle

Watches both ailments and palpation points for changes, and alerts for new drawings.

This is to keep the drawing routines from drawing background too often.
tensioner_ready: %sEmitting sensor_pad_connected signal!
StateWatcher.alert_if_all_devices_are_idleStateWatcher.cnc_connectedemitting any_device_busy signalStateWatcher.tensioner_is_idlecnc_ready<module statewatcher>StateWatcher.tensioner_connectedpressurepadStateWatcher.cnc_is_busyStateWatcher.sensor_pad_disconnectedsensor_datatensioner is doing shitcnc_is_connectedcnc_ready: %sStateWatcher.__init__Emitting all_devices_idle signal in 2 seconds
C:\msys64\home\cbper\statewatcher.pyEmitting cnc_connected signal!
StateWatcher.sensor_pad_connectedStateWatcher.tensioner_is_busyStateWatcher.cnc_disconnected_TemplateMetaclass.__init__<module string>bracedarg_usedis_attrformat() missing 1 required positional argument: 'format_string'format_fieldA string class for supporting $-substitutions.used_argsrecursion_depthauto_arg_indexliteral_textoctdigitsvformatTemplate.__init___vformatdescriptor 'safe_substitute' of 'Template' object needs an argumentcapwords.<locals>.<genexpr>capwords(s [,sep]) -> string

    Split the argument into words using split, capitalize each
    word using capitalize, and join the capitalized words using
    join.  If the optional second argument sep is absent or None,
    runs of whitespace characters are replaced by a single space
    and leading and trailing whitespace are removed, otherwise
    sep is used to split and join the words.

    formatter_field_name_splitFormatter.check_unused_argsconvert_fielddescriptor 'substitute' of 'Template' object needs an argumentascii_lowercaseascii_uppercaseTemplate.substitute.<locals>.convertdescriptor 'format' of 'Formatter' object needs an argument
    %(delim)s(?:
      (?P<escaped>%(delim)s) |   # Escape sequence of two delimiters
      (?P<named>%(id)s)      |   # delimiter and a Python identifier
      {(?P<braced>%(id)s)}   |   # delimiter and a braced identifier
      (?P<invalid>)              # Other ill-formed delimiter exprs
    )
    Formatter.get_valueToo many positional argumentsMax string recursion exceededFormatter.vformatA collection of string constants.

Public module variables:

whitespace -- a string containing all ASCII whitespace
ascii_lowercase -- a string containing all ASCII lowercase letters
ascii_uppercase -- a string containing all ASCII uppercase letters
ascii_letters -- a string containing all ASCII letters
digits -- a string containing all ASCII decimal digits
hexdigits -- a string containing all ASCII hexadecimal digits
octdigits -- a string containing all ASCII octal digits
punctuation -- a string containing all ASCII punctuation characters
printable -- a string containing all ASCII characters considered printable

Template.safe_substituteC:\msys64\mingw64\lib\python3.6\string.pyFormatter._vformatFormatter.format_fieldUnrecognized named group in patternFormatter.convert_fieldFormatter.parse(?-i:[_a-zA-Z][_a-zA-Z0-9]*)Template.safe_substitute.<locals>.convertFormatter.get_fieldcannot switch from manual field specification to automatic field numberingPassing 'format_string' as keyword argument is deprecatedformatter_parserInvalid placeholder in string: line %d, col %dTemplate._invalidUnknown conversion specifier {0!s}idpattern 	
iter_unpack_clearcachepack_into<module struct>C:\msys64\mingw64\lib\python3.6\struct.pyc2pwrite_communicatePIPE_BUFstderr_threadReturn a list of command-line arguments reproducing the current
    settings in sys.flags and sys.warnoptions.hStdOutputPopen._communicateKill the process with SIGKILL
            Popen.__enter__Return (exitcode, output) of executing cmd in a shell.

    Execute the string 'cmd' in a shell with 'check_output' and
    return a 2-tuple (status, output). The locale encoding is used
    to decode the output and process newlines.

    A trailing newline is stripped from the output.
    The exit status for the command can be interpreted
    according to the rules for the function 'wait'. Example:

    >>> import subprocess
    >>> subprocess.getstatusoutput('ls /bin/ls')
    (0, '/bin/ls')
    >>> subprocess.getstatusoutput('cat /bin/junk')
    (1, 'cat: /bin/junk: No such file or directory')
    >>> subprocess.getstatusoutput('/bin/junk')
    (127, 'sh: /bin/junk: not found')
    >>> subprocess.getstatusoutput('/bin/kill $$')
    (-15, '')
    Command '%s' timed out after %s secondspass_fds not supported on Windows.CompletedProcess.__repr__Raise CalledProcessError if the exit code is non-zero.write_throughCreate new Popen instance._internal_pollbs_bufAlias for output attribute, to match stderrRun command with arguments.  Wait for command to complete or
    timeout, then return the returncode attribute.

    The arguments are the same as for the Popen constructor.  Example:

    retcode = call(["ls", "-l"])
    TimeoutExpired.__str___execute_childECHILDCREATE_NEW_PROCESS_GROUP_WEXITSTATUSWSTOPSIGSubprocesses with accessible I/O streams

This module allows you to spawn processes, connect to their
input/output/error pipes, and obtain their return codes.

For a complete description of this module see the Python documentation.

Main API
========
run(...): Runs a command, waits for it to complete, then returns a
          CompletedProcess instance.
Popen(...): A class for flexibly executing a command in a new process

Constants
---------
DEVNULL: Special value that indicates that os.devnull should be used
PIPE:    Special value that indicates a pipe should be created
STDOUT:  Special value that indicates that stderr should go to stdout


Older API
=========
call(...): Runs a command, waits for it to complete, then returns
    the return code.
check_call(...): Same as call() but raises CalledProcessError()
    if return code is not 0
check_output(...): Same as check_call() but returns the contents of
    stdout instead of a return code
getoutput(...): Runs a command in the shell, waits for it to complete,
    then returns the output
getstatusoutput(...): Runs a command in the shell, waits for it to complete,
    then returns a (exitcode, output) tuple
_WNOHANGReturn a duplicate of handle, which is inheritableclose_fds is not supported on Windows platforms if you redirect stdin/stdout/stderr
    Translate a sequence of arguments into a command line
    string, using the same rules as the MS C runtime:

    1) Arguments are delimited by white space, which is either a
       space or a tab.

    2) A string surrounded by double quotation marks is
       interpreted as a single argument, regardless of white space
       contained within.  A quoted string can be embedded in an
       argument.

    3) A double quotation mark preceded by a backslash is
       interpreted as a literal double quotation mark.

    4) Backslashes are interpreted literally, unless they
       immediately precede a double quotation mark.

    5) If backslashes immediately precede a double quotation mark,
       every pair of backslashes is interpreted as a literal
       backslash.  If the number of backslashes is odd, the last
       backslash escapes the next double quotation mark as
       described in rule 3.
    _closed_child_pipe_fdsCOMSPECwShowWindowCheck if child process has terminated.  Returns returncode
            attribute.

            This method is called by __del__, so it can only refer to objects
            in its local scope.

            _stdin_writeget_osfhandlePopen._execute_child.<locals>.<genexpr>no_user_siteHandle.Closesend_signalPopen.send_signalSTD_INPUT_HANDLE/bin/shorig_timeoutinput_viewPopen._try_waitcheck_returncode©ÚselfÚargsÚbufsizeÚ
executableÚstdinÚstdoutÚstderrÚ
preexec_fnÚ	close_fdsÚshellÚcwdÚenvÚuniversal_newlinesÚstartupinfoÚcreationflagsÚrestore_signalsÚstart_new_sessionÚpass_fdsÚencodingÚerrorsÚany_stdio_setÚp2creadÚp2cwriteÚc2preadÚc2pwriteÚerrreadÚerrwriteÚ	text_modeÚfÚto_closeÚfdCommand '%s' died with unknown signal %d._PIPE_BUFargs={!r}Popen._check_timeoutRaised when run() is called with check=True and the process
    returns a non-zero exit status.

    Attributes:
      cmd, returncode, stdout, stderr, output
    _stderr_buffreturncode={!r}hStdInputConstruct and return tuple with IO objects:
            p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite
            stdin and input arguments may not both be used.SubprocessErrorRun command with arguments.  Wait for command to complete.  If
    the exit code was zero then return, otherwise raise
    CalledProcessError.  The CalledProcessError object will have the
    return code in the returncode attribute.

    The arguments are the same as for the call function.  Example:

    check_call(["ls", "-l"])
    _fileobj2outputdwFlagstimeout_millisSW_HIDEnoexecTerminate the process with SIGTERM
            cmd.exeInteract with process: Send data to stdin.  Read data from
        stdout and stderr, until end-of-file is reached.  Wait for
        process to terminate.

        The optional "input" argument should be data to be sent to the
        child process (if self.universal_newlines is True, this should
        be a string; if it is False, "input" should be bytes), or
        None, if no data should be sent to the child.

        communicate() returns a tuple (stdout, stderr).  These will be
        bytes or, if self.universal_newlines was True, a string.
        _save_input_handle_exitstatusReturn output (stdout or stderr) of executing cmd in a shell.

    Like getstatusoutput(), except the exit status is ignored and the return
    value is a string containing the command's output.  Example:

    >>> import subprocess
    >>> subprocess.getoutput('ls /bin/ls')
    '/bin/ls'
    DetachReturn a list of command-line arguments reproducing the current
    optimization settings in sys.flags.CTRL_C_EVENTPopen._handle_exitstatusSTARTF_USESHOWWINDOWCREATE_NEW_CONSOLESTD_OUTPUT_HANDLESTD_ERROR_HANDLESTARTF_USESTDHANDLESSTARTUPINFOSTILL_ACTIVESend a signal to the process. Execute a child program in a new process.

    For a complete description of the arguments see the Python documentation.

    Arguments:
      args: A string, or a sequence of program arguments.

      bufsize: supplied as the buffering argument to the open() function when
          creating the stdin/stdout/stderr pipe file objects

      executable: A replacement program to execute.

      stdin, stdout and stderr: These specify the executed programs' standard
          input, standard output and standard error file handles, respectively.

      preexec_fn: (POSIX only) An object to be called in the child process
          just before the child is executed.

      close_fds: Controls closing or inheriting of file descriptors.

      shell: If true, the command will be executed through the shell.

      cwd: Sets the current directory before the child is executed.

      env: Defines the environment variables for the new process.

      universal_newlines: If true, use universal line endings for file
          objects stdin, stdout and stderr.

      startupinfo and creationflags (Windows only)

      restore_signals (POSIX only)

      start_new_session (POSIX only)

      pass_fds (POSIX only)

      encoding and errors: Text mode encoding and error handling to use for
          file objects stdin, stdout and stderr.

    Attributes:
        stdin, stdout, stderr, pid, returncode
    This exception is raised when the timeout expires while waiting for a
    child process.

    Attributes:
        cmd, output, stdout, stderr, timeout
    Command '%s' returned non-zero exit status %d._child_created_translate_newlinesbufsize must be an integer_waitpidPopen.kill<module subprocess>_devnullTimeoutExpired.__init___stdout_buff_get_devnullcreationflags is only supported on Windows platformspass_fds overriding close_fds.Check if child process has terminated. Set and return returncode
        attribute.Popen._stdin_writeGetStdHandle_readerthread_WTERMSIG_ECHILD_deadstate_WaitForSingleObject_WAIT_OBJECT_0_GetExitCodeProcess'endtime' argument is deprecated; use 'timeout'.Popen._translate_newlinesillegal environment variable nameCalledProcessError.__init__Cannot send input after starting communication_input_offsetstdout={!r}_PopenSelectorignore_environment_WIFSTOPPEDHandle.Detach_get_handlesUnknown child exit status!Run command with arguments and return a CompletedProcess instance.

    The returned instance will have attributes args, returncode, stdout and
    stderr. By default, stdout and stderr are not captured, and those attributes
    will be None. Pass stdout=PIPE and/or stderr=PIPE in order to capture them.

    If check is True and the exit code was non-zero, it raises a
    CalledProcessError. The CalledProcessError object will have the return code
    in the returncode attribute, and output & stderr attributes if those streams
    were captured.

    If timeout is given, and the process takes too long, a TimeoutExpired
    exception will be raised.

    There is an optional argument "input", allowing you to
    pass a string to the subprocess's stdin.  If you use this argument
    you may not also use the Popen constructor's "stdin" argument, as
    it will be used internally.

    The other arguments are the same as for the Popen constructor.

    If universal_newlines=True is passed, the "input" argument must be a
    string and stdout/stderr in the returned object will be strings rather than
    bytes.
    needquoteCheck if child process has terminated.  Returns returncode
            attribute.

            This method is called by __del__, so it cannot reference anything
            outside of the local scope (nor can any methods it calls).

            _communication_startedWait for child process to terminate.  Returns returncode
            attribute.Terminates the process.CalledProcessError.stdoutCTRL_BREAK_EVENTExecute program (MS Windows version)CalledProcessError.__str__Bad exception data from child: {!r}All callers to this function MUST hold self._waitpid_lock.already closed_PLATFORM_DEFAULT_CLOSE_FDSwait_flagsCommand '%s' died with %r.Popen._make_inheritablePopen._internal_pollstartupinfo is only supported on Windows platformsPopen._readerthreadC:\msys64\mingw64\lib\python3.6\subprocess.pyPopen._get_handles_WIFEXITEDTimeoutExpired.stdout_optim_args_from_interpreter_flagsstdout_thread_WSTOPSIGstderr={!r}subprocess %s is still runningü©ñÒMb@?Popen._save_inputCompletedProcess.__init__preexec_fn is not supported on Windows platformsCompletedProcess.check_returncodeConvenience for checking if a timeout has expired.Popen._remaining_time{} /c "{}"_mswindowsExecute program (POSIX version)_WIFSIGNALEDA process that has finished running.

    This is returned by run().

    Attributes:
      args: The list or str args passed to run().
      returncode: The exit code of the process, negative for signals.
      stdout: The standard output (None if not captured).
      stderr: The standard error (None if not captured).
    Popen.__del__©)ÚselfÚargsÚ
executableÚ
preexec_fnÚ	close_fdsÚpass_fdsÚcwdÚenvÚstartupinfoÚcreationflagsÚshellÚp2creadÚp2cwriteÚc2preadÚc2pwriteÚerrreadÚerrwriteÚrestore_signalsÚstart_new_sessionÚorig_executableÚerrpipe_readÚerrpipe_writeÚlow_fds_to_closeÚlow_fdÚenv_listÚkÚvÚexecutable_listÚfds_to_keepÚ
devnull_fdÚerrpipe_dataÚpartÚpidÚstsÚexception_nameÚ	hex_errnoÚerr_msgÚchild_exception_typeÚ	errno_numÚchild_exec_never_calledÚerr_filenameflag_opt_mapPopen.__exit__Convenience for _communicate when computing timeouts.©ÚselfÚargsÚ
executableÚ
preexec_fnÚ	close_fdsÚpass_fdsÚcwdÚenvÚstartupinfoÚcreationflagsÚshellÚp2creadÚp2cwriteÚc2preadÚc2pwriteÚerrreadÚerrwriteÚunused_restore_signalsÚunused_start_new_sessionÚcomspecÚhpÚhtÚpidÚtidPopen._get_devnullRun command with arguments and return its output.

    If the exit code was non-zero it raises a CalledProcessError.  The
    CalledProcessError object will have the return code in the returncode
    attribute and output in the output attribute.

    The arguments are the same as for the Popen constructor.  Example:

    >>> check_output(["ls", "-l", "/dev/null"])
    b'crw-rw-rw- 1 root root 1, 3 Oct 18  2007 /dev/null\n'

    The stdout argument is not allowed as it is used internally.
    To capture standard error in the result, use stderr=STDOUT.

    >>> check_output(["/bin/sh", "-c",
    ...               "ls -l non_existent_file ; exit 0"],
    ...              stderr=STDOUT)
    b'ls: non_existent_file: No such file or directory\n'

    There is an additional optional argument, "input", allowing you to
    pass a string to the subprocess's stdin.  If you use this argument
    you may not also use the Popen constructor's "stdin" argument, as
    it too will be used internally.  Example:

    >>> check_output(["sed", "-e", "s/foo/bar/"],
    ...              input=b"when in the course of fooman events\n")
    b'when in the course of barman events\n'

    If universal_newlines=True is passed, the "input" argument must be a
    string and the return value will be a string rather than bytes.
    Unsupported signal: {}hStdErrorPopen.communicateBINLIBDESTINCLUDEPYenv_basePYTHONUSERBASE{srcdir}/IncludePYTHONFRAMEWORKget_makefile_filenameC:\msys64\mingw64\lib\python3.6\sysconfig.pyReturn the value of a single variable using the dictionary returned by
    'get_config_vars()'.

    Equivalent to get_config_vars().get(name)
    EXT_SUFFIX\${([A-Za-z][A-Za-z0-9_]*)}_print_dictInitialize the module as appropriate for NT_PY_VERSION_SHORT_NO_DOT\pcbuild\amd64get_scheme_namesplatstdlibpurelibplatlib_b2h\pcbuild\win32Return a string that identifies the current platform.

    This is used mainly to distinguish platform-specific build directories and
    platform-specific built distributions.  Typically includes the OS name
    and version and the architecture (as supplied by 'os.uname()'),
    although the exact information included depends on the OS; eg. for IRIX
    the architecture isn't particularly important (IRIX only runs on SGI
    hardware), but for Linux the kernel version isn't particularly
    important.

    Examples of returned values:
       linux-i586
       linux-alpha (?)
       solaris-2.6-sun4u
       irix-5.3
       irix64-6.2

    Windows will return one of:
       win-amd64 (64bit Windows on AMD64 (aka x86_64, Intel64, EM64T, etc)
       win-ia64 (64bit Windows on Itanium)
       win32 (all others - specifically, sys.platform is returned)

    For other non-POSIX platforms, currently just returns 'sys.platform'.
    py_version_nodotuserbaseReturn a tuple containing the paths names.rel_re: '${SYS_PREFIX}'_EXEC_PREFIXInitialize the module as appropriate for POSIX systems._get_sysconfigdata_name_init_posixget_config_h_filenameSetup.distSetup.localpybuilddirdestfileitaniumbitness' + sys.prefix + '%s-%s-%scheck_home: sys.prefix: sys.prefix + 'APPDATA\$\(([A-Za-z][A-Za-z0-9_]*)\)Parse a config.h-style file.

    A dictionary containing name/value pairs is returned.  If an
    optional dictionary is passed in as the second argument, it is
    used instead of a new dictionary.
    other_dictDisplay all information sysconfig detains.#define ([A-Z][A-Za-z0-9_]+) (.*)
_PYTHON_BUILD	%s = "%s"%s-%s.%saix_generate_posix_vars_getuserbase.<locals>.joinuser_PYTHON_SYSCONFIGDATA_NAME_BASE_EXEC_PREFIX_sysconfigdata_{abi}_{platform}_{multiarch}config-%s%sbuild_time_varsdefine_rxpy_version_short_get_default_schemeget_path_namesget_python_versionparse_config_hconfig_dir_name-pydebug_PROJECT_BASE_sys_homeinstalled_baseCurrent installation scheme: "%s"target_keys_PYTHON_HOST_PLATFORMundef_rxpyconfig.h_safe_realpathReturn the path of pyconfig.h._extend_dictplatincludeûzposix_prefix{zstdlibz-{installed_base}/lib/python{py_version_short}z
platstdlibz'{platbase}/lib/python{py_version_short}zpurelibz1{base}/lib/python{py_version_short}/site-packageszplatlibz5{platbase}/lib/python{py_version_short}/site-packageszincludez;{installed_base}/include/python{py_version_short}{abiflags}zplatincludez?{installed_platbase}/include/python{py_version_short}{abiflags}zscriptsz
{base}/binzdataz{base}0z
posix_home{zstdlibz{installed_base}/lib/pythonz
platstdlibz{base}/lib/pythonzpurelibz{base}/lib/pythonzplatlibz{base}/lib/pythonzincludez{installed_base}/include/pythonzplatincludez{installed_base}/include/pythonzscriptsz
{base}/binzdataz{base}0znt{zstdlibz-{installed_base}/lib/python{py_version_short}z
platstdlibz#{base}/lib/python{py_version_short}zpurelibz#{base}/lib/python{py_version_short}zplatlibz#{base}/lib/python{py_version_short}zincludez1{installed_base}/include/python{py_version_short}zplatincludez1{installed_base}/include/python{py_version_short}zscriptsz
{base}/binzdataz{base}0znt_user{zstdlibz'{userbase}/lib/python{py_version_short}z
platstdlibz'{userbase}/lib/python{py_version_short}zpurelibz5{userbase}/lib/python{py_version_short}/site-packageszplatlibz5{userbase}/lib/python{py_version_short}/site-packageszincludez+{userbase}/include/python{py_version_short}zscriptsz{userbase}/binzdataz
{userbase}0z
posix_user{zstdlibz'{userbase}/lib/python{py_version_short}z
platstdlibz'{userbase}/lib/python{py_version_short}zpurelibz5{userbase}/lib/python{py_version_short}/site-packageszplatlibz5{userbase}/lib/python{py_version_short}/site-packageszincludez+{userbase}/include/python{py_version_short}zscriptsz{userbase}/binzdataz
{userbase}0zosx_framework_user{zstdlibz{userbase}/lib/pythonz
platstdlibz{userbase}/lib/pythonzpurelibz#{userbase}/lib/python/site-packageszplatlibz#{userbase}/lib/python/site-packageszincludez{userbase}/includezscriptsz{userbase}/binzdataz
{userbase}00projectbase--generate-posix-vars([a-zA-Z][a-zA-Z0-9_]+)\s*=\s*(.*)SO is deprecated, use EXT_SUFFIX_SCHEME_KEYSBINDIR_INSTALL_SCHEMEStarget_dict_parse_makefileis_python_build_USER_BASEbuild_time_vars = /[*] #undef ([A-Z][A-Za-z0-9_]+) [*]/
build/lib.%s-%sinvalid Python installation: unable to open %sReturn a tuple containing the schemes names._multiarchGenerate the Python module containing build-time variables.Return the path of the Makefile._subst_varsPython version: "%s"pybuilddir.txtinc_dir{projectbase}/.Platform: "%s"_PYTHON_PROJECT_BASEParse a Makefile-style file.

    A dictionary containing name/value pairs is returned.  If an
    optional dictionary is passed in as the second argument, it is
    used instead of a new dictionary.
     bit (_POSIX_BUILDWith no arguments, return a dictionary of all configuration
    variables relevant for the current platform.

    On Unix, this means every variable defined in Python's installed Makefile;
    On Windows it's a much smaller set.

    With arguments, return a list of values that result from looking up
    each argument in the configuration variable dictionary.
    ©ÚfilenameÚvarsÚreÚ_variable_rxÚ_findvar1_rxÚ_findvar2_rxÚdoneÚnotdoneÚfÚlinesÚlineÚmÚnÚvÚtmpvÚ	variablesÚrenamed_variablesÚnameÚvalueÚm1Úm2ÚfoundÚitemÚafterÚk<module sysconfig># system configuration generated and used by the sysconfig module
_init_non_posixReturn a mapping containing an install scheme.

    ``scheme`` is the install scheme name. If not provided, it will
    return the default scheme for the current platform.
    _BASE_PREFIXReturn a path corresponding to the scheme.

    ``scheme`` is the install scheme name.
    _expand_varsAccess to Python's configuration information._is_python_source_dir%d.%sClose the TarFile. In write-mode, two finishing zero blocks are
           appended to the archive.
        Make a file called targetpath.
        Make a file from a TarInfo object with an unknown type
           at targetpath.
        addfile$Id: tarfile.py 88586 2011-02-25 15:42:01Z marc-andre.lemburg $_StreamProxy__writenot an lzma fileExtract a member from the archive as a file object. `member' may be
           a filename or a TarInfo object. If `member' is a regular file or a
           link, an io.BufferedReader object is returned. Otherwise, None is
           returned.
        TarFile.taropennot a bzip2 fileReturn the object as a ustar header block.
        TarFile.xzopen{!r} file is extracted.TarFile.openGNU.sparse.majorlinkpath_Stream__readRead from and write to tar format archives.
Copy length bytes from fileobj src to fileobj dst.
       If length is None, copy the entire content.
    %s is closed_LowLevelFile.read.tbz.tb2TarFile.chownMake a fifo called targetpath.
        lzma module is not available././@LongLinkInformational class which holds the details about an
       archive member given by a tar header block.
       TarInfo objects are returned by TarFile.getmember(),
       TarFile.getmembers() and TarFile.gettarinfo() and are
       usually created internally.
    special devices not supported by systemLars GustÃ¤bel (lars@gustaebel.de)--listReturn a header block. info is a dictionary with file
           information, format must be one of the *_FORMAT constants.
        nothing to openpax_headers_Stream.__writecreate_pax_header_Stream.__del__Return size bytes from the stream.
        CONTTYPEXGLTYPEextractfileReturn the members of the archive as a list of TarInfo objects. The
           list has the same order as the members in the archive.
        Extract a member from the archive to the current working directory,
           using its full name. Its file information is extracted as accurately
           as possible. `member' may be a filename or a TarInfo object. You can
           specify a different directory using `path'. File attributes (owner,
           mtime, mode) are set unless `set_attrs' is False. If `numeric_owner`
           is True, only the numbers for user/group names are used and not
           the names.
        tarfile: Unknown file type %r, extracted as regular file.Low-level file object. Supports reading and writing.
       It is used instead of a regular file object for streaming
       access.
    GNU_MAGICConstruct a TarInfo object. name is the optional name
           of the member.
        TarInfo._proc_sparseA simple command line interface for tarfile module.Read through the entire archive file and look for readable
           members.
        Return a POSIX.1-2008 extended or global header sequence
           that contains a list of keyword, value pairs. The values
           must be strings.
        TarInfo._setlinkpathTarFile._find_link_targetinvalid compressed data_LowLevelFile.__init__TarInfo._proc_gnusparse_10148b8x356bzlib module is not availableC:\msys64\mingw64\lib\python3.6\tarfile.py_Stream.__init__st_rdev(\d+) ([^=]+)=TarInfo._proc_paxchksumissymtruncated headercould not change modification timeGeneral exception for extract errors.blockinfolastposrealposTarFile.__iter___Stream._init_write_gzdevmajorfifo not supported by systemTarInfo.tobufConvert a number field to a python number.
    <file>_LowLevelFile.writeTarInfo.issymFind the target member of a symlink or hardlink member in the
           archive.
        comptypecould not change modeTarFile.__exit__Initialize for reading a gzip compressed fileobj.
        empty headerPAX_NUMBER_FIELDS_FileInFile.seekTarInfo._proc_gnusparse_00TarFile.addfileDIRTYPECreate tarfile from sourcesTarFile.makefifoTarInfo._proc_gnulongbz2 module is not availableException for truncated headers.saved_posOpen bzip2 compressed tar archive name for reading or writing.
           Appending is not allowed.
        missing or bad subsequent headerisblkundiscernible modeExFileObject.__init___proc_gnusparse_01TarInfo._apply_pax_info{!r} file created.TarInfo._proc_gnusparse_01TarInfo.isfifo%dsSeek to a position in the file.
        copybufsizeTarFile._checkMake a directory called targetpath.
        frombufTarInfo._create_gnu_long_header_Stream.readReturn a GNUTYPE_LONGNAME or GNUTYPE_LONGLINK sequence
           for name.
        Return the TarInfo's attributes as a dictionary.
        awxustar 00signed_chksumFind an archive member by name from bottom to top.
           If tarinfo is given, it is used as the starting point.
        PAX_FIELDSREGULAR_TYPESmakelinkExtract the TarInfo object tarinfo to a physical
           file called targetpath.
        r:*_getmemberuse the filter argument instead<tarfile>_sparse_structsException for end of file headers.TarInfo.create_pax_global_headerGNU.sparse.sizegetgrgid_Stream._init_read_gzCheck if TarFile is still open, and if the operation's mode
           corresponds to TarFile's mode.
        Return True if name points to a tar archive that we
       are able to handle, else return False.
    Return the string payload filled with zero bytes
           up to the next 512 byte border.
        TarFile.chmodcould not change ownerDeprecated in this location; use stat.filemode.Create a TarInfo object from the result of os.stat or equivalent
           on an existing file. The file is either named by `name', or
           specified as a file object `fileobj' with a file descriptor. If
           given, `arcname' specifies an alternative name for the file in the
           archive, otherwise, the name is taken from the 'name' attribute of
           'fileobj', or the 'name' argument. The name should be a text
           string.
        cannot extract (sym)link as file objectSet file permissions of targetpath according to tarinfo.
        TarFile.makedirTest if a tarfile is validhdrcharsetTarFile.next_posix_split_nameinvalid headerSet modification time of targetpath according to tarinfo.
        TarInfo.isdevTarInfo.get_infooverflow in number fieldignore_zeroserrorlevelTarFile.__enter__Invalid argumentTarFile._dbgExtract all members from the archive to the current working
           directory and set owner, modification time and permissions on
           directories afterwards. `path' specifies a different directory
           to extract to. `members' is optional and must be a subset of the
           list returned by getmembers(). If `numeric_owner` is True, only
           the numbers for user/group names are used and not the names.
        {!r} file is extracted into {!r} directory.gzip module is not availablegzopenbz2open$Date: 2011-02-25 17:42:01 +0200 (Fri, 25 Feb 2011) $GNU.sparse.minorempty file_FileInFile.writableis_tarfileCompressionErrorStreamErrorExtractErrorHeaderErrorUSTAR_FORMATGNU_FORMATPAX_FORMATDEFAULT_FORMATbad checksumTarInfo._posix_split_nametarfile: %s %r_FileInFile.flushCHRTYPEstatres_FileInFile.seekableSYMTYPE--createischrLENGTH_NAMEBLKTYPEProcess the blocks that hold a GNU longname
           or longlink member.
        ]  unknown compression type %r_FileInFile.readintoReturn a tar header as a string of 512 byte blocks.
        unable to resolve link inside archive<module tarfile>RECORDSIZE__cvsid__TarFile.extractfilegeteuidReturn a TarInfo object for member `name'. If `name' can not be
           found in the archive, KeyError is raised. If a member occurs more
           than once in the archive, its last occurrence is assumed to be the
           most up-to-date version.
        _Stream.__readTarInfo._create_pax_generic_header%10snot a gzip fileTarInfo._proc_memberBase exception for header errors._FileInFile.__init__Open an (uncompressed) tar archive `name'. `mode' is either 'r' to
           read from an existing archive, 'a' to append data to an existing
           file or 'w' to create a new file overwriting an existing one. `mode'
           defaults to 'r'.
           If `fileobj' is given, it is used for reading or writing data. If it
           can be determined, `mode' is overridden by `fileobj's mode.
           `fileobj' is not closed, when TarFile is closed.
        ý7zXZTarFile.gzopenO_TRUNCinodeReturn the object as a ustar header block. If it cannot be
           represented this way, prepend a pax extended header sequence
           with supplement information.
        Process a builtin type or an unknown type which
           will be treated as a regular file.
        _Stream.closeTarFile.getnamesException for unreadable tar archives.fallback_encodingfallback_errorsorigsizeConvert a python number to a number field.
    deprecated in favor of stat.filemodest_nlinkTarInfo.create_gnu_headeroffset_dataExtract tarfile into target dir\d+ GNU.sparse.numbytes=(\d+)\n--testSubsequentHeaderErrorException for unsupported operations on stream-like TarFiles.Small proxy class that enables transparent compression
       detection for the Stream interface (mode 'r|*').
    TarInfo.fromtarfile_proc_builtinbad operation for mode %rTarInfo._blockLENGTH_PREFIXOpen a tar archive for reading, writing or appending. Return
           an appropriate TarFile class.

           mode:
           'r' or 'r:*' open for reading with transparent compression
           'r:'         open for reading exclusively uncompressed
           'r:gz'       open for reading with gzip compression
           'r:bz2'      open for reading with bzip2 compression
           'r:xz'       open for reading with lzma compression
           'a' or 'a:'  open for appending, creating the file if necessary
           'w' or 'w:'  open for writing without compression
           'w:gz'       open for writing with gzip compression
           'w:bz2'      open for writing with bzip2 compression
           'w:xz'       open for writing with lzma compression

           'x' or 'x:'  create a tarfile exclusively without compression, raise
                        an exception if the file is already created
           'x:gz'       create a gzip compressed tarfile, raise an exception
                        if the file is already created
           'x:bz2'      create a bzip2 compressed tarfile, raise an exception
                        if the file is already created
           'x:xz'       create an lzma compressed tarfile, raise an exception
                        if the file is already created

           'r|*'        open a stream of tar blocks with transparent compression
           'r|'         open an uncompressed stream of tar blocks for reading
           'r|gz'       open a gzip compressed stream of tar blocks
           'r|bz2'      open a bzip2 compressed stream of tar blocks
           'r|xz'       open an lzma compressed stream of tar blocks
           'w|'         open an uncompressed stream for writing
           'w|gz'       open a gzip compressed stream for writing
           'w|bz2'      open a bzip2 compressed stream for writing
           'w|xz'       open an lzma compressed stream for writing
        Process a GNU tar extended sparse header, version 0.1.
        GNU.sparse.realsizeConstruct a TarInfo object from a 512 byte bytes object.
        BLOCKSIZE_StreamProxy.__init__TarInfo._decode_pax_fieldCalculate the checksum for a member's header by summing up all
       characters except for the chksum field which is treated as if
       it was filled with spaces. According to the GNU tar sources,
       some tars (Sun and NeXT) calculate chksum with signed char,
       which will be different if there are chars in the buffer with
       the high bit set. So we calculate two checksums, unsigned and
       signed.
    FIFOTYPE_StreamProxy.readGustavo Niemeyer, Niels GustÃ¤bel, Richard Townsend.TarFile.closedevminor_StreamProxy.getcomptypetar_fileslinkname is too longtar_modeWrite string s to the stream.
        %10dTarFile._extract_memberPOSIX_MAGIC<output_dir>TarInfo.islnkMake a (symbolic) link called targetpath. If it cannot be created
          (platform limitation), we try to make a copy of the referenced file
          instead of a link.
        tarfile: Skipped %r{!r} is a tar archive.{!r} is not a tar archive.
TarInfo._create_headerReturn the members of the archive as a list of their names. It has
           the same order as the list returned by getmembers().
        stmdisextended_setpathTarInfo.isregReturn the next member of the archive as a TarInfo object, when
           TarFile is opened for reading. Return None if there is no more
           available.
        seeking backwards is not allowedA thin wrapper around an existing file object that
       provides a part of its data as an individual file
       object.
    invalid formatReturn the next size number of bytes from the stream.
           If size is not defined, return all bytes of the stream
           up to EOF.
        TarFile.utime_create_payloadunsupported compression methodustar   st_gidunexpected end of dataTarInfo._setpath\d+ GNU.sparse.offset=(\d+)\nTarInfo.ischrBZhTarInfo.issparseReturn the stream's file pointer position.
        _safe_print././@PaxHeaderException for empty headers.148B8x356Btar_namecompressionsbltn_open_Stream__writeShow listing of a tarfile_Stream._readTarInfo._create_payloadnot_compressedTarInfo.isdir_extfileobjClass that serves as an adapter between TarFile and
       a stream-like object.  The stream-like object only
       needs to have a read() or write() method and is accessed
       blockwise.  Use of gzip or bzip2 compression is possible.
       A stream-like object could be for example: sys.stdin,
       sys.stdout, a socket, a tape device etc.

       _Stream is intended to be used only internally.
    AREGTYPETarInfo._getlinkpathinodes_Stream.writeReturn the object as a GNU header block sequence.
        Provide an iterator object.
        TarFile.makedevClose the _Stream object. No operation should be
           done on it afterwards.
        Open uncompressed tar archive name for reading or writing.
        TruncatedHeaderErrormap_indexGNUTYPE_SPARSEOPEN_METH0x%X: %sBase exception.SOLARIS_XHDTYPEReplace fields with supplemental information from a previous
           pax extended or global header.
        filename %r not found\d+ hdrcharset=([^\n]+)\nThe TarFile Class provides an interface to tar archives.
    symlink_exceptionfile could not be opened successfullyEmptyHeaderError_Stream.tellfirstmemberTarInfo.isfileGNU_TYPES21 hdrcharset=BINARY
mode must be 'r', 'a', 'w' or 'x'Add the file `name' to the archive. `name' may be any type of file
           (directory, fifo, symbolic link, etc.). If given, `arcname'
           specifies an alternative name for the file in the archive.
           Directories are added recursively by default. This can be avoided by
           setting `recursive' to False. `exclude' is a function that should
           return True for each filename to be excluded. `filter' is a function
           that expects a TarInfo object argument and returns the changed
           TarInfo object, if it returns None the TarInfo object will be
           excluded from the archive.
        TarFile._loadSUPPORTED_TYPES%0*ounsigned_chksumtarfile: Unsupported type %rConstruct a _Stream object.
        LENGTH_LINKReturn the next TarInfo object from TarFile object
           tarfile.
        0.9.0Print a table of contents to sys.stdout. If `verbose' is False, only
           the names of the members are printed. If it is True, an `ls -l'-like
           output is produced. `members' is optional and must be a subset of the
           list returned by getmembers().
        TarInfo._getpathtarfile: Excluded %rcalc_chksumsTarFile.makefile--extractProcess a GNU tar extended sparse header, version 1.0.
        1AY&SYGNU.sparse.nameWrite string s to the stream if a whole new block
           is ready to be written.
        Open gzip compressed tar archive name for reading or writing.
           Appending is not allowed.
        EOFHeaderErrorTarFile.open.<locals>.not_compressed©znamezmodezuidzgidzsizezmtimezchksumztypezlinknamezunamezgnamezdevmajorzdevminorzoffsetzoffset_datazpax_headerszsparseztarfilez_sparse_structsz_link_target%06o fileobjectcreate_ustar_headerTarFile._getmemberProcess a GNU sparse header plus extra headers.
        GNU.sparse.mapException for unavailable compression methods.Choose the right processing method depending on
           the type and call it.
        mode must be 'r', 'w' or 'x'_FileInFile.readable_FileInFile.tell_Stream.seekTarInfo.__init__linkname %r not foundOpen lzma compressed tar archive name for reading or writing.
           Appending is not allowed.
        _LowLevelFile.closeÿTarFile.bz2openMake a character or block device called targetpath.
        Decode a single field from a pax record.
        Process a GNU tar extended sparse header, version 0.0.
        TarFile.__init__Convert a null-terminated bytes object to a string.
    Initialize for writing with gzip compression.
        TarInfo.create_pax_headermode must be 'r' or 'w'TarInfo.create_ustar_headerSplit a name longer than 100 chars into a prefix
           and a name part.
        Return the object as a pax global header block sequence.
        TarFile.makeunknownTarFile.makelinkException for missing and invalid extended headers.Add the TarInfo object `tarinfo' to the archive. If `fileobj' is
           given, it should be a binary file, and tarinfo.size bytes are read
           from it and added to the archive. You can create TarInfo objects
           directly, or by using gettarinfo().
        _FileInFile.closeProcess an extended or global header as described in
           POSIX.1-2008.
        TarInfo._proc_builtinRound up a byte count by BLOCKSIZE and return it,
           e.g. _block(834) => 1024.
        Write debugging output to sys.stderr.
        Read data from the file.
        PAX_NAME_FIELDSSet owner of targetpath according to tarinfo. If numeric_owner
           is True, use .gid/.uid instead of .gname/.uname. If numeric_owner
           is False, fall back to .gid/.uid when the search based on name
           fails.
        TarFile.list_StreamProxy.closeException for invalid headers.Return the current file position.
        Return size bytes from stream. If internal buffer is empty,
           read another block from the stream.
        TarFile.extractall.<locals>.<lambda>TarInfo.isblkLNKTYPEConvert a string to a null-terminated bytes object.
    TarInfo.frombufTarInfo.__repr__Set the stream's file pointer to pos. Negative seeking
           is forbidden.
        SpooledTemporaryFile.__init___get_default_tempdirTemporaryDirectory._cleanupTemporary file wrapper, specialized to switch from BytesIO
    or StringIO to a real file when it exceeds a certain size or
    when a fileno is needed.
    SpooledTemporaryFile.closed_TemporaryFileWrapper.__getattr__.<locals>.func_wrapper_Randomgettempprefix_TemporaryFileWrapper.closeCommon parameter processing for most APIs in this module.output_typeSpooledTemporaryFile.write_RandomNameSequence.rng_TemporaryFileCloser.__del__No usable temporary directory found in %sNo usable temporary directory name foundSpooledTemporaryFile.__iter__SpooledTemporaryFile.flush_TemporaryFileCloser.__init__C:\msys64\mingw64\lib\python3.6\tempfile.pySpooledTemporaryFile.tell_RandomNameSequence.__iter__Look at the type of all args and divine their implied return type.SpooledTemporaryFile.readTMPDIR\tmpW_OK_rngrolloverSpooledTemporaryFile._check_infer_return_typewarn_messageCan't mix bytes and non-bytes in path components.An instance of _RandomNameSequence generates an endless
    sequence of unpredictable strings which can safely be incorporated
    into file names.  Each string is six characters long.  Multiple
    threads can safely use the same instance at the same time.

    _RandomNameSequence is an iterator.Create and return a temporary file.
    Arguments:
    'prefix', 'suffix', 'dir' -- as for mkstemp.
    'mode' -- the mode argument to io.open (default "w+b").
    'buffering' -- the buffer size argument to io.open (default -1).
    'encoding' -- the encoding argument to io.open (default None)
    'newline' -- the newline argument to io.open (default None)
    'delete' -- whether the file is deleted on close (default True).
    The file is created as mkstemp() would do it.

    Returns an object with a file-like interface; the name of the file
    is accessible as its 'name' attribute.  The file will be automatically
    deleted when it is closed unless the 'delete' argument is set to False.
    Calculate the default directory to use for temporary files.
    This routine should be called exactly once.

    We determine whether or not a candidate temp dir is usable by
    trying to create and write to a file in that directory.  If this
    is successful, the test file is deleted.  To prevent denial of
    service, the name of the test file must be randomized.TMP_MAXgettempprefixbgettempdirbblat_TemporaryFileWrapper.__exit__TemporaryDirectory.__init__cur_pid_closerSpooledTemporaryFile.__exit__abcdefghijklmnopqrstuvwxyz0123456789__TemporaryFileWrapper.__iter__Temporary files.

This module provides generic, low- and high-level interfaces for
creating temporary files and directories.  All of the interfaces
provided by this module can be used without fear of race conditions
except for 'mktemp'.  'mktemp' is subject to race conditions and
should not be used; it is provided for backward compatibility only.

The default path names are returned as str.  If you supply bytes as
input, all return values will be in bytes.  Ex:

    >>> tempfile.mkstemp()
    (4, '/tmp/tmptpu9nin8')
    >>> tempfile.mkdtemp(suffix=b'')
    b'/tmp/tmppbi8f0hy'

This module also provides some data items to the user:

  TMP_MAX  - maximum number of names that will be tried before
             giving up.
  tempdir  - If this is set to a string before the first use of
             any routine from this module, it will be considered as
             another candidate location to store temporary files.
_max_size
        Close the temporary file, possibly deleting it.
        _rolledSpooledTemporaryFile.truncate/usr/tmpc:\tmp_TemporaryFileCloser.closeCreate and return a temporary file.
        Arguments:
        'prefix', 'suffix', 'dir' -- as for mkstemp.
        'mode' -- the mode argument to io.open (default "w+b").
        'buffering' -- the buffer size argument to io.open (default -1).
        'encoding' -- the encoding argument to io.open (default None)
        'newline' -- the newline argument to io.open (default None)
        The file is created as mkstemp() would do it.

        Returns an object with a file-like interface.  The file has no
        name, and will cease to exist when it is closed.
        SpooledTemporaryFile.newlinesCannot enter context with closed fileTemporaryDirectory.__repr__SpooledTemporaryFile.encodingUser-callable function to create and return a unique temporary
    file.  The return value is a pair (fd, name) where fd is the
    file descriptor returned by os.open, and name is the filename.

    If 'suffix' is not None, the file name will end with that suffix,
    otherwise there will be no suffix.

    If 'prefix' is not None, the file name will begin with that prefix,
    otherwise a default prefix is used.

    If 'dir' is not None, the file will be created in that directory,
    otherwise a default directory is used.

    If 'text' is specified and true, the file is opened in text
    mode.  Else (the default) the file is opened in binary mode.  On
    some operating systems, this makes no difference.

    If any of 'suffix', 'prefix' and 'dir' are not None, they must be the
    same type.  If they are bytes, the returned name will be bytes; str
    otherwise.

    The file is readable and writable only by the creating user ID.
    If the operating system uses permission bits to indicate whether a
    file is executable, the file is executable by no one. The file
    descriptor is not inherited by children of this process.

    Caller is responsible for deleting the file when done with it.
    SpooledTemporaryFile.fileno_sanitize_paramsSpooledTemporaryFile.softspace<{} {!r}>_shutilTemporaryDirectory.__enter__Generate a list of candidate temporary directories which
    _get_default_tempdir will try._mkstemp_innerclose_calledSpooledTemporaryFile.readlinesO_TEMPORARY_rng_pid<module tempfile>_TemporaryFileWrapper.__enter__c:\temp_TemporaryFileArgs_once_lock_O_TMPFILE_WORKSCreate and return a temporary directory.  This has the same
    behavior as mkdtemp but can be used as a context manager.  For
    example:

        with TemporaryDirectory() as tmpdir:
            ...

    Upon exiting the context, the directory and everything contained
    in it are removed.
    A bytes version of tempfile.gettempdir().Temporary file wrapper

    This class provides a wrapper around files opened for
    temporary use.  In particular, it seeks to automatically
    remove the file when it is no longer needed.
    SpooledTemporaryFile.rolloverSpooledTemporaryFile.seekSpooledTemporaryFile.isattyO_NOFOLLOWenvnameflags2_RandomNameSequence.__next__/var/tmp_TemporaryFileWrapper.__init__SpooledTemporaryFile.__enter__A separate object allowing proper closing of a temporary file's
    underlying file object, without adding a __del__ method to the
    temporary file.SpooledTemporaryFile.nameNo usable temporary filename found_text_openflagsSpooledTemporaryFile.writelines_name_sequenceUser-callable function to create and return a unique temporary
    directory.  The return value is the pathname of the directory.

    Arguments are as for mkstemp, except that the 'text' argument is
    not accepted.

    The directory is readable, writable, and searchable only by the
    creating user.

    Caller is responsible for deleting the directory when done with it.
    User-callable function to return a unique temporary file name.  The
    file is not created.

    Arguments are similar to mkstemp, except that the 'text' argument is
    not accepted, and suffix=None, prefix=None and bytes file names are not
    supported.

    THIS FUNCTION IS UNSAFE AND SHOULD NOT BE USED.  The file name may
    refer to a file that did not exist at some point, but by the time
    you get around to creating it, someone else may have beaten you to
    the punch.
    TemporaryDirectory.cleanupThe default prefix for temporary directories._get_candidate_namesCode common to mkstemp, TemporaryFile, and NamedTemporaryFile.Accessor for tempfile.tempdir._bin_openflagsImplicitly cleaning up {!r}No usable temporary file name foundCommon setup sequence for all user-callable interfaces.The default prefix for temporary directories as bytes.TemporaryDirectory.__exit___candidate_tempdir_listSpooledTemporaryFile.modedisconnecting tensionertensioner got first line for status:Tensioner.__init__Sending command to tensioner controllercommand handledtensioner home stop calledtensioner alert_when_idle exception Tensioner.handlertensioner::check_for_command unexpected exception %stensioner has no ports to close<module tensioner>Tensioner.send_commandTensioner.alert_when_idleTensioner.reconnectleaving first loop of runconnection_is_alive exception 333333Ó?Couldn't connect to tensioner on %sTensioner.runTensioner.connection_is_alivetensioner::send_command exception: %sTensioner.handle_commandtensioner is about to call tensioner_is_idleC:\msys64\home\cbper\tensioner.pyTensioner.tensioner_home_stoptensioner::alert_when_idle reachedcalled tensioner home stoptensioner.handler does not recognize command %sCommunicates with the tensioner ArduinoTensioner.disconnectTensioner.check_for_command_munge_whitespace(text : string) -> string

        Munge whitespace in text: expand tabs and convert all other
        whitespace characters to spaces.  Eg. " foo\tbar\n\nbaz"
        becomes " foo    bar  baz".
        TextWrapper.fillcur_linefill(text : string) -> string

        Reformat the single paragraph in 'text' to fit in lines of no
        more than 'self.width' columns, and return a new string
        containing the entire wrapped paragraph.
        replace_whitespacefix_sentence_endingsbreak_long_wordsdrop_whitespacebreak_on_hyphensmax_linesTextWrapper._munge_whitespace_wrap_chunks[\w!"\'&.,?]prefixed_linesspace_leftRemove any common leading whitespace from every line in `text`.

    This can be used to make triple-quoted strings line up with the left
    edge of the display, while still presenting them in the source code
    in indented form.

    Note that tabs and spaces are both treated as whitespace, but they
    are not equal: the lines "  hello" and "\thello" are
    considered to have no common leading whitespace.  (This behaviour is
    new in Python 2.5; older versions of this module incorrectly
    expanded tabs before searching for common leading whitespace.)
    
        ( # any whitespace
          %(ws)s+
        | # em-dash between words
          (?<=%(wp)s) -{2,} (?=\w)
        | # word, possibly hyphenated
          %(nws)s+? (?:
            # hyphenated word
              -(?: (?<=%(lt)s{2}-) | (?<=%(lt)s-%(lt)s-))
              (?= %(lt)s -? %(lt)s)
            | # end of word
              (?=%(ws)s|\Z)
            | # em-dash
              (?<=%(wp)s) (?=-{2,}\w)
            )
        )Fill a single paragraph of text, returning a new string.

    Reformat the single paragraph in 'text' to fit in lines of no more
    than 'width' columns, and return a new string containing the entire
    wrapped paragraph.  As with wrap(), tabs are expanded and other
    whitespace characters converted to space.  See TextWrapper class for
    available keyword args to customize wrapping behaviour.
    [^\d\W]TextWrapper._fix_sentence_endingscur_len^[ 	]+$_leading_whitespace_re(%s+)indent.<locals>.predicate_handle_long_word(chunks : [string],
                             cur_line : [string],
                             cur_len : int, width : int)

        Handle a chunk of text (most likely a word, not whitespace) that
        is too long to fit in any line.
        wordsep_simple_renowhitespace_fix_sentence_endings(chunks : [string])

        Correct for sentence endings buried in 'chunks'.  Eg. when the
        original text contains "... foo.\nBar ...", munge_whitespace()
        and split() will convert that to [..., "foo.", " ", "Bar", ...]
        which has one too few spaces; this method simply changes the one
        space to two.
        wordsep_reTextWrapper._handle_long_wordText wrapping and filling.
Adds 'prefix' to the beginning of selected lines in 'text'.

    If 'predicate' is provided, 'prefix' will only be added to the lines
    where 'predicate(line)' is True. If 'predicate' is not provided,
    it will default to adding 'prefix' to all non-empty lines that do not
    consist solely of whitespace characters.
    patsearchplaceholder too large for max width<module textwrap>wrap(text : string) -> [string]

        Reformat the single paragraph in 'text' so it fits in lines of
        no more than 'self.width' columns, and return a list of wrapped
        lines.  Tabs in 'text' are expanded with string.expandtabs(),
        and all other whitespace characters (including newline) are
        converted to space.
        indent.<locals>.prefixed_lines	
 unicode_whitespace_trans [...][a-z][\.\!\?][\"\']?\Zprev_lineTextWrapper._wrap_chunksuspace(^[ 	]*)(?:[^ 	
])_wrap_chunks(chunks : [string]) -> [string]

        Wrap a sequence of text chunks and return a list of lines of
        length 'self.width' or less.  (If 'break_long_words' is false,
        some lines may be longer than this.)  Chunks correspond roughly
        to words and the whitespace between them: each chunk is
        indivisible (modulo 'break_long_words'), but a line break can
        come between any two chunks.  Chunks should not have internal
        whitespace; ie. a chunk is either all whitespace or a "word".
        Whitespace chunks will be removed from the beginning and end of
        lines, but apart from that whitespace is preserved.
        _split_chunks_whitespace_only_reTextWrapper._splitsentence_end_rereversed_chunksword_punct
    Object for wrapping/filling text.  The public interface consists of
    the wrap() and fill() methods; the other methods are just there for
    subclasses to override in order to tweak the default behaviour.
    If you want to completely replace the main wrapping algorithm,
    you'll probably have to override _wrap_chunks().

    Several instance attributes control various aspects of wrapping:
      width (default: 70)
        the maximum width of wrapped lines (unless break_long_words
        is false)
      initial_indent (default: "")
        string that will be prepended to the first line of wrapped
        output.  Counts towards the line's width.
      subsequent_indent (default: "")
        string that will be prepended to all lines save the first
        of wrapped output; also counts towards each line's width.
      expand_tabs (default: true)
        Expand tabs in input text to spaces before further processing.
        Each tab will become 0 .. 'tabsize' spaces, depending on its position
        in its line.  If false, each tab is treated as a single character.
      tabsize (default: 8)
        Expand tabs in input text to 0 .. 'tabsize' spaces, unless
        'expand_tabs' is false.
      replace_whitespace (default: true)
        Replace all whitespace characters in the input text by spaces
        after tab expansion.  Note that if expand_tabs is false and
        replace_whitespace is true, every tab will be converted to a
        single space!
      fix_sentence_endings (default: false)
        Ensure that sentence-ending punctuation is always followed
        by two spaces.  Off by default because the algorithm is
        (unavoidably) imperfect.
      break_long_words (default: true)
        Break words longer than 'width'.  If false, those words will not
        be broken, and some lines might be longer than 'width'.
      break_on_hyphens (default: true)
        Allow breaking hyphenated words. If true, wrapping will occur
        preferably on whitespaces and right after hyphens part of
        compound words.
      drop_whitespace (default: true)
        Drop leading and trailing whitespace from lines.
      max_lines (default: None)
        Truncate wrapped lines.
      placeholder (default: ' [...]')
        Append to the last line of truncated text.
    _split(text : string) -> [string]

        Split the text to wrap into indivisible chunks.  Chunks are
        not quite the same as words; see _wrap_chunks() for full
        details.  As an example, the text
          Look, goof-ball -- use the -b option!
        breaks into the following chunks:
          'Look,', ' ', 'goof-', 'ball', ' ', '--', ' ',
          'use', ' ', 'the', ' ', '-b', ' ', 'option!'
        if break_on_hyphens is True, or in:
          'Look,', ' ', 'goof-ball', ' ', '--', ' ',
          'use', ' ', 'the', ' ', '-b', ' ', option!'
        otherwise.
        Collapse and truncate the given text to fit in the given width.

    The text first has its whitespace collapsed.  If it then fits in
    the *width*, it is returned as is.  Otherwise, as many words
    as possible are joined and then the placeholder is appended::

        >>> textwrap.shorten("Hello  world!", width=12)
        'Hello world!'
        >>> textwrap.shorten("Hello  world!", width=11)
        'Hello [...]'
    C:\msys64\mingw64\lib\python3.6\textwrap.pyTextWrapper._split_chunksTextWrapper.__init__invalid width %r (must be > 0)TextWrapper.wrapWrap a single paragraph of text, returning a list of wrapped lines.

    Reformat the single paragraph in 'text' so it fits in lines of no
    more than 'width' columns, and return a list of wrapped lines.  By
    default, tabs in 'text' are expanded with string.expandtabs(), and
    all other whitespace characters (including newline) are converted to
    space.  See TextWrapper class for available keyword args to customize
    wrapping behaviour.
    cannot wait on un-acquired lockA string used for identification purposes only.

        It has no semantics. Multiple threads may be given the same name. The
        initial name is set by the constructor.

        Return whether the thread is alive.

        This method returns True just before the run() method starts until just
        after the run() method terminates. The module function enumerate()
        returns a list of all alive threads.

         (most likely raised during interpreter shutdown):Thread.__init__() not calledStart the thread's activity.

        It must be called at most once per thread object. It arranges for the
        object's run() method to be invoked in a separate thread of control.

        This method will raise a RuntimeError if called more than once on the
        same thread object.

        Thread.is_aliveCondition._acquire_restorenew_activeactive_countReturn a list of all Thread objects currently alive.

    The list includes daemonic threads, dummy thread objects created by
    current_thread(), and the main thread. It excludes terminated threads and
    threads that have not yet been started.

    Create a barrier, initialised to 'parties' threads.

        'action' is a callable which, when supplied, will be called by one of
        the threads after they have all entered the barrier and just prior to
        releasing them all. If a 'timeout' is provided, it is uses as the
        default for all subsequent 'wait()' calls.

        _daemonic_bootstrap_innerBarrier._enter_isliceThread._bootstrap_innerisDaemon_RLock.__exit___profile_hookException in thread %s:
%sThread._reset_internal_lockstlockcannot join current threadBarrier.n_waitingAcquire a semaphore, decrementing the internal counter by one.

        When invoked without arguments: if the internal counter is larger than
        zero on entry, decrement it by one and return immediately. If it is zero
        on entry, block, waiting until some other thread has called release() to
        make it larger than zero. This is done with proper interlocking so that
        if multiple acquire() calls are blocked, release() will wake exactly one
        of them up. The implementation may pick one at random, so the order in
        which blocked threads are awakened should not be relied on. There is no
        return value in this case.

        When invoked with blocking set to true, do the same thing as when called
        without arguments, and return true.

        When invoked with blocking set to false, do not block. If a call without
        an argument would block, return false immediately; otherwise, do the
        same thing as when called without arguments, and return true.

        When invoked with a timeout other than None, it will block for at
        most timeout seconds.  If acquire does not complete successfully in
        that interval, return false.  Return true otherwise.

        Thread._set_ident_DummyThread.__init__Barrier.brokenThread._set_tstate_lockA boolean value indicating whether this thread is a daemon thread.

        This must be set before start() is called, otherwise RuntimeError is
        raised. Its initial value is inherited from the creating thread; the
        main thread is not a daemon thread and therefore all threads created in
        the main thread default to daemon = False.

        The entire Python program exits when no alive non-daemon threads are
        left.

        C:\msys64\mingw64\lib\python3.6\threading.pyPlace the barrier into a 'broken' state.

        Useful in case of error.  Any currently waiting threads and threads
        attempting to 'wait()' will have BrokenBarrierError raised.

        Release a lock, decrementing the recursion level.

        If after the decrement it is zero, reset the lock to unlocked (not owned
        by any thread), and if any other threads are blocked waiting for the
        lock to become unlocked, allow exactly one of them to proceed. If after
        the decrement the recursion level is still nonzero, the lock remains
        locked and owned by the calling thread.

        Only call this method when the calling thread owns the lock. A
        RuntimeError is raised if this method is called when the lock is
        unlocked.

        There is no return value.

        waiters_to_notifyThread.__init__() was not called_RLock.acquirecannot join a dummy threadsetprofile_RLock._release_save_format_exc_MainThread.__init__Class that implements a condition variable.

    A condition variable allows one or more threads to wait until they are
    notified by another thread.

    If the lock argument is given and not None, it must be a Lock or RLock
    object, and it is used as the underlying lock. Otherwise, a new RLock object
    is created and used as the underlying lock.

    main_threadMethod representing the thread's activity.

        You may override this method in a subclass. The standard run() method
        invokes the callable object passed to the object's constructor as the
        target argument, if any, with sequential and keyword arguments taken
        from the args and kwargs arguments, respectively.

        A class that represents a thread of control.

    This class can be safely subclassed in a limited fashion. There are two ways
    to specify the activity: by passing a callable object to the constructor, or
    by overriding the run() method in a subclass.

    Factory function that returns a new reentrant lock.

    A reentrant lock must be released by the thread that acquired it. Once a
    thread has acquired a reentrant lock, the same thread may acquire it again
    without blocking; the thread must release it once for each time it has
    acquired it.

    _RLock.__init__saved_stategotitEvent._reset_internal_locksReturn true if and only if the internal flag is true.Barrier._releaseImplements a bounded semaphore.

    A bounded semaphore checks to make sure its current value doesn't exceed its
    initial value. If it does, ValueError is raised. In most situations
    semaphores are used to guard resources with limited capacity.

    If the semaphore is released too many times it's a sign of a bug. If not
    given, value defaults to 1.

    Like regular semaphores, bounded semaphores manage a counter representing
    the number of release() calls minus the number of acquire() calls, plus an
    initial value. The acquire() method blocks if necessary until it can return
    without making the counter negative. If not given, value defaults to 1.

    This class implements reentrant lock objects.

    A reentrant lock must be released by the thread that acquired it. Once a
    thread has acquired a reentrant lock, the same thread may acquire it
    again without blocking; the thread must release it once for each time it
    has acquired it.

    _initializedThread-%d_newnameThread._wait_for_tstate_lockThread.daemon_RLock._acquire_restore_PyRLock<module threading>Barrier.abortImplements a Barrier.

    Useful for synchronizing a fixed number of threads at known synchronization
    points.  Threads block on 'wait()' and are simultaneously once they have all
    made that call.

    Barrier.waitthread.__init__() not calledcan't specify timeout for non-blocking acquireRelease a semaphore, incrementing the internal counter by one.

        When the counter is zero on entry and another thread is waiting for it
        to become larger than zero again, wake up that thread.

        Barrier._wait.<locals>.<lambda>Barrier.resetThreadErrorThis class implements semaphore objects.

    Semaphores manage a counter representing the number of release() calls minus
    the number of acquire() calls, plus an initial value. The acquire() method
    blocks if necessary until it can return without making the counter
    negative. If not given, value defaults to 1.

    _is_owned_CRLockTimer.runcannot notify on un-acquired lock_exc_info_limboSemaphore released too many timesThread._deletethreads can only be started onceBoundedSemaphore.releaseClass implementing event objects.

    Events manage a flag that can be set to true with the set() method and reset
    to false with the clear() method. The wait() method blocks until the flag is
    true.  The flag is initially false.

    Return True if the barrier is in a broken state.Wait until a condition evaluates to True.

        predicate should be a callable which result will be interpreted as a
        boolean value.  A timeout may be provided giving the maximum time to
        wait.

        Semaphore.__exit__<%s %s.%s object owner=%r count=%d at %s>Set a trace function for all threads started from the threading module.

    The func will be passed to sys.settrace() for each thread, before its run()
    method is called.

    Thread.join_RLock._is_ownedSet a profile function for all threads started from the threading module.

    The func will be passed to sys.setprofile() for each thread, before its
    run() method is called.

    Block until the internal flag is true.

        If the internal flag is true on entry, return immediately. Otherwise,
        block until another thread calls set() to set the flag to true, or until
        the optional timeout occurs.

        When the timeout argument is present and not None, it should be a
        floating point number specifying a timeout for the operation in seconds
        (or fractions thereof).

        This method returns the internal flag on exit, so it will always return
        True except if a timeout is given and the operation times out.

        _main_threadAcquire a lock, blocking or non-blocking.

        When invoked without arguments: if this thread already owns the lock,
        increment the recursion level by one, and return immediately. Otherwise,
        if another thread owns the lock, block until the lock is unlocked. Once
        the lock is unlocked (not owned by any thread), then grab ownership, set
        the recursion level to one, and return. If more than one thread is
        blocked waiting until the lock is unlocked, only one at a time will be
        able to grab ownership of the lock. There is no return value in this
        case.

        When invoked with the blocking argument set to true, do the same thing
        as when called without arguments, and return true.

        When invoked with the blocking argument set to false, do not block. If a
        call without an argument would block, return false immediately;
        otherwise, do the same thing as when called without arguments, and
        return true.

        When invoked with the floating-point timeout argument set to a positive
        value, block for at most the number of seconds specified by timeout
        and as long as the lock cannot be acquired.  Return true if the lock has
        been acquired, false if the timeout has elapsed.

        _is_stopped_RLock.releaseRelease a semaphore, incrementing the internal counter by one.

        When the counter is zero on entry and another thread is waiting for it
        to become larger than zero again, wake up that thread.

        If the number of releases exceeds the number of acquires,
        raise a ValueError.

        Thread._stopWake up all threads waiting on this condition.

        If the calling thread has not acquired the lock when this method
        is called, a RuntimeError is raised.

        Thread.isDaemonWake up one or more threads waiting on this condition, if any.

        If the calling thread has not acquired the lock when this method is
        called, a RuntimeError is raised.

        This method wakes up at most n of the threads waiting for the condition
        variable; it is a no-op if no threads are waiting.

        _start_new_threadThread.identThread.setDaemon<Condition(%s, %d)>Thread module emulating a subset of Java's threading model.notifyAllReturn the current Thread object, corresponding to the caller's thread of control.

    If the caller's thread of control was not created through the threading
    module, a dummy thread object with limited functionality is returned.

    Dummy-%dReturn the number of Thread objects currently alive.

    The returned count is equal to the length of the list returned by
    enumerate().

    _RLock.__repr__Condition._is_ownedRemove current thread from the dict of currently running threads.isAliveBarrier._breakThread.startsemaphore initial value must be >= 0_trace_hook_DummyThread.join_DummyThread.is_aliveCondition._release_saveSemaphore.acquireWait until notified or until a timeout occurs.

        If the calling thread has not acquired the lock when this method is
        called, a RuntimeError is raised.

        This method releases the underlying lock, and then blocks until it is
        awakened by a notify() or notify_all() call for the same condition
        variable in another thread, or until the optional timeout occurs. Once
        awakened or timed out, it re-acquires the lock and returns.

        When the timeout argument is present and not None, it should be a
        floating point number specifying a timeout for the operation in seconds
        (or fractions thereof).

        When the underlying lock is an RLock, it is not released using its
        release() method, since this may not actually unlock the lock when it
        was acquired multiple times recursively. Instead, an internal interface
        of the RLock class is used, which really unlocks it even when it has
        been recursively acquired several times. Another internal interface is
        then used to restore the recursion level when the lock is reacquired.

        Wait for the barrier.

        When the specified number of threads have started waiting, they are all
        simultaneously awoken. If an 'action' was provided for the barrier, one
        of the threads will have executed that callback prior to returning.
        Returns an individual index number from 0 to 'parties-1'.

        Set the internal flag to true.

        All threads waiting for it to become true are awakened. Threads
        that call wait() once the flag is true will not block at all.

        _initial_value_active_limbo_lockStop the timer if it hasn't finished yet.Call a function after a specified number of seconds:

            t = Timer(30.0, f, args=None, kwargs=None)
            t.start()
            t.cancel()     # stop the timer's action if it's still waiting

    Û   z	get_identzactive_countz	Conditionzcurrent_threadz	enumeratezmain_threadzTIMEOUT_MAXzEventzLockzRLockz	SemaphorezBoundedSemaphorezThreadzBarrierzBrokenBarrierErrorzTimerzThreadErrorz
setprofilezsettracezlocalz
stack_sizeReset the internal flag to false.

        Subsequently, threads calling wait() will block until set() is called to
        set the internal flag to true again.

        Return the number of threads required to trip the barrier.
        Set a lock object which will be released by the interpreter when
        the underlying thread state (see pystate.h) gets deleted.
        This constructor should always be called with keyword arguments. Arguments are:

        *group* should be None; reserved for future extension when a ThreadGroup
        class is implemented.

        *target* is the callable object to be invoked by the run()
        method. Defaults to None, meaning nothing is called.

        *name* is the thread name. By default, a unique name is constructed of
        the form "Thread-N" where N is a small decimal number.

        *args* is the argument tuple for the target invocation. Defaults to ().

        *kwargs* is a dictionary of keyword arguments for the target
        invocation. Defaults to {}.

        If a subclass overrides the constructor, it must make sure to invoke
        the base class constructor (Thread.__init__()) before doing anything
        else to the thread.

        Thread.getNamecannot join thread before it is startedactiveCountBarrier._exit_pickSomeNonDaemonThreadReturn the main thread object.

    In normal conditions, the main thread is the thread from which the
    Python interpreter was started.
    Thread.__repr___DummyThread._stopReturn the number of threads currently waiting at the barrier.cannot set daemon status of active threadThread.nameBarrier.partiesReset the barrier to the initial state.

        Any threads currently waiting will get the BrokenBarrier exception
        raised.

        Thread identifier of this thread or None if it has not been started.

        This is a nonzero integer. See the thread.get_ident() function. Thread
        identifiers may be recycled when a thread exits and another thread is
        created. The identifier is available even after the thread has exited.

        Thread.setNameTimer.cancelWait until the thread terminates.

        This blocks the calling thread until the thread whose join() method is
        called terminates -- either normally or through an unhandled exception
        or until the optional timeout occurs.

        When the timeout argument is present and not None, it should be a
        floating point number specifying a timeout for the operation in seconds
        (or fractions thereof). As join() always returns None, you must call
        isAlive() after join() to decide whether a timeout happened -- if the
        thread is still alive, the join() call timed out.

        When the timeout argument is not present or None, the operation will
        block until the thread terminates.

        A thread can be join()ed many times.

        join() raises a RuntimeError if an attempt is made to join the current
        thread as that would cause a deadlock. It is also an error to join() a
        thread before it has been started and attempts to do so raises the same
        exception.

        local_nsdefault_repeatstmt is neither a string nor callable--unit
def inner(_it, _timer{init}):
    {setup}
    _t0 = _timer()
    for _i in _it:
        {stmt}
    _t1 = _timer()
    return _t1 - _t0
%d loops,autorange<module timeit>use -h/--help for command line helptime_takendummy_src_nameMain program, used when run as a script.

    The optional 'args' argument specifies the command line to be parsed,
    defaulting to sys.argv[1:].

    The return value is an exit code to be passed to sys.exit(); it
    may be None to indicate success.

    When an exception happens during timing, a traceback is printed to
    stderr and the return value is 1.  Exceptions at other times
    (including the template compilation) are not caught.

    '_wrap_timer' is an internal interface used for unit testing.  If it
    is not None, it must be a callable that accepts a timer function
    and returns another timer function (used for unit testing).
    Constructor.  See class doc string.--numberunit=default_numberHelper to reindent a multi-line statement.--clockgcold--setup, _stmt=_stmtrepeat=, _setup=_setupClass for timing execution speed of small code snippets.

    The constructor takes a statement to be timed, an additional
    statement used for setup, and a timer function.  Both statements
    default to 'pass'; the timer function is platform-dependent (see
    module doc string).  If 'globals' is specified, the code will be
    executed within that namespace (as opposed to inside timeit's
    namespace).

    To measure the execution time of the first statement, use the
    timeit() method.  The repeat() method is a convenience to call
    timeit() multiple times and return a list of results.

    The statements may contain newlines, as long as they don't contain
    multi-line string literals.
    main.<locals>.callbackraw times:n:u:s:r:tcpvhnumber=<timeit-src>Timer.repeat--repeatHelper to print a traceback from the timed code.

        Typical use:

            t = Timer(...)       # outside the try/except
            try:
                t.timeit(...)    # or t.repeat(...)
            except:
                t.print_exc()

        The advantage over the standard traceback is that source lines
        in the compiled template will be displayed.

        The optional file argument directs where the traceback is
        sent; it defaults to sys.stderr.
        {num} loops -> {secs:.{prec}g} secs_setup()©ÚargsÚ_wrap_timerÚgetoptÚoptsÚerrÚtimerÚstmtÚnumberÚsetupÚrepeatÚverboseÚ	time_unitÚunitsÚ	precisionÚoÚaÚosÚtÚcallbackÚ_ÚrÚbestÚusecÚscaleÚscalesÚworstÚwarnings_stmt()setup is neither a string nor callableprocess_timeperf_counterstmtprefix--processConvenience function to create Timer object and call repeat method.Timer.timeitTimer.print_excThe test results are likely unreliable. The worst
time (%.*g %s) was more than four times slower than the best time.Unrecognized unit. Please select usec, msec, or sec.Convenience function to create Timer object and call timeit method.best of %d: %.*g %s per loopTimer.autorangeCall timeit() a few times.

        This is a convenience function that calls the timeit()
        repeatedly, returning a list of results.  The first argument
        specifies how many times to call timeit(), defaulting to 3;
        the second argument specifies the timer argument, defaulting
        to one million.

        Note: it's tempting to calculate mean and standard deviation
        from the result vector and report these.  However, this is not
        very useful.  In a typical case, the lowest value gives a
        lower bound for how fast your machine can run the given code
        snippet; higher values in the result vector are typically not
        caused by variability in Python's speed, but by other
        processes interfering with your timing accuracy.  So the min()
        of the result is probably the only number you should be
        interested in.  After that, you should look at the entire
        vector and apply common sense rather than statistics.
        Time 'number' executions of the main statement.

        To be precise, this executes the setup statement once, and
        then returns the time it takes to execute the main statement
        a number of times, as a float measured in seconds.  The
        argument is the number of times through the loop, defaulting
        to one million.  The main statement, the setup statement and
        the timer function to be used are passed to the constructor.
        Tool for measuring execution time of small code snippets.

This module avoids a number of common traps for measuring execution
times.  See also Tim Peters' introduction to the Algorithms chapter in
the Python Cookbook, published by O'Reilly.

Library usage: see the Timer class.

Command line usage:
    python timeit.py [-n N] [-r N] [-s S] [-t] [-c] [-p] [-h] [--] [statement]

Options:
  -n/--number N: how many times to execute 'statement' (default: see below)
  -r/--repeat N: how many times to repeat the timer (default 3)
  -s/--setup S: statement to be executed once initially (default 'pass').
                Execution time of this setup statement is NOT timed.
  -p/--process: use time.process_time() (default is time.perf_counter())
  -t/--time: use time.time() (deprecated)
  -c/--clock: use time.clock() (deprecated)
  -v/--verbose: print raw timing results; repeat for more digits precision
  -u/--unit: set the output time unit (usec, msec, or sec)
  -h/--help: print this usage message and exit
  --: separate options from statement, use when statement starts with -
  statement: statement to be timed (default 'pass')

A multi-line statement may be given by specifying each line as a
separate argument; indented lines are possible by enclosing an
argument in quotes and using leading spaces.  Multiple -s options are
treated similarly.

If -n is not given, a suitable number of loops is calculated by trying
successive powers of 10 until the total time is at least 0.2 seconds.

Note: there is a certain baseline overhead associated with executing a
pass statement.  It differs between versions.  The code here doesn't try
to hide it, but you should be aware of it.  The baseline overhead can be
measured by invoking the program without arguments.

Classes:

    Timer

Functions:

    timeit(string, string) -> float
    repeat(string, string) -> list
    default_timer() -> float

C:\msys64\mingw64\lib\python3.6\timeit.pyReturn the number of loops and time taken so that total time >= 0.2.

        Calls the timeit method with *number* set to successive powers of
        ten (10, 100, 1000, ...) up to a maximum of one billion, until
        the time taken is at least 0.2 second, or the maximum is reached.
        Returns ``(number, time_taken)``.

        If *callback* is given and is not None, it will be called after
        each trial with two arguments: ``callback(number, time_taken)``.
        RARROWinFileName#--end constants--#--start constants--C:\msys64\mingw64\lib\python3.6\token.pyLib/token.pyI/O error: %s
ISNONTERMINAL#define[ 	][ 	]*([A-Z0-9][A-Z0-9_]*)[ 	][ 	]*([0-9][0-9]*)outFileNameISTERMINALToken constants (from "token.h").ISEOFNT_OFFSETInclude/token.h<module token>unknown encoding for {!r}: {}_valid_string_prefixes\\\r?\nbom_foundread_or_stopfind_cookieUntokenizer.untokenizeprev_rowline_string\*\*=?>>=?<<=?//=?[+\-*/%&@|^=<>]=?[0-9](?:_?[0-9])*\.(?:[0-9](?:_?[0-9])*)?\.[0-9](?:_?[0-9])*TokenInfolatin-1-iso-8859-1-iso-latin-1-Imagnumber\
Tokenization help for Python programs.

tokenize(readline) is a generator that breaks a stream of bytes into
Python tokens.  It decodes the bytes according to PEP-0263 for
determining source file encoding.

It accepts a readline-like method which is called repeatedly to get the
next line of input (or b"" for EOF).  It generates 5-tuples with these
members:

    the token type (see token.py)
    the token (a string)
    the starting (row, column) indices of the token (a 2-tuple of ints)
    the ending (row, column) indices of the token (a 2-tuple of ints)
    the original line (string)

It is designed to match the working of the Python tokenizer exactly, except
that it produces COMMENT tokens for comments and gives type OP for all
operators.  Additionally, all token lists start with an ENCODING token
which tells you which encoding was used to decode the bytes stream.
TokenError"[^\n"\\]*(?:\\.[^\n"\\]*)*")]}C:\msys64\mingw64\lib\python3.6\tokenize.pyTransform tokens back into Python source code.
    It returns a bytes object, encoded using the ENCODING
    token, which is the first token sequence output by tokenize.

    Each element returned by the iterable must be a token sequence
    with at least two elements, a token number and token value.  If
    only two tokens are passed, the resulting output is poor.

    Round-trip invariant for full input:
        Untokenized source will match input source exactly

    Round-trip invariant for limited input:
        # Output bytes will tokenize back to the input
        t1 = [tok[:2] for tok in tokenize(f.readline)]
        newcode = untokenize(t1)
        readline = BytesIO(newcode).readline
        t2 = [tok[:2] for tok in tokenize(readline)]
        assert t1 == t2
    Open a file in read only mode using the encoding detected by
    detect_encoding().
    --exactencoding problem: utf-8toks_appendIntnumberendpats[:;.,@]Double30[oO](?:_?[0-7])+invalid or missing encoding declaration0[xX](?:_?[0-9a-fA-F])+PseudoExtras_get_normal_name(?:0(?:_?0)*|[1-9](?:_?[0-9])*)unknown encoding: #[^\r\n]*Expfloatunexpected error: %s[^"\\]*(?:(?:\\.|"(?!""))[^"\\]*)*"""© ÚreadlineÚencodingÚlnumÚparenlevÚ	continuedÚnumcharsÚcontstrÚneedcontÚcontlineÚindentsÚstashedÚ	async_defÚasync_def_indentÚasync_def_nlÚlineÚposÚmaxÚendmatchÚendÚcolumnÚcomment_tokenÚnl_posÚpseudomatchÚstartÚsposÚeposÚtokenÚinitialÚendprogÚstrstartÚtokÚindentHexnumber%-20s%-15s%-15rannotated_typeStopTokenizing0[bB](?:_?[01])+ContStrtype string start end linetok_type%d,%d-%d,%d:filename.py\\\r?\n|\Zadd_whitespacepython -m tokenizeTokenInfo.exact_type[^'\\]*(?:(?:\\.|'(?!''))[^'\\]*)*'''blank_rerl_gen'[^\n'\\]*(?:\\.[^\n'\\]*)*Single3the file to tokenize; defaults to stdindisplay token names using the exact typeBinnumberencoding problem for {!r}: utf-8^[ \t\f]*#.*?coding[:=][ \t]*([-\w.]+)PlainToken[jJ]PointfloatEXACT_TOKEN_TYPESPseudoTokenmain.<locals>.perrormain.<locals>.error^[ \t\f]*(?:[#\r\n]|$)Untokenizer.__init__%s:%d:%d: error: %s_all_string_prefixes{} for {!r}prevstringrow_offset<module tokenize>toknum
    The detect_encoding() function is used to detect the encoding that should
    be used to decode a Python source file.  It requires one argument, readline,
    in the same way as the tokenize() generator.

    It will call readline a maximum of twice, and return the encoding used
    (as a string) and a list of any lines (left as bytes) it has read in.

    It detects the encoding from the presence of a utf-8 bom or an encoding
    cookie as specified in pep-0263.  If both a bom and a cookie are present,
    but disagree, a SyntaxError will be raised.  If the encoding cookie is an
    invalid charset, raise a SyntaxError.  Note that if a utf-8 bom is found,
    'utf-8-sig' is returned.

    If no encoding is specified, then the default of 'utf-8' will be returned.
    permutationstoken_range[eE][-+]?[0-9](?:_?[0-9])*cookie_re
    The tokenize() generator requires one argument, readline, which
    must be a callable object which provides the same interface as the
    readline() method of built-in file objects.  Each call to the function
    should return one line of input as bytes.  Alternatively, readline
    can be a callable function terminating with StopIteration:
        readline = open(myfile, 'rb').__next__  # Example of alternate readline

    The generator produces 5-tuples with these members: the token type; the
    token string; a 2-tuple (srow, scol) of ints specifying the row and
    column where the token begins in the source; a 2-tuple (erow, ecol) of
    ints specifying the row and column where the token ends in the source;
    and the line on which the token was found.  The line passed is the
    logical line; continuation lines are included.

    The first token sequence will always be an ENCODING token
    which tells you which encoding was used to decode the bytes stream.
    tokvaldetect_encoding.<locals>.find_cookieTokenInfo.__repr__StringPrefix<tokenize>[][(){}]Untokenizer.add_whitespacestartline'[^\n'\\]*(?:\\.[^\n'\\]*)*'[0-9](?:_?[0-9])*[jJ]detect_encoding.<locals>.read_or_stopFunnytriple_quotedsingle_quotedImitates get_normal_name in tokenizer.c.[^'\\]*(?:\\.[^'\\]*)*'unindent does not match any outer indentation levelFloatnumberOctnumberstart ({},{}) precedes previous end ({},{})Untokenizer.compat#
orig_enc[^"\\]*(?:\\.[^"\\]*)*"GvR, ESR, Tim Peters, Thomas Wouters, Fred Drake, Skip Montanaro, Raymond Hettinger, Trent Nelson, Michael FoordTokenInfo(type=%s, string=%r, start=%r, end=%r, line=%r)EOF in multi-line statementprev_col[ \f\t]*%d (%s)DecnumberEOF in multi-line stringformat_tbFrameSummary.__eq__TracebackException.__eq__print_lastPrint up to 'limit' stack trace entries from the traceback 'tb'.

    If 'limit' is omitted or None, all entries are printed.  If 'file'
    is omitted or None, the output goes to sys.stderr; otherwise
    'file' should be an open file or file-like object with a write()
    method.
    FrameSummary.__repr__Format the exception.

        If chain is not *True*, *__cause__* and *__context__* will not be formatted.

        The return value is a generator of strings, each ending in a newline and
        some containing internal newlines. `print_exception` is a wrapper around
        this method which just prints the lines to a file.

        The message indicating which exception occurred is always the last
        string in the output.
        <unprintable %s object>extract_stack{}: {}
Print exception up to 'limit' stack trace entries from 'tb' to 'file'.

    This differs from print_tb() in the following ways: (1) if
    traceback is not None, it prints a header "Traceback (most recent
    call last):"; (2) it prints the exception type and value after the
    stack trace; (3) if type is SyntaxError and value has the
    appropriate format, it prints the line where the syntax error
    occurred with a caret on the next line indicating the approximate
    position of the error.
    StackSummary.from_listextract_tbFrameSummary.__iter__Create a TracebackException from an exception.no last exceptionFrameSummary.__init__    {}^
TracebackException.__init__badlineC:\msys64\mingw64\lib\python3.6\traceback.pyShorthand for 'format_list(extract_stack(f, limit))'.last_fileFrameSummary.linewalk_stack
During handling of the above exception, another exception occurred:

_context_messagefrom_exceptionAn exception ready for rendering.

    The traceback module captures enough attributes from the original exception
    to this intermediary form to ensure that no references are held, while
    still being able to fully print or format it.

    Use `from_exception` to create TracebackException instances from exception
    objects, or the constructor to create TracebackException instances from
    individual components.

    - :attr:`__cause__` A TracebackException of the original *__cause__*.
    - :attr:`__context__` A TracebackException of the original *__context__*.
    - :attr:`__suppress_context__` The *__suppress_context__* value from the
      original exception.
    - :attr:`stack` A `StackSummary` representing the traceback.
    - :attr:`exc_type` The class of the original traceback.
    - :attr:`filename` For syntax errors - the filename where the error
      occurred.
    - :attr:`lineno` For syntax errors - the linenumber where the error
      occurred.
    - :attr:`text` For syntax errors - the text where the error
      occurred.
    - :attr:`offset` For syntax errors - the offset into the text where the
      error occurred.
    - :attr:`msg` For syntax errors - the compiler error message.
    Format the exception part of a traceback.

    The arguments are the exception type and value such as given by
    sys.last_type and sys.last_value. The return value is a list of
    strings, each ending in a newline.

    Normally, the list contains a single string; however, for
    SyntaxError exceptions, it contains several lines that (when
    printed) display detailed information about where the syntax
    error occurred.

    The message indicating which exception occurred is always the last
    string in the list.

    
The above exception was the direct cause of the following exception:

lookup_linesTracebackException.formatExtract, format and print information about Python stack traces.This is a shorthand for 'print_exception(sys.last_type,
    sys.last_value, sys.last_traceback, limit, file)'.tracebacklimitTracebackException.__str__Format a list of traceback entry tuples for printing.

    Given a list of tuples as returned by extract_tb() or
    extract_stack(), return a list of strings ready for printing.
    Each string in the resulting list corresponds to the item with the
    same index in the argument list.  Each string ends in a newline;
    the strings may contain internal newlines as well, for those items
    whose source text line is not None.
    A stack of frames.  File "{}", line {}
extracted_list  [Previous line repeated <FrameSummary file {filename}, line {lineno} in {name}>Format the exception part of the traceback.

        The return value is a generator of strings, each ending in a newline.

        Normally, the generator emits a single string; however, for
        SyntaxError exceptions, it emites several lines that (when
        printed) display detailed information about where the syntax
        error occurred.

        The message indicating which exception occurred is always the last
        string in the output.
        Clear all references to local variables in the frames of a traceback.frame_genConstruct a FrameSummary.

        :param lookup_line: If True, `linecache` is consulted for the source
            code line. Otherwise, the line will be looked up when first needed.
        :param locals: If supplied the frame locals, which will be captured as
            object representations.
        :param line: If provided, use this instead of looking up the line in
            the linecache.
        Print a stack trace from its invocation point.

    The optional 'f' argument can be used to specify an alternate
    stack frame at which to start. The optional 'limit' and 'file'
    arguments have the same meaning as for print_exception().
    TracebackException.format_exception_only.<locals>.<genexpr>walk_tb<no detail available> more times]
Print the list of tuples as returned by extract_tb() or
    extract_stack() as a formatted stack trace to the given file.    {name} = {value}
FrameSummary.__getitem__A shorthand for 'format_list(extract_tb(tb, limit))'.<module traceback>Walk a traceback yielding the frame and line number for each frame.

    This will follow tb.tb_next (and thus is in the opposite order to
    walk_stack). Usually used with StackSummary.extract.
    _cause_messagelast_nameFrameSummary.__init__.<locals>.<genexpr>fnames_some_strTracebackException._load_linesStackSummary.formatReturn list of up to limit pre-processed entries from traceback.

    This is useful for alternate formatting of stack traces.  If
    'limit' is omitted or None, all entries are extracted.  A
    pre-processed stack trace entry is a quadruple (filename, line
    number, function name, text) representing the information that is
    usually printed for a stack trace.  The text is a string with
    leading and trailing whitespace stripped; if the source is not
    available it is None.
    _format_final_exc_lineCreate a StackSummary from a simple list of tuples.

        This method supports the older Python API. Each tuple should be a
        4-tuple with (filename, lineno, name, line) elements.
        A single frame from a traceback.

    - :attr:`filename` The filename for the frame.
    - :attr:`lineno` The line within filename for the frame that was
      active when the frame was captured.
    - :attr:`name` The name of the function or method that was executing
      when the frame was captured.
    - :attr:`line` The text from the linecache module for the
      of code that was running when the frame was captured.
    - :attr:`locals` Either None if locals were not supplied, or a dict
      mapping the name to the repr() of the variable.
    Extract the raw traceback from the current stack frame.

    The return value has the same format as for extract_tb().  The
    optional 'f' and 'limit' arguments have the same meaning as for
    print_stack().  Each item in the list is a quadruple (filename,
    line number, function name, text), and the entries are in order
    from oldest to newest stack frame.
    Format a stack trace and the exception information.

    The arguments have the same meaning as the corresponding arguments
    to print_exception().  The return value is a list of strings, each
    ending in a newline and some containing internal newlines.  When
    these lines are concatenated and printed, exactly the same text is
    printed as does print_exception().
    caretspacePrivate API. force all lines in the stack to be loaded.Like print_exc() but return a string.Shorthand for 'print_exception(*sys.exc_info(), limit, file)'.Walk a stack yielding the frame and line number for each frame.

    This will follow f.f_back from the given frame. If no frame is given, the
    current stack is used. Usually used with StackSummary.extract.
      File "{}", line {}, in {}
Format the stack ready for printing.

        Returns a list of strings ready for printing.  Each string in the
        resulting list corresponds to a single frame from the stack.
        Each string ends in a newline; the strings may contain internal
        newlines as well, for those items with source text lines.

        For long sequences of the same frame and line, the first few
        repetitions are shown, followed by a summary line stating the exact
        number of further repetitions.
        TracebackException.from_exceptionCreate a StackSummary from a traceback or stack object.

        :param frame_gen: A generator that yields (frame, lineno) tuples to
            include in the stack.
        :param limit: None to include all frames or the number of frames to
            include.
        :param lookup_lines: If True, lookup lines for each frame immediately,
            otherwise lookup is deferred until the frame is rendered.
        :param capture_locals: If True, the local variables from each frame will
            be captured as object representations into the FrameSummary.
        filter_tracesKiBStatisticDiff.__eq__Frame.lineno_format_sizeStatistic.__repr__Traceback.__eq__Statistic.__hash__
        Write the snapshot into a file.
        Snapshot.compare_totrace_tracebacknew_traces
    Statistic difference on memory allocations between two Snapshot instance.
    _group_byStatistic.__str__
        Load a snapshot from a file.
        %s: size=%s (%s), count=%i (%+i)
        Create a new Snapshot instance with a filtered traces sequence, filters
        is a list of Filter or DomainFilter instances.  If filters is an empty
        list, return a new Snapshot instance with a copy of the traces.
        Filter._match_frame_implcumulative mode cannot by used with key type %r_Traces.__getitem__.<locals>.<genexpr>DomainFilter._match<module tracemalloc>count_diffkey_typeFilter.filename_patternStatistic.__init__unknown key_type: %ris_tracingnew_groupFrame.__str__%s: size=%s, count=%iBaseFilter.__init__Trace.__hash__, average=%s_tracemalloc
    Snapshot of traces of memory blocks allocated by Python.
    C:\msys64\mingw64\lib\python3.6\tracemalloc.py_get_object_tracebackold_groupStatistic._sort_key_compare_grouped_statsinclude_filtersexclude_filterstrace_filter_filename_patternDomainFilter.__init__Trace.__eq__get_traceback_limitFrame.filenameFrame.__hash__Traceback.__len__Trace.tracebackSnapshot.statistics<Trace domain=%s size=%s, traceback=%r>Traceback.__contains__
    Trace of a memory block.
    filters must be a list of filters, not %s_Traces.__len__%+.0f %sFrame.__lt__Traceback.__getitem__
    Frame of a traceback.
    _Traces.__eq__
        Compute the differences with an old snapshot old_snapshot. Get
        statistics as a sorted list of StatisticDiff instances, grouped by
        group_by.
        _match_traceback%.1f %sMiBFilter._match_traceback
    Statistic difference on memory allocations between an old and a new
    Snapshot instance.
    _normalize_filenameBaseFilter._matchTrace.__str__Statistic.__eq__
        Group statistics by key_type. Return a sorted list of Statistic
        instances.
        StatisticDiff._sort_keySnapshot._filter_trace.<locals>.<genexpr>TiBTraceback.format<StatisticDiff traceback=%r size=%i (%+i) count=%i (%+i)>%.0f %s<Frame filename=%r lineno=%r>Traceback.__getitem__.<locals>.<genexpr>_Traces.__contains___Traces.__repr__Frame.__init__Trace.sizeTrace.__init__Traceback.__lt__Frame.__eq__StatisticDiff.__repr__
    Take a snapshot of traces of memory blocks allocated by Python.
    the tracemalloc module must be tracing memory allocations to take a snapshot%+.1f %sDomainFilter.domain_Traces.__init___get_tracesTraceback.__hash__all_framesTraceback.__repr__<Traces len=%s>GiB<Statistic traceback=%r size=%i count=%i>
    Sequence of Frame instances sorted from the most recent frame
    to the oldest frame.
    Snapshot.dumpStatisticDiff.__str__
    Get the traceback where the Python object *obj* was allocated.
    Return a Traceback instance.

    Return None if the tracemalloc module is not tracing memory allocations or
    did not trace the allocation of the object.
    <Traceback %r>Filter._match_traceback.<locals>.<genexpr>Snapshot.__init__Snapshot._group_byStatisticDiff.__init__size_diffTrace.domainTrace.__repr__Snapshot.filter_tracesSnapshot.loadStatisticDiff.__hash__Frame.__repr__C:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\tree\__init__.pybuildParseTreeneeds__initializing__buildConditionalExpressionNodeAugAssignReformulationWithStatementsmodule_variableReformulationSubscriptExpressionsMemory usage changed loading module '%s': %sbuildTryFinallyNode2.<locals>.<lambda>ReformulationLambdaExpressionsbuildBytesNodeis_modulepath_imported_namebuildStatementLoopContinue'continue' not supported inside 'finally' clauseC:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\tree\Building.pyReformulationNamespacePackagesReformulationCallExpressionsError, '%s' is not a proper python module name.
buildReturnNode'return' outside functionReformulationAssertStatementsparameter_namesbuildReprNodebuildTryNode.<locals>.<lambda>ReformulationContractionExpressions<module tree.Building>buildEllipsisNodebuildAwaitNode%s: Using 'global' statement on module level has no effect.FormattedValueReformulationComparisonExpressionsbuildNamedConstantNodebuildJoinedStrNodebuildStringNode%s: can't open file '%s'.
handleNonlocalDeclarationNodeReformulationYieldExpressionsReformulationClassesReformulationWhileLoopStatementsbuildRaiseNodeAnnAssign'return' with value in async generatorReformulationForLoopStatementsbuildConditionNode Build the internal node tree from source code.

Does all the Python parsing and puts it into a tree structure for use in later
stages of the compilation process.

In the "nuitka.tree.TreeHelpers" module, the dispatching is happening. One function
deals with every node kind as found in the AST. The parsing is centered around
the module "ast" output.

Many higher level language features and translated into lower level ones.

In-place assignments, for loops, while loops, classes, complex calls, with
statements, and even or/and etc. are all translated to simpler constructs.

The output of this module is a node tree, which contains only relatively low
level operations. A property of the output is also an overlaid tree of provider
structure that indicates variable provision.

Classes are handled in a separate module. They are re-formulated into functions
producing dictionaries used to call the metaclass with.

Try/except/else statements are handled in a separate module. They are
re-formulated into using a temporary variable to track if the else branch
should execute.

Try/finally statements are handled in a separate module. They are re-formulated
to use a nested try/finally for (un)publishing the exception for Python3.

With statements are handled in a separate module. They are re-formulated into
special attribute lookups for "__enter__" and "__exit__", calls of them,
catching and passing in exceptions raised.

buildExprOnlyNodename '%s' is parameter and nonlocalbuildVariableReferenceNode%s: can't find '__main__' module in '%s'
buildBinaryOpNodeTryExceptReformulationExecStatementsAsyncForname '%s' is %s and globalmaximum recursion depthtbackbuildNumberNodehandleGlobalDeclarationNode'return' with argument inside generatorbuildFormattedValueNode The code of the module is too complex.

        It cannot be compiled, with recursive code, and therefore the bytecode
        should be used instead.

        Example of this is "idnadata".
    cannot make __class__ globalbuildAttributeNodeIfExpbuildStatementLoopBreakReformulationPrintStatementsbuildUnaryOpNodestar_list_variablemapping_casenon_tuple_codecomplex_call_helper_dict_unpacking_checksmakeStarListArgumentErrorRaise_makeRaiseDuplicationItemcalled_variablestar_dict_variablecomplex_call_helper_pos_star_list_makeNameAttributeLookupgetCallableNameDescBody.<locals>.<genexpr>star_arg_dict_variabletmp_keys_variablekw_variablecomplex_call_helper_pos_keywords_star_list_star_dictnormal_casestmp_key_variableinstance_case_makeRaiseExceptionMustBeMappingcomplex_call_helper_star_dictdicts_itercomplex_call_helper_keywords_star_list_star_dictdict_itercomplex_call_helper_star_list_star_dictstar_arg_listtmp_iter2_variabletree.ComplexCallHelperFunctionscomplex_call_helper_pos_keywords_star_dictfunctions_caseclass_caseargs_itemstar_arg_list_variableupdate_bodytmp_dict_variablemapping_loop_bodydict_loop_bodydict_caseorderArgs.<locals>.weight This module is providing helper functions for complex call re-formulations.

One for each type of call. _makeIteratingLoopStatement_makeStarDictArgumentToDictStatement_makeStarDictArgumentMergeToKwStatementkey_xxx<module tree.ComplexCallHelperFunctions>getDoubleStarArgsConversion_makeStarListArgumentToTupleStatementget_callable_name_desccomplex_call_helper_pos_star_list_star_dictC:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\tree\ComplexCallHelperFunctions.pycomplex_call_helper_pos_star_dictcomplex_call_helper_keywords_star_dictVariableWriteExtractor.onEnterNode Extracting visitors.

This is used for look-aheads supporting abstract execution. We need to e.g.
know the variables written by a piece of code ahead of abstractly executing a
loop.
VariableWriteExtractor.getResult Extract variables written to.

    written_toVariableUsageUpdater.onEnterNodeisStatementReleaseVariableVariableWriteExtractor.__init__VariableUsageUpdater.__init__<module tree.Extractions>C:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\tree\Extractions.pycached_value<module tree.InternalModule> Cache result of a function call without arguments.

    Used for all internal function accesses to become a singleton.

    Note: This doesn't much specific anymore, but we are not having
    this often enough to warrent re-use or generalization.

     Internal module

This is a container for helper functions that are shared across modules. It
may not exist, and is treated specially in code generation. This avoids to
own these functions to a random module.
once_decorator.<locals>.replacementC:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\tree\InternalModule.py Get the singleton internal module.

     Overloaded for operation before the node children were done. visitFunctionC:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\tree\Operations.py Overloaded for operation after the node children were done. <module tree.Operations>VisitorNoopMixin.onLeaveNode Operations on the tree.

This is mostly for the different kinds of visits that the node tree can have.
You can visit a scope, a tree (module), or every scope of a tree (module).

VisitorNoopMixin.onEnterNodevisitModule'None' child encounteredraise_statement<module tree.ReformulationAssertStatements>C:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\tree\ReformulationAssertStatements.py Reformulation of assert statements.

Consult the developer manual for information. TODO: Add ability to sync
source code comments with developer manual sections.

sub_nodeexecute_in_placeslice_kindstarred assignment target must be in a list or tupletuple_unpacktwo starred expressions in assignmentinplace_assign_subscrinplace_node_buildInplaceAssignSubscriptNodeinplace_to_tmpcopy_to_tmptree.ReformulationAssignmentStatements_buildInplaceAssignAttributeNodetmp_sourceinplace_assign_attrpreserve_to_tmp2source_iter_buildInplaceAssignVariableNodelower_ref1lower_ref2tmp_variable1tmp_variable2copy_back_from_tmp_buildInplaceAssignSliceNodeC:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\tree\ReformulationAssignmentStatements.pybuildAssignmentStatementsFromDecodeddim_kinddecodeAssignTarget.<locals>.<genexpr> Python3.6 annotation assignment.

    assign_unpacktmp_variable3final_statementsupper_ref1inplace_assign_slicedimsupper_ref2preserve_to_tmp1©ÚproviderÚkindÚdetailÚsourceÚ
source_refÚlookup_sourceÚattribute_nameÚ
subscribedÚ	subscriptÚlowerÚupperÚuse_sliceobjÚ
temp_scopeÚsource_iter_varÚelement_varsÚstarred_list_varÚstarred_indexÚ
statementsÚelement_indexÚelementÚelement_varÚiter_creation_classÚfinal_statements Reformulation of assignment statements.

Consult the developer manual for information. TODO: Add ability to sync
source code comments with developer manual sections.

<module tree.ReformulationAssignmentStatements> Reformulation of boolean and/or expressions.

Consult the developer manual for information. TODO: Add ability to sync
source code comments with developer manual sections.

tree.ReformulationBooleanExpressions<module tree.ReformulationBooleanExpressions>C:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\tree\ReformulationBooleanExpressions.pybool_opbuildOrNodenode_arg Reformulation of call expressions.

Consult the developer manual for information. TODO: Add ability to sync
source code comments with developer manual sections.

C:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\tree\ReformulationCallExpressions.pytree.ReformulationCallExpressionstmp_called<module tree.ReformulationCallExpressions>_makeCallNodebuildCallNode.<locals>.<genexpr>get_helperdict_unpacking_call<module tree.ReformulationClasses>class_decl_dicttmp_class_dicttmp_metaclass_buildClassNode2class_statement_nodesclass_doctmp_basesselect_metaclass©ÚproviderÚnodeÚ
source_refÚclass_statement_nodesÚ	class_docÚ
temp_scopeÚ	tmp_basesÚtmp_class_decl_dictÚtmp_metaclassÚtmp_preparedÚclass_creation_functionÚclass_variableÚclass_variable_refÚparent_moduleÚcode_objectÚbodyÚsource_ref_origÚ
statementsÚqualnameÚqualname_refÚqualname_assignÚdecorated_bodyÚ	decoratorÚkeywordsÚ unspecified_metaclass_expressionÚfinal Reformulation of class statements.

Consult the developer manual for information. TODO: Add ability to sync
source code comments with developer manual sections.

_buildClassNode3C:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\tree\ReformulationClasses.pybuildComplexComparisonNode.<locals>.makeValueComparisonReturnC:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\tree\ReformulationComparisonExpressions.py<module tree.ReformulationComparisonExpressions>comparison_chainmakeTempAssignmentcomparison_resultbuildComplexComparisonNode.<locals>.makeTempAssignmentoperand_%dmakeReleaseStatementbuildComplexComparisonNode.<locals>.makeReleaseStatement Reformulation of comparison chain expressions.

Consult the developer manual for information. TODO: Add ability to sync
source code comments with developer manual sections.

maker_classbuildGeneratorExpressionNode.<locals>.<genexpr>_makeIteratorNextnext_classis_asynciterator_refrelease_statements_getStopIterationNametree.ReformulationContractionExpressionsiter_value_%dcontainer_tmp_buildContractionBodyNodeiter_tmpcontraction_resultifsassign_provideremit_classassign_iter_statementcontraction_iter_%dC:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\tree\ReformulationContractionExpressions.py<module tree.ReformulationContractionExpressions>©ÚproviderÚnodeÚ
emit_classÚstart_valueÚcontainer_tmpÚiter_tmpÚ
temp_scopeÚassign_providerÚfunction_bodyÚ
source_refÚtmp_variablesÚ
statementsÚcurrent_bodyÚcountÚqualÚtmp_value_variableÚiterator_refÚtmp_iter_variableÚnested_statementsÚvalue_iteratorÚloop_statementsÚ
conditionsÚrelease_statementsiter_class_buildContractionNodelist_contraction_buildPython2ListContraction_makeIteratorCreation Reformulation of contraction expressions.

Consult the developer manual for information. TODO: Add ability to sync
source code comments with developer manual sections.

_unpack_dictC:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\tree\ReformulationDictionaryCreation.pytree.ReformulationDictionaryCreationbuildDictionaryUnpacking<module tree.ReformulationDictionaryCreation>getDictUnpackingHelper Reformulation of dictionary creations.

Dictionary creations might be directly translated to constants, or they might
become nodes that build dictionaries.

For Python3.5, unpacking can happen while creating dictionaries, these are
being re-formulated to an internal function.

Consult the developer manual for information. TODO: Add ability to sync
source code comments with developer manual sections.

<module tree.ReformulationExecStatements>globals_valueglobals_keeper_variablelocals_keeper_variableplain_indicator_variableC:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\tree\ReformulationExecStatements.pyexec: arg 1 must be a string, file, or code object Wrap the locals and globals arguments for "eval".

        This is called from the outside, and when the node tree
        already exists.
    locals_default Reformulation of "exec" statements

Consult the developer manual for information. TODO: Add ability to sync
source code comments with developer manual sections.

tree.ReformulationForLoopStatementsC:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\tree\ReformulationForLoopStatements.pycleanup_statements_buildForLoopNodeiter_sourcefor_loop Reformulation of for loop statements.

Consult the developer manual for information. TODO: Add ability to sync
source code comments with developer manual sections.

for_iterator<module tree.ReformulationForLoopStatements>©ÚproviderÚfunction_kindÚnameÚfunction_docÚflagsÚnodeÚ
source_refÚkindÚ
extractArgÚspecial_argsÚextractNormalArgsÚnormal_argsÚ
parametersÚmessageÚparent_moduleÚcode_objectÚ
outer_bodyÚ
inner_nameÚ	iter_varsÚvaluesÚ
statementsÚ
unpackFromÚarg_nameÚsourceÚ	code_bodyspecial_arg_namekw_only_name Reformulation of function statements.

Consult the developer manual for information. TODO: Add ability to sync
source code comments with developer manual sections.

buildFunctionWithParsing.<locals>.<lambda>sub_special_indexbuildParameterAnnotations.<locals>.extractArgbuildParameterAnnotations.<locals>.<lambda>buildFunctionWithParsing.<locals>.extractArgkwargannotationC:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\tree\ReformulationFunctionStatements.pyfunction_statements_bodybuildFunctionWithParsing.<locals>.unpackFromunsupported for kind ©ÚproviderÚnodeÚ
source_refÚfunction_statement_nodesÚfunction_docÚfunction_kindÚflagsÚcreator_function_bodyÚ_Úcode_objectÚfunction_bodyÚvariableÚ
decoratorsÚdefaultsÚfunction_statements_bodyÚannotationsÚkw_defaultsÚcreation_nodeÚfunction_creationÚdecorated_functionÚ	decoratorÚresultkw_only_namesbuildParameterAnnotations.<locals>.addAnnotation_insertInitialSetLocalsDictStatementreturn_statementarg_varlocals_statementsub_arg$inner<module tree.ReformulationFunctionStatements>_insertFinalReturnStatement©ÚproviderÚnodeÚ
source_refÚfunction_statement_nodesÚfunction_docÚfunction_kindÚflagsÚfunction_bodyÚ	code_bodyÚcode_objectÚvariableÚ
decoratorsÚdefaultsÚkw_defaultsÚfunction_statements_bodyÚannotationsÚfunction_creationÚ	decoratorÚdecorated_functionÚresultbuildFunctionWithParsing.<locals>.extractNormalArgsarg_iter_%dvarargannotationmodule_topnamefrom __future__ imports must occur at the beginning of the fileimport_fromasname<module tree.ReformulationImportStatements>not a chance_future_specsfuture feature %s is not defined_local_name_future_import_nodes Reformulation of import statements.

Consult the developer manual for information. TODO: Add ability to sync
source code comments with developer manual sections.

©ÚproviderÚnodeÚ
source_refÚmodule_nameÚlevelÚ	level_objÚtarget_namesÚimport_namesÚimport_descÚobject_nameÚ
local_nameÚimport_globalsÚimport_localsÚimported_from_moduleÚmulti_namesÚ
statementsÚtmp_import_fromÚimport_statementsÚfirstÚtarget_nameÚimport_nameC:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\tree\ReformulationImportStatements.pyimport * only allowed at module level_handleFutureImport_enableFutureFeaturetree.ReformulationLambdaExpressionsC:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\tree\ReformulationLambdaExpressions.py Reformulation of lambda expressions.

Consult the developer manual for information. TODO: Add ability to sync
source code comments with developer manual sections.

frame_class<module tree.ReformulationLambdaExpressions>C:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\tree\ReformulationNamespacePackages.pypackage_package_name<module tree.ReformulationNamespacePackages>path_partcreatePython3NamespacePathNUITKA_PACKAGE_%s
Namespace packages of Python3.3 or higher

path_value/notexistcreatePathAssignment.<locals>.makeCalltarget_default_statementtree.ReformulationPrintStatements<module tree.ReformulationPrintStatements>tmp_target_variableprint_statements Reformulation of print statements.

Consult the developer manual for information. TODO: Add ability to sync
source code comments with developer manual sections.

C:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\tree\ReformulationPrintStatements.py<module tree.ReformulationSequenceCreation>can use starred expression only as assignment target_buildSequenceUnpacking_buildTupleUnpacking_unpack_setgetListUnpackingHelper_buildSetUnpackinggetSetUnpackingHelperC:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\tree\ReformulationSequenceCreation.py_unpack_list For use in Python3 classes for the bases.

     Reformulation of sequence creations.

Sequences might be directly translated to constants, or they might become
nodes that build tuples, lists, or sets.

For Python3.5, unpacking can happen while creating sequences, these are
being re-formulated to an internal function.

Consult the developer manual for information. TODO: Add ability to sync
source code comments with developer manual sections.

tree.ReformulationSubscriptExpressions<module tree.ReformulationSubscriptExpressions> Reformulation of subscript into slicing.

For Python2, there is a difference between x[a], x[a:b], x[a:b:c] whereas
Python3 treats the later by making a slice object, Python2 tries to have
special slice access, if available, or building a slice object only at the
end.

Consult the developer manual for information. TODO: Add ability to sync
source code comments with developer manual sections.
C:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\tree\ReformulationSubscriptExpressions.pyexception_expressionexception_assignexception_blocktarget_infoexception_typesno_raiseunhandled_indicator<module tree.ReformulationTryExceptStatements>default 'except:' must be last_makeTryExceptSingleHandlerNodetmp_handler_indicator_variable Reformulation of try/except statements.

Consult the developer manual for information. TODO: Add ability to sync
source code comments with developer manual sections.

makeTryExceptNoRaiseC:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\tree\ReformulationTryExceptStatements.pymakeTryFinallyStatement.<locals>.getFinalfinal2C:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\tree\ReformulationTryFinallyStatements.py<module tree.ReformulationTryFinallyStatements> Reformulation of try/finally statements.

Consult the developer manual for information. TODO: Add ability to sync
source code comments with developer manual sections.

 Reformulation of while loop statements.

Loops in Nuitka have no condition attached anymore, so while loops are
re-formulated like this:

.. code-block:: python

    while condition:
        something()

.. code-block:: python

    while 1:
        if not condition:
            break

        something()

This is to totally remove the specialization of loops, with the condition moved
to the loop body in an initial conditional statement, which contains a ``break``
statement.

That achieves, that only ``break`` statements exit the loop, and allow for
optimization to remove always true loop conditions, without concerning code
generation about it, and to detect such a situation, consider e.g. endless
loops.

.. note::

   Loop analysis (not yet done) can then work on a reduced problem (which
   ``break`` statements are executed under what conditions) and is then
   automatically very general.

   The fact that the loop body may not be entered at all, is still optimized,
   but also in the general sense. Explicit breaks at the loop start and loop
   conditions are the same.

tree.ReformulationWhileLoopStatementswhile_loopC:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\tree\ReformulationWhileLoopStatements.py<module tree.ReformulationWhileLoopStatements>tree.ReformulationWithStatementsbody_linenooptional_vars Reformulation of with statements.

Consult the developer manual for information. TODO: Add ability to sync
source code comments with developer manual sections.

context_exprsassign_targetsterminal_statement<module tree.ReformulationWithStatements>©ÚproviderÚcontext_exprÚassign_targetÚbodyÚbody_linenoÚsyncÚ
source_refÚwith_sourceÚ
temp_scopeÚtmp_source_variableÚtmp_exit_variableÚtmp_enter_variableÚtmp_indicator_variableÚ
statementsÚ	with_bodyÚdeepestÚwith_exit_source_refÚattribute_lookup_classÚenter_valueÚexit_value_exceptionÚexit_value_no_exceptionÚattribute_assignmentsC:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\tree\ReformulationWithStatements.py_buildWithNodetree.ReformulationYieldExpressions'yield' outside functionC:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\tree\ReformulationYieldExpressions.py'%s' inside async function_checkInsideGenerator Reformulation of "yield" and "yield from" expressions.

Consult the developer manual for information. TODO: Add ability to sync
source code comments with developer manual sections.

<module tree.ReformulationYieldExpressions> Read source code from files.

This is tremendously more complex than one might think, due to encoding issues
and version differences of Python versions.
python2.7source_fileline1_matchline2_matchNon-ASCII character '\x%s' in file %s on line %d, but no encoding declared; see http://python.org/dev/peps/pep-0263/ for detailswrong_byteC:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\tree\SourceReading.py_readSourceCodeFromFilename3byte 0x([a-f0-9]{2}) in position_readSourceCodeFromFilename2_source_codeso_farpython2.6python3.5python3.2python3.4python3.3_detectEncoding2The program you compiled wants to be run with: %s.

Nuitka is currently running with Python version '%s', which seems to not
match that. Nuitka cannot guess the Python version of your source code. You
therefore might want to specify: '%s -m nuitka'.

That will make use the correct Python version for Nuitka.
<module tree.SourceReading>coding[:=]\s*([-\w.]+)display_filetree.SyntaxErrorsC:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\tree\SyntaxErrors.py  File "%s", line %d
    %s
%s: %s  File "%s", line %d
    %s
    %s^
%s: %s Handling of syntax errors.

Format SyntaxError/IndentationError exception for output, as well as
raise it for the given source code reference.
raiseSyntaxError.<locals>.readSource  File "%s", line %s
%s: %sbuild_nodes_args2C:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\tree\TreeHelpers.py Create conditional statement, with yes_branch not being empty.

        May have to invert condition to achieve that.
    build_nodes_args1indicationsmakeStatementsSequence.<locals>.<genexpr>node_source_refconst_typedetectFunctionBodyKind.<locals>._check Helper functions for parsing the AST nodes and building the Nuitka node tree.

<module tree.TreeHelpers>Problem at '%s' with %s.class_containerbuild_contextsmakeSequenceCreationOrConstant.<locals>.<genexpr><module %s>build_nodes_args3 Make a statement sequence, but only if more than one statement

    Useful for when we can unroll constructs already here, but are not sure if
    we actually did that. This avoids the branch or the pollution of doing it
    always.
    can not delete variable '%s' referenced in nested scopeisStatementLoopqualname_nodeno binding for nonlocal '%s' foundVariableClosureLookupVisitorPhase3was_takenparent_provider<module tree.VariableClosure> Variable closure phase 3: Find errors and complete frame variables.

        In this phase, we can do some fix-ups and find errors. We might e.g.
        detect that a "del" was executed on a shared variable, which is not
        allowed for Python 2.x, so it must be caught. The parsing wouldn't do
        that.

        Also, frame objects for functions should learn their variable names.
    non_local_namesVariableClosureLookupVisitorPhase2VariableClosureLookupVisitorPhase2._attachVariable Variable closure phase 1: Find assignments and early closure references.

        In class context, a reference to a variable must be obeyed immediately,
        so that "variable = variable" takes first "variable" as a closure and
        then adds a new local "variable" to override it from there on. For the
        not early closure case of a function, this will not be done and only
        assignments shall add local variables, and references will be ignored
        until phase 2.
    seen_function_handleQualnameSetupVariableClosureLookupVisitorPhase1._handleQualnameSetupclass_variable_name Variable closure taking.

This is the completion of variable object completion. The variables were not
immediately resolved to be bound to actual scopes, but are only now.

Only after this is executed, variable reference nodes can be considered
complete.
_shouldUseLocalsDictVariableClosureLookupVisitorPhase1.onEnterNodesubnode_sourceVariableClosureLookupVisitorPhase2.onEnterNodeVariableClosureLookupVisitorPhase1._handleNonLocal'break' outside loop Variable closure phase 2: Find assignments and references.

        In class context, a reference to a variable must be obeyed immediately,
        so that "variable = variable" takes first "variable" as a closure and
        then adds a new local "variable" to override it from there on.

        So, assignments for early closure, accesses will already have a
        variable set now, the others, only in this phase.
    C:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\tree\VariableClosure.pyVariableClosureLookupVisitorPhase1.onLeaveNodeisStatementDelVariableNamefunction_variable'continue' not properly in loopVariableClosureLookupVisitorPhase3.onEnterNodeisStatementDelAttributeVariableClosureLookupVisitorPhase1._shouldUseLocalsDictisStatementAssignmentAttributeTerminal utilities.OFLAGLFLAGISPEED<module tty>C:\msys64\mingw64\lib\python3.6\tty.pyBRKINTPut terminal into a raw mode.IFLAGPut terminal into a cbreak mode.Calculate the most derived metaclass._GeneratorWrapper.sendcoroutine.<locals>.wrapped_calculate_meta_GeneratorWrapper.__init___GeneratorWrapper.gi_framemetaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases_GeneratorWrapper.throwgi_yieldfromnew_classDynamicClassAttribute.__init___GeneratorWrapper.__next__fdelbase_metafdocConvert regular generator function to a coroutine._GeneratorWrapper.gi_yieldfrom_GeneratorWrapper__wrappedSimpleNamespaceDynamicClassAttribute.__set__Create a class object dynamically using the appropriate metaclass.cr_awaitoverwrite_doc_GeneratorWrapper.closeDynamicClassAttribute.__get___C._mDynamicClassAttribute.getterCall the __prepare__ method of the appropriate metaclass.

    Returns (metaclass, namespace, kwds) as a 3-tuple

    *metaclass* is the appropriate metaclass
    *namespace* is the prepared class namespace
    *kwds* is an updated copy of the passed in kwds argument with any
    'metaclass' entry removed. If no kwds argument is passed in, this will
    be an empty dict.
    can't set attribute_GeneratorWrapper__isgenDynamicClassAttribute.setterLambdaTypeownerclasstypes.coroutine() expects a callableprepare_class<module types>Route attribute access on a class to __getattr__.

    This is a descriptor, used to define attributes that act differently when
    accessed through an instance and through a class.  Instance access remains
    normal, but access to an attribute through a class will be routed to the
    class's __getattr__ method; this is done by raising AttributeError.

    This allows one to have properties active on an instance, and have virtual
    attributes on the class with the same name (see Enum for an example).

    _GeneratorWrapper.gi_codeC:\msys64\mingw64\lib\python3.6\types.py_GeneratorWrapper.__iter__cr_codeunreadable attribute_GeneratorWrapper.gi_runningDynamicClassAttribute.__delete__DynamicClassAttribute.deleter
Define names for built-in types that aren't directly accessible as a builtin.
can't delete attributeResizableImage.invalidateResizableImage.__init__fill_preservescaleToFitstretchToFitpaintimage_widthimage_heightframe_widthframe_heightResizableImage.drawConstruct a ResizableImage control.

        Parameters:
        aspect -- Maintain aspect ratio?
        enlarge -- Allow image to be scaled up?
        interp -- Method of interpolation to be used.
        backcolor -- Tuple (R, G, B) with values ranging from 0 to 1,
            or None for transparent.
        max -- Max dimensions for internal image (width, height).

        UltrasoundImage.__init__abnormal/ultrasound_images/scale_simpleINTERP_BILINEAR<module ultrasound>frame_aspectResizableImage.on_realizeResizableImage.set_from_pixbufResizes a rectangle to fit within another.

    Parameters:
    image -- A tuple of the original dimensions (width, height).
    frame -- A tuple of the target dimensions (width, height).
    aspect -- Maintain aspect ratio?
    enlarge -- Allow image to be scaled up?

    image_aspectUltrasoundImage.change_ailmentset_backgroundis_imageResizableImage.exposeINTERP_NEAREST File is image if it has a common suffix and it is a regular file set_source_pixbufResizableImage.set_from_fileresizeToFitC:\msys64\home\cbper\ultrasound.py<module unittest>C:\msys64\mingw64\lib\python3.6\unittest\__init__.py_TextTestResultthis_dir
Python unit testing framework, based on Erich Gamma's JUnit and Kent Beck's
Smalltalk testing framework (used with permission).

This module contains the core framework classes that form the basis of
specific test cases and suites (TestCase, TestSuite etc.), and also a
text-based utility class for running the tests and reporting the results
 (TextTestRunner).

Simple usage:

    import unittest

    class IntegerArithmeticTestCase(unittest.TestCase):
        def testAdd(self):  # test method names begin with 'test'
            self.assertEqual((1 + 2), 3)
            self.assertEqual(0 + 1, 1)
        def testMultiply(self):
            self.assertEqual((0 * 10), 0)
            self.assertEqual((5 * 8), 40)

    if __name__ == '__main__':
        unittest.main()

Further information is available in the bundled documentation, and from

  http://docs.python.org/library/unittest.html

Copyright (c) 1999-2003 Steve Purcell
Copyright (c) 2003-2010 Python Software Foundation
This module is free software, and you may redistribute it and/or modify
it under the same terms as Python itself, so long as this copyright message
and disclaimer are retained in their original form.

IN NO EVENT SHALL THE AUTHOR BE LIABLE TO ANY PARTY FOR DIRECT, INDIRECT,
SPECIAL, INCIDENTAL, OR CONSEQUENTIAL DAMAGES ARISING OUT OF THE USE OF
THIS CODE, EVEN IF THE AUTHOR HAS BEEN ADVISED OF THE POSSIBILITY OF SUCH
DAMAGE.

THE AUTHOR SPECIFICALLY DISCLAIMS ANY WARRANTIES, INCLUDING, BUT NOT
LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A
PARTICULAR PURPOSE.  THE CODE PROVIDED HEREUNDER IS ON AN "AS IS" BASIS,
AND THERE IS NO OBLIGATION WHATSOEVER TO PROVIDE MAINTENANCE,
SUPPORT, UPDATES, ENHANCEMENTS, OR MODIFICATIONS.
seq_typeFunctionTestCase.__init___AssertWarnsContext.__exit___AssertLogsContext.__enter___LoggingWatcheran exception type or tuple of exception typesstandardMsgtest_caselogger_name%s unexpectedly found in %sFail if the two objects are equal as determined by their
           difference rounded to the given number of decimal places
           (default 7) and comparing to zero, or by comparing that the
           difference between the two objects is less than the given delta.

           Note that decimal places (from zero) are usually not the same
           as significant digits (measured from the most significant digit).

           Objects that are equal automatically fail.
        max_difffailUnlessRaisesassertListEqualTestCase.assertEqualcallable_objexpected_regexSecond sequence is not a %s: %sHonour the longMessage attribute when generating failure messages.
        If longMessage is False this means:
        * Use only an explicit message if it is provided
        * Otherwise use the standard message for the assert

        If longMessage is True:
        * Use the standard message
        * If an explicit message is provided, plus ' : ' and the explicit message
        %s is not falseisTesttestFunc_BaseTestCaseContext_OutcomeItems in the first set but not the second:_testFuncJust like self.assertTrue(a <= b), but with a nicer default message.item2A test case that wraps a test function.

    This is useful for slipping pre-existing test functions into the
    unittest framework. Optionally, set-up and tidy-up functions can be
    supplied. As with TestCase, the tidy-up ('tearDown') function will
    always be called if the set-up ('setUp') function ran successfully.
    A class whose instances are single test cases.

    By default, the test code itself should be placed in a method named
    'runTest'.

    If the fixture may be used for many test cases, create as
    many test methods as are needed. When instantiating such a TestCase
    subclass, specify in the constructor arguments the name of the test method
    that the instance is to execute.

    Test authors should subclass TestCase for their own tests. Construction
    and deconstruction of the test's environment ('fixture') can be
    implemented by overriding the 'setUp' and 'tearDown' methods respectively.

    If it is necessary to override the __init__ method, the base class
    __init__ method must always be called. It is important that subclasses
    should not change the signature of their __init__ method, since instances
    of the classes are instantiated automatically by parts of the framework
    in order to be run.

    When subclassing TestCase, you can set these attributes:
    * failureException: determines which exception will be raised when
        the instance's assertion methods fail; test methods raising this
        exception will be deemed to have 'failed' rather than 'errored'.
    * longMessage: determines whether long messages (including repr of
        objects used in assert methods) will be printed on failure in *addition*
        to any explicit message passed.
    * maxDiff: sets the maximum length of a diff in failure messages
        by assert methods using difflib. It is looked up as an instance
        attribute so can be configured by individual tests if required.
    TestCase.addCleanupassertNotAlmostEqualno logs of level {} or higher triggered on {}TestCase.assertIntestPartExecutor_raiseFailureTestCase._addSkipFail if the two objects are unequal as determined by the '=='
           operator.
        _BaseTestCaseContext._raiseFailureTestCase.assertIsNotsecond_seqmismatchedexpected_warningJust like self.assertTrue(a not in b), but with a nicer default message.unexpected_regex
Diff is %s characters long. Set self.maxDiff to None to see it.
Unable to index element %d of second %s
_SubTest.idTestCase.assertWarns_AssertRaisesBaseContextoriginal_funcdeprecated_funcassertNotRegexpMatchesa warning type or tuple of warning typesSecond argument is not a dictionaryTestCase.assertLessFunctionTestCase.__str__firstlinesunittest.caseCreate an instance of the class that will use the named test
           method when executed. Raises a ValueError if the instance does
           not have a method with the specified name.
        TestCase.assertLogsJust like self.assertTrue(a > b), but with a nicer default message.assertNotInTestCase.assertRaises
First differing element %d:
%s
%s
_SubTest.__str__Unable to index element %d of first %s
expr1expr2
    A logging handler capturing all (raw and formatted) logging output.
    TestCase._deprecateGet a detailed comparison function for the types of the two args.

        Returns: A callable accepting (first, second, msg=None) that will
        raise a failure exception if first != second with a useful human
        readable error message for those types.
        FunctionTestCase.shortDescriptionFirst sequence is not a %s: %s_AssertRaisesBaseContext.__init__A context manager used to implement TestCase.assertRaises* methods.TestCase.assertTrueIncluded for symmetry with assertIsNone.Returns a one-line description of the subtest, or None if no
        description has been provided.
        <module unittest.case>TestCase.assertNotIn%s is not an instance of %rTestResult has no addSkip method, skips not reported__unittest_expecting_failure__expected_regex must not be empty._SubTest.__init___CapturingHandler.__init__assertEqualsTestCase._truncateMessage"{}" does not match "{}"orig_resulttestMethodskip_whyexpecting_failure_methodexpecting_failure_classFunctionTestCase.tearDownTestCase.assertFalseTestCase.assertNotIsInstance(<subtest>)test_itemskip_wrapperA context manager used to implement TestCase.assertLogs().params_desclist1list2Fail unless a warning of class warnClass is triggered
           by the callable when invoked with specified positional and
           keyword arguments.  If a different type of warning is
           triggered, it will not be handled: depending on the other
           warning filtering rules in effect, it might be silenced, printed
           out, or raised as an exception.

           If called with the callable and arguments omitted, will return a
           context object used like this::

                with self.assertWarns(SomeWarning):
                    do_something()

           An optional keyword argument 'msg' can be provided when assertWarns
           is used as a context object.

           The context manager keeps a reference to the first matching
           warning as the 'warning' attribute; similarly, the 'filename'
           and 'lineno' attributes give you information about the line
           of Python code from which the warning was triggered.
           This allows you to inspect the warning after the assertion::

               with self.assertWarns(SomeWarning) as cm:
                   do_something()
               the_warning = cm.warning
               self.assertEqual(the_warning.some_attribute, 147)
        assertGreaterEqualexc_nameSecond argument is not a stringTestCase._formatMessageIncluded for symmetry with assertIsInstance.The default assertEqual implementation, not type specific.Fail if the two objects are equal as determined by the '!='
           operator.
        assertCountEqualassertLessEqual%s not greater than %sSame as self.assertTrue(isinstance(obj, cls)), with a nicer
        default message.typeobj_AssertWarnsContext.__enter__%s == %s within %s deltasubtests cannot be run directly_subtestfirst_matching
        If args is empty, assertRaises/Warns is being used as a
        context manager, so check for a 'msg' kwarg and return self.
        If args is not empty, call a callable passing positional and keyword
        arguments.
        assertRaisesRegexJust like self.assertTrue(a is not b), but with a nicer default message.diffMsg_AssertLogsContext.__exit__assertNotAlmostEquals
    Skip a test unless the condition is true.
    TestCase._feedErrorsToResultFail immediately, with the given message.Run the test without collecting errors in a TestResultReturns a one-line description of the test, or None if no
        description has been provided.

        The default implementation of this method returns the first line of
        the specified test method's docstring.
        Second %s has no length.    Non-sequence?Hook method for deconstructing the test fixture after testing it.TestCase.assertListEqual_cleanupsTestCase.assertSetEqualAsserts that the message in a triggered warning matches a regexp.
        Basic functioning is similar to assertWarns() with the addition
        that only warnings whose messages also match the regular expression
        are considered successful matches.

        Args:
            expected_warning: Warning class expected to be triggered.
            expected_regex: Regex (re pattern object or string) expected
                    to be found in error message.
            args: Function to be called and extra positional args.
            kwargs: Extra kwargs.
            msg: Optional message used in case of failure. Can only be used
                    when assertWarnsRegex is used as a context manager.
        seq_type_namelen2item1_base_type_strTestCase.defaultTestResultTestResult has no addUnexpectedSuccess method, reporting as failureassertRegexMissing: %sC:\msys64\mingw64\lib\python3.6\unittest\case.py_setUpFuncset1set2difference1difference2TestCase.assertLessEqualRegex matched: %r matches %r in %r_BaseTestCaseContext.__init__%s == %s within %r placesExecute all cleanup functions. Normally called for you after
        tearDown.{} not triggered_AssertRaisesBaseContext.handleassertRaisesRegexpFail if the two objects are unequal as determined by their
           difference rounded to the given number of decimal places
           (default 7) and comparing to zero, or by comparing that the
           difference between the two objects is more than the given
           delta.

           Note that decimal places (from zero) are usually not the same
           as significant digits (measured from the most significant digit).

           If the two objects compare equal then they will automatically
           compare almost equal.
        TestCase.assertSequenceEqualassertTupleEqualHook method for setting up class fixture before running tests in the class.assertNotEqualFirst extra element %d:
%s
first_seq
    Skip a test if the condition is true.
    Just like self.assertTrue(a is b), but with a nicer default message._baseAssertEqual_addExpectedFailure_ShouldStop_Outcome.testPartExecutor_AssertRaisesContextTestCase.assertIsNone_type_equality_funcsItems in the second set but not the first:secondlinesassertDictContainsSubsetTestCase.setUpClass__unittest_skip_why___diffThresholdA context manager used to implement TestCase.assertWarns* methods.Element counts were not equal:
TestCase.assertRaisesRegexFirst has %d, Second has %d:  %raddTypeEqualityFunc%s != %s within %r placesHook method for setting up the test fixture before exercising it.Check that the expression is false.asserterunexpectedly None%s is not trueTestResult has no addExpectedFailure method, reporting as passesinvalid type when attempting set difference: %sfailUnlessEqualbasetypeAdd a type specific assertEqual style function to compare a type.

        This method is for use by TestCase subclasses that need to register
        their own type equality functions to provide nicer error messages.

        Args:
            typeobj: The data type to call this function on when both values
                    are of the same type in assertEqual().
            function: The callable taking two arguments and an optional
                    msg= argument that raises self.failureException with a
                    useful error message when the two arguments are not equal.
        FunctionTestCase.idassertAlmostEqualsHook method for deconstructing the class fixture after running all tests in the class.old_propagateTestCase._baseAssertEqualSame as self.assertTrue(obj is None), with a nicer default message.
    The test should stop.
    assertion_funcTestCase.assertTupleEqualTestCase.tearDownClass%r is an invalid keyword argument for this functionTestCase.assertIsNotNoneJust like self.assertTrue(a in b), but with a nicer default message.TestCase._deprecate.<locals>.deprecated_funcChecks whether dictionary is a superset of subset.Fail unless an exception of class expected_exception is raised
           by the callable when invoked with specified positional and
           keyword arguments. If a different type of exception is
           raised, it will not be caught, and the test case will be
           deemed to have suffered an error, exactly as for an
           unexpected exception.

           If called with the callable and arguments omitted, will return a
           context object used like this::

                with self.assertRaises(SomeException):
                    do_something()

           An optional keyword argument 'msg' can be provided when assertRaises
           is used as a context object.

           The context manager keeps a reference to the exception as
           the 'exception' attribute. This allows you to inspect the
           exception after the assertion::

               with self.assertRaises(SomeException) as cm:
                   do_something()
               the_exception = cm.exception
               self.assertEqual(the_exception.error_code, 3)
        callable is Noneparams_mapA list-specific equality assertion.

        Args:
            list1: The first list to compare.
            list2: The second list to compare.
            msg: Optional message to use on failure instead of a list of
                    differences.

        Check that the expression is true.{} not raisedunexpectedly identical: %sFirst argument is not a dictionaryold_levelold_success_is_subtypeAsserts that the message in a raised exception matches a regex.

        Args:
            expected_exception: Exception class expected to be raised.
            expected_regex: Regex (re pattern object or string) expected
                    to be found in error message.
            args: Function to be called and extra positional args.
            kwargs: Extra kwargs.
            msg: Optional message used in case of failure. Can only be used
                    when assertRaisesRegex is used as a context manager.
        TestCase.assertDictContainsSubset.<locals>.<genexpr>_Outcome.__init__TestCase.countTestCasesTestCase._addUnexpectedSuccessFirst %s has no length.    Non-sequence?TestCase.assertNotEqualTestCase.assertMultiLineEqual_is_subtype.<locals>.<genexpr><%s testMethod=%s>TestCase.assertIsInstanceTestCase.doCleanupsNo test%s, expected: %s, actual: %s_subtest_msg_sentinel_testMethodDoc
First %s contains %d additional elements.
{} not triggered by {}%s not greater than or equal to %sTestCase.addTypeEqualityFunc_UnexpectedSuccessassertDictEqualAn equality assertion for ordered sequences (like lists and tuples).

        For the purposes of this function, a valid ordered sequence type is one
        which can be indexed, has a length, and has an equality operator.

        Args:
            seq1: The first sequence to compare.
            seq2: The second sequence to compare.
            seq_type: The expected datatype of the sequences, or None if no
                    datatype should be enforced.
            msg: Optional message to use on failure instead of a list of
                    differences.
        _AssertRaisesContext.__enter___CapturingHandler.emitTestCase.assertDictEqualFunctionTestCase.__repr__assertNotEqualsJust like self.assertTrue(a >= b), but with a nicer default message.TestCase.skipTestsubTest
Second %s contains %d additional elements.
Test case implementation<%s tec=%s>FunctionTestCase.runTestTestCase.assertCountEqualTestCase.__call__Regex didn't match: %r not found in %rAdd a function, with arguments, to be called when the test is
        completed. Functions added are called on a LIFO basis and are
        called after tearDown on test failure or success.

        Cleanup items are called even if setUp fails (unlike tearDown).%s not found in %sSkip this test._tearDownFuncsecond argument does not support set difference: %sTestCase.assertGreaterresult_supports_subtests_SubTest.runTest_AssertRaisesContext.__exit__%s is not Nonespecify delta or places not bothTestCase.assertNotRegex%s() arg 1 must be %sobj_nameTestCase.assertGreaterEqualFunctionTestCase.__hash__TestCase._getAssertEqualityFunc
    Unconditionally skip a test.
    Fail the test unless the text matches the regular expression.Assert that two multi-line strings are equal.%ss differ: %s != %s
First argument is not a string%s not less than %s
    The test was supposed to fail, but it didn't!
    TestCase.subTestTestCase.assertNotAlmostEqualfailIfEqualTestCase.assertWarnsRegex_SubTest.shortDescriptionTestCase.assertRegexPlease use {0} instead._SubTest._subDescription%s : %sA set-specific equality assertion.

        Args:
            set1: The first set to compare.
            set2: The second set to compare.
            msg: Optional message to use on failure instead of a list of
                    differences.

        assertSetEqual uses ducktyping to support different types of sets, and
        is optimized for sets specifically (parameters must support a
        difference method).
        FunctionTestCase.__eq__Fail unless a log message of level *level* or higher is emitted
        on *logger_name* or its children.  If omitted, *level* defaults to
        INFO and *logger* defaults to the root logger.

        This method must be used as a context manager, and will yield
        a recording object with two attributes: `output` and `records`.
        At the end of the context manager, the `output` attribute will
        be a list of the matching formatted log messages and the
        `records` attribute will be a list of the corresponding LogRecord
        objects.

        Example::

            with self.assertLogs('foo', level='INFO') as cm:
                logging.getLogger('foo').info('first message')
                logging.getLogger('foo.bar').error('second message')
            self.assertEqual(cm.output, ['INFO:foo:first message',
                                         'ERROR:foo.bar:second message'])
        Just like self.assertTrue(a < b), but with a nicer default message.%s != %s within %s deltaassertDictContainsSubset is deprecatedReturn a context manager that will return the enclosed block
        of code in a subtest identified by the optional message and
        keyword parameters.  A failure in the subtest marks the test
        case as failed but resumes execution at the end of the enclosed
        block, allowing further test code to be executed.
        warnings_manager
    Raise this exception in a test to skip it.

    Usually you can use TestCase.skipTest() or one of the skipping decorators
    instead of raising this directly.
    FunctionTestCase.setUpA tuple-specific equality assertion.

        Args:
            tuple1: The first tuple to compare.
            tuple2: The second tuple to compare.
            msg: Optional message to use on failure instead of a list of
                    differences.
        TestCase.failAn unordered sequence comparison asserting that the same elements,
        regardless of order.  If the same element occurs more than once,
        it verifies that the elements occur the same number of times.

            self.assertEqual(Counter(list(first)),
                             Counter(list(second)))

         Example:
            - [0, 1, 1] and [1, 0, 1] compare equal.
            - [0, 0, 1] and [0, 1] compare unequal.

        failIfAlmostEqualskip.<locals>.decorator.<locals>.skip_wrapper
Unable to index element %d of first %s
_SubTest._subDescription.<locals>.<genexpr>Fail the test if the text matches the regular expression.TestCase._addExpectedFailureDIFF_OMITTED%s not less than or equal to %s_AssertLogsContext.__init__assertRegexpMatchesTestCase.assertAlmostEqualMismatched values: %s{} not raised by {}%s is an instance of %r%s is not %s_CapturingHandler.flushfirst argument does not support set difference: %sno such test method in %s: %sfailUnlessAlmostEqual_match_pathtestCaseNameserror_caseFailed to access attribute:
%s_FailedTest.__getattr__.<locals>.testFailure$py.classTestLoader.__init__testCaseClasssortUsingsuiteClassuse_load_testsTestLoader.loadTestsFromModuleTestLoader.getTestCaseNamesReturn a suite of all test cases contained in the given moduleloadTestsFromModule() got an unexpected keyword argument '{}'_make_failed_load_tests_make_failed_testCan not use builtin modules as dotted module namesReturn a suite of all test cases found using the given sequence
        of string specifiers. See 'loadTestsFromName()'.
        %r module incorrectly imported from %r. Expected %r. Is this module globally installed?TestLoader._match_pathsortTestMethodsUsingTestLoader._get_module_from_name_find_test_path_relpathVALID_MODULE_NAMETestLoader._find_test_pathtestMethodPrefix_get_name_from_path<module unittest.loader>don't know how to make test from: %suse_load_tests is deprecated and ignoredtop_partFailed to import test module: %s
%sTestLoader._get_directory_containing_module_jython_aware_splitextcalling %s returned %s, not a testtestSkippedReturn a sorted sequence of method names found within testCaseClass
        _loading_packagesReturn a suite of all test cases contained in testCaseClassTestLoader.loadTestsFromNametop_level_dirPath must be within the projectloadTestsFromTestCaseshould_recurseloaded_suite
    This class is responsible for loading tests according to various criteria
    and returning them wrapped in a TestSuite
    Return a suite of all test cases given a string specifier.

        The name may resolve either to a module, a test case class, a
        test method within a test case class, or a callable object which
        returns a TestCase or TestSuite instance.

        The method optionally resolves the names relative to a given module.
        _FailedTest.__init___make_skipped_test.<locals>.testSkippedC:\msys64\mingw64\lib\python3.6\unittest\loader.pyisTestMethodcomplaintis_not_importableModuleSkippedset_implicit_topthe_module_top_level_dir_find_testsLoading unittests.©ÚselfÚ	full_pathÚpatternÚ	namespaceÚbasenameÚnameÚmoduleÚeÚ
error_caseÚerror_messageÚmod_fileÚrealpathÚfullpath_noextÚ
module_dirÚmod_nameÚexpected_dirÚmsgÚ
load_testsÚtestsÚpackageUsed by discovery. Yields test suites it loads.Test cases should not be derived from TestSuite. Maybe you meant to derive from TestCase?TestLoader.getTestCaseNames.<locals>.isTestMethodTestLoader._find_tests_makeLoaderTestLoader._get_name_from_pathdon't know how to discover from {!r}Start directory is not importable: %rparts_copytestFnNamesnext_attributeFailed to call load_tests:
%s_make_failed_import_testTestLoader.loadTestsFromNamesTestLoader.discoverFind and return all test modules from the specified start
        directory, recursing into subdirectories to find them and return all
        tests found within them. Only test files that match the pattern will
        be loaded. (Using shell style pattern matching.)

        All test modules must be importable from the top level of the project.
        If the start directory is not the top level directory then the top
        level directory must be specified separately.

        If a test package name (directory with '__init__.py') matches the
        pattern then the package will be checked for a 'load_tests' function. If
        this exists then it will be called with (loader, tests, pattern) unless
        the package has already had load_tests called from the same discovery
        invocation, in which case the package module object is not scanned for
        tests - this ensures that when a package uses discover to further
        discover child tests that infinite recursion does not happen.

        If load_tests exists then discovery does *not* recurse into the package,
        load_tests is responsible for loading all tests in the package.

        The pattern is deliberately not stored as a loader attribute so that
        packages can continue discovery themselves. top_level_dir is stored so
        load_tests does not need to pass this argument in to loader.discover().

        Paths are sorted before being imported to ensure reproducible execution
        order even on filesystems with non-alphabetical ordering like ext3/4.
        Used by discovery.

        Loads tests from a single file, or a directories' __init__.py when
        passed the directory.

        Returns a tuple (None_or_tests_from_file, should_recurse).
        [_a-z]\w*\.py$TestLoader.loadTestsFromTestCaseloadTestsFromModule() takes 1 positional argument but {} were givenShow local variables in tracebacksQuiet outputTestProgram._getMainArgParser--localsStop on first fail or error--buffer--failfastcreateTestsparent_parserMAIN_EXAMPLESTestProgram.__init__TestProgram._getDiscoveryArgParserTestProgram.createTestsTestProgram._do_discoveryExamples:
  %(prog)s                           - run default set of tests
  %(prog)s MyTestSuite               - run suite 'MyTestSuite'
  %(prog)s MyTestCase.testSomething  - run MyTestCase.testSomething
  %(prog)s MyTestCase                - run all 'test*' test methods
                                       in MyTestCase
Directory to start discovery ('.' default)%s discover--top-level-directory<module unittest.main>testRunnertestLoadercatchbreak--patternTop level directory of project (defaults to start directory)Catch Ctrl-C and display results so far--catchTestProgram._initArgParsersrunTestsrel_pathTestProgram.parseArgs--start-directoryFor test discovery all test modules must be importable from the top level directory of the project.Examples:
  %(prog)s test_module               - run tests from test_module
  %(prog)s module.TestClass          - run tests from module.TestClass
  %(prog)s module.Class.test_method  - run specified test method
  %(prog)s path/to/test_file.py      - run tests from test_file.py
_print_helpTestProgram.usageExitprogNamea list of any number of test modules, classes and test methods.Buffer stdout and stderr during testsA command-line program that runs a set of tests; this is primarily
       for making test modules conveniently executable.
    TestProgram._print_helpMODULE_EXAMPLESPattern to match tests ('test*.py' default)_discovery_parser_getParentArgParser_main_parser_convert_name_convert_namestestNamesUnittest main programTestProgram.runTestsTestProgram._getParentArgParserC:\msys64\mingw64\lib\python3.6\unittest\main.py
Stdout:
%stb_eCalled once after all tests are executed.

        See stopTest for a method called after each test.
        TestResult.addSkipTestResult._restoreStdoutConverts a sys.exc_info()-style tuple of values into a string.TestResult.addSubTestTestResult._setupStdoutCalled when the given test is about to be runIndicates that the tests should be aborted.TestResult.wasSuccessfulTestResult._exc_info_to_stringTestResult.stopTestRunCalled when the given test has been run_original_stdoutCalled once before any tests are executed.

        See startTest for a method called before each test.
        TestResult._is_relevant_tb_level
Stderr:
%sC:\msys64\mingw64\lib\python3.6\unittest\result.py_stdout_bufferTestResult._count_relevant_tb_levels<module unittest.result><%s run=%i errors=%i failures=%i>TestResult.printErrorsSTDERR_LINETestResult.addSuccessTestResult.__repr__TestResult.addErrorTestResult.addUnexpectedSuccess_original_stderrfailfast.<locals>.innerSTDOUT_LINECalled at the end of a subtest.
        'err' is None if the subtest ended successfully, otherwise it's a
        tuple of values as returned by sys.exc_info().
        msgLinesTest result object_stderr_bufferTestResult.startTestRun_mirrorOutputCalled when a test has completed successfullyTestResult.__init__Called by TestRunner after test runTestResult.addExpectedFailureCalled when a test was expected to fail, but succeed.Called when an expected failure/error occurred.Holder for test result information.

    Test results are automatically managed by the TestCase and TestSuite
    classes, and do not need to be explicitly manipulated by writers of tests.

    Each instance holds the total number of tests run, and collections of
    failures and errors that occurred among those test runs. The collections
    contain tuples of (testcase, exceptioninfo), where exceptioninfo is the
    formatted traceback of the error that occurred.
    Tells whether or not this result was a success.Called when an error has occurred. 'err' is a tuple of values as
        returned by sys.exc_info().
        TestResult.addFailureCalled when a test is skipped._makeResultPlease use assert\w+ instead.TextTestRunner.runTextTestResult.printErrorListstopTimeTextTestResult.__init___WritelnDecoratorunittest.runnerresultclassflavour_WritelnDecorator.__init__showAllTextTestResult.addSkipRunning tests_WritelnDecorator.writelntimeTakenunexpected successes=%dseparator2doc_first_line<module unittest.runner>TextTestResult.addUnexpectedSuccessA test runner class that displays results in textual form.

    It prints out the names of tests as they are run, errors as they
    occur, and a summary of the results at the end of the test run.
    expectedFailsTextTestResult.startTestskipped=%dfailures=%dTextTestResult.getDescriptionRun the given test case or test suite.TextTestResult.addErrorseparator1TextTestResult.addExpectedFailureTextTestResult.addFailureexpected failures=%dUsed to decorate file-like objects with a handy 'writeln' methodTextTestResult.printErrorsskipped {0!r}errors=%dRan %d test%s in %.3fsA test result class that can print formatted text results to a stream.

    Used by TextTestRunner.
    TextTestResult.addSuccessTextTestRunner._makeResultTextTestRunner.__init__C:\msys64\mingw64\lib\python3.6\unittest\runner.py_WritelnDecorator.__getattr__Construct a TextTestRunner.

        Subclasses should accept **kwargs to ensure compatibility as the
        interface changes.
        default_handlerexpected SIGINT signal handler to be signal.SIG_IGN, signal.SIG_DFL, or a callable objectinstalled_handler_InterruptHandler.__init__unused_frameremoveHandler.<locals>.inneroriginal_handlerunused_signum_InterruptHandler.__call___InterruptHandler.__init__.<locals>.default_handlerdefault_int_handler<module unittest.signals>C:\msys64\mingw64\lib\python3.6\unittest\signals.py_interrupt_handlerTestSuite._handleModuleFixtureTestSuite._handleModuleTearDown_ErrorHolder.__repr___ErrorHolder.run<module unittest.suite>BaseTestSuite.__iter__errorNamecurrentModulecurrentClassC:\msys64\mingw64\lib\python3.6\unittest\suite.py_ErrorHolder.countTestCases_get_previous_moduleBaseTestSuite.addTest_handleClassSetUp
    Placeholder for a TestCase inside a result. As far as a TestResult
    is concerned, this looks exactly like a unit test. Used to insert
    arbitrary errors into a test suite run.
    tests must be an iterable of tests, not a stringpreviousClassclassNameBaseTestSuite.__init__TestSuite.debug_addClassOrModuleLevelExceptionA test suite is a composite test consisting of a number of TestCases.

    For use, create an instance of TestSuite, then add test case instances.
    When all tests have been added, the suite can be passed to a test
    runner, such as TextTestRunner. It will run the individual test cases
    in the order in which they were added, aggregating the results. When
    subclassing, do not forget to call the base class constructor.
    _call_if_exists_DebugResultsetUpModule_removed_testsBaseTestSuite.__eq__BaseTestSuite._removeTestAtIndexTestSuite.runpreviousModuletearDownClass (%s)tearDownModuleBaseTestSuite.countTestCasessetUpClass (%s)setUpModule (%s)_call_if_exists.<locals>.<lambda>topLevelBaseTestSuite.debugTestSuite._handleClassSetUpRun the tests without collecting errors in a TestResultBaseTestSuite.__call__addTests{} is not callable_isnotsuiteBaseTestSuite.run<%s tests=%s>TestSuite._addClassOrModuleLevelException_tearDownPreviousClassTestSuite._get_previous_moduleBaseTestSuite.addTests_ErrorHolder.id<ErrorHolder description=%r>_ErrorHolder.__str__A crude way to tell apart testcases and suites with duck-typingTestCases and TestSuites must be instantiated before passing them to addTest()Used by the TestSuite to hold previous class when running in debug._ErrorHolder.__call__tearDownModule (%s)A simple test suite that doesn't provide class or module shared fixtures.
    Stop holding a reference to the TestCase at index._ErrorHolder.shortDescription_ErrorHolder.__init__TestSuite._tearDownPreviousClassBaseTestSuite.__repr___MIN_COMMON_LENcnt_s_PLACEHOLDER_LENReturn -1 if x < y, 0 if x == y and 1 if x > y_common_shorten_repr.<locals>.<genexpr>cnt_tother_elemunittest.util_MAX_LENGTHunorderable_list_differenceReturns list of (cnt_act, cnt_exp, elem) triples where the counts differ_ordered_countC:\msys64\mingw64\lib\python3.6\unittest\util.pyactual expected value_MIN_END_LENsorted_list_differenceFinds elements in only one or the other of two, sorted input lists.

    Returns a two-element tuple of lists.    The first list contains those
    elements in the "expected" list but not in the "actual" list, and the
    second contains those elements in the "actual" list but not in the
    "expected" list.    Duplicate elements in either input list are ignored.
    _MIN_BEGIN_LEN<module unittest.util>_Mismatch%s[%d chars]%s_MIN_DIFF_LENcommon_lenSame behavior as sorted_list_difference but
    for lists of unorderable items (like dicts).

    As it does a linear search per item (remove) it
    has O(n*n) performance.suffixlen [truncated]...Return dict of element counts, in the order they were first seenVarious utility functions.C:\msys64\mingw64\lib\python3.6\urllibC:\msys64\mingw64\lib\python3.6\urllib\__init__.pyURLError.__str__Exception classes raised by urllib.

The base exception class is URLError, which inherits from OSError.  It
doesn't define any behavior of its own, but is the base class for all
exceptions defined in this package.

HTTPError is an exception class that is also a valid HTTP response
instance.  It behaves this way because HTTP protocol errors are valid
responses, with a status code, headers, and a body.  In some contexts,
an application may want to handle an exception like a regular
response.
<urlopen error %s>ContentTooShortError.__init__URLError.__init__Raised when HTTP error occurs, but also acts like non-error returnHTTPError.__str__<module urllib.error><HTTPError %s: %r>HTTPError.__init__C:\msys64\mingw64\lib\python3.6\urllib\error.pyHTTP Error %s: %sHTTPError.headersHTTPError.reasonException raised when downloaded size does not match content-length.HTTPError.__repr___HTTPError__super_initdefragThe URL with no fragment identifier.quoterquote('abc def') -> 'abc%20def'

    Each part of a URL, e.g. the path info, the query, etc., has a
    different set of reserved characters that must be quoted.

    RFC 2396 Uniform Resource Identifiers (URI): Generic Syntax lists
    the following reserved characters.

    reserved    = ";" | "/" | "?" | ":" | "@" | "&" | "=" | "+" |
                  "$" | ","

    Each of these characters is reserved in some component of a URL,
    but not necessarily in all of them.

    By default, the quote function is intended for quoting the path
    section of a URL.  Thus, it will not encode '/'.  This character
    is reserved, but in typical usage the quote function is being
    called on a path where the existing slash characters are used as
    reserved characters.

    string and safe may be either str or bytes objects. encoding and errors
    must not be specified if string is a bytes object.

    The optional encoding and errors parameters specify how to deal with
    non-ASCII characters, as accepted by the str.encode method.
    By default, encoding='utf-8' (characters are encoded with UTF-8), and
    errors='strict' (unsupported characters raise a UnicodeEncodeError).
    nntpSplitResultBytes.geturl
The hierarchical path, such as the path to a file to download.
host_portParseResultBytes.geturlbad query field: %rParse a query given as a string argument.

        Arguments:

        qs: percent-encoded query string to be parsed

        keep_blank_values: flag indicating whether blank values in
            percent-encoded queries should be treated as blank strings.
            A true value indicates that blanks should be retained as
            blank strings.  The default false value indicates that
            blank values are to be ignored and treated as if they were
            not included.

        strict_parsing: flag indicating what to do with parsing errors.
            If false (the default), errors are silently ignored.
            If true, errors raise a ValueError exception.

        encoding and errors: specify how to decode percent-encoded sequences
            into Unicode characters, as accepted by the bytes.decode() method.

        Returns a dictionary.
    non_hierarchicaluses_netlocÛ   zurlparsez
urlunparsezurljoinz	urldefragzurlsplitz
urlunsplitz	urlencodezparse_qsz	parse_qslzquotez
quote_pluszquote_from_byteszunquotezunquote_pluszunquote_to_byteszDefragResultzParseResultzSplitResultzDefragResultByteszParseResultByteszSplitResultBytesmmsgopherrtspusips%{:02X}url fragment_coerce_result_encoded_counterpartsplitnportStandard approach to decoding parsed results from bytes to strEncode a dict or sequence of two-element tuples into a URL query string.

    If any values in the query arg are sequences and doseq is true, each
    sequence element is converted to a separate parameter.

    If the query arg is a sequence of two-element tuples, the order of the
    parameters in the output will match the order of parameters in the
    input.

    The components of a query arg may each be either a string or a bytes type.

    The safe, encoding, and errors parameters are passed down to the function
    specified by quote_via (encoding and errors only if a component is a str).
    Like quote(), but also replace ' ' with '+', as required for quoting
    HTML form values. Plus signs in the original string are escaped unless
    they are included in safe. It also does not have safe default to '/'.
    urlsplit.<locals>.<genexpr>¾A   é-   é.   é0   é1   é2   é3   é4   é5   é6   é7   é8   é9   éA   éB   éC   éD   éE   éF   éG   éH   éI   éJ   éK   éL   éM   éN   éO   éP   éQ   éR   éS   éT   éU   éV   éW   éX   éY   éZ   é_   éa   éb   éc   éd   ée   éf   ég   éh   éi   éj   ék   él   ém   én   éo   ép   éq   ér   és   ét   éu   év   éw   éx   éy   éz   Standard approach to encoding parsed results from str to bytesuses_queryParse a URL into 6 components:
    <scheme>://<netloc>/<path>;<params>?<query>#<fragment>
    Return a 6-tuple: (scheme, netloc, path, params, query, fragment).
    Note that we don't break the components up in smaller bits
    (e.g. netloc is a single string) and we don't expand % escapes.Cannot mix str and non-str argumentsSplitResult.geturlprosperosftp_result_pairs_ResultMixinBytes_DefragResultBasetelnetsplithost('//host[:port]/path') --> 'host[:port]', '/path'._hostinfo_implicit_errors(.*):([0-9]*)$_NetlocResultMixinBytes._userinfo_asciire([ -]+)_decode_args_implicit_encoding_NetlocResultMixinBaseCombine the elements of a tuple as returned by urlsplit() into a
    complete URL as a string. The data argument can be any five-item iterable.
    This may result in a slightly different, but equivalent URL, if the URL that
    was parsed originally had unnecessary delimiters (for example, a ? with an
    empty query; the RFC states that these are equivalent)./?#C:\msys64\mingw64\lib\python3.6\urllib\parse.pyparsed_resultsplitquery('/path?query') --> '/path', 'query'.name_value<module urllib.parse>safe: bytes object._portprog_hostprogsplitresult_NetlocResultMixinBytes._hostinfo_ResultMixinStr_fix_result_transcoding_SplitResultBaseA mapping from bytes (in range(0,256)) to strings.

    String values are percent-encoded byte values, unless the key < 128, and
    in the "safe" set (either the specified safe set, or default set).
    _typeprog_ALWAYS_SAFE_BYTES_safe_quoters_ResultMixinStr.encode.<locals>.<genexpr>_NetlocResultMixinBase.usernameSpecifies URL scheme for the request.allow_fragmentssplituser('user[:passwd]@host[:port]') --> 'user[:passwd]', 'host[:port]'.//([^/#?]*)(.*)have_open_br_NetlocResultMixinStrInvalid IPv6 URL
Network location where the request is made to.
_NetlocResultMixinStr._hostinfoscheme netloc path params query fragmentLike unquote(), but also replace plus signs by spaces, as required for
    unquoting HTML form values.

    unquote_plus('%7e/abc+def') -> '~/abc def'
    _ResultMixinBytes.decode.<locals>.<genexpr>Put a parsed URL back together again.  This may result in a
    slightly different, but equivalent URL, if the URL that was parsed
    originally had redundant delimiters, e.g. a ? with an empty query
    (the draft states that these are equivalent).splitport('host:port') --> 'host', 'port'._NetlocResultMixinBase.passwordDefragResult.geturlsvn+sshwsssnewsLike quote(), but accepts a bytes object rather than a str, and does
    not perform string-to-bytes encoding.  It always returns an ASCII string.
    quote_from_bytes(b'abc def?') -> 'abc%20def%3f'
    
DefragResult(url, fragment)

A 2-tuple that contains the url without fragment identifier and the fragment
identifier as a separate argument.
scheme netloc path query fragmentunwrap('<URL:type://host/path>') --> 'type://host/path'.Shared methods for the parsed result objects containing a netloc element_splitnetlocuses_relativeunquote_to_bytes('abc%20def') -> b'abc def'.splitattr('/path;attr1=value1;attr2=value2;...') ->
        '/path', ['attr1=value1', 'attr2=value2', ...].Quoter_NetlocResultMixinStr._userinfo©ÚbaseÚurlÚallow_fragmentsÚ_coerce_resultÚbschemeÚbnetlocÚbpathÚbparamsÚbqueryÚ	bfragmentÚschemeÚnetlocÚpathÚparamsÚqueryÚfragmentÚ
base_partsÚsegmentsÚresolved_pathÚsegClear the parse cache and the quoters cache.Quoter.__missing___splitparamsParse a URL into 5 components:
    <scheme>://<netloc>/<path>?<query>#<fragment>
    Return a 5-tuple: (scheme, netloc, path, query, fragment).
    Note that we don't break the components up in smaller bits
    (e.g. netloc is a single string) and we don't expand % escapes._hextobyte_decodedbracketedsplittype('type:opaquestring') --> 'type', 'opaquestring'.quote_from_bytes() expected bytesPort out of range 0-65535splittag('/path#tag') --> '/path', 'tag'.
ParseResult(scheme, netloc, path, params,  query, fragment)

A 6-tuple that contains components of a parsed URL.
wdelimsplitvalue('attr=value') --> 'attr', 'value'.not a valid non-string sequence or mapping object
SplitResult(scheme, netloc, path, query, fragment)

A 5-tuple that contains the different components of a URL. Similar to
ParseResult, but does not split params.
Û   Ú zftpzhttpzgopherznntpztelnetzimapzwaiszfilezmmszhttpszshttpzsnewszprosperozrtspzrtspuzrsynczsvnzsvn+sshzsftpznfszgitzgit+sshzwszwssdefporthave_infohave_password_NetlocResultMixinBase.port
The query component, that contains non-hierarchical data, that along with data
in path component, identifies a resource in the scope of URI's scheme and
network location.
scheme_chars([^/:]+):(.*)Join a base URL and a possibly relative URL to form an absolute
    interpretation of the latter.str_input
Fragment identifier, that allows indirect identification of a secondary resource
by reference to a primary resource and additional identifying information.
Removes any existing fragment from URL.

    Returns a tuple of the defragmented URL and the fragment.  If
    the URL contained no fragments, the second element is the
    empty string.
    uses_paramsquote() doesn't support 'errors' for bytes_parse_cacheabcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789+-.
Parameters for last path element used to dereference the URI in order to provide
access to perform some operation on the resource.
_coerce_args
Fragment identifier separated from URL, that allows indirect identification of a
secondary resource by reference to a primary resource and additional identifying
information.
ParseResult.geturlReplace %xx escapes by their single-character equivalent. The optional
    encoding and errors parameters specify how to decode percent-encoded
    sequences into Unicode characters, as accepted by the bytes.decode()
    method.
    By default, percent-encoded sequences are decoded with UTF-8, and invalid
    sequences are replaced by a placeholder character.

    unquote('abc%20def') -> 'abc def'.
    Quoter.__repr___encode_resultMAX_CACHE_SIZE_decode_args.<locals>.<genexpr>Split host and port, returning numeric port.
    Return given default port if no ':' found; defaults to -1.
    Return numerical port if a valid number are found after ':'.
    Return None if ':' but not a valid number.Quoter.__init__Parse a query given as a string argument.

        Arguments:

        qs: percent-encoded query string to be parsed

        keep_blank_values: flag indicating whether blank values in
            percent-encoded queries should be treated as blank strings.
            A true value indicates that blanks should be retained as blank
            strings.  The default false value indicates that blank values
            are to be ignored and treated as if they were  not included.

        strict_parsing: flag indicating what to do with parsing errors. If
            false (the default), errors are silently ignored. If true,
            errors raise a ValueError exception.

        encoding and errors: specify how to decode percent-encoded sequences
            into Unicode characters, as accepted by the bytes.decode() method.

        Returns a list, as G-d intended.
    _hexdig_ParseResultBase_decoded_counterpartsplitpasswd('user:passwd') -> 'user', 'passwd'._NetlocResultMixinBase.hostnamequote() doesn't support 'encoding' for bytesto_bytes(u"URL") --> 'URL'.uses_fragmentParse (absolute and relative) URLs.

urlparse module is based upon the following RFC specifications.

RFC 3986 (STD66): "Uniform Resource Identifiers" by T. Berners-Lee, R. Fielding
and L.  Masinter, January 2005.

RFC 2732 : "Format for Literal IPv6 Addresses in URL's by R.Hinden, B.Carpenter
and L.Masinter, December 1999.

RFC 2396:  "Uniform Resource Identifiers (URI)": Generic Syntax by T.
Berners-Lee, R. Fielding, and L. Masinter, August 1998.

RFC 2368: "The mailto URL scheme", by P.Hoffman , L Masinter, J. Zawinski, July 1998.

RFC 1808: "Relative Uniform Resource Locators", by R. Fielding, UC Irvine, June
1995.

RFC 1738: "Uniform Resource Locators (URL)" by T. Berners-Lee, L. Masinter, M.
McCahill, December 1994

RFC 3986 is considered the current standard and any future changes to
urlparse module should conform with it.  The urlparse module is
currently not entirely compliant with this RFC due to defacto
scenarios for parsing, and for backward compatibility purposes, some
parsing quirks from older RFCs are retained. The testcases in
test_urlparse.py provides a good indicator of parsing behavior.
DefragResultBytes.geturlAccept authority or URI and extract only the authority and path.Use HTTPS protocol._proxy_bypass_macosx_sysconfProxyServerURLopener.open_https_thishostftpwrapper_ftperrorsmax_redirectionsReturn an HTTPResponse object for the request, using http_class.

        http_class must implement the HTTPConnection API from http.client.
        user_passwd{}#{}Return (scheme, user, password, host/port) given a URL or an authority.

    If a URL is supplied, it must have an authority (host:port) component.
    According to RFC 3986, having an authority component means the URL must
    have two slashes after the scheme.
    getproxies_registrynoncefile:// scheme is supported only on localhostunknown url typecadefaultFancyURLopener.__init__http_error_303proxy_passwdauth_valftp error %r(\d+(?:\.\d+)*)(/\d+)?Override this in a GUI environment!Use FTP protocol., digest="%s"^([^/:]+)://set_proxyinstall_opener_open_generic_httpInternal Server Error: Redirect RecursionfullurlCONTENT_HEADERSAbstractHTTPHandler.__init__ftpwrapper.retrfileURLopener.open_unknown_proxyadd_password, opaque="%s"open_local_fileBasic %sProxy-authorizationhttps_openredirect_dictAbstractHTTPHandler.set_http_debuglevelAbstractBasicAuthHandler.http_requestRequest.add_unredirected_headerftpwrapper.__init__Return a dictionary of scheme -> proxy server URL mappings.

    Scan the environment for variables named <scheme>_proxy;
    this seems to be the standard convention.  If you need a
    different way, you can pass a proxies dictionary to the
    [Fancy]URLopener constructor.

    Request.dataOpenerDirector.openpassword_mgrFancyURLopener.http_error_302proxy_bypass_environmentprompt_user_passwdsetMaxConns;base64Request.has_headerproxy_openhttp_error_307Content-Length: %dsel_pathretriedFTPHandler.connect_ftpBaseHandler.close©ÚselfÚreqÚftplibÚ	mimetypesÚhostÚportÚuserÚpasswdÚmsgÚpathÚattrsÚdirsÚfileÚfwÚtypeÚattrÚvalueÚfpÚretrlenÚheadersÚmtypeÚexpÚexcheader_itemsblocknumwww-authenticateinternetSettingsHTTPSHandler.__init__OS-specific conversion from a relative URL of the 'file' scheme
        to a file system path; not recommended for general use.Add a header to be used by the HTTP interface only
        e.g. u.addheader('Accept', 'sound/basic')local file error: not on local hostchallengeContent-type: %s©ÚselfÚreqÚchalÚrealmÚnonceÚqopÚ	algorithmÚopaqueÚHÚKDÚuserÚpwÚentdigÚA1ÚA2ÚncvalueÚcnonceÚnoncebitÚrespdigÚbase_URLopener__unlinkProxyHandler.proxy_openauth_headerFancyURLopener.retry_https_basic_auth_call_chainhttps_requestno_proxy_listContent-length: %d
ftp error: %rfqdnprocess_responseexpected BaseHandler instance, got %rcheck_cacheError 407 -- proxy authentication required.
        This function supports Basic authentication only.proxy-authenticateftp error: proxy support for ftp protocol currently not implementedReturn True, if host should be bypassed.

        Checks proxy settings gathered from the environment, if specified,
        or the registry.

        FancyURLopener.get_user_passwdlocalnameauthurireduced_authuriauthinfoFileHandler.open_local_file_url_tempfilesFancyURLopener.http_error_407AbstractBasicAuthHandler does not support the following scheme: '%s'urltypeunknown url type: %sHTTPPasswordMgr.is_suburiHTTPCookieProcessor.http_responseproxy_settingshostonlyip2numhostIPC:\msys64\mingw64\lib\python3.6\urllib\request.py%s_openURLopener.close, qop=auth, nc=%s, cnonce="%s"ProxyBasicAuthHandlerThe HTTP server returned a redirect error that would lead to an infinite loop.
The last 30x error message was:
An authentication protocol defined by RFC 2069

    Digest authentication improves on basic authentication because it
    does not transmit passwords in the clear.
    OpenerDirector._openProxyHandler.__init__Handle http errors.

        Derived class can override this, or provide specific handlers
        named http_error_DDD where DDD is the 3-digit error code.get_algorithm_implsftpwrapper.real_closehttps://%s*/*file_open%(class)s style of invoking requests is deprecated. Use newer urlopen functions/methodsDate: %sAbstractDigestAuthHandler does not support the following scheme: '%s'HTTPHandler.http_openproxyhost%s://%sHTTPDigestAuthHandler.http_error_401FancyURLopener.retry_proxy_https_basic_auth©ÚselfÚurlÚfilenameÚ
reporthookÚdataÚtypeÚurl1ÚfpÚhdrsÚmsgÚheadersÚtfpÚtempfileÚgarbageÚpathÚsuffixÚfdÚresultÚbsÚsizeÚreadÚblocknumÚblockAbstractDigestAuthHandler.get_authorizationBaseHandler.add_parentmax_repeatsReturn the set of errors raised by the FTP class.UnknownHandlerParse lists as described by RFC 2068 Section 2.

    In particular, parse comma-separated lists where the elements of
    the list may include quoted-strings.  A quoted-string could
    contain a comma.  A non-quoted string could have quotes in the
    middle.  Neither commas nor quotes count if they are escaped.
    Only double-quotes count, not single-quotes.
    (?:.*,)*[ 	]*([^ 	]+)[ 	]+realm=(["']?)([^"']*)\2http_error_%dReturn the IP address of the magic hostname 'localhost'.default_openconnection_factoryTransfer-encodingproxy_bypass_registryreduced_uri%/:=&?~#+!$,;'@()*[]|%s:%s:%sUse HTTP protocol.Request._parseRequest.full_url%a, %d %b %Y %H:%M:%S GMTHTTPPasswordMgr.find_user_passwordProxyOverride(.+\.)?%s$urlpartsCacheFTPHandler.setTimeoutAbstractDigestAuthHandler.get_entity_digestinvalid proxy for %sReturn an empty email Message object._have_sslHTTPErrorProcessornewurlproxyselectorOpenerDirector._call_chainhttp_conn_argsproxy_authAbstractBasicAuthHandler.http_error_auth_reqedadd_handlerupdate_authenticatedAbstractDigestAuthHandler.get_cnonceproxyEnableunredirected_hdrsgetproxies_environmentCacheFTPHandler.check_cacheFancyURLopener.http_error_307FancyURLopener.http_error_default%s:%s:%s:HTTPBasicAuthHandler.http_error_401mediatypeEnter password for %s in %s at %s: digest auth failed%s:%s:%s:%s:%sContent-Type: %s
Content-Length: %d
Last-modified: %s
Request.get_methodMake an HTTP connection using connection_class.

        This is an internal method that should be called from
        open_http() or open_https().

        Arguments:
        - connection_factory should take a host name and return an
          HTTPConnection instance.
        - url is the url to retrieval or a host, relative-path pair.
        - data is payload for a POST request or None.
        application/x-www-form-urlencodedHTTPErrorProcessor.http_responseHTTPRedirectHandler.redirect_request_localhostfile error: proxy support for file protocol currently not implementedHTTPSHandler.https_openAbstractHTTPHandler._get_content_lengthipAddrClean up temporary files from urlretrieve calls.authreqFancyURLopener.retry_http_basic_authis_authenticatedretry_http_digest_authURLopener._https_connectionRequest.has_proxydata errorcredentialsauth_strURLopener.addheaderno host givenlocal file url may start with / or file:. Unknown url of type: %sAbstractBasicAuthHandler.http_responseClass used by open_ftp() for cache of open FTP connections.file not on local hosthttp_error_301qop '%s' is not supported.endtransferError 401 -- authentication required.
        This function supports Basic authentication only.Use URLopener().open(file) instead of open(file, 'r').FancyURLopener.retry_proxy_http_basic_authftpobjnoheadersFileHandler.get_nameshttp protocol error: bad status line_get_proxy_settingsclient_version
    Return True iff this host shouldn't be accessed using a proxy

    This function uses the MacOSX framework SystemConfiguration
    to fetch the proxy information.

    proxy_settings come from _scproxy._get_proxy_settings or get mocked ie:
    { 'exclude_simple': bool,
      'exceptions': ['foo.bar', '*.bar.com', '127.0.0.1', '10.1', '10.0/16']
    }
    BaseHandler.__lt__SSL support not availableReturn a dictionary of scheme -> proxy server URL mappings.

        This function uses the MacOSX framework SystemConfiguration
        to fetch the proxy information.
        Error 307 -- relocated, but turn POST into error.%s://%s%sproxy_auth_hdrHTTPPasswordMgrWithPriorAuth<module urllib.request>parse_http_listCreate an opener object from a list of handlers.

    The opener will use several default handlers, including support
    for HTTP, FTP and when applicable HTTPS.

    If any of the handlers passed as arguments are subclasses of the
    default handlers, the default handlers will not be used.
    reset_retry_countusername="%s", realm="%s", nonce="%s", uri="%s", response="%s"DataHandlerinf_msg_proxy_bypass_macosx_sysconf.<locals>.ip2numReturn a dictionary of scheme -> proxy server URL mappings.

        Win32 uses the registry to store proxies.

        AbstractBasicAuthHandler.__init__URLopener.open_fileReturn a dictionary of scheme -> proxy server URL mappings.

        Returns settings gathered from the environment, if specified,
        or the registry.

        Check if test is below base in a URI tree

        Both args must be URIs in reduced form.
        ftp://%sdefault_methodHTTPDefaultErrorHandler.http_error_defaultRequest.remove_headerProxyHandler.__init__.<locals>.<lambda>keepaliveredirect_internalrawHostOpen the URL url, which can be either a string or a Request object.

    *data* must be an object specifying additional data to be sent to
    the server, or None if no such data is needed.  See Request for
    details.

    urllib.request module uses HTTP/1.1 and includes a "Connection:close"
    header in its HTTP requests.

    The optional *timeout* parameter specifies a timeout in seconds for
    blocking operations like the connection attempt (if not specified, the
    global default timeout setting will be used). This only works for HTTP,
    HTTPS and FTP connections.

    If *context* is specified, it must be a ssl.SSLContext instance describing
    the various SSL options. See HTTPSConnection for more details.

    The optional *cafile* and *capath* parameters specify a set of trusted CA
    certificates for HTTPS requests. cafile should point to a single file
    containing a bundle of CA certificates, whereas capath should point to a
    directory of hashed certificate files. More information can be found in
    ssl.SSLContext.load_verify_locations().

    The *cadefault* parameter is ignored.

    This function always returns an object which can work as a context
    manager and has methods such as

    * geturl() - return the URL of the resource retrieved, commonly used to
      determine if a redirect was followed

    * info() - return the meta-information of the page, such as headers, in the
      form of an email.message_from_string() instance (see Quick Reference to
      HTTP Headers)

    * getcode() - return the HTTP status code of the response.  Raises URLError
      on errors.

    For HTTP and HTTPS URLs, this function returns a http.client.HTTPResponse
    object slightly modified. In addition to the three new methods above, the
    msg attribute contains the same information as the reason attribute ---
    the reason phrase returned by the server --- instead of the response
    headers as it is specified in the documentation for HTTPResponse.

    For FTP, file, and data URLs and requests explicitly handled by legacy
    URLopener and FancyURLopener classes, this function returns a
    urllib.response.addinfourl object.

    Note that None may be returned if no handler handles the request (though
    the default installed global OpenerDirector uses UnknownHandler to ensure
    this never happens).

    In addition, if proxy settings are detected (for example, when a *_proxy
    environment variable like http_proxy is set), ProxyHandler is default
    installed and makes sure the requests are handled through the proxy.

    retrieve(url) returns (filename, headers) for a local object
        or (tempfilename, headers) for a remote object.AbstractDigestAuthHandler.get_algorithm_implsftp_openmaxtriesftpcacheFancyURLopener.http_error_301DataHandler.data_openCacheFTPHandler.connect_ftptext/plain;charset=US-ASCIIProxyBasicAuthHandler.http_error_407default_classesBasic Auth Realm was unquotedFTPHandler.ftp_opentempcachehttps_handler<local>URLopener.retrieveAbstractDigestAuthHandler.reset_retry_countUse "data" URL.handler_orderAbstractDigestAuthHandler.get_algorithm_impls.<locals>.<lambda>max_conns_randombytesURLopener.open_ftplocalfileProxyEnableunknown_openURLopener.open_local_file_parse_proxyURLopener.open_datahttp_error_%sÛ!   zRequestzOpenerDirectorzBaseHandlerzHTTPDefaultErrorHandlerzHTTPRedirectHandlerzHTTPCookieProcessorzProxyHandlerzHTTPPasswordMgrzHTTPPasswordMgrWithDefaultRealmzHTTPPasswordMgrWithPriorAuthzAbstractBasicAuthHandlerzHTTPBasicAuthHandlerzProxyBasicAuthHandlerzAbstractDigestAuthHandlerzHTTPDigestAuthHandlerzProxyDigestAuthHandlerzHTTPHandlerzFileHandlerz
FTPHandlerzCacheFTPHandlerzDataHandlerzUnknownHandlerzHTTPErrorProcessorzurlopenzinstall_openerzbuild_openerzpathname2urlzurl2pathnamez
getproxieszurlretrievez
urlcleanupz	URLopenerzFancyURLopenerParse list of key=value strings where keys are not duplicated.url error
    Retrieve a URL into a temporary location on disk.

    Requires a URL argument. If a filename is passed, it is used as
    the temporary file location. The reporthook argument should be
    a callable that accepts a block number, a read size, and the
    total file size of the URL target. The data argument should be
    valid URL encoded data.

    If a filename is passed and the URL points to a local resource,
    the result is a copy from local file to new file.

    Returns a tuple containing the path to the newly created
    data file as well as the resulting HTTPMessage object.
    UnknownHandler.unknown_openHTTPCookieProcessor.http_requestlast_noncedo_request_FancyURLopener.redirect_internalSoftware\Microsoft\Windows\CurrentVersion\Internet SettingsHTTPPasswordMgr.add_passwordUse local file or FTP depending on form of URL.parse_keqv_listreduce_uriftpwrapper.closeHTTPPasswordMgr.__init__CacheFTPHandler.__init__r_schemeURLopener.cleanuplocalhost/cafile, cpath and cadefault are deprecated, use a custom context instead.handle_openDefault error handling -- don't raise an exception.FancyURLopener.http_error_303_full_urlTest if proxies should not be used for a particular host.

    Checks the proxy dict for the value of no_proxy, which should
    be a list of comma separated DNS suffixes, or '*' for all hosts.

    _get_proxiesAbstractBasicAuthHandler.retry_http_basic_authHTTPPasswordMgrWithPriorAuth.is_authenticatedHTTPPasswordMgrWithPriorAuth.update_authenticatedError 301 -- also relocated (permanently).orig_typecredsdata error: proxy support for data protocol currently not implemented, algorithm="%s"%08xRequest.header_itemsURLopener.__del__Return the IP addresses of the current host.Content-type: %s
Content-length: %d
Unsupported digest authentication algorithm %rProcess HTTP error responses.AbstractDigestAuthHandler.retry_http_digest_authMAXFTPCACHEgethostbyname_exorigurlproxies must be a mappingproxy URL with no authority: %r_URLopener__tempfilesOpenerDirector.closeUse local file.nonce_countFancyURLopener.http_error_401You can't pass both context and any of cafile, capath, and cadefault_noheadersproxyServerRequest.get_headerRequest.add_headerFancyURLopener.prompt_user_passwdhttp_error_500HTTPRedirectHandler.http_error_302Proxy-Authorizationretrieval incomplete: got only %i out of %i bytesurlfileAn extensible library for opening URLs using a variety of protocols

The simplest way to use this module is to call the urlopen function,
which accepts a string containing a URL or a Request object (described
below).  It opens the URL and returns the results as file-like
object; the returned object has some extra methods described below.

The OpenerDirector manages a collection of Handler objects that do
all the actual work.  Each Handler implements a particular protocol or
option.  The OpenerDirector is a composite object that invokes the
Handlers needed to open the requested URL.  For example, the
HTTPHandler performs HTTP GET and POST requests and deals with
non-error returns.  The HTTPRedirectHandler automatically deals with
HTTP 301, 302, 303 and 307 redirect errors, and the HTTPDigestAuthHandler
deals with digest authentication.

urlopen(url, data=None) -- Basic usage is the same as original
urllib.  pass the url and optionally data to post to an HTTP URL, and
get a file-like object back.  One difference is that you can also pass
a Request instance instead of URL.  Raises a URLError (subclass of
OSError); for HTTP errors, raises an HTTPError, which can also be
treated as a valid response.

build_opener -- Function that creates a new OpenerDirector instance.
Will install the default handlers.  Accepts one or more Handlers as
arguments, either instances or Handler classes that it will
instantiate.  If one of the argument is a subclass of the default
handler, the argument will be installed instead of the default.

install_opener -- Installs a new opener as the default opener.

objects of interest:

OpenerDirector -- Sets up the User Agent as the Python-urllib client and manages
the Handler classes, while dealing with requests and responses.

Request -- An object that encapsulates the state of a request.  The
state can be as simple as the URL.  It can also include extra HTTP
headers, e.g. a User-Agent.

BaseHandler --

internals:
BaseHandler and parent
_call_chain conventions

Example usage:

import urllib.request

# set up authentication info
authinfo = urllib.request.HTTPBasicAuthHandler()
authinfo.add_password(realm='PDQ Application',
                      uri='https://mahler:8092/site-updates.py',
                      user='klem',
                      passwd='geheim$parole')

proxy_support = urllib.request.ProxyHandler({"http" : "http://ahad-haam:3128"})

# build a new opener that adds authentication and caching FTP handlers
opener = urllib.request.build_opener(proxy_support, authinfo,
                                     urllib.request.CacheFTPHandler)

# install it
urllib.request.install_opener(opener)

f = urllib.request.urlopen('http://www.python.org/')
HTTPCookieProcessor.__init__OpenerDirector.errorBasic {}file_closeRequest.set_proxyFileHandler.file_openReturn a Request or None in response to a redirect.

        This is called by the http_error_30x methods when a
        redirection response is received.  If a redirection should
        take place, return a new Request to allow http_error_30x to
        perform the redirect.  Otherwise, raise HTTPError if no-one
        else should try to handle this url.  Return None if you can't
        but another Handler might.
        addheadersproxyOverridePython-urllib/%s%s:%s@%sProxyDigestAuthHandler.http_error_407Request.get_full_urlsel_hostrealhostUser-agentAbstractHTTPHandler.do_openftp error: no host givenHTTPPasswordMgrWithPriorAuth.__init__Overridable interface to open unknown URL type.gaierrorHTTPRedirectHandler.redirect_request.<locals>.<genexpr>CacheFTPHandler.clear_cache_cut_port_re_safe_gethostbynameDefault error handler: close the connection and raise OSError.OpenerDirector.add_handlerftpwrapper.file_closeURLopener._open_generic_httpgetproxies_macosx_sysconfAbstractHTTPHandler.do_open.<locals>.<genexpr>HTTPPasswordMgr.reduce_uri Redirection to url '%s' is not allowed.auth_cacheClass to open URLs.
    This is a class rather than just a subroutine because we may need
    more than one set of global protocol-specific options.
    Note -- this is a base class for those who don't want the
    automatic handling of errors type 302 (relocated) and 401
    (authorization needed).[ 	]*([^ 	]+)[ 	]+realm="([^"]*)"soonestReturn a string indicating the HTTP request method.AbstractHTTPHandler.do_request_url_typesocket error©ÚselfÚurlÚ	mimetypesÚhostÚpathÚportÚuserÚpasswdÚftplibÚattrsÚdirsÚfileÚkeyÚkÚvÚtypeÚattrÚvalueÚfpÚretrlenÚmtypeÚheadersÚexpAbstractDigestAuthHandler.__init__OpenerDirector.__init__Error 303 -- also relocated (essentially identical to 302).POST data should be bytes, an iterable of bytes, or a file object. It cannot be of type str.Derived class with handlers for errors we can handle (perhaps).ftpwrapper.initOS-specific conversion from a file system path to a relative URL
        of the 'file' scheme; not recommended for general use.%s - Redirection to url '%s' is not allowedunknown url type: %rDigest %sCacheFTPHandler.setMaxConnsbad data URLhttps_responseReturn True, if host should be bypassed.

        Checks proxy settings gathered from the environment, if specified,
        or from the MacOSX framework SystemConfiguration.

        ftpwrapper.endtransferError 302 -- relocated (temporarily).AbstractDigestAuthHandler.http_error_auth_reqedEnter username for %s at %s: Content-type: %s
Content-length: %d
Last-modified: %s
HTTPPasswordMgrWithDefaultRealm.find_user_passwordHTTPPasswordMgrWithPriorAuth.add_passwordClass to add a close hook to an open file.addclosehook.__init__Base class for addinfo and addclosehook. Is a good idea for garbage collection.addbase.__init__addinfourl.__init__addbase.__exit__addclosehook.closehookargsaddbase.__enter__class to add info() and geturl() methods to an open file.<urllib response><module urllib.response>addinfo.__init__Response classes used by urllib.

The base class, addbase, defines a minimal file-like interface,
including read() and readline().  The typical response object is an
addinfourl instance, which defines an info() method that returns
headers and a geturl() method that returns the url.
addbase.__repr__addinfourl.getcodeaddinfo.infoaddinfourl.geturl<%s at %r whose fp = %r>class to add an info() method to an open file.C:\msys64\mingw64\lib\python3.6\urllib\response.pyC:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\utilsC:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\utils\__init__.py<module utils.AppDirs>/nonexistent//sbuild-nonexistent/C:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\utils\AppDirs.pyuser_data_dirappdirsFileOperationsuser_cache_dir Wrapper around appdir from PyPI

We do not assume to be installed and fallback to an inline copy and if that
is not installed, we use our own code for best effort.
" "\\%o_encodePythonStringToC<module utils.CStrings> C string encoding

This contains the code to create string literals for C to represent the given
values and little more.
[^a-zA-Z0-9_] Encode a string, so that it gives a C string literal.

        This doesn't handle limits.
    encodePythonIdentifierToC.<locals>.<genexpr> Encode an identifier from a given Python string.

    encodePythonIdentifierToC.<locals>.r\	
"?C:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\utils\CStrings.py$$%d$path_elementsenv_var_nameold_path Find Python on Windows.

    _unused_err Call a process and check result code.

        This is for Python 2.6 compatibility, which doesn't have that in its
        standard library.
     Do exec in a portable way preserving exit code.

        On Windows, unfortunately there is no real exec, so we have to spawn
        a new process instead.
     Find an execute in PATH environment. C:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\utils\Execution.py Program execution related stuff.

Basically a layer for os, subprocess, shutil to come together. It can find
binaries (needed for exec) and run them capturing outputs.
<module utils.Execution>_dirnamessplitPath.<locals>.<genexpr> Give a sorted path, base filename pairs of a directory.C:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\utils\FileOperations.py Relative path, if possible.  Remove a directory recursively.

        On Windows, it happens that operations fail, and succeed when reried,
        so added a retry and small delay, then another retry. Should make it
        much more stable during tests.

        All kinds of programs that scan files might cause this, but they do
        it hopefully only briefly.
    withTemporaryFilename Are two paths the same.

    Same meaning here, that case differences ignored on platforms where
    that is the norm, and with normalized, and turned absolut paths,
    there is no differences.
     Create a directory if it doesn'T exist.removeDirectory.<locals>.onError Utils for file and directory operations.

This provides enhanced and more error resilient forms of standard
stuff. It will also frequently add sorting.

<module utils.FileOperations> Split path, skipping empty elements. counted_del.<locals>.wrapped_delwrapped_initdel_funccounted_initscounted_init.<locals>.wrapped_init<module utils.InstanceCounters> Instance counter primitives

We don't use a meta class as it's unnecessary complex, and portable meta classes
have their difficulties, and want to count classes, who already have a meta
class.

This is going to expanded with time.

counted_delsempty_delC:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\utils\InstanceCounters.pyInit/del calls:C:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\utils\MemoryUsage.py      0A%.2f KB (%d bytes)getOwnProcessMemoryUsagegetOwnProcessMemoryUsage.<locals>.PROCESS_MEMORY_COUNTERS_EXPageFaultCount      ÐA<module utils.MemoryUsage>psapiQuotaPeakNonPagedPoolUsageTop 50 memory allocations:      @PrivateUsageRUSAGE_SELFGetProcessMemoryInfoMemoryWatch.finish%.2f GB (%d bytes)PeakPagefileUsageWorkingSetSize%.2f MB (%d bytes)QuotaPeakPagedPoolUsageì       ögetrusageQuotaPagedPoolUsage Memory usage of own process in bytes.

    MemoryWatch.__init__MemoryWatch.asStr Tools for tracing memory usage at compiled time.

QuotaNonPagedPoolUsagePeakWorkingSetSizeru_maxrss This module deals with finding and information about shared libraries.

<module utils.SharedLibraries>C:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\utils\SharedLibraries.py<module utils.Shebang>getShebangFromFile^#!\s*(.*?)\nC:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\utils\Shebang.py Utils to work with shebang lines.

ThreadPoolExecutor.__enter__<module utils.ThreadedExecutor> Threaded pool execution.

This can use Python3 native, Python2.7 backport, or has a Python2.6 stub that
does not thread at all.
ThreadPoolExecutor.__exit__C:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\utils\ThreadedExecutor.pystart_timeC:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\utils\Timing.pyStopWatch.__init__StopWatch.deltaTimerReport.__exit__StopWatch.start<module utils.Timing>TimerReport.__init__ Time taking.

Mostly for measurements of Nuitka of itself, e.g. how long did it take to
call an external tool.
TimerReport.__enter__StopWatch.end Timer that reports how long things took.

        Mostly intended as a wrapper for external process calls.
    processor	:$_$C:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\utils\Utils.pycpuinfo_file<module utils.Utils>/proc/cpuinfo Encode variable name that is potentially not ASCII to ASCII only.

        For Python3, unicode identifiers can be used, but these are not
        possible in C, so we need to replace them.
     Utility module.

Here the small things that fit nowhere else and don't deserve their own module.

Warning: %s
Truncated input fileC:\msys64\mingw64\lib\python3.6\uu.py<module uu> 
end
uuencode/uudecode main program--textusage: %prog [-d] [-t] [input [output]]b2a_uuopened_fileshdrfieldsImplementation of the UUencode and UUdecode functions.

encode(in_file, out_file [,name, mode])
decode(in_file [, out_file, mode])
Decode uuencoded file 	
No valid begin line found in input filedata is text, encoded format unix-compatible text?Decode (instead of encode)?: cannot do -t to stdouta2b_uu--decodeCannot overwrite existing file: %sUuencode filebegin %o %s
: cannot do -t from stdininvalid lineno %rlocal_values_filters_versionInsert an entry into the list of warnings filters (at the front).

    'action' -- one of "error", "ignore", "always", "default", "module",
                or "once"
    'message' -- a regex that the warning message must match
    'category' -- a class that the warning must be a subclass of
    'module' -- a regex that the module name must match
    'lineno' -- an integer line number, 0 matches all warnings
    'append' -- if true, append to the list of filters
    resource_action^[a-zA-Z0-9_]+$invalid warning category: %rmodule=%rException used by option processing helpers.module must be a stringA context manager that copies and restores the warnings filter upon
    exiting the context.

    The 'record' argument specifies whether warnings should be captured by a
    custom implementation of warnings.showwarning() and be appended to a list
    returned by the context manager. Otherwise None is returned by the context
    manager. The objects appended to the list are arguments whose attributes
    mirror the arguments to showwarning().

    The 'module' argument is to specify an alternative module to the module
    named 'warnings' and imported under that name. This argument is only useful
    when testing the warnings module itself.

    catch_warnings.__enter__Specify whether to record warnings and if an alternative module
        should be used other than sys.modules['warnings'].

        For compatibility with Python 3.0, please consider all arguments to be
        keyword-only.

        _setoptiononcekeyaltkey_add_filterunknown warning category: %r_OptionErrorcatch_warnings.__init__category must be a Warning subclassdefaultactionInsert a simple entry into the list of warnings filters (at the front).

    A simple filter matches all modules and messages.
    'action' -- one of "error", "ignore", "always", "default", "module",
                or "once"
    'category' -- a class that the warning must be a subclass of
    'lineno' -- an integer line number, 0 matches all warnings
    'append' -- if true, append to the list of filters
    warnings.showwarning() must be set to a function or methodinvalid module name: %rcategory must be a Warning subclass, not '{:s}'fnl_next_external_frameresetwarningsObject allocated at (most recent call first):
  File "%s", lineno %s
Find the next frame that doesn't involve CPython internals._WARNING_DETAILScatch_warnings.__exit__Cannot exit %r without entering first_is_internal_framelineno must be an int >= 0Hook to write a warning to a file; replace if you like.WarningMessage.__str__Signal whether the frame is an internal CPython implementation detail._formatwarnmsg_getactioncategory must be a classUnrecognized action (%r) in warnings.filters:
 %s_onceregistryClear the list of warning filters, so that no filters are active._enteredWarningMessage.__init___getcategoryCannot enter %r twicemessage must be a string_formatwarning_orig_category_name%s:%s: %s: %s
too many fields (max 5): %rC:\msys64\mingw64\lib\python3.6\warnings.py_defaultaction_filters_mutatedcatch_warnings.__repr___formatwarnmsg_implInvalid -W option ignored:record=True{message : %r, category : %r, filename : %r, lineno : %s, line : %r}<module warnings>bytes_action_showwarnmsg_implFunction to format a warning the standard way.Issue a warning, or maybe ignore it or raise an exception.Python part of the warnings subsystem._showwarning_orig_warnings_defaults_processoptionsWeakMethod.__eq___InfoWeakKeyDictionary.__delitem__ReferenceTypefinalize.alive_dirty_lenfinalize._select_for_exit.<locals>.<lambda>getweakrefsWeakValueDictionary._commit_removalsWeakValueDictionary.__contains__WeakKeyDictionary.__repr__WeakKeyDictionary.itemsWeakValueDictionary.__getitem__Weak reference support for Python.

This module is an implementation of PEP 205:

http://www.python.org/dev/peps/pep-0205/
KeyedRef.__init__WeakKeyDictionary.__contains__WeakKeyDictionary.keysself_wrfinalize._InfoWhether finalizer should be called at exitWeakMethod.__ne__<%s object at %#x; for %r at %#x>C:\msys64\mingw64\lib\python3.6\weakref.pyWeakValueDictionary.__init__WeakValueDictionary.__len__WeakValueDictionary.keysWeakKeyDictionary.update
    A custom `weakref.ref` subclass which simulates a weak reference to
    a bound method, working around the lifetime problem of bound methods.
    _remove_dead_weakrefgetweakrefcountCallableProxyTypeProxyTypesWhether finalizer is aliveWeakKeyDictionary.__init__<%s object at %#x; dead>WeakKeyDictionary.copyWeakValueDictionary.__init__.<locals>.removereenable_gcIf alive then mark as dead and return (obj, func, args, kwargs);
        otherwise return Nonefinalize.peekWeakValueDictionary.__setitem__WeakKeyDictionary.__deepcopy__WeakValueDictionary.getWeakValueDictionary.update_func_ref_meth_typeReturn an iterator that yields the weak references to the values.

        The references are not guaranteed to be 'live' at the time
        they are used, so the result of calling the references needs
        to be checked before being used.  This can be used to avoid
        creating references that will cause the garbage collector to
        keep the values around longer than needed.

        WeakMethod.__call__If alive then return (obj, func, args, kwargs);
        otherwise return NoneWeakValueDictionary.itervaluerefsWeakMethod.__new___atomic_removalReturn a list of weak references to the keys.

        The references are not guaranteed to be 'live' at the time
        they are used, so the result of calling the references needs
        to be checked before being used.  This can be used to avoid
        creating references that will cause the garbage collector to
        keep the keys around longer than needed.

        Specialized reference that includes a key corresponding to the value.

    This is used in the WeakValueDictionary to avoid having to create
    a function object for each key stored in the mapping.  A shared
    callback object can use the 'key' attribute of a KeyedRef instead
    of getting a reference to the key from an enclosing scope.

    argument should be a bound method, not {}WeakValueDictionary.popitemWeakKeyDictionary.__setitem__WeakKeyDictionary._scrub_removalsfinalize.detachWeakKeyDictionary.popWeakKeyDictionary.valuesWeakMethod.__new__.<locals>._cbWeakKeyDictionary.__init__.<locals>.removefinalize.atexitfinalize.__init___registered_with_atexitkeyrefsfinalize.__call__If alive then mark as dead and return func(*args, **kwargs);
        otherwise return NoneReturn a list of weak references to the values.

        The references are not guaranteed to be 'live' at the time
        they are used, so the result of calling the references needs
        to be checked before being used.  This can be used to avoid
        creating references that will cause the garbage collector to
        keep the values around longer than needed.

        WeakKeyDictionary.setdefaultWeakKeyDictionary.__len__WeakValueDictionary.__delitem__WeakValueDictionary.setdefaultWeakValueDictionary.__repr__WeakKeyDictionary.popitemWeakValueDictionary.itemsWeakKeyDictionary._commit_removals<module weakref>WeakKeyDictionary.getWeakValueDictionary.__deepcopy__descriptor 'update' of 'WeakValueDictionary' object needs an argumentMapping class that references values weakly.

    Entries in the dictionary will be discarded when no strong
    reference to the value exists anymore
    WeakKeyDictionary.keyrefsWeakValueDictionary.valuesWeakKeyDictionary.__getitem___index_iterClass for finalization of weakrefable objects

    finalize(obj, func, *args, **kwargs) returns a callable finalizer
    object which will be called when obj is garbage collected. The
    first time the finalizer is called it evaluates func(*arg, **kwargs)
    and returns the result. After this the finalizer is dead, and
    calling it just returns None.

    When the program exits any remaining finalizers for which the
    atexit attribute is true will be run in reverse order of creation.
    By default atexit is true.
    KeyedRef.__new__descriptor '__init__' of 'WeakValueDictionary' object needs an argumentfinalize._exitfuncWeakValueDictionary.copyfinalize.__repr__ Mapping class that references keys weakly.

    Entries in the dictionary will be discarded when there is no
    longer a strong reference to the key. This can be used to
    associate additional data with an object owned by other parts of
    an application without adding attributes to those objects. This
    can be especially useful with objects that override attribute
    accesses.
    WeakValueDictionary.valuerefsLauncher class for Elinks browsers.autoraiseC:\Program Filescould not locate runnable browserGrail.openKonqueror.openGrail._remotesafarixdg-openDISPLAYOmniWebmozillaGenericBrowser.openReturn a browser launcher instance appropriate for the environment.MacOSX.openiceweaselnew_winkonquerorClass for all browsers which are to be started in the
       background.Bad 'new' parameter to open(); elinksLauncher class for Aqua browsers on Mac OS X

        Optionally specify a browser name on instantiation.  Note that this
        will not work for Aqua browsers if the user has moved the application
        package after installation.

        If no browser is specified, the default browser, as specified in the
        Internet System Preferences panel, will be used.
        -new-tabMacOSXOSAScript.opengrailWindowsDefault-remoteLauncher class for Galeon/Epiphany browsers.kfmkfmclientremote_action_newwinskipstoneopenURL(%s%action)Grail._find_grail_rcBaseBrowserexpected 0, 1, or 2, got %sWindowsDefault.open_userchoicesLauncher class for Google Chrome browser.osascriptfirebirdtoWindowosapipemozilla-firebirdchromium-browserLauncher class for Mozilla browsers.--silentwindows-defaultBaseBrowser.open_new_tabUnixBrowser._invoke_synthesizeinoutBROWSERopen location "%s"iceapex-www-browserParent class for all Unix browsers with remote functionality.mozilla-firefoxUsage: %s [-n | -t] url
    -n: open new window
    -t: open new tab%22Interfaces for launching and remotely controlling Web browsers.MacOSX.__init__galeonepiphanyParent class for all browsers. Do not use directly.PROGRAMFILESLauncher class for Opera browser.startfileKDE_FULL_SESSIONupdate_tryorderraise_optstoWindow %dgoogle-chromeMacOSXOSAScript.__init__UnixBrowser.openw3mBackgroundBrowsergvfs-openseamonkeyRegister a browser connector and, optionally, connection.mosaic
                   tell application "%s"
                       activate
                       open location "%s"
                   end
                   OpenURL "%s"GNOME_DESKTOP_SESSION_IDLauncher class for Netscape browser.Attempt to synthesize a controller base on existing controllers.

    This is useful to create a controller when a user specifies a path to
    an entry in the BROWSER environment variable -- we can copy a general
    controller to operate using a specific installation of the desired
    browser in this way.

    If we can't create a controller in this way, or if there is no
    executable for the requested browser, return [None, None].

    ,new-tabLOAD maybes,new-page_browsers-noraiseGenericBrowser.__init__<module webbrowser>newTab.grail-unixiexploreChromium--new-windowgnome-open,new-windowController for the KDE File Manager (kfm, or Konqueror).

    See the output of ``kfmclient --commands``
    for more information on the Konqueror remote-control interface.
    Internet Explorer\IEXPLORE.EXEremote_action_newtabregister_X_browsersC:\msys64\mingw64\lib\python3.6\webbrowser.pyBaseBrowser.__init__remote_argsLOADNEW tell application "%s"
                                activate
                                %s %s
                            end tellClass for all browsers started with a command
       and without remote functionality.BackgroundBrowser.openCore XML support for Python.

This package contains four sub-packages:

dom -- The W3C Document Object Model.  This supports DOM Level 1 +
       Namespaces.

parsers -- Python wrappers for XML parsers (currently only supports Expat).

sax -- The Simple API for XML, developed by XML-Dev, led by David
       Megginson and ported to Python by Lars Marius Garshol.  This
       supports the SAX 2 API.

etree -- The ElementTree XML library.  This is a subset of the full
       ElementTree XML release.

C:\msys64\mingw64\lib\python3.6\xml\__init__.pyC:\msys64\mingw64\lib\python3.6\xml\etreeC:\msys64\mingw64\lib\python3.6\xml\etree\__init__.pyprepare_starprepare_descendantprepare_self.<locals>.selectparent_mapunsupported expressionprepare_parent-()invalid pathinvalid predicateprepare_predicate.<locals>.selectXPath offset from last() must be negativeC:\msys64\mingw64\lib\python3.6\xml\etree\ElementPath.pyresult_map@-='XPath position >= 1 expectedxpath_tokenizerelemsprepare_child_SelectorContextcache_key_SelectorContext.__init__prepare_child.<locals>.selectprepare_parent.<locals>.selectprefix %r not found in prefix mapget_parent_mapxml.etree.ElementPathprepare_descendant.<locals>.selectinvalid descendantprepare_star.<locals>.select('[^']*'|\"[^\"]*\"|::|//?|\.\.|\(\)|[/.*:\[\]\(\)@=])|((?:\{[^}]+\})?[^/\[\]\(\)@=\s]+)|\s+<module xml.etree.ElementPath>xpath_tokenizer_re\-?\d+$-()-unsupported functioncannot use absolute path on elementhttp://www.w3.org/XML/1998/namespacehttp://www.w3.org/1999/xhtmlhttp://www.w3.org/1999/02/22-rdf-syntax-ns#http://schemas.xmlsoap.org/wsdl/http://www.w3.org/2001/XMLSchemahttp://www.w3.org/2001/XMLSchema-instancehttp://purl.org/dc/elements/1.1/file_or_filenamexml_declarationdefault_namespaceshort_empty_elementsenc_lowerdeclared_encodingqnamesQName.__repr___flushTreeBuilder_ListDataStream.seekableattrib_inElement.__getitem__Get element attribute.

        Equivalent to attrib.get, but some implementations may handle this a
        bit more efficiently.  *key* is what attribute to look for, and
        *default* is what to return if the attribute was not found.

        Returns a string containing the attribute value, or the default if
        attribute was not found.

        register_namespacefeed() called after end of streaminternal error (tail)Element.makeelementbasefontisindexProcessingInstructionElement.__setitem__Find all matching subelements by tag name or path.

        *path* is a string having either an element tag or an XPath,
        *namespaces* is an optional mapping from namespace prefix to full name.

        Returns list containing all matching elements in document order.

        TreeBuilder._flushErrorColumnNumberFind all matching subelements by tag name or path.

        *path* is a string having either an element tag or an XPath,
        *namespaces* is an optional mapping from namespace prefix to full name.

        Return an iterable yielding all matching elements in document order.

        _Element_Py_raiseerrorAn auxiliary stream accumulating into a list reference.Prefix format reserved for internal useElement.itemsXMLParser.__init__missing toplevel elementgetiteratortext_or_uriThis method of XMLParser is deprecated.  Define doctype() method on the TreeBuilder target._get_writer.<locals>.<lambda>close_sourceattrib must be dict, not %sReturn copy of current element.

        This creates a shallow copy. Subelements will be shared with the
        original tree.

        _setevents_fixnameCreate tree iterator.

        The iterator loops over the element and all subelements in document
        order, returning all elements with a matching tag.

        If the tree structure is modified during iteration, new or removed
        elements may or may not be included.  To get a stable set, use the
        list() function on the iterator, and loop over the resulting list.

        *tag* is what tags to look for (default is to return all elements)

        Return an iterator containing all the matching elements.

        _parse_wholepullparseradd_qname<!--%s-->TreeBuilder.__init__ElementTree.iterRemove matching subelement.

        Unlike the find methods, this method compares elements based on
        identity, NOT ON tag value or contents.  To remove subelements by
        other means, the easiest way is to use a list comprehension to
        select what elements to keep, and then use slice assignment to update
        the parent element.

        ValueError is raised if a matching element could not be found.

        XMLParser.doctypeXMLParser.close xmlns%s="%s"XMLParser._fixnameElementTree.getiteratorFind all matching subelements by tag name or path.

        Same as getroot().iterfind(path), which is element.iterfind()

        *path* is a string having either an element tag or an XPath,
        *namespaces* is an optional mapping from namespace prefix to full name.

        Return an iterable yielding all matching elements in document order.

        Element._assert_is_elementXMLPullParser.feedTreeBuilder.startXMLPullParser.read_events<module xml.etree.ElementTree>Element.iterTreeBuilder.dataFind all matching subelements by tag name or path.

        Same as getroot().findall(path), which is Element.findall().

        *path* is a string having either an element tag or an XPath,
        *namespaces* is an optional mapping from namespace prefix to full name.

        Return list containing all matching elements in document order.

        QName.__init___ListDataStream.writedata_handlerXMLParser._setevents.<locals>.handlerElementTree.__init__cannot serialize %r (type %s)Set element attribute.

        Equivalent to attrib[key] = value, but some implementations may handle
        this a bit more efficiently.  *key* is what attribute to set, and
        *value* is the attribute value to set it to.

        Element.__bool__Element.setGet element attributes as a sequence.

        The attributes are returned in arbitrary order.  Equivalent to
        attrib.items().

        Return a list of (name, value) tuples.

        Element.itertextns%dattr_listXMLParser._endFind first matching element by tag name or path.

        Same as getroot().findtext(path),  which is Element.findtext()

        *path* is a string having either an element tag or an XPath,
        *namespaces* is an optional mapping from namespace prefix to full name.

        Return the first matching element, or None if no element was found.

        _serialize_html.<locals>.<lambda>IterParseIteratorQName.__eq__undefined entity %s: line %d, column %dstart-nsIncrementally parse XML document into ElementTree.

    This class also reports what's going on to the user based on the
    *events* it is initialized with.  The supported events are the strings
    "start", "end", "start-ns" and "end-ns" (the "ns" events are used to get
    detailed namespace information).  If *events* is omitted, only
    "end" events are reported.

    *source* is a filename or file object containing XML data, *events* is
    a list of events to report back, *parser* is an optional parser instance.

    Returns an iterator providing (event, elem) pairs.

    missing end tags_escape_attrib_html_ListDataStream.writableevents_queueFind first matching element by tag name or path.

        Same as getroot().find(path), which is Element.find()

        *path* is a string having either an element tag or an XPath,
        *namespaces* is an optional mapping from namespace prefix to full name.

        Return the first matching element, or None if no element was found.

        internal error (text)SubElementc14nStartNamespaceDeclHandlertostringlistFind first matching element by tag name or path.

        *path* is a string having either an element tag or an XPath,
        *namespaces* is an optional mapping from namespace prefix to full name.

        Return the first matching element, or None if no element was found.

        Write element tree or element structure to sys.stdout.

    This function should be used for debugging only.

    *elem* is either an ElementTree, or a single Element.  The exact output
    format is implementation dependent.  In this version, it's written as an
    ordinary XML file.

    Element.clearElement.getiteratorElementTree.iterfind_serialize_xml.<locals>.<lambda>specified_attributesThe behavior of this method will change in future versions.  Use specific 'len(elem)' or 'elem is not None' test instead.event_nameiterparse.<locals>.iteratorltagpubidReturn an iterator over currently available (event, elem) pairs.

        Events are consumed from the internal event queue as they are
        retrieved from the iterator.
        1.3.0QName.__lt__TreeBuilder.closeReplace root element of this tree.

        This will discard the current contents of the tree and replace it
        with the given element.  Use with care!

        close_handlerFeed encoded data to parser.Element.keyscannot use non-qualified names with default_namespace optionDefaultHandlerExpandElementTree.parse_ListDataStream.__init__&#10;QName.__hash__Processing Instruction element factory.

    This function creates a special element which the standard serializer
    serializes as an XML comment.

    *target* is a string containing the processing instruction, *text* is a
    string containing the processing instruction contents, if any.

    Element.extendAppend subelements from a sequence.

        *elements* is a sequence with zero or more elements.

        ns\d+$Element structure builder for XML source data based on the expat parser.

    *html* are predefined HTML entities (deprecated and not supported),
    *target* is an optional target object which defaults to an instance of the
    standard TreeBuilder class, *encoding* is an optional encoding string
    which if given, overrides the encoding specified in the XML file:
    http://www.iana.org/assignments/character-sets

    Create a new element with the same type.

        *tag* is a string containing the element name.
        *attrib* is a dictionary containing the element attributes.

        Do not call this method, use the SubElement factory function instead.

        <?%s?>fromstringlistElementTree.getroot(Deprecated)  Handle doctype declaration

        *name* is the Doctype name, *pubid* is the public identifier,
        and *system* is the system identifier.

        Register a namespace prefix.

    The registry is global, and any existing mapping for either the
    given prefix or the namespace URI will be removed.

    *prefix* is the namespace prefix, *uri* is a namespace uri. Tags and
    attributes in this namespace will be serialized with prefix if possible.

    ValueError is raised if prefix is reserved or is invalid.

    Expat %d.%d.%dErrorLineNumber_escape_cdataReset element.

        This function removes all subelements, clears all attributes, and sets
        the text and tail attributes to None.

        Write element tree to a file as XML.

        Arguments:
          *file_or_filename* -- file name or a file object opened for writing

          *encoding* -- the output encoding (default: US-ASCII)

          *xml_declaration* -- bool indicating if an XML declaration should be
                               added to the output. If None, an XML declaration
                               is added if encoding IS NOT either of:
                               US-ASCII, UTF-8, or Unicode

          *default_namespace* -- sets the default XML namespace (for "xmlns")

          *method* -- either "xml" (default), "html, "text", or "c14n"

          *short_empty_elements* -- controls the formatting of elements
                                    that contain no content. If True (default)
                                    they are emitted as a single self-closed
                                    tag, otherwise they are emitted as a pair
                                    of start/end tags

        Generate string representation of XML element.

    All subelements are included.  If encoding is "unicode", a string
    is returned. Otherwise a bytestring is returned.

    *element* is an Element instance, *encoding* is an optional output
    encoding defaulting to US-ASCII, *method* is an optional output which can
    be one of "xml" (default), "html", "text" or "c14n".

    Returns an (optionally) encoded string containing the XML data.

    Finish feeding data to parser.

        Unlike XMLParser, does not return the root element. Use
        read_events() to consume elements from XMLPullParser.
        No module named expat; use SimpleXMLTreeBuilder insteadThis search is broken in 1.3 and earlier, and will be fixed in a future version.  If you rely on the current behaviour, change it to %rgetchildrenLightweight XML support for Python.

 XML is an inherently hierarchical data format, and the most natural way to
 represent it is with a tree.  This module has two classes for this purpose:

    1. ElementTree represents the whole XML document as a tree and

    2. Element represents a single node in this tree.

 Interactions with the whole document (reading and writing to/from files) are
 usually done on the ElementTree level.  Interactions with a single XML element
 and its sub-elements are done on the Element level.

 Element is a flexible container object designed to store hierarchical data
 structures in memory. It can be described as a cross between a list and a
 dictionary.  Each Element has a number of properties associated with it:

    'tag' - a string containing the element's name.

    'attributes' - a Python dictionary storing the element's attributes.

    'text' - a string containing the element's text content.

    'tail' - an optional string containing text after the element's end tag.

    And a number of child elements stored in a Python sequence.

 To create an element instance, use the Element constructor,
 or the SubElement factory function.

 You can also use the ElementTree class to wrap an element structure
 and convert it to and from XML.

Element.copyElement.__delitem__CommentHandlerElementTree.findallElement.getchildrenElement.__init__Element.__len__write_c14nReturn True if *element* appears to be an Element.Element.removeQName.__le___events_queueParse XML document from string constant.

    This function can be used to embed "XML Literals" in Python code.

    *text* is a string containing XML data, *parser* is an
    optional parser instance, defaulting to the standard XMLParser.

    Returns an Element instance.

    ordered_attributesXMLPullParser.closeParse XML document from string constant for its IDs.

    *text* is a string containing XML data, *parser* is an
    optional parser instance, defaulting to the standard XMLParser.

    Returns an (Element, dict) tuple, in which the
    dict maps element id:s to elements.

    Open new element and return it.

        *tag* is the element name, *attrs* is a dict containing element
        attributes.

        Parse XML document from sequence of string fragments.

    *sequence* is a list of other sequence, *parser* is an optional parser
    instance, defaulting to the standard XMLParser.

    Returns an Element instance.

     %s="%s"An XML element.

    This class is the reference implementation of the Element interface.

    An element's length is its number of subelements.  That means if you
    want to check if an element is truly empty, you should check BOTH
    its length AND its text attribute.

    The element tag, attribute names, and attribute values can be either
    bytes or strings.

    *tag* is the element name.  *attrib* is an optional dictionary containing
    element attributes. *extra* are additional element attributes given as
    keyword arguments.

    Example form:
        <tag attrib>text<child/>...</tag>tail

    iselementXMLParser.feedÛ   zCommentzdumpzElementzElementTreez
fromstringzfromstringlistz	iselementz	iterparsezparsez
ParseErrorzPIzProcessingInstructionzQNamez
SubElementztostringztostringlistzTreeBuilderzVERSIONzXMLzXMLIDz	XMLParserzXMLPullParserzregister_namespaceunknown method %rElementTree._setroot_close_and_return_root_ListDataStream.tell&#09;Return root element of this tree.QName.__ge__events_to_reportSubelement factory which creates an element instance, and appends it
    to an existing parent.

    The element tag, attribute names, and attribute values can be either
    bytes or Unicode strings.

    *parent* is the parent element, *tag* is the subelements name, *attrib* is
    an optional directory containing element attributes, *extra* are
    additional attributes given as keyword arguments.

    Get list of attribute names.

        Names are returned in an arbitrary order, just like an ordinary
        Python dict.  Equivalent to attrib.keys()

        QName.__str__Find text for first matching element by tag name or path.

        *path* is a string having either an element tag or an XPath,
        *default* is the value to return if the element was not found,
        *namespaces* is an optional mapping from namespace prefix to full name.

        Return text content of first matching element, or default value if
        none was found.  Note that if an element is found having no text
        content, the empty string is returned.

        This method will be removed in future versions.  Use 'tree.iter()' or 'list(tree.iter())' instead._namespaces.<locals>.add_qnameXMLPullParser.__init__Create text iterator.

        The iterator loops over the element and all subelements in document
        order, returning all inner text.

        Element.iterfindEndNamespaceDeclHandlerbuffer_textThis method will be removed in future versions.  Use 'elem.iter()' or 'list(elem.iter())' instead.An error when parsing an XML document.

    In addition to its exception value, a ParseError contains
    two extra attributes:
        'code'     - the specific exception code
        'position' - the line and column of the error

    Flush builder buffers and return toplevel document Element.Load external XML document into element tree.

        *source* is a file name or file object, *parser* is an optional parser
        instance that defaults to XMLParser.

        ParseError is raised if the parser fails to parse the document.

        Returns the root element of the given source document.

        Finish feeding data to parser and return element structure.Create and return tree iterator for the root element.

        The iterator loops over all elements in this tree, in document order.

        *tag* is a string with the tag name to iterate over
        (default is to return all elements).

        _doctypeTreeBuilder.endAdd *subelement* to the end of this element.

        The new element will appear in document order after the last existing
        subelement (or directly after the text, if it's the first subelement),
        but before the end tag for this element.

        XMLPullParser._close_and_return_rootAn XML element hierarchy.

    This class also provides support for serialization to and from
    standard XML.

    *element* is an optional root element node,
    *file* is an optional file handle or file name of an XML file whose
    contents will be used to initialize the tree with.

    iterparse.<locals>.IterParseIteratorElementTree.write_c14n(Deprecated) Return all subelements.

        Elements are returned in document order.

        Close and return current Element.

        *tag* is the element name.

        C:\msys64\mingw64\lib\python3.6\xml\etree\ElementTree.pyexpected an Element, not %s_namespace_mapQualified name wrapper.

    This class can be used to wrap a QName attribute value in order to get
    proper namespace handing on output.

    *text_or_uri* is a string containing the QName value either in the form
    {uri}local, or if the tag argument is given, the URI part of a QName.

    *tag* is an optional argument which if given, will make the first
    argument (text_or_uri) be interpreted as a URI, and this argument (tag)
    be interpreted as a local name.

    Element.__repr__Element.appendunknown event %rXMLParser._defaultThis method will be removed in future versions.  Use 'list(elem)' or iteration over elem instead.HTML_EMPTYComment element factory.

    This function creates a special element which the standard serializer
    serializes as an XML comment.

    *text* is a string containing the comment string.

    Parse XML document into element tree.

    *source* is a filename or file object containing XML data,
    *parser* is an optional parser instance defaulting to XMLParser.

    Return an ElementTree instance.

    Element.insertXMLParser._raiseerrorQName.__gt__end tag mismatch (expected %s, got %s)XMLParser._start_XMLParser__doctypeInsert *subelement* at position *index*._raise_serialization_errorGeneric element structure builder.

    This builder converts a sequence of start, data, and end method
    calls to a well-formed element structure.

    You can use this class to build an element structure using a custom XML
    parser, or a parser for some other XML-like format.

    *element_factory* is an optional element factory which is called
    to create new Element instances, as necessary.

    ElementTree.findtext_serialize_textProcessingInstructionHandlerAdd text to current element.Python interfaces to XML parsers.

This package contains one module:

expat -- Python wrapper for James Clark's Expat parser, with namespace
         support.

C:\msys64\mingw64\lib\python3.6\xml\parsersC:\msys64\mingw64\lib\python3.6\xml\parsers\__init__.pyInterface to the Expat non-validating XML parser.xml.parsers.expat.modelC:\msys64\mingw64\lib\python3.6\xml\parsers\expat.py<module xml.parsers.expat>C:\msys64\mingw64\lib\python3.6\xmlrpcC:\msys64\mingw64\lib\python3.6\xmlrpc\__init__.py%Y%m%dT%H:%M:%S_MultiCallMethod<methodCall>
<methodName></struct></value>
</double></value>
<member>
_extra_headers<param>
DateTime.__str___iso8601_formatINVALID_METHOD_PARAMSServerProxy.__init__chostdump_intrequest_body</dateTime.iso8601></value>
DateTime.encodeMarshaller.dump_datetime_ServerProxy__encodinguri [,options] -> a logical connection to an XML-RPC server

    uri is the connection point on the server, given as
    scheme://host/target.

    The standard implementation always supports the "http" scheme.  If
    SSL socket support is available (Python 2.0), it also supports
    "https".

    If the target part and the slash preceding it are both omitted,
    "/RPC2" is assumed.

    The following options can be given as keyword arguments:

        transport: a transport factory
        encoding: the request encoding (default is UTF-8)

    All 8-bit strings passed to the server proxy are assumed to use
    the given encoding.
    GzipDecodedResponseBinary.__eq__a file-like object to decode a response encoded with the gzip
    method, as described in RFC 1952.
    make_comparable_methodnamecall_listinvalid data_datetime_type<%s %s: %r>Unmarshaller.end_nilA workaround to get special attributes on the ServerProxy
           without interfering with the magic __getattr__
        </methodResponse>
<value><base64>
Content-EncodingMarshaller.dump_arraySafeTransport<value><int>bigdecimalBase class for client errors._ServerProxy__transportuse_datetime<value><boolean>Marshaller.dump_long_Method.__call__<value><string>dump_bytesIndicates an XML-RPC fault package._MultiCallMethod.__call__argument must be tuple or Fault instanceResponseErrorCan't compare %s and %sDateTime.__lt__</int></value>
dictionary key must be string<name>%s</name>
marshalled_list<params>
__closeMultiCall.__getattr__FastParserNOT_WELLFORMED_ERROR<value><array><data>
_use_bytesuser_agent_marks</base64></value>
_ServerProxy__allow_noneMultiCallIteratorExpatParser.feedfaultCodefaultString_MultiCallMethod__nameUnmarshaller.start%04d%02d%02dT%02d:%02d:%02dSYSTEM_ERROR<value><struct>
DateTime.make_comparableTransport.get_host_info</member>
bigintegerServerProxy.__getattr__Marshaller.dump_boolsend_content<fault>
mkdatetimemkbytesFault.__repr__</params>
_ServerProxy__handlerUnmarshaller.__init__
An XML-RPC client interface for Python.

The marshalling and response parser code can also be used to
implement XML-RPC servers.

Exported exceptions:

  Error          Base class for client errors
  ProtocolError  Indicates an HTTP protocol error
  ResponseError  Indicates a broken response package
  Fault          Indicates an XML-RPC fault package

Exported classes:

  ServerProxy    Represents a logical connection to an XML-RPC server

  MultiCall      Executor of boxcared xmlrpc requests
  DateTime       dateTime wrapper for an ISO 8601 string or time tuple or
                 localtime integer value to generate a "dateTime.iso8601"
                 XML-RPC value
  Binary         binary data wrapper

  Marshaller     Generate an XML-RPC params chunk from a Python data structure
  Unmarshaller   Unmarshal an XML-RPC response from incoming XML event message
  Transport      Handles an HTTP transaction to an XML-RPC server
  SafeTransport  Handles an HTTPS transaction to an XML-RPC server

Exported constants:

  (none)

Exported functions:

  getparser      Create instance of the fastest available parser & attach
                 to an unmarshalling object
  dumps          Convert an argument tuple or a Fault instance to an XML-RPC
                 request (or response, if the methodresponse option is used).
  loads          Convert an XML-RPC packet to unmarshalled data plus a method
                 name (None if not present).
gzip_encodebad boolean valueencode_thresholdUnmarshaller.end_dateTimePython-xmlrpc/%sUnmarshaller.getmethodnameDateTime.__le__%4YTransport.getparserGenerate an XML-RPC params chunk from a Python data structure.

    Create a Marshaller instance for each set of parameters, and use
    the "dumps" method to convert your data (represented as a tuple)
    to an XML-RPC params chunk.  To write a fault response, pass a
    Fault instance instead.  You may prefer to use the "dumps" module
    function for this purpose.
    </boolean></value>
Unmarshaller.end_bigdecimalDateTime.__init__DateTime.__repr__</fault>
Unmarshaller.end_base64Unmarshaller.dataFastUnmarshaller_ServerProxy__hostTransport.parse_responseresponse tuple must be a singletonBinary.__str__accept_gzip_encodingTransport.send_headersBinary.encode<value><double>DateTime.__eq__Unmarshaller.end_methodNamedump_nilmake_connectionIterates over the results of a multicall. Exceptions are
    raised in response to xmlrpc faults.Binary.decodeunexpected type in multicall resultcannot marshal recursive sequences%4Y%m%dT%H:%M:%S<module xmlrpc.client>end_value_Method__nameServerProxy.__enter__Marshaller.dump_bytessingle_requestFastMarshaller_Marshaller__dumpUnmarshaller.xmlend_dispatch<value><nil/></value>expected bytes or bytearray, not %sTransport.closeUnmarshaller.end_arrayUNSUPPORTED_ENCODINGcannot marshal recursive dictionariesUnmarshaller.end_stringSafeTransport.__init__Marshaller.dump_unicodeTransport.send_requestxmlheaderECONNRESETMarshaller.dump_double</string></value>
Unmarshaller.end_dispatch_day0MultiCall.__init__max_decodeDateTime.timetupleint exceeds XML-RPC limits_ServerProxy__requestServerProxy.__exit__</data></array></value>
</param>
WRAPPERSAttribute %r not foundGzipDecodedResponse.__init__INVALID_ENCODING_CHAR_Method__sendHandles an HTTP transaction to an XML-RPC server.</methodName>
Unmarshaller.end_doubleServerProxy.__repr__TRANSPORT_ERROR</methodCall>
Unmarshaller.end_structTransport.send_content<value><dateTime.iso8601>_Method.__init__data -> gzip encoded data

    Encode data using the gzip content encoding as described in RFC 1952
    Marshaller.dump_nilIndicates a broken response package._Method.__getattr___MultiCallMethod__call_listUnmarshal an XML-RPC response, based on incoming XML event
    messages (start, data, end).  Call close() to get the resulting
    data structure.

    Note that this reader is fairly tolerant, and gladly accepts bogus
    XML-RPC data without complaining (but not bogus XML).
    APPLICATION_ERROR_ServerProxy__verboseDateTime wrapper for an ISO 8601 string or time tuple or
    localtime integer value to generate 'dateTime.iso8601' XML-RPC
    value.
    Unmarshaller.end_intMarshaller.dump_instanceGzipDecodedResponse.closeMETHOD_NOT_FOUNDMultiCall.__call___use_datetimedata -> unmarshalled data, method name

    Convert an XML-RPC packet to unmarshalled data plus a method
    name (None if not present).

    If the XML-RPC packet represents a fault condition, this function
    raises a Fault exception.
    _MultiCallMethod.__init__Handles an HTTPS transaction to an XML-RPC server.ExpatParser.closeFault.__init__data [,options] -> marshalled data

    Convert an argument tuple or a Fault instance to an XML-RPC
    request (or response, if the methodresponse option is used).

    In addition to the data object, the following options can be given
    as keyword arguments:

        methodname: the method name for a methodCall packet

        methodresponse: true to create a methodResponse packet.
        If this option is used with a tuple, the tuple must be
        a singleton (i.e. it can contain only one element).

        encoding: the packet encoding (default is UTF-8)

    All byte strings in the data structure are assumed to use the
    packet encoding.  Unicode strings are automatically converted,
    where necessary.
    ServerProxy.__closeMarshaller.__init__Transport.make_connectionMarshaller.__dump_arbitrary_instancePARSE_ERRORend_faultUnmarshaller.end_booleanDateTime.__gt__<?xml version='1.0'?>
_ServerProxy__closegzfProtocolError.__init___MultiCallMethod.__getattr__ServerProxy.__requestbody:MultiCallIterator.__init__<%s for %s: %s %s>gzip_decodeUnmarshaller.end_paramsMarshaller.dump_struct_MultiCall__call_listTransport.request_MultiCall__servergzip encoded data -> unencoded data

    Decode data using the gzip content encoding as described in RFC 1952
    INVALID_XMLRPCExpatParser.__init__ServerProxy.__call__Marshaller.dumpsyour version of http.client doesn't support HTTPSSafeTransport.make_connectionIndicates an HTTP protocol error.DateTime.__ge__Transport.single_request<methodResponse>
unsupported XML-RPC protocolcannot marshal %s objects<%s for %s%s>Unmarshaller.end_faultcannot marshal None unless allow_none is enabledProtocolError.__repr__getparser() -> parser, unmarshaller

    Create an instance of the fastest available parser, and attach it
    to an unmarshalling object.  Return both objects.
    C:\msys64\mingw64\lib\python3.6\xmlrpc\client.pyextra_kwargsmax gzipped payload length exceededserver -> an object used to boxcar method calls

    server should be a ServerProxy object.

    Methods can be added to the MultiCall using normal
    method call syntax e.g.:

    multicall = MultiCall(server_proxy)
    multicall.add(2,3)
    multicall.get_address("Guido")

    To execute the multicall, call the MultiCall object e.g.:

    add_result, address = multicall()
    DateTime.decodeUnmarshaller.end_valueMultiCallIterator.__getitem__MultiCall.__repr__Unmarshaller.close_ECD_SIZEZipInfofheaderkey0compression type %d (%s)PyZipFile._get_codenameRead and return a line from the stream.

        If limit is specified, at most limit bytes will be read.
        Bad magic number for file headerBadZipFileBadZipfileZIP_STOREDZIP_BZIP2ZIP_LZMALargeZipFile_close_fileobj_CD64_DISK_NUMBER_STARTpycache_opt0Bad magic number for central directorynull_byte_readbufferExtract the ZipInfo object 'member' to a physical
           file on the path targetpath.
        _ZipWriteFile._fileobjwritestrDuplicate name: %rClass with attributes describing each file in the ZIP archive.        Usage:
            zipfile.py -l zipfile.zip        # Show listing of a zipfile
            zipfile.py -t zipfile.zip        # Test if a zipfile is valid
            zipfile.py -e zipfile.zip target # Extract zipfile into target dir
            zipfile.py -c zipfile.zip src ... # Create zipfile from sources
        Bad CRC-32 for file %rZipFile.__repr__ZipFile.open.<locals>.<lambda>Can't write to ZIP archive while an open writing handle exists.Replace bad characters and remove trailing dots from parts.Compression requires the (missing) lzma modulefilterfuncTruncated central directoryzinfo_or_arcnameZipFile.getinfoOpen the ZIP file with mode read 'r', write 'w', exclusive create 'x',
        or append 'a'.Check for errors before writing a file to the archive.NameToInfoFile is not a zip file_CD64_OFFSET_START_CENTDIRDEFAULT_VERSIONCan't close the ZIP file while there is an open writing handle on it. Close the writing handle before closing the zip._CD_DISK_NUMBER_STARTZIP_FILECOUNT_LIMIT_CD_TIME_didModifyûé    zstoreé   zshrinké   zreduceé   zreduceé   zreduceé   zreduceé   zimplodeé   ztokenizeé   zdeflateé	   z	deflate64é
   zimplodeé   zbzip2é   zlzmaé   zterseé   zlz77éa   zwavpackéb   zppmd0Truncated file headerZipFile._write_end_recordstringEndArchive64Mode must be 'r', 'w', 'x', or 'a'key2zef_filesizeEndCentDircompress_typeRead up to n bytes with at most one read() system call._CD_EXTRACT_VERSION_raw_time_CD_COMPRESSED_SIZEmin_versionReturn the per-file header as a string.allowZip64endrec<4s4B4HL2L5H2Lwrite() requires mode 'w', 'x', or 'a'Attempt to write to ZIP archive that was already closedZipFile._sanitize_windows_name.<locals>.<genexpr>ZipInfo._encodeFilenameFlagsAttempt to write ZIP archive that was already closedThe following enclosed file is corrupted: {!r}orig_filenamecreate_systemcreate_versionextract_versionflag_bitsinternal_attrexternal_attrheader_offsetcompress_sizefile_size_allowZip64Put the bytes from filename into the archive under the name
        arcname.structEndArchive64badfileaddToZipzippathtestzipCompression requires the (missing) bz2 moduleforce_zip64dosdateZIP64_VERSION<LQQ_Tellable.closeCorrupt extra field %04x (size=%d) file=%rAdding filesize_cdoffset_cdcentdircommentSizefpinExtract all members from the archive to the current working
           directory. `path' specifies a different directory to extract to.
           `members' is optional and must be a subset of the list returned
           by namelist().
        ZipFile.extract_FH_FILENAME_LENGTH
    Raised when writing a zipfile, the zipfile requires ZIP64 extensions
    and those extensions are disabled.
    _CD_FLAG_BITSZipFile.printdirReturn a list of class ZipInfo instances for files in the
        archive.MAX_NPKcompressed patched data (flag bit 5)BZIP2_VERSION_CD_EXTERNAL_FILE_ATTRIBUTESdisk_num_filePassedZipFile.readpycache_opt1_CD_CREATE_VERSIONConstruct an appropriate ZipInfo for a file on the filesystem.

        filename should be the path to a file or directory on the filesystem.

        arcname is the name which it will have within the archive (by default,
        this will be the same as filename, but without a drive letter and with
        leading path separators removed).
        PyZipFile._get_codename.<locals>._compileZipFile._extract_member.<locals>.<genexpr>_CD_FILENAME_LENGTHZipFile.testzipwritepy_UpdateKeysfile_pyfile_pycpycache_opt2archivenameLZMACompressor.flushPKReturns buffered bytes without advancing the position.File size unexpectedly exceeded ZIP64 limitZipExtFile.__repr___RealGetContents_CD_DATEmodeDictdirsizesetpasswordZipExtFile.readabledecrypterfile %r skipped by filterfuncCentral directory size_GenerateCRCTable%-46s %s %12dzipfiles that span multiple disks are not supported_FH_LAST_MOD_DATE_SharedFilezipinfo
    Read the ZIP64 end-of-archive records and use that to update endrec
    _compress_left<4sLQLfilelistZipfile sizeZipExtFile.readline_windows_illegal_name_trans_table_fpcloseÛ   é    r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   r   ZipFile.infoliststructEndArchive64LocatorZipFile._fpcloseinvalid value for 'optimize': {!r}maxCommentStartZipFile.commentrequires_zip64_FH_SIGNATURE_compress_type_CD64_DIRECTORY_SIZEFile-like object for reading an archive member.
       Is returned by ZipFile.open().
    ZipFile requires mode 'r', 'w', 'x', or 'a'x+b filemode=%rZipFile.__init___running_crc_ECD_LOCATION_FH_LAST_MOD_TIME_FH_EXTRACT_SYSTEMRead in the table of contents for the ZIP file.<HH_CD_SIGNATURECompression requires the (missing) zlib moduleLZMADecompressor.__init__PKstringEndArchive64LocatorDecrypt a single character._get_compressorCall the "close()" method in case the user forgot.ZipInfo.from_fileC:\msys64\mingw64\lib\python3.6\zipfile.pyZipFile.writeAdding files from directoryinvalid_path_partsCan't write to the ZIP file while there is another write handle open on it. Close the first handle before opening another._check_compressionAttempt to use ZIP archive that was already closedWrite a file into the archive.  The contents is 'data', which
        may be either a 'str' or a 'bytes' instance; if it is a 'str',
        it is encoded as UTF-8 first.
        'zinfo_or_arcname' is either a ZipInfo instance or
        the name of the file in the archive._ECD_DISK_START_ECD_ENTRIES_THIS_DISK_CD_COMPRESS_TYPEReturn True if this archive member is a directory._ZipWriteFile.close_CD64_CREATE_VERSION_CD64_DIRECTORY_RECSIZE_CD_INTERNAL_FILE_ATTRIBUTESFile name in directory %r and header %r differ.LZMACompressor._init_FH_EXTRACT_VERSION_ZipDecrypter._crc32_ECD_DISK_NUMBERsizeEndCentDir64Locatormain.<locals>.addToZipZipExtFile._read2_Tellable.flushMIN_READ_SIZEZipFile.__enter___CD_UNCOMPRESSED_SIZE<LLLReturn file bytes (as a string) for name._ZipDecrypter._UpdateKeysDone testing_Tellable.tell_FH_EXTRA_FIELD_LENGTH<HHQQ<BBH_file_size
Read and write ZIP files.

XXX references to utf-8 need further investigation.
_ECD_ENTRIES_TOTAL_writecheckpoly_fileRefCntdisknoreloffread_versiondisk_dirdircountdircount2diroffset<QQQZipExtFile._update_crc compress_type=%s<4s4H2LH_zinfoZIP does not support timestamps before 1980<%s filename=%rReturn (filename, archivename) for the path.

        Given a module name path, return the correct file path and
        archive name, compiling if necessary.  For example, given
        /python/lib/string, return (/python/lib/string.pyc, string).
        That compression method is not supported<4s2B4HL2L2HZipFile._RealGetContents_CD64_EXTRACT_VERSIONPK_get_decompressorRead and return up to n bytes.
        If the argument is omitted, None, or negative, data is read and returned until EOF is reached..
        stringCentralDirClose the file, and for mode 'w', 'x' and 'a' write the ending
        records.Archive comment is too long; truncating to %d bytesrecData_Tellable.writeFilesize would require ZIP64 extensions_decrypterFile Name                                             Modified             Size_compress_sizeZipInfo.__init__Read all the files and check the CRC._ZipWriteFile.writabledostime_decodeExtraZIP64_LIMITkey1pwd: expected bytes, got %sZipFile.extractallsizeFileHeaderinitname:<>|"?*_CD64_SIGNATUREZ_DEFAULT_COMPRESSIONCan't read from the ZIP file while there is an open writing handle on it. Close the writing handle before trying to read.I/O operation on closed file.MAX_EXTRACT_VERSION_ECD_OFFSETZIP_MAX_COMMENTgiven, inferred, offset©ÚselfÚzinfoÚdtÚdosdateÚdostimeÚextraÚ	file_sizeÚcompress_sizeÚheader_offsetÚ
extra_dataÚmin_versionÚextract_versionÚcreate_versionÚfilenameÚ	flag_bitsÚcentdirÚpos2ÚcentDirCountÚcentDirSizeÚcentDirOffsetÚrequires_zip64Úzip64endrecÚzip64locrecÚendrec Class with methods to open, read, write, close, list zip files.

    z = ZipFile(file, mode="r", compression=ZIP_STORED, allowZip64=True)

    file: Either the path to the file, or a file-like object.
          If it is a path, the file will be opened and closed by ZipFile.
    mode: The mode can be either read 'r', write 'w', exclusive create 'x',
          or append 'a'.
    compression: ZIP_STORED (no compression), ZIP_DEFLATED (requires zlib),
                 ZIP_BZIP2 (requires bz2) or ZIP_LZMA (requires lzma).
    allowZip64: if True ZipFile will create files with ZIP64 extensions when
                needed, otherwise it will raise an exception when this would
                be necessary.

    ZipFile._open_to_writeThe comment text associated with the ZIP file. mode=%rReturn the instance of ZipInfo given 'name'.ZipExtFile.peek_SharedFile.__init___SharedFile.readÍÌÌÌÌÌð?Return file-like object for 'name'.

        name is a string for the file name within the ZIP file, or a ZipInfo
        object.

        mode should be 'r' to read a file already in the ZIP file, or 'w' to
        write to a file newly added to the archive.

        pwd is the password to decrypt files (only used for reading).

        When writing, if the file size is not known in advance but may exceed
        2 GiB, pass force_zip64 to use the ZIP64 format, which can handle large
        files.  If the size is known in advance, it is best to pass a ZipInfo
        instance for name, with zinfo.file_size set.
        structCentralDir_FH_CRCZipInfo.FileHeaderCentral directory offsetAdd all files from "pathname" to the ZIP archive.

        If pathname is a package directory, search the directory and
        all package subdirectories recursively for all *.py and enter
        the modules into the archive.  If pathname is a plain
        directory, listdir *.py and enter all modules.  Else, pathname
        must be a Python *.py file and the module will be put into the
        archive.  Added modules are always module.pyc.
        This method will compile the module.py into module.pyc if
        necessary.
        If filterfunc(pathname) is given, it is called with every argument.
        When it is False, the file or directory is skipped.
        Set default password for encrypted files._FH_COMPRESSED_SIZEClass to handle decryption of files stored within a ZIP archive.

    ZIP supports a password-based form of encryption. Even though known
    plaintext attacks have been found against it, it is still useful
    to be able to get data out of such a file.

    Usage:
        zd = _ZipDecrypter(mypwd)
        plain_char = zd(cypher_char)
        plain_text = map(zd, cypher_text)
    _CD64_NUMBER_ENTRIES_TOTAL compress_size=%r_EndRecData64_ZipDecrypter.__init__ZipInfo._decodeExtraZipExtFile.read1compressor_namesZipExtFile.close_unconsumedLZMA_VERSIONReturn data from the "End of Central Directory" record, or None.

    The data is a list of the nine items in the ZIP "End of central dir"
    record followed by a tenth item, the file seek offset of this record._ZipWriteFile.write_check_zipfilePyZipFile.__init__LZMADecompressor.decompress<module zipfile>_Tellable.__init__ZipFile.__exit___ECD_COMMENTFiles added with writepy() must end with ".py"File %r is encrypted, password required for extractionThere is no item named %r in the archiveZipExtFile.__init__ZipInfo.__repr__sizeCentralDirZipFile.writestrCompressed size unexpectedly exceeded ZIP64 limitZipFile.close<4sQ2H2L4Q_ECD_COMMENT_SIZE file_size=%rClass to create ZIP archives with Python library files and packages._FH_UNCOMPRESSED_SIZE_CD_COMMENT_LENGTHExtract a member from the archive to the current working directory,
           using its full name. Its file information is extracted as accurately
           as possible. `member' may be a filename or a ZipInfo object. You can
           specify a different directory using `path'.
        _FH_COMPRESSION_METHODQuickly see if a file is a ZIP file by checking the magic number.

    The filename argument may be a file or file-like object too.
    Files count external_attr=%#xBad password for file %rAdding package instructFileHeaderis_encrypted_ZipWriteFile.__init___CD_CRC_ECD_SIGNATURE_CD_EXTRACT_SYSTEMLZMACompressor.__init__fname_strcrctable_CD_EXTRA_FIELD_LENGTHZipExtFile._read1strong encryption (flag bit 6)Print a table of contents for the zip file.comment: expected bytes, got %s_CD_CREATE_SYSTEMCompute the CRC32 primitive on one byte._expected_crc name=%r mode=%rZipInfo.is_dirforce_zip64 is True, but allowZip64 was False when opening the ZIP file.PyZipFile.writepy_ZipDecrypter.__call___FH_GENERAL_PURPOSE_FLAG_BITS_CD_LOCAL_HEADER_OFFSET%s %r skipped by filterfunczip file version %.1f_seekableLZMACompressor.compressopen() requires mode "r" or "w"ZipFile.namelist_ZipDecrypter._GenerateCRCTableZipFile.setpassword_CD64_NUMBER_ENTRIES_THIS_DISKpwd is only supported for reading filesReturn a list of file names in the archive._SharedFile.closeGenerate a CRC-32 table.

        ZIP encryption uses the CRC32 one-byte primitive for scrambling some
        internal keys. We noticed that a direct implementation is faster than
        relying on binascii.crc32().
        ZipFile._writecheckZipFile.__del__stringFileHeaderPK¹?É?      à?      ð?      ø?       @      @      ð{®Gáz?©?      Ð?      è?      4@shí|?é?     @@CS8GtELtEOddatkfp1fp2fxnkwsHBoxIPowISIGIXONLSQBRSQBRsvgUAddUSubVBARVBoxVMIN_bz2cdlleltsfInXfcreisscsmsl    .AAMPERBinOpCOLONCOMMAEBADFEPIPEEQUALGEnumICRNLINPCKMINUSOPOSTTILDE_json_mathbyreffNullfOutXgetOSisLtoisSetmknodopmappangopath1path2propstopfdCLRDTRCLRRTSDarwinEAGAINEEXISTEINVALENOENTGBoxedGFlagsICANONIEXTENISTRIPLBRACELPCSTRLPWSTRNoNameO_EXCLO_RDWRPARENBParityRBRACESETDTRSETRTSS_IFMTWINEXEWinDLL_DupFd_rlockail_crb2a_qpc_bytecmp_opcygwindarwinduplexendposerrmsgexc_tbgetClsgetcwdgetpidgetuidhEventinfileis_toplchownmkfifooptargorelseosnamesimlogskipIfst_devst_inost_uidtolistwindllxalignyalign<unknown>ALIASESATEQUALBUFSIZEEQEQUALGREATERLPCWSTRMAXYEARMatMultPERCENTPowerPCPurposeSIXBITSS_IFBLKS_IFCHRS_IFREGS_IMODES_IRWXGS_IRWXOS_ISBLKS_ISCHRS_ISDIRS_ISLNKS_ISREGSetCompStarredUI_INFOXonChar_dsrdtr_launch_locked_parity_r_long_rtscts_w_longail_svgbasedirc_floatc_int64c_shortc_ubytec_ulongcbInQuechflagschild_rchild_wdb_conndll_maperrcodeexctypefBinaryfParityfreebsdgetArgsgetBodygetImaggetKindgetLeftgetModegetcwdbgetfqdnhasfreehasjabshasjrelhasnamein_nodeisClangisDebugisMingwis_dictlistDirlocaltmmaxdictmaxlistnewdatanewfileopenbsdorig_stpkgpathps_namerecvfdsselfrefsendfdssetBodyst_modetm_zonetobytesì        BaudRateByteSizeCFWSListClassDefDictCompExpanderExtSliceFIVEBITSFTP_PORTIMatMultINFINITEKEY_READLDSHAREDListCompMAX_PATHMINEQUALNOTEQUALN_TOKENSNotebookO_BINARYO_NOCTTYO_RDONLYO_WRONLYPOS_LEFTSEEK_CURSEEK_ENDSEEK_SETSUBDEBUGS_ISFIFOStopBitsTHURSDAYTarErrorTextViewTreeViewUserTypeWinErrorXoffChar_IntEnum__date____info___authkey_closefp_get_sep_maxsize_parties_semlock_writing_xonxoffarch_keyattrnamec_doublec_size_tc_ushortc_void_pcbOutQueclassobjcleandoccmdqueuecnc_portcompat32copysigncr_frameddx_listdel_nodedist_dirdll_nameendGraphend_iterend_timeenvironbfetchonefile_numgetFlagsgetLowergetPairsgetRightgetStartgetUppergetblockgetgrnamgetpwnamgetpwuidhas_exechasconsthaslocalhide_allidle_addin_line1int_nodeis_addedis_shlibisstringitemsizekernel32learninglen_nodemain_dirmakePathmaximizemaxothermaxtuplenew_codenewvaluenext_argnot_nodenotebookoldvalueoutlinespage_numpyi_filerbufsizereadlinkrel_listrun_nameset_nodesocktypestartposstrclassstrerrorsys_pathtestsRunthislinetoStringtok_nameuserhomewaittimewinerrorxoptionsyoptionsAT_LOCALEAsyncWithBAUDRATESBLDSHAREDCH_LOCALEEIGHTBITSENDMARKERFORBIDDENLEFTSHIFTLESSEQUALListStoreMAXGROUPSMAXREPEATMAX_WBITSOP_IGNOREPLUSEQUALPY_SOURCESEVENBITSSIG_BLOCKSTAREQUALTCSAFLUSHUNARY_NOTVBAREQUALVFuncInfoXmlClient__flags____gtype___bytesize_getframe_stopbits_typecodeaddressofalter_sysapply_tagarg_valueargs_dictbuildNodebyte_viewcanonnamecase_listco_linenocurrentbpddx_indexexec_bodyfile_namefile_pathfinalbodyfork_execfromFlagsfull_namegetAppDirgetCalledgetErrorsgetOpenergetValuesget_modelget_widthgetbuffergetsignalgetsizeofglobal_nsgroupdicthas_superhelp_texticon_pathinit_frominst_dictisProfileisVerboseis_frozenis_reloadisenablediterItemsiter_nodelast_linelazycachelive_viewlocateDLLlong_nodemain_quitmakeSuitemaxstringmktime_tzmode_codenew_raisenew_statenext_nodeno_branchnone_nullnot_emptyold_valueorig_argspopenargspredictorprep_dataprintLinepythonapiread_coderef_countsemprefixsetCalledset_valuesetcbreakslotstatestart_dirstr_valuesub_debugtb_localstcgetattrtemp_filetm_gmtoffupperdirsuse_labelvar_usagevisitTreevisitablewordcharsAMPEREQUALAT_UNICODECH_UNICODECIRCUMFLEXCOMMASPACECO_VARARGSCancelIoExCreatePipeDOUBLESTARERRORTOKENGInterfaceImportFromMARKPARITYNO_CONTENTObjectInfoPARITY_ODDQueryValueRIGHTSHIFTSLASHEQUALSOL_SOCKETSTOCK_STOPSUBWARNINGStructInfoWINSERVICE_MODE_READ__author____return___calc_mode_dtr_state_iterating_itertools_processes_rts_statea2b_base64added_flagall_errorsappendleftb2a_base64bases_namebit_lengthbytes_nodec_longlongcandidatescheckDebugcheckcachechild_nameclose_menucode_flagscommenterscomparatorcorrectioncr_runningcreate_tagdeleteFileelse_blockenable_vteend_targetenum_klasserror_permfErrorCharfindsourcefixed_sizefloat_nodefromStringgetCloseFdgetGlobalsgetNewlineget_g_typeget_heightget_loadergetabsfilegettimeoutgroupindexguard_modehascomparehelp_linesin_contextin_waitingintro_textisHashableis_exitingis_zipfileleft_valuelocals_argmain_addedmangleNamemax_heightmust_existnew_importnew_paramsnewheadersnextModulenice_childno_assertsnode_classobey_childobject_argother_argspangocairopath_args1path_args2path_args3printStatsproxy_typepublic_excsem_unlinkset_markupsettimeoutshouldStopshow_sconsskipUnlessstartGraphstart_iterstart_listsuper_typetextdomaintracker_fdtype_shapevalue_nodeAspectFrameAsyncResultBAD_REQUESTC_EXTENSIONDOUBLESLASHDrawingAreaEWOULDBLOCKFormatErrorFunctionDefHeaderLabelIPPROTO_TCPLC_MESSAGESMAXLINESIZEPARITY_EVENPARITY_MARKPARITY_NONEPY_COMPILEDPyGIWarningPyStringMapSERVER_AUTHSPACEPARITYSyncManagerTCP_NODELAYUNKNOWN8BIT_MODE_WRITE__credits____mp_main____pycache___gcd_import_get_cached_inheriting_max_appendadd_buttonsaddresslistappend_listappend_pageassign_nodebase_prefixbisect_leftbody_decodebuild_triedbutton_vboxbytes_typesc_ulonglongcalled_namecancel_readchange_descchange_tagscode_prefixcomparatorscompressobjdb_filenamedigest_sizeexec_localsexec_sourcefDtrControlfRtsControlfds_to_passflushStdoutfrom_buffergetBlockTrygetBranchNogetCacheDirgetDefaultsgetElementsgetEncodinggetFileListgetGotoCodegetIconPathgetJobLimitgetLoopBodygetMainArgsgetOptimizegetSentinelgetaddrinfogetpeernamegetsocknameglobals_arggroups_of_3helper_argshelper_namehkey_branchinline_copyintro_labelisShowSconsiter_fieldsiter_lengthkeeper_varslineno_namelocals_nodelookup_nodemethod_infomodule_kindmodule_typenamed_childnew_builtinnew_modulesorientationosx_versionout_waitingpackage_dirparent_namepipe_handlepre_modulesprocess_objrecv_handleright_valuesave_stdoutsearch_pathself_modulesend_handleserver_portset_justifyset_paddingset_tab_possetblockingsize_pointssource_pathsourcelinessplit_pathsstore_constsub_warningsupports_fdunpack_fromunused_datawaitWorkersAT_MULTILINECO_COROUTINECallableInfoCharsetErrorECONNABORTEDEXTENDED_ARGFORMAT_VALUEFunctionInfoGREATEREQUALMessageClassNAME_MAPPINGNOT_MODIFIEDNameConstantONE5STOPBITSORIGINAL_DIRPARITY_SPACEPERCENTEQUALPOLICY_NEVERParserCreateQueryValueExSO_REUSEADDRSTOPBITS_ONESTOPBITS_TWOTYPE_INVALIDWAIT_TIMEOUT_MODE_CLOSED_SimpleCData__internal___close_stdin_decomp_args_format_text_max_workers_nameToLevel_port_handle_python_exit_tunnel_hostacquire_lockall_suffixesappend_valueareSamePathsasyncgen_refbuildAndNodebuiltin_specbutton_tablecairo_createcallable_argcancel_writecatch_breaksclear_framescnc_commandscommand_namecomplex_nodeconfig_labelcopyUsedDLLsdefault_portdisplay_linedo_setlocaleenable_gudevexec_globalsexitpriorityfOutxCtsFlowfOutxDsrFlowfind_libraryformatOutputframe_handleframe_linenofunction_refgetBranchYesgetBufferinggetCallsCodegetCoreCountgetFunctionsgetIndexCodegetLabelCodegetNewLocalsgetOutputDirgetStringArgget_end_iterget_importerget_nth_pageget_selectedget_suffixesget_temp_dirgiven_valuesglobals_nameglobals_nodegtkunixprinthandler_bodyhasattr_attrheader_bytesindent_firstisFullCompatisPackageDirisShowMemoryisUnstrippedis_namespacekeeper_indexlist2cmdlineloader_statelocals_ownermemory_watchnew_constantnew_variableold_handlersold_variableoutline_bodyparseShebangpost_modulespyi_filenamepython_debugquote_stringrelease_lockrelease_nameremoveResultrender_cairosetFunctionsset_editableset_expandedset_iteratorsimplefiltersteal_handlestr_iteratorsuper_objectthreads_inituse_rawinputused_modulesCreateProcessDEF_MEM_LEVELDOT_ATOM_ENDSERROR_SUCCESSHAVE_ARGUMENTHTTPExceptionInterfaceInfoPKG_DIRECTORYRESET_CONTENTSEM_VALUE_MAXSTATEMENT_TRYSUPPRESS_HELPTracebackType__copyright____newobj_ex___builtin_open_ignore_epipe_parsedate_tz_set_fileattr_write_atomicaddRootModuleadd_from_fileappend_columnargs_variableassign_sourcebase_filenamebuildExecNodebuildNodeListbuiltin_classbuiltin_namescatch_returnscollection_noconfig_buttoncoroutine_refcorrect_labelcurrent_indexcurrent_questdecode_paramsdecode_sourcedecompressobjdict_arg_namedictset_valuedll_filenamesenable_webkitencoded_linesfAbortOnErrorfindTestCasesfinished_textfunction_declgenerator_refgetCallsDeclsgetFormatSpecgetKwDefaultsgetOutputPathgetSourceCodegetStatementsgetSubscribedget_addr_specget_argumentsget_exec_pathget_namespaceget_selectiongetmodulenamehandler_blockhasRootModuleheader_decodeisPythonDebugis_nuitka_runlist_iteratorlocale_configmodule_importneeds_releasenew_statementnice_childrennorm_encodingoriginal_nodeother_modulesowning_modulepopFutureSpecprintIndentedread_unsignedrebound_tasksrelease_namessequence_kindsetStatementsset_alignmentset_deletableset_line_wrapset_wrap_modesetup_trasfersignal_sourcesplash_screenstate_watchersubnode_valuesurrogatepasstake_snapshottemp_providertemplate_argsthread_modulethreads_enterthreads_leavethree_way_cmptouch_alertertrace_importsuseless_paramuser_providedwarn_explicit<setcontraction>BufferTooShortCO_VARKEYWORDSIMPORT_MAPPINGJUSTIFY_CENTERLEFTSHIFTEQUALName_ExceptionREQUEST_METHODSRE_FLAG_ASCIISRE_FLAG_DEBUGSTATEMENT_EXECSTATEMENT_LOOPScrolledWindowTreeViewColumn_check_methods_encode_base64_exit_function_log_to_stderr_shutdown_lock_write_timeoutbarry_as_FLUFLbindtextdomainbuildFrameNodebuildPrintNodebuildYieldNodebytes_iteratorcode_generatedcollection_yescoverage_tablecreate_dynamicdecorator_listenable_popplerencodeNonAsciiencode_7or8bitencode_chunkedencode_rfc2231events_pendingfilterwarningsfindlinestartsfinished_labelgenerator_gotogetAnnotationsgetAsyncgenRefgetCommentCodegetDestinationgetDontInheritgetFunctionRefgetMsvcVersiongetPythonFlagsgetRootModulesgetSideEffectsget_allocationget_executableget_start_itergetsourcelinesglobal_contextinstallHandlerinstancemethodisExperimentalisShowProgressis_constructorisinstance_clsline_bufferingload_overridesmain_iterationmodule_aliasesmodule_contextmodule_relpathnamed_childrennew_case_blocknew_collectionnew_data_framenew_expressionnew_statementsnon_printablesold_collectionopen_osfhandleoriginal_bytespalpation_gridplugin_optionspre_assessmentprintSeparatorps_normal_argspushFutureSpecqualname_setupreadSourceLineregisterResultremainingCountrs485_settingssensors_threadset_from_stocksetup_transferspawnv_passfdsstatement_reprtuple_iteratorvalue_arg_namevariable_ordervshape_unknownweakref_module<dictcontraction><listcontraction>CIRCUMFLEXEQUALDOUBLESTAREQUALDefaultSelectorDuplicateHandleEXPRESSION_CALLKEY_WOW64_32KEYKEY_WOW64_64KEYNOT_IMPLEMENTEDPyFrozenSet_NewRIGHTSHIFTEQUALResourceWarningSOURCE_SUFFIXESSRE_FLAG_DOTALLSRE_FLAG_LOCALESRE_INFO_PREFIX_ForkingPickler_check_hostname_decomp_factory_has_surrogates_testMethodName_testRunEntered_threads_queuesactive_childrenany_case_moduleargument_valuesassert_spawningbinary_filenamebuildAssertNodebuildAssignNodebuildBoolOpNodebuildDeleteNodebuildLambdaNodebuildModuleTreebuiltin_id_speccatch_continuescheckPluginPathco_has_stardictco_has_starlistdestination_pidexception_causeexpand_templateexpectedFailurefinish_transfergenerateTryCodegenerate_tokensgetArchitecturegetAssignSourcegetBuildContextgetCoroutineRefgetExpressionNogetFunctionCodegetGeneratorRefgetLookupSourcegetMaxIndexCodegetMinIndexCodegetModuleByNamegetModuleValuesgetReleaseCodesgetSourceModulegetVariableCodeget_cache_tokenimage_availableinclude_closureincorrect_labelinplace_suspectinstall_signalsisShowInclusionisinstance_instlive_view_frameload_cert_chainmakeModuleFramenew_builtin_refnew_module_namenext_case_labelorigin_req_hostoutput_filenameplugin_filenamepopBuildContextpositional_argsps_kw_only_argspython_compilerset_homogeneousset_shadow_typeset_width_charsshallMakeModuleshowMemoryTracesource_filenamesupports_dir_fdunconsumed_tailvariable_tracesyou_chose_labelAsyncFunctionDefCellRendererTextDOUBLESLASHEQUALEXPRESSION_YIELDHAVE_SEND_HANDLEHIGHEST_PROTOCOLNUITKA_SITE_FLAGPOLICY_AUTOMATICSIGNAL_RUN_FIRSTSRE_FLAG_UNICODESRE_FLAG_VERBOSESRE_INFO_CHARSETSRE_INFO_LITERALSTATEMENT_RETURN_check_arg_types_fix_co_filename_verbose_messageanswer_challengebase_exec_prefixbladder_commandsbuiltin_bin_specbuiltin_chr_specbuiltin_dir_specbuiltin_hex_specbuiltin_int_specbuiltin_len_specbuiltin_oct_specbuiltin_ord_specbuiltin_set_specbuiltin_str_specbuiltin_sum_speccase_text_buffercatch_exceptionscode_object_argscompareConstantscreateModuleTreedecideModuleTreedecrease_tensionenable_goocanvasexpectedFailuresgenerateExecCodegenerateLoopCodegetAssertionCodegetBranchingCodegetErrorExitCodegetExceptionTypegetExpressionYesgetImportedNamesgetNuitkaVersiongetSconsDataPathget_address_listget_country_nameget_unstructuredgettotalrefcountimport_main_pathincrease_tensionincrement_linenoisRemoveBuildDirisStandaloneModeisdatadescriptoriter_child_nodeskeeper_variablesmodule_code_namemodule_from_specpackage_filenameportNotOpenErrorps_default_countps_dict_star_argps_list_star_argpushBuildContextremoveDoneModulesave_displayhookset_border_widthset_col_spacingsset_current_pageset_default_sizeset_row_spacingsset_size_requestshallCreateGraphspec_from_loadersub_dll_filenamesubnode_fallbacktarget_cell_codetypecode_or_typevariable_activesview_assessmentsìûÿÿÿ         ì   ÿÿÿÿ BYTECODE_SUFFIXESDisconnectWarningEndElementHandlerGetCurrentProcessHKEY_CURRENT_USERMOVED_PERMANENTLYNodeMetaClassBaseSRE_FLAG_TEMPLATE__unittest_skip___classSetupFailed_code_to_bytecode_find_module_shim_get_exports_list_getdefaultlocale_load_module_shim_pending_removals_update_dtr_state_update_rts_stateaddImportedModuleailment_locationsall_feature_namesarbitrary_addressbuildExtSliceNodebuildFunctionNodebuiltin_bool_specbuiltin_dict_specbuiltin_eval_specbuiltin_hash_specbuiltin_iter_specbuiltin_list_specbuiltin_long_specbuiltin_next_specbuiltin_open_specbuiltin_repr_specbuiltin_vars_speccache_from_sourcecoverage_analyzerdefaultTestLoaderdeliver_challengeenable_adjustmentgenerateRaiseCodegenerateYieldCodegetArgumentValuesgetCallCodeNoArgsgetConstantAccessgetConstantWeightgetDependsExePathgetExceptionCausegetExceptionTracegetExceptionValuegetExecutablePathgetIndexValueCodegetInternalModulegetPluginsEnabledgetPositionalArgsgetStatementTracegetSubDirectoriesget_frozen_objectget_language_namegetwindowsversionis_frozen_packagemakeGlobalContextmilestone_3_labelpackage_directorypackage_file_nameprepareModuleCodequalname_providerrecurse_attemptedreplaceRootModulesource_from_cachetmp_item_variabletouch_again_labeluse_builtin_typeswriteTimeoutErrorì   ÿÿÿÿ AsyncGeneratorTypeBigEndianStructureCO_ASYNC_GENERATORCO_FUTURE_DIVISIONCodeTooComplexCodeEXTENSION_SUFFIXESHKEY_LOCAL_MACHINEInvalidHeaderErrorMilestoneNameLabelRTS_CONTROL_TOGGLESRE_FLAG_MULTILINE_builtin_from_name_flush_std_streams_inverted_registry_moduleSetUpFailed_previousTestClass_run_after_forkers_semaphore_tracker_strptime_datetime_use_builtin_typesbuildAnnAssignNodebuildAsyncWithNodebuildListUnpackingbuildSubscriptNodebuildWhileLoopNodebuildYieldFromNodebuiltin_anon_codesbuiltin_anon_namesbuiltin_ascii_specbuiltin_bytes_specbuiltin_float_specbuiltin_range_specbuiltin_slice_specbuiltin_super_specbuiltin_tuple_specbuiltin_type1_specbuiltin_type3_specbuiltin_type_namesbytearray_iteratorcnc_device_is_idlecomputeBuiltinCallconfig_explanationcreateConstantDictenumerate_versionsextractBuiltinArgsextractDocFromBodygenerateBranchCodegenerateModuleCodegenerateReturnCodegetCheckObjectCodegetClosureCopyCodegetExportScopeCodegetModuleWhiteListgetPluginsDisabledget_locale_optionsget_spawning_popeninstruction_buttonis_internal_moduleisgetsetdescriptorismemberdescriptormakeComparisonNodemakeExpressionCallparameter_providerparse_mime_versionpreserve_exceptionreset_input_bufferset_icon_from_fileset_locale_handlerset_spawning_popenshallCreatePyiFileshallRunInDebuggerstandard_b64encodestartMemoryTracingstatement_sequencewrapped_expressionAuthenticationErrorBuiltinFunctionTypeCOMPILER_FLAG_NAMESDTR_CONTROL_DISABLEERROR_IO_INCOMPLETEEXPRESSION_MAKE_SETRTS_CONTROL_DISABLEReadIntervalTimeoutSRE_FLAG_IGNORECASESTATEMENTS_SEQUENCESTATEMENT_DEL_SLICEStartElementHandler__abstractmethods____warningregistry___extension_registry_finalizer_registry_force_start_method_inter_byte_timeoutaddUncompiledModuleassigned_assessmentbuildComparisonNodebuildDictionaryNodebuildImportFromNodebuildStatementsNodebuiltin_anon_valuesbuiltin_divmod_specbuiltin_format_specbuiltin_import_specbuiltin_locals_specbuiltin_xrange_specdisconnection_labeldont_write_bytecodeduplicate_for_childempty_special_classfunction_body_codesfunction_decl_codesgenerateHelpersCodegenerateReraiseCodegetModuleAccessCodegetShallFollowExtragetVariableCodeNamegetVariablesWritteninternal_source_refisExecutableCommandisPythonShlibModuleisUninstalledPythonisWhiteListedImportmakeConstantRefNodemakeVariableRefNoderegister_after_forkreset_output_bufferset_max_width_charsshallExplainImportsshallTraceExecutionsize_or_initializertmp_break_indicatortmp_result_variableunexpectedSuccessesupdateVariableUsagewin_disable_consoleCharacterDataHandlerEXPRESSION_MAKE_DICTEXPRESSION_MAKE_LISTGetSetDescriptorTypeINVALID_HANDLE_VALUEMemberDescriptorTypeNUITKA_SITE_FILENAMEREQUEST_URI_TOO_LONGREVERSE_NAME_MAPPINGSTATEMENT_LOOP_BREAKSTATEMENT_SET_LOCALSUnsupportedOperation__libmpdec_version___count_diff_hashableaddPythonHighlighterbuiltin_compile_specbuiltin_complex_specbuiltin_getattr_specbuiltin_globals_specbuiltin_hasattr_specbuiltin_module_namesbuiltin_named_valuesbuiltin_setattr_specbuiltin_unicode_specdisplayTreeInspectorexception_preservinggenerateDelSliceCodegenerateExecfileCodegeneric_sound_questsgetBlockBreakHandlergetComputationResultgetErrorExitBoolCodegetFileReferenceModegetNuitkaVersionYeargetOwnerFromCodeNamegetShebangFromSourceget_preparation_dataget_required_versionhasFilenameExtensionhas_unqualified_execimported_module_nameisAllowedToReexecuteisStatementLoopBreakparseSourceCodeToAstpre_assessment_labelpretty_ailment_namesshallFollowNoImportsshallFreezeAllStdlibshallWarnUnusualCodeunary_operator_codesDUPLICATE_SAME_ACCESSEXPRESSION_ASYNC_ITEREXPRESSION_ASYNC_NEXTEXPRESSION_ASYNC_WAITEXPRESSION_BUILTIN_IDEXPRESSION_CALL_EMPTYEXPRESSION_CLASS_BODYEXPRESSION_COMPARISONEXPRESSION_MAKE_TUPLEEXPRESSION_YIELD_FROMExpressionBuiltinListLittleEndianStructureNuitkaAssumptionErrorSTATEMENT_CONDITIONALSTATEMENT_IMPORT_STARSTATEMENT_PRINT_VALUESTATEMENT_RETURN_NONESTATEMENT_RETURN_TRUEabnormality_detectionassumeYesForDownloadsbinary_operator_codesbuildAsyncForLoopNodebuildTryExceptionNodebuiltin_execfile_speccheckPluginSinglePathcheck_xml_persistencecomparison_inversionscustomize_config_varsgenerateAsyncIterCodegenerateAsyncNextCodegenerateAsyncWaitCodegenerateBuiltinIdCodegenerateConditionCodegenerateLoopBreakCodegenerateYieldFromCodegetAsyncgenObjectCodegetBlockExceptHandlergetBlockReturnHandlergetFunctionDirectDeclgetIntendedPythonArchgetModuleConstantCodegetModuleFromCodeNamegetMustIncludeModulesgetMustNotGetHereCodegetNamedArgumentPairsgetPositionalArgumentgetPythonPathForSconsgetShallFollowModulesgetStatementsAppendedgetUnhashableConstantgetfilesystemencodingisExpressionClassBodyisExpressionMakeTupleparsedate_to_datetimeprepareCodeGenerationprototype_text_bufferreplaceImportedModulerich_comparison_codesshallDisplayBuiltTreeshallDumpBuiltTreeXMLshallFollowAllImportstemplate_header_guard0123456789ABCDEFabcdefEXPRESSION_BUILTIN_BINEXPRESSION_BUILTIN_CHREXPRESSION_BUILTIN_HEXEXPRESSION_BUILTIN_LENEXPRESSION_BUILTIN_OCTEXPRESSION_BUILTIN_ORDEXPRESSION_BUILTIN_REFEXPRESSION_BUILTIN_SETEXPRESSION_BUILTIN_STREXPRESSION_CONDITIONALEXPRESSION_IMPORT_NAMEExpressionBuiltinTupleREVERSE_IMPORT_MAPPINGSTATEMENT_RETURN_FALSEShapeTypeBuiltinModuleUndecodableBytesDefect_create_stdlib_contextbuildAsyncFunctionNodebuildImportModulesNodebuildInplaceAssignNodebuildTupleCreationNodebuiltin_bytearray_specbuiltin_frozenset_speccreateNamespacePackageddx_question_interfacedestroy_signal_handlergenerateBuiltinChrCodegenerateBuiltinLenCodegenerateBuiltinOrdCodegenerateBuiltinSetCodegenerateBuiltinStrCodegenerateImportNameCodegenerateImportStarCodegeneratePrintValueCodegetCodeObjectsDeclCodegetCodeObjectsInitCodegetCoroutineObjectCodegetExceptionIdentifiergetGeneratorObjectCodegetMustIncludePackagesgetPthImportedPackagesgetReferenceExportCodegetShallFollowInNoCasegetSharedLibrarySuffixgetStatementsPrependedgetTargetPythonDLLPathisImportedModuleByNameisImportedModuleByPathisPreloadedPackagePathmakeAbsoluteImportNodenon_local_declarationsremoveUncompiledModulesetBuildingDispatcherssetMainScriptDirectorysetPthImportedPackagestemplate_function_bodyview_assessment_buttonCO_FUTURE_BARRY_AS_BDFLDEBUG_BYTECODE_SUFFIXESERROR_NOT_ENOUGH_MEMORYERROR_OPERATION_ABORTEDEXPRESSION_BUILTIN_BOOLEXPRESSION_BUILTIN_DICTEXPRESSION_BUILTIN_DIR1EXPRESSION_BUILTIN_EVALEXPRESSION_BUILTIN_EXECEXPRESSION_BUILTIN_HASHEXPRESSION_BUILTIN_INT1EXPRESSION_BUILTIN_INT2EXPRESSION_BUILTIN_LISTEXPRESSION_BUILTIN_OPENEXPRESSION_BUILTIN_SUM1EXPRESSION_BUILTIN_SUM2EXPRESSION_BUILTIN_VARSEXPRESSION_OUTLINE_BODYEXPRESSION_SIDE_EFFECTSEXPRESSION_SLICE_LOOKUPEXPRESSION_VARIABLE_REFFinalizationVisitorBaseICON_SIZE_LARGE_TOOLBARMaybeLocalVariableUsageNonASCIILocalPartDefectNuitkaOptimizationErrorSTATEMENT_DEL_ATTRIBUTESTATEMENT_DEL_SUBSCRIPTSTATEMENT_LOOP_CONTINUESTATEMENT_PRINT_NEWLINESTOPBITS_ONE_POINT_FIVE_GLOBAL_DEFAULT_TIMEOUT_count_diff_all_purposeany_task_just_completedbind_textdomain_codesetbuildSetContractionNodebuiltin_anon_value_listbuiltin_exception_namesbuiltin_isinstance_speccheckStatementsSequenceddx_interface_gladefilegenerateBuiltinDictCodegenerateBuiltinDir1CodegenerateBuiltinHashCodegenerateBuiltinInt1CodegenerateBuiltinInt2CodegenerateBuiltinListCodegenerateBuiltinVarsCodegenerateCAPIObjectCode0generateConditionalCodegenerateDelVariableCodegenerateExpressionsCodegenerateSetCreationCodegenerateSideEffectsCodegenerateSliceLookupCodegenerateUnpackCheckCodegetBlockContinueHandlergetCallCodePosArgsQuickgetImportedModuleByNamegetImportedModuleByPathgetPythonExePathWindowsgetStandardLibraryPathsinstruction_explanationisCompiledPythonPackageisExpressionFunctionRefisExpressionVariableRefisStatementLoopContinuemakeBinaryOperationNodenew_case_block_observersensor_pad_is_connectedset_output_flow_controlshallExecuteImmediatelyshallHaveStatementLinesshallWarnImplicitRaisesspec_from_file_locationstandalone_entry_pointstemplate_frozen_modulestemplate_iterator_checkvariable_closure_tracesCO_FUTURE_GENERATOR_STOPCO_FUTURE_PRINT_FUNCTIONEXPRESSION_BUILTIN_ASCIIEXPRESSION_BUILTIN_FLOATEXPRESSION_BUILTIN_ITER1EXPRESSION_BUILTIN_ITER2EXPRESSION_BUILTIN_LONG1EXPRESSION_BUILTIN_LONG2EXPRESSION_BUILTIN_NEXT1EXPRESSION_BUILTIN_NEXT2EXPRESSION_BUILTIN_SLICEEXPRESSION_BUILTIN_SUPEREXPRESSION_BUILTIN_TUPLEEXPRESSION_BUILTIN_TYPE1EXPRESSION_BUILTIN_TYPE3EXPRESSION_COMPARISON_INEXPRESSION_COMPARISON_ISEXPRESSION_FUNCTION_CALLEXPRESSION_OPERATION_NOTReadTotalTimeoutConstantSTATEMENT_RELEASE_LOCALSall_comparison_functionsbuildDictContractionNodebuildListContractionNodebuildParameterKwDefaultsbuiltin_classmethod_specbuiltin_exception_valuescompleteVariableClosuresemitLineNumberUpdateCodegenerateBuiltinAsciiCodegenerateBuiltinIter1CodegenerateBuiltinIter2CodegenerateBuiltinLong1CodegenerateBuiltinLong2CodegenerateBuiltinNext1CodegenerateBuiltinNext2CodegenerateBuiltinSliceCodegenerateBuiltinSuperCodegenerateBuiltinTupleCodegenerateDelAttributeCodegenerateDelSubscriptCodegenerateExceptionRefCodegenerateFunctionCallCodegenerateListCreationCodegenerateLoopContinueCodegeneratePrintNewlineCodegetIntendedPythonVersiongetLocalVariableCodeTypegetLocalVariableInitCodeget_introspection_moduleisStaticallyLinkedPythonmakeConditionalStatementmakeExpressionBuiltinRefonModuleOptimizationStepquestion_mark_view_framesetPreloadedPackagePathssetStatementDispatchDictsupports_follow_symlinkstemplate_loop_break_nextunary_operator_functionswithEnvironmentPathAddedwrapEvalGlobalsAndLocalsCO_FUTURE_ABSOLUTE_IMPORTERROR_INVALID_USER_BUFFEREXPRESSION_BUILTIN_BYTES1EXPRESSION_BUILTIN_BYTES3EXPRESSION_BUILTIN_FORMATEXPRESSION_BUILTIN_IMPORTEXPRESSION_BUILTIN_RANGE1EXPRESSION_BUILTIN_RANGE2EXPRESSION_BUILTIN_RANGE3EXPRESSION_CONDITIONAL_OREXPRESSION_SPECIAL_UNPACKIncrementalNewlineDecoderSTATEMENT_EXPRESSION_ONLYSTATEMENT_RAISE_EXCEPTIONSTATEMENT_RETURN_CONSTANTWriteTotalTimeoutConstant_call_with_frames_removed_decode_filter_properties_encode_filter_propertiesbinary_operator_functionsbuildSequenceCreationNodebuiltin_named_values_listbuiltin_staticmethod_specconvertNoneConstantToNonecoverage_assessment_modeldetectPthImportedPackagesextractKindAndArgsFromXMLgenerateBuiltinBytes1CodegenerateBuiltinBytes3CodegenerateBuiltinFormatCodegenerateBuiltinImportCodegenerateLocalsDictDelCodegenerateLocalsDictSetCodegenerateSetLocalsDictCodegenerateSpecialUnpackCodegenerateTupleCreationCodegetAsyncgenObjectDeclCodegetAttributeCheckBoolCodegetMetapathLoaderBodyCodegetNameReferenceErrorCodegetVariableAssignmentCodeisExpressionBuiltinImportisUncompiledPythonPackageparse_content_type_headersaved_exam_pressurepointssetExpressionDispatchDictshallDetectMissingPluginsshallDisableConsoleWindowtemplate_frame_guard_oncetemplate_generator_makingtemplate_global_copyrighttemplate_helper_impl_declCO_FUTURE_UNICODE_LITERALSEXPRESSION_BUILTIN_COMPILEEXPRESSION_BUILTIN_GETATTREXPRESSION_BUILTIN_GLOBALSEXPRESSION_BUILTIN_HASATTREXPRESSION_BUILTIN_SETATTREXPRESSION_BUILTIN_UNICODEEXPRESSION_BUILTIN_XRANGE1EXPRESSION_BUILTIN_XRANGE2EXPRESSION_BUILTIN_XRANGE3EXPRESSION_CONDITIONAL_ANDEXPRESSION_OPERATION_UNARYEXPRESSION_RAISE_EXCEPTIONExpressionBuiltinFrozensetHTTP_VERSION_NOT_SUPPORTEDHeaderMissingRequiredValueInvalidBase64PaddingDefectSTATEMENT_ASSIGNMENT_SLICESTATEMENT_GENERATOR_RETURNSTATEMENT_LOCALS_DICT_SYNCSTATEMENT_RELEASE_VARIABLE_frozen_importlib_externalassigned_assessment_buttonbuiltin_function_or_methodcheckPluginFilenamePatterncheckPythonVersionFromCodegenerateBuiltinCompileCodegenerateBuiltinGetattrCodegenerateBuiltinGlobalsCodegenerateBuiltinHasattrCodegenerateBuiltinSetattrCodegenerateBuiltinUnicodeCodegenerateBytecodeFrozenCodegenerateExpressionOnlyCodegenerateLocalsDictSyncCodegenerateOperationUnaryCodegenerateReturnConstantCodegetConstantIterationLengthgetConstantsDefinitionCodegetCoroutineObjectDeclCodegetExperimentalIndicationsgetGeneratorObjectDeclCodegetSupportedPythonVersionsisCompileTimeConstantValuelocation_coverage_analyzermakeDictCreationOrConstantmakeUncompiledPythonModuleshallFollowStandardLibraryshallOnlyExecCCompilerCalltemplate_constants_readingtemplate_read_mvar_unclearAbSim 2.0CloseBoundaryNotFoundDefectEXPRESSION_ATTRIBUTE_LOOKUPEXPRESSION_BUILTIN_COMPLEX1EXPRESSION_BUILTIN_COMPLEX2EXPRESSION_BUILTIN_EXECFILEEXPRESSION_CALL_NO_KEYWORDSEXPRESSION_CONSTANT_INT_REFEXPRESSION_CONSTANT_SET_REFEXPRESSION_CONSTANT_STR_REFEXPRESSION_MAKE_SET_LITERALEXPRESSION_OPERATION_BINARYEXPRESSION_OUTLINE_FUNCTIONEXPRESSION_SELECT_METACLASSEXPRESSION_SUBSCRIPT_LOOKUPNoBoundaryInMultipartDefectOPTIMIZED_BYTECODE_SUFFIXESSTATEMENT_PUBLISH_EXCEPTIONSTATEMENT_RERAISE_EXCEPTIONSTATEMENT_SET_OPERATION_ADDStartBoundaryNotFoundDefectaddFunctionVariableReleasescontaining_comparison_codesddx_question_interface_vboxdetectPreLoadedPackagePathsgenerateAssignmentSliceCodegenerateAttributeLookupCodegenerateChildExpressionCodegenerateDictOperationInCodegenerateFunctionOutlineCodegenerateOperationBinaryCodegenerateRaiseExpressionCodegenerateSelectMetaclassCodegenerateSetOperationAddCodegenerateSubscriptLookupCodegenerateVariableReleaseCodegetBuiltinLoopBreakNextCodeisExpressionTempVariableRefkw_defaults_before_defaultsmakeConstantReplacementNodemakeDictCreationOrConstant2makeExpressionBuiltinLocalsmakeStatementReturnConstantneeds_generator_return_exitshallNotDoExecCCompilerCalltemplate_del_global_unclearview_assessment_explanationEXPRESSION_BUILTIN_FROZENSETEXPRESSION_COMPARISON_IS_NOTEXPRESSION_COMPARISON_NOT_INEXPRESSION_CONSTANT_DICT_REFEXPRESSION_CONSTANT_LIST_REFEXPRESSION_CONSTANT_LONG_REFEXPRESSION_CONSTANT_NONE_REFEXPRESSION_CONSTANT_TRUE_REFEXPRESSION_CONSTANT_TYPE_REFEXPRESSION_DICT_OPERATION_INEXPRESSION_FUNCTION_CREATIONEXPRESSION_TEMP_VARIABLE_REFSTATEMENT_DICT_OPERATION_SETbuildDictionaryUnpackingArgsconvertFunctionCallToOutlinegenerateBuiltinFrozensetCodegenerateBuiltinLocalsRefCodegenerateChildExpressionsCodegenerateConditionalAndOrCodegenerateDictOperationGetCodegenerateDictOperationSetCodegenerateExceptionPublishCodegenerateImportModuleHardCodegenerateListOperationPopCodegenerateReturnedValueRefCodegetBuiltinIsinstanceBoolCodegetErrorLineNumberUpdateCodegetErrorVariableDeclarationsgetTracebackMakingIdentifierisExpressionFunctionCreationisExpressionReturnedValueRefpre_assessment_coverage_viewtemplate_frame_attach_localsEXPRESSION_BUILTIN_BYTEARRAY1EXPRESSION_BUILTIN_BYTEARRAY3EXPRESSION_BUILTIN_ISINSTANCEEXPRESSION_BUILTIN_LOCALS_REFEXPRESSION_CALL_KEYWORDS_ONLYEXPRESSION_CONSTANT_BYTES_REFEXPRESSION_CONSTANT_FALSE_REFEXPRESSION_CONSTANT_FLOAT_REFEXPRESSION_CONSTANT_SLICE_REFEXPRESSION_CONSTANT_TUPLE_REFEXPRESSION_DICT_OPERATION_GETEXPRESSION_IMPORT_MODULE_HARDEXPRESSION_LIST_OPERATION_POPEXPRESSION_RETURNED_VALUE_REFInvalidBase64CharactersDefectMisplacedEnvelopeHeaderDefect_create_default_https_contextbuiltin_exception_values_listcheckFutureImportsOnlyAtStartcheckStatementsSequenceOrNoneemitErrorLineNumberUpdateCodefunction_direct_body_templategenerateBuiltinIsinstanceCodegenerateConstantReferenceCodegenerateReleaseLocalsDictCodegenerateStatementSequenceCodegenerateStringContenationCodegenerateVariableReferenceCodegetFunctionCallHelperStarDictgetFunctionCallHelperStarListisStatementAssignmentVariablemakeReraiseExceptionStatementpre_assessment_coverage_frametemplate_asyncgen_return_exittemplate_function_return_exittemplate_metapath_loader_bodytemplate_module_body_templateEXPRESSION_BUILTIN_CLASSMETHODEXPRESSION_BUILTIN_LOCALS_COPYEXPRESSION_CONSTANT_XRANGE_REFEXPRESSION_LOCALS_VARIABLE_REFSTATEMENT_ASSIGNMENT_ATTRIBUTESTATEMENT_ASSIGNMENT_SUBSCRIPTSTATEMENT_SPECIAL_UNPACK_CHECK_generateStatementSequenceCodedemoteCompiledModuleToBytecodefinalizeFunctionLocalVariablesgenerateAssignmentVariableCodegenerateDictionaryCreationCodegenerateMakeAsyncgenObjectCodegenerateSetLiteralCreationCodegenerateSetOperationUpdateCodeisExpressionAsyncgenObjectBodyisWhiteListedNotExistingModuletemplate_coroutine_return_exittemplate_error_catch_exceptiontemplate_frame_guard_generatortemplate_generator_return_exittemplate_module_exception_exittemplate_set_locals_dict_valueEXPRESSION_BUILTIN_STATICMETHODEXPRESSION_CONSTANT_COMPLEX_REFEXPRESSION_CONSTANT_UNICODE_REFEXPRESSION_MAKE_ASYNCGEN_OBJECTEXPRESSION_OPERATION_BINARY_ADDEXPRESSION_SET_OPERATION_UPDATEEXPRESSION_STRING_CONCATENATIONREQUEST_HEADER_FIELDS_TOO_LARGESTATEMENT_DICT_OPERATION_REMOVESTATEMENT_DICT_OPERATION_UPDATESTATEMENT_GENERATOR_RETURN_NONESTATEMENT_LIST_OPERATION_APPENDSTATEMENT_SET_LOCALS_DICTIONARYassigned_assessment_explanationbuildDeleteStatementFromDecodedgenerateAssignmentAttributeCodegenerateAssignmentSubscriptCodegenerateDictOperationRemoveCodegenerateDictOperationUpdateCodegenerateExceptionCaughtTypeCodegenerateGeneratorReturnNoneCodegenerateListOperationAppendCodegenerateListOperationExtendCodegenerateMakeCoroutineObjectCodegenerateMakeGeneratorObjectCodegenerateModuleAttributeFileCodegenerateModuleAttributeNameCodegenerateModuleAttributeSpecCodegetComparisonExpressionBoolCodegetExceptionKeeperVariableNamesgetShallFollowExtraFilePatternsisExpressionCoroutineObjectBodyisExpressionGeneratorObjectBodyneedsSetLiteralReverseInsertionshallClearPythonPathEnvironmenttemplate_frame_guard_cache_decltemplate_frame_guard_frame_decltemplate_frame_guard_full_blocktemplate_make_asyncgen_templatetemplate_make_function_template¾   úFú2Údú8ÚcÚDÚEú3ÚBÚAú6ú5ú7Ú0ÚaÚ1ÚfÚeÚbú4ú9ÚC/sbin/ldconfigEXPRESSION_BUILTIN_ANONYMOUS_REFEXPRESSION_BUILTIN_EXCEPTION_REFEXPRESSION_CONSTANT_ELLIPSIS_REFEXPRESSION_DICT_OPERATION_NOT_INEXPRESSION_LIST_OPERATION_EXTENDEXPRESSION_LOCALS_VARIABLE_CHECKEXPRESSION_MAKE_COROUTINE_OBJECTEXPRESSION_MAKE_GENERATOR_OBJECTEXPRESSION_OPERATION_BINARY_MULTMissingHeaderBodySeparatorDefectgenerateBuiltinIterForUnpackCodegenerateBuiltinMakeExceptionCodegenerateComparisonExpressionCodegenerateExceptionCaughtValueCodegenerateGeneratorReturnValueCodegenerateImportModuleNameHardCodegenerateModuleVariableAccessCodegetFunctionCallHelperPosStarDictgetFunctionCallHelperPosStarListgetModuleNameAndKindFromFilenameparse_content_disposition_headertemplate_asyncgen_exception_exittemplate_function_exception_exittemplate_make_coroutine_templatetemplate_module_noexception_exitSerial.reset_input_bufferArgument 'newline' not supported in binary modePopen.terminatePopen.duplicate_for_childVerbose outputtemplate_frame_guard_full_exception_handlerCondition.notifyimg/acdet-logo.gifRemoved dead statements.Test whether a path is absoluteUserType.build_button%d-%02d-%02d %02d:%02d:%02dRead terminal status line: Clear To Send        Send break condition. Timed, returns to idle state after given
        duration.
        Port is already open.%(levelname)s:%(name)s:%(message)sOutput the given byte string over the serial port.template_metapath_loader_shlib_module_entry&quot;Argument 'encoding' not supported in binary modeSerial.out_waiting%*s%-*s  Use default semantics for module creation.OrderedDict.__init__Queue.qsizeraw-unicode-escape%s = %s( %s );True if this file is closed.keep-aliveCan only operate on a valid port handle        Clear output buffer, aborting the current output and
        discarding all that is in the buffer.
        appendix rD.items() -> a set-like object providing a view on D's items%s = PyTuple_New( %d );<%s(%s, %s)>encodings.aliasesUserType.configEvent.is_setSerial.send_breakhas illegal childSet terminal status line: Request To SendDidn't find childSerial._update_rts_stateTYPE ACan't mix absolute and relative pathslxml.etree_d.pydOrderedDict.__eq__Queue.full_DupFd.__init__template_frame_guard_generator_return_handlerPyQt5.QtGuiCondition.__init__%s = %s_%s( %s, %s );Set terminal status line: Data Terminal Ready/System/Library/CoreServices/SystemVersion.plistInvalid mode: %rUserType.finish_transfergallbladder g\\\1{}={!r}Namespace.__repr__<span size='20000'>Instructor-led Assessment</span>dist-packagesOrderedDict.clearCannot replace withincorrect number of arguments%s = DICT_REMOVE_ITEM( %s, %s );UserType.__init__Recursed to module package.BoundedSemaphore.__init__Pancreas Tendernesslocale.jsonobject of type '%s' has no len()Condition.__exit__Serial.open%BsimLog.txtTest whether a path exists.  Returns True for broken symbolic linksovary_right g%s/%sgroup argument must be None for nowSerial.set_output_flow_control%s = Py_None;Returns the final component of a pathnameSourceLoader.path_mtimecannot schedule new futures after shutdownBaseline AssessmentValue propagated for '%s' from '%s'.makeRaiseTypeErrorExceptionReplacementFromTemplateAndValueSerial.ctsSet communication parameters on opened port.appendix g        Open port with current settings. This may throw a SerialException
        if the port cannot be opened.
        state-changeQueue.get_nowaitReturn a relative version of a path Built-in iterator nodes.

These play a role in for loops, and in unpacking. They can something be
predicted to succeed or fail, in which case, code can become less complex.

The length of things is an important optimization issue for these to be
good.
{}={}Condition.__repr__Listener.<lambda>Complete Assigned Assessment%s != falseResolve a relative module name to an absolute one.splenomegaly n.txzcommonpath.<locals>.<genexpr>Read terminal status line: Data Set ReadySerial._update_dtr_stateThreadPoolExecutor.__init__        Clear output buffer, aborting the current output and discarding all
        that is in the buffer.
        makeTryExceptSingleHandlerNodeWithPublish'"'"'filename must be a str, bytes, file or PathLike objectUserType.build_logoOutput the given string over the serial port.OrderedDict.popitem{%s}%s@executable_path/icon.ico%s == false<span size='24000'>Welcome to AbSim!</span>%s: %s
MilestoneNameLabel.__init__no path specifiedD.values() -> an object providing a view on D's valuesgetFunctionCallHelperPosKeywordsStarListStarDictUserType.assessment%s -> %s<span size='20000'>{label_text}</span>exception_type = %s;Return buffered data without advancing the file position.

        Always returns at least one byte of data, unless at EOF.
        The exact number of bytes returned is unspecified.
        exception_value = %s;        Flush of file like objects. In this case, wait until all data
        is written.
                Read size bytes from the serial port. If a timeout is set it may
        return less characters as requested. With no timeout it will block
        until the requested number of bytes is read.
        Read a line of uncompressed bytes from the file.

        The terminating newline (if present) is retained. If size is
        non-negative, no more than size bytes will be read (in which
        case the line may be incomplete). Returns b'' if already at EOF.
        Return the number of bytes currently in the input buffer.gtk.gdk<%s %r>%s=%rnot-foundPopen.waitno ports to close or delete?struct Nuitka_CellObject *%sThis is the interface to self-assess on ailment location and guardingInvalidMultipartContentTransferEncodingDefectRemoved sequence creation for unused sequence.Internal support module for sreOrderedDict.copyHelpFormatter._format_text<?xml version='1.0' encoding='%s'?>
<%s at %#x>UserType.learningEvent.setThis method is called when there is the remote possibility
        that we ever need to stop in this function.Return the number of characters currently in the input buffer.Breakpoint number expectedstdout argument not allowed, it will be overridden.--jobsOrderedDict.keysEXPRESSION_LOCALS_VARIABLE_REF_OR_FALLBACKCompressed data ended before the end-of-stream marker was reachedReturn statement raises in returned expression, removed return.
"""
%s"""Returns the directory component of a pathname [closed]colon ggi._gobjectenlarged_bladder novary_left g!"#$%&'()*+,-./:;<=>?@[\]^_`{|}~Serial.in_waitingPopen._launchinitializer must be a callabletask_done() called too many times%s = true;border-widthlocal variable '%s' referenced before assignmentCondition.notify_allGroup.display_name.tar.bz2Serial.writecursor-changedunknown tag %rorig-prefix.txtPopen.poll'%s' object is not a mappingThreadPoolExecutor.submitUserType.view_assessmentsQueue.put_nowait%s = PyList_New( %d );max_workers must be greater than 0pythonservice.exe&amp;Condition.wait_for<span size='20000'>Customize sensor settings</span>Serial.cd%s argument after ** must be a mapping, not %sPressure pad is not connected! Please check the USB cable and turn off AbSim for five seconds.OrderedDict.valuesReturn repr for the module.

        The method is deprecated.  The import machinery does the job itself.

        PyQt5.QtCoreSerial.riBuilt-in call to '%s' computed.Problem with %r at %sUserType.assigned_assessmentReturn whether the file was opened for writing. Named children dictionary.

            For use in debugging and XML output.
        :\d+$Serial.cancel_writeSourceLoader.path_statsReturn the file descriptor for the underlying file.utf-16-le%s = LOOKUP_BUILTIN( %s );commonpath() arg is an empty sequencetemplate_metapath_loader_bytecode_module_entryPort must be configured before it can be used.template_metapath_loader_compiled_package_entryListener.__exit__Barrier.__init__show program's version number and exitappendix gr_DupFd.detachtemplate_metapath_loader_compiled_module_entryNamespace.__init__.tbz2Serial.reset_output_bufferInvalid mode: {!r}Flush and close the file.

        May be called more than once without error. Once the file is
        closed, any other operation on it will raise a ValueError.
        .tar.xz%s argument after * must be an iterable, not %s Dummy file to make this directory a package. C:\msys64\home\cbper\sim.py{0}.{1}.{2}UserType.setup_transferSerial.cancel_read%s == 1Serial._update_break_statetemplate_read_locals_mapping_without_fallbackSOFTWARE\Python\PythonCore\%s\InstallPathhepatomegaly nutf-16-beSerial.close
Gets and sets default settings
C:\\msys64\\mingw64\\bin\\python3%s = PyDict_SetItem( %s, %s, %s );<%s %r at %#x>OrderedDict.__setitem__Argument 'errors' not supported in binary modeClear input buffer, discarding all that is in the buffer.wait.<locals>.<genexpr><span font='20'><b>Next Case</b></span>Urinary Bladder Tenderness_%s%sThis is the interface to train on depth with no ailments activegetFunctionCallHelperKeywordsStarListStarDictCompressed file ended before the end-of-stream marker was reachedshow this help message and exitStudent IDtemplate_read_locals_dict_without_fallbackSerial.dsrUserType.add_buttons Entry point for code.

            Normally ourselves. Only outlines will refer to their parent which
            technically owns them.

        Brian Quinlan (brian@sweetapp.com)UserType.close_menuOrderedDict.setdefaultvscrollbar-policy<span size='20000'>Learn and practice abdominal palpation</span>could not write to portOrderedDict.__reversed__ Set a child value.

            Do not overload, provider self.checkers instead.
        Self-directed LearningRead terminal status line: Ring Indicator%s.%s(%s)<span size='20000'>View Performance on Previous Assessments</span>Close portDisconnectWarning.__init__Address.display_name<IIPolls the serial port for updatesCondition.__enter__Change the exclusive access setting.%s = BOOL_FROM( %s == %s );Return whether the file supports seeking._ag.<locals>._ag<span font='24'>getaddrinfo returns an empty list%*s%s:
<span size='20000'>Demonstrate proficiency in abdominal palpation</span>Event.clearEvent.__init__cannot release un-acquired lockgenerateLocalsDictVariableRefOrFallbackCodeswitch-pageIndent decreased below 0.Normalize path, eliminating double slashes, etc.%s__%sEvent.waithscrollbar-policytemplate_read_locals_mapping_with_fallbackGiven a sequence of path names, returns the longest common sub-path.r+bglade/student_ddx_interface_expanders.uiKa-Ping Yee <ping@lfw.org>SourceLoader.set_data<span size='20000'>AbSim Configuration</span>OrderedDict.__repr__nuitka.plugins.Plugins%*s%s
Explicit raise already raises implicitly building exception type.OrderedDict.items%s = _PyDict_NewPresized( %d );OrderedDict.__delitem__nonnumeric port: '%s'EXPRESSION_CAUGHT_EXCEPTION_TRACEBACK_REFmakeRaiseExceptionReplacementExpressionFromInstanceListener.__enter__Return request-host, as defined by RFC 2965.

    Variation from RFC: returned value is lowercased, for convenient
    comparison.

    Recursed to module.uniconvertor.app.modules_WorkItem.__init__ Code to generate and interact with compiled function objects.

Read terminal status line: Carrier Detectinvalid action: %rD.keys() -> a set-like object providing a view on D's keysSerial.flushView Completed Assessmentstemplate_frame_guard_generator_exception_handler%s got multiple values for keyword argument '%s'Value.__repr__Timer.__init__makeStatementExpressionOnlyReplacementNodeReturn whether the file was opened for reading.EXPRESSION_BUILTIN_LOCALS_UPDATEDEXPRESSION_BUILTIN_MAKE_EXCEPTIONEXPRESSION_CONSTANT_BYTEARRAY_REFEXPRESSION_CONSTANT_FROZENSET_REFEXPRESSION_CONSTANT_SET_EMPTY_REFMultipartInvariantViolationDefectSTATEMENT_RESTORE_FRAME_EXCEPTIONgenerateConstantNoneReferenceCodegenerateConstantTrueReferenceCodegenerateFrameRestoreExceptionCodegenerateLocalsDictVariableRefCodegenerateModuleAttributeLoaderCodeisStatementAssignmentVariableNamemakeBuiltinExceptionParameterSpecmakeStatementsSequenceOrStatementtemplate_coroutine_exception_exittemplate_generator_exception_exittemplate_set_locals_mapping_valuetemplate_update_locals_dict_valuewrapExpressionWithNodeSideEffectsEXPRESSION_BUILTIN_ITER_FOR_UNPACKEXPRESSION_CONSTANT_DICT_EMPTY_REFEXPRESSION_CONSTANT_LIST_EMPTY_REFEXPRESSION_IMPORT_MODULE_NAME_HARDEXPRESSION_OPERATION_BINARY_DIVMODSTATEMENT_PRESERVE_FRAME_EXCEPTIONSTATEMENT_RAISE_EXCEPTION_IMPLICITgenerateAttributeLookupSpecialCodegenerateConstantFalseReferenceCodegenerateFramePreserveExceptionCodegenerateModuleAttributePackageCodegetExceptionPreserverVariableNamesgetExceptionUnpublishedReleaseCodegetHumanReadableProcessMemoryUsagegetLocalVariableReferenceErrorCodeshallNotUseDependsExeCachedResultstemplate_asyncgen_noexception_exittemplate_function_make_declaration-!*+/EXPRESSION_ATTRIBUTE_LOOKUP_SPECIALEXPRESSION_CONSTANT_TUPLE_EMPTY_REFEXPRESSION_OPERATION_BINARY_INPLACEFirstHeaderLineIsContinuationDefectSTATEMENT_LOCALS_DICT_OPERATION_DELSTATEMENT_LOCALS_DICT_OPERATION_SETgenerateLocalsDictVariableCheckCodegetComplexCallSequenceErrorTemplategetFrameVariableTypeDescriptionCodemakeStatementsSequenceFromStatementtemplate_call_method_with_args_decltemplate_call_method_with_args_impltemplate_coroutine_noexception_exittemplate_generator_noexception_exitEXPRESSION_CAUGHT_EXCEPTION_TYPE_REFEXPRESSION_MODULE_ATTRIBUTE_FILE_REFEXPRESSION_MODULE_ATTRIBUTE_NAME_REFEXPRESSION_MODULE_ATTRIBUTE_SPEC_REFgenerateExceptionCaughtTracebackCodemakeExpressionOperationBinaryInplacemakeStatementsSequenceFromStatementsshallNotStoreDependsExeCachedResultstemplate_error_catch_quick_exceptiontemplate_function_direct_declarationtemplate_update_locals_mapping_valueEXPRESSION_CAUGHT_EXCEPTION_VALUE_REFEXPRESSION_COMPARISON_EXCEPTION_MATCHgenerateConstantEllipsisReferenceCodegetErrorMessageExecWithNestedFunctiongetFunctionCallHelperKeywordsStarDictgetFunctionCallHelperStarListStarDictmakeStatementsSequenceReplacementNodetemplate_call_function_with_args_decltemplate_call_function_with_args_impltemplate_publish_exception_to_handlerEXPRESSION_MODULE_ATTRIBUTE_LOADER_REFmakeRaiseExceptionReplacementStatementparse_content_transfer_encoding_headerpre_assessment_coverage_view_resourcestemplate_asyncgen_object_body_templatetemplate_asyncgen_object_decl_templatetemplate_error_format_string_exceptiontemplate_genfunc_yielder_body_templatetemplate_genfunc_yielder_decl_templateEXPRESSION_CONSTANT_FROZENSET_EMPTY_REFEXPRESSION_MODULE_ATTRIBUTE_PACKAGE_REFtemplate_coroutine_object_body_templatetemplate_coroutine_object_decl_templatetemplate_read_locals_dict_with_fallbackgetFunctionCallHelperDictionaryUnpackinggetFunctionCallHelperPosKeywordsStarDictgetFunctionCallHelperPosStarListStarDictmakeRaiseExceptionExpressionFromTemplatetemplate_frame_guard_full_return_handlerã               @   s   d Z dS )z. Dummy file to make this directory a package. N)Ú__doc__© r   r   úgC:\Users\cbper\AppData\Local\Programs\Python\Python36-32\Lib\site-packages\nuitka\distutils\__init__.pyÚ<module>   s    ã               @   sl   d Z dZdZdZdZdZddlZG dd	 d	Ze Zej	Z	ej
Z
ejZejZejZejZd
d Zdd ZdS )z,A simple log mechanism styled after PEP 282.é   é   é   é   é   é    Nc               @   sP   e Zd ZefddZdd Zdd Zdd Zd	d
 Zdd Z	dd Z
dd ZdS )ÚLogc             C   s
   || _ d S )N)Ú	threshold)Úselfr   © r
   ú0C:\msys64\mingw64\lib\python3.6\distutils\log.pyÚ__init__   s    zLog.__init__c             C   s   |t ttttfkr"tdt| || jkr|r8|| }|tttfkrNtj	}ntj
}|jdkrv|j}|j|dj|}|jd|  |j  d S )Nz%s wrong log levelÚstrictÚbackslashreplacez%s
)ÚDEBUGÚINFOÚWARNÚERRORÚFATALÚ
ValueErrorÚstrr   ÚsysÚstderrÚstdoutÚerrorsÚencodingÚencodeÚdecodeÚwriteÚflush)r	   ÚlevelÚmsgÚargsÚstreamr   r
   r
   r   Ú_log   s    

zLog._logc             G   s   | j ||| d S )N)r#   )r	   r   r    r!   r
   r
   r   Úlog%   s    zLog.logc             G   s   | j t|| d S )N)r#   r   )r	   r    r!   r
   r
   r   Údebug(   s    z	Log.debugc             G   s   | j t|| d S )N)r#   r   )r	   r    r!   r
   r
   r   Úinfo+   s    zLog.infoc             G   s   | j t|| d S )N)r#   r   )r	   r    r!   r
   r
   r   Úwarn.   s    zLog.warnc             G   s   | j t|| d S )N)r#   r   )r	   r    r!   r
   r
   r   Úerror1   s    z	Log.errorc             G   s   | j t|| d S )N)r#   r   )r	   r    r!   r
   r
   r   Úfatal4   s    z	Log.fatalN)Ú__name__Ú
__module__Ú__qualname__r   r   r#   r$   r%   r&   r'   r(   r)   r
   r
   r
   r   r      s   r   c             C   s   t j}| t _|S )N)Ú_global_logr   )r   Úoldr
   r
   r   Úset_threshold?   s    r/   c             C   s8   | dkrt t n"| dkr$t t n| dkr4t t d S )Nr   r   r   )r/   r   r   r   )Úvr
   r
   r   Úset_verbosityE   s    

r1   )Ú__doc__r   r   r   r   r   r   r   r-   r$   r%   r&   r'   r(   r)   r/   r1   r
   r
   r
   r   Ú<module>   s    )